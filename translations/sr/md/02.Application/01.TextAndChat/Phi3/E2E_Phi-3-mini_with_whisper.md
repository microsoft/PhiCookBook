<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "006e8cf75211d3297f24e1b22e38955f",
  "translation_date": "2025-07-17T02:23:21+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "sr"
}
-->
# Interactive Phi 3 Mini 4K Instruct Chatbot са Whisper-ом

## Преглед

Interactive Phi 3 Mini 4K Instruct Chatbot је алат који омогућава корисницима да комуницирају са Microsoft Phi 3 Mini 4K instruct демо-ом користећи текст или аудио унос. Четбот се може користити за разне задатке, као што су превођење, временске информације и опште прикупљање података.

### Почетак рада

Да бисте користили овај четбот, једноставно пратите ове кораке:

1. Отворите нови [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb)
2. У главном прозору нотебоока видећете интерфејс четбокса са пољем за унос текста и дугметом „Send“.
3. Да бисте користили четбот заснован на тексту, једноставно укуцајте поруку у поље за унос текста и кликните на дугме „Send“. Четбот ће одговорити аудио фајлом који се може репродуковати директно унутар нотебоока.

**Note**: Овај алат захтева GPU и приступ Microsoft Phi-3 и OpenAI Whisper моделима, који се користе за препознавање говора и превођење.

### Захтеви за GPU

За покретање овог демо-а потребно је 12 ГБ GPU меморије.

Захтеви за меморију приликом покретања **Microsoft-Phi-3-Mini-4K instruct** демо-а на GPU-у зависе од више фактора, као што су величина улазних података (аудио или текст), језик који се користи за превођење, брзина модела и расположива меморија на GPU-у.

Уопштено, Whisper модел је дизајниран за рад на GPU-овима. Препоручена минимална количина GPU меморије за покретање Whisper модела је 8 ГБ, али може да поднесе и веће количине меморије ако је потребно.

Важно је напоменути да покретање великог обима података или великог броја захтева на моделу може захтевати више GPU меморије и/или изазвати проблеме са перформансама. Препоручује се да тестирате свој случај употребе са различитим конфигурацијама и пратите коришћење меморије како бисте одредили оптимална подешавања за ваше специфичне потребе.

## E2E пример за Interactive Phi 3 Mini 4K Instruct Chatbot са Whisper-ом

Jupyter notebook под називом [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) показује како користити Microsoft Phi 3 Mini 4K instruct Demo за генерисање текста из аудио или писаног уноса. Нотебоок дефинише неколико функција:

1. `tts_file_name(text)`: Ова функција генерише име фајла на основу улазног текста за чување генерисаног аудио фајла.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: Ова функција користи Edge TTS API за генерисање аудио фајла из листе делова улазног текста. Улазни параметри су листа делова, брзина говора, име гласа и путања за чување генерисаног аудио фајла.
1. `talk(input_text)`: Ова функција генерише аудио фајл користећи Edge TTS API и чува га под случајним именом у директоријуму /content/audio. Улазни параметар је текст који се претвара у говор.
1. `run_text_prompt(message, chat_history)`: Ова функција користи Microsoft Phi 3 Mini 4K instruct демо за генерисање аудио фајла из улазне поруке и додаје га у историју чет-а.
1. `run_audio_prompt(audio, chat_history)`: Ова функција претвара аудио фајл у текст користећи Whisper модел API и прослеђује га функцији `run_text_prompt()`.
1. Код покреће Gradio апликацију која омогућава корисницима да комуницирају са Phi 3 Mini 4K instruct демо-ом тако што ће уносити поруке или отпремати аудио фајлове. Излаз се приказује као текстуална порука у апликацији.

## Решавање проблема

Инсталација Cuda GPU драјвера

1. Уверите се да су ваше Linux апликације ажурне

    ```bash
    sudo apt update
    ```

1. Инсталирајте Cuda драјвере

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. Региструјте локацију cuda драјвера

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Провера величине Nvidia GPU меморије (Потребно 12GB GPU меморије)

    ```bash
    nvidia-smi
    ```

1. Празна кеш меморија: Ако користите PyTorch, можете позвати torch.cuda.empty_cache() да ослободите сву неискоришћену кеш меморију како би могла да се користи од стране других GPU апликација

    ```python
    torch.cuda.empty_cache() 
    ```

1. Провера Nvidia Cuda

    ```bash
    nvcc --version
    ```

1. Извршите следеће кораке да бисте креирали Hugging Face токен.

    - Идите на [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo).
    - Изаберите **New token**.
    - Унесите име пројекта које желите да користите.
    - Изаберите **Type** као **Write**.

> **Note**
>
> Ако наиђете на следећу грешку:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> Да бисте решили проблем, укуцајте следећу команду у вашем терминалу.
>
> ```bash
> sudo ldconfig
> ```

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем AI сервиса за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетним извором. За критичне информације препоручује се професионални људски превод. Нисмо одговорни за било каква неспоразума или погрешна тумачења настала коришћењем овог превода.