<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T15:25:08+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "sr"
}
-->
# Безбедност вештачке интелигенције за Phi моделе
Породица Phi модела је развијена у складу са [Microsoft Responsible AI Standard](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard), који је компанијски скуп захтева заснованих на следећих шест принципа: одговорност, транспарентност, праведност, поузданост и безбедност, приватност и безбедност, и инклузивност који чине [Microsoft-ове принципе одговорне вештачке интелигенције](https://www.microsoft.com/ai/responsible-ai).

Као и претходни Phi модели, усвојен је вишеаспектни приступ оцењивању безбедности и пост-тренинг безбедносне мере, уз додатне мере које узимају у обзир вишејезичке способности овог издања. Наш приступ обуци безбедности и оцењивању укључујући тестирање кроз више језика и категорија ризика описан је у [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833). Док Phi модели имају користи од овог приступа, програмери треба да примене најбоље праксе одговорне вештачке интелигенције, укључујући мапирање, мерење и ублажавање ризика повезаних са њиховом специфичном применом и културним и језичким контекстом.

## Најбоље праксе

Као и други модели, породицу Phi модела потенцијално могу да се понашају на начине који нису праведни, поуздани или који могу бити увредљиви.

Неки од ограничења понашања SLM и LLM о којима треба бити свестан укључују:

- **Квалитет услуге:** Phi модели су првенствено обучавани на енглеском тексту. Језици осим енглеског ће имати лошије перформансе. Варијанте енглеског језика са мањом заступљеношћу у подацима за обуку могу имати лошије перформансе него стандардни амерички енглески.
- **Заступљеност шкода и одржавање стереотипа:** Ови модели могу претерано или недовољно заступити групе људи, избрисати заступљеност неких група, или појачати понижавајуће или негативне стереотипе. Упркос безбедносној пост-трениншкој обради, ова ограничења могу и даље бити присутна због различитих нивоа заступљености различитих група или присуства примера негативних стереотипа у подацима за обуку који одражавају стварне светске образце и друштвене пристрасности.
- **Неодговарајући или увредљив садржај:** Ови модели могу генерисати друге врсте неодговарајућег или увредљивог садржаја, што може учинити њихову примену неисправном у осетљивим контекстима без додатних ублажавања која су специфична за случај коришћења.
- **Поузданост информација:** Језички модели могу генерисати бесмислен садржај или фабриковати садржај који може звучати разложно али је нетачан или застарео.
- **Ограничен опсег за код:** Већина података за обуку Phi-3 заснована је на Питону и користи уобичајене пакете као што су "typing, math, random, collections, datetime, itertools". Ако модел генерише Питон скрипте које користе друге пакете или скрипте на другим језицима, снажно препоручујемо корисницима да ручно провере све употребе API-ја.

Програмери треба да примењују најбоље праксе одговорне вештачке интелигенције и одговорни су за обезбеђење да специфичан случај коришћења буде у складу са релевантним законима и прописима (нпр. приватност, трговина и сл.).

## Разматрања одговорне вештачке интелигенције

Као и други језички модели, Phi серија модела потенцијално може да се понаша на начине који нису праведни, поуздани или увредљиви. Нека од ограничења на која треба обратити пажњу укључују:

**Квалитет услуге:** Phi модели су првенствено обучавани на енглеском тексту. Језици осим енглеског ће имати лошије перформансе. Варијанте енглеског језика са мањом заступљеношћу у подацима за обуку могу имати лошије перформансе него стандардни амерички енглески.

**Заступљеност шкода и одржавање стереотипа:** Ови модели могу претерано или недовољно заступити групе људи, избрисати заступљеност неких група, или појачати понижавајуће или негативне стереотипе. Упркос безбедносној пост-трениншкој обради, ова ограничења могу и даље бити присутна због различитих нивоа заступљености различитих група или присуства примера негативних стереотипа у подацима за обуку који одражавају стварне светске образце и друштвене пристрасности.

**Неодговарајући или увредљив садржај:** Ови модели могу генерисати друге врсте неодговарајућег или увредљивог садржаја, што може учинити њихову примену неисправном у осетљивим контекстима без додатних ублажавања која су специфична за случај коришћења.
Поузданост информација: Језички модели могу генерисати бесмислен садржај или фабриковати садржај који може звучати разложно али је нетачан или застарео.

**Ограничен опсег за код:** Већина података за обуку Phi-3 заснована је на Питону и користи уобичајене пакете као што су "typing, math, random, collections, datetime, itertools". Ако модел генерише Питон скрипте које користе друге пакете или скрипте на другим језицима, снажно препоручујемо корисницима да ручно провере све употребе API-ја.

Програмери треба да примене најбоље праксе одговорне вештачке интелигенције и одговорни су за обезбеђење да специфичан случај коришћења буде у складу са релевантним законима и прописима (нпр. приватност, трговина и сл.). Важна поља за разматрање укључују:

**Додела:** Модели можда нису погодни за сценарије који могу имати значајан утицај на правни статус или доделу ресурса или животних прилика (нпр. стамбено питање, запошљавање, кредитирање и слично) без даљих процена и додатних техника уклањања пристрасности.

**Високо ризични сценарији:** Програмери треба да процене прикладност коришћења модела у високо ризичним сценаријима где неправедни, непоуздани или увредљиви резултати могу имати изузетно велике трошкове или довести до штете. Ово укључује давање савета у осетљивим или експертским доменима где су тачност и поузданост критични (нпр. правни или здравствени савети). Додатне мере заштите треба имплементирати на нивоу апликације у складу са контекстом примене.

**Дезинформације:** Модели могу произвести нетачне информације. Програмери треба да прате најбоље праксе транспарентности и да обавесте крајње кориснике да комуницирају са системом вештачке интелигенције. На нивоу апликације, програмери могу изградити механизме повратне информације и цевоводе који усмеравају одговоре у складу са специфичним, контекстуалним информацијама случаја коришћења, техником познатом као Retrieval Augmented Generation (RAG).

**Генерисање штетног садржаја:** Програмери треба да процене одговоре у њиховом контексту и користе расположиве класификаторе безбедности или прилагођена решења погодна за њихов случај коришћења.

**Злоупотреба:** Други облици злоупотребе као што су превара, спам или производња малвера могу бити могући, и програмери треба да осигурају да њихове апликације не крше применљиве законе и прописе.

### Фина подешавања и безбедност AI садржаја

Након фина подешавања модела, топло препоручујемо коришћење мера [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) ради праћења садржаја генерисаног од стране модела, идентификовања и блокирања потенцијалних ризика, претњи и проблема са квалитетом.

![Phi3AISafety](../../../../../translated_images/sr/01.phi3aisafety.c0d7fc42f5a5c405.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) подржава и текстуални и сликовни садржај. Може бити имплементирана у облаку, у изолованим контејнерима и на крајним/уграђеним уређајима.

## Преглед Azure AI Content Safety

Azure AI Content Safety није решење које одговара свима; може се прилагодити како би се усагласило са специфичним политикама предузећа. Поред тога, њени вишејезички модели омогућавају разумевање више језика истовремено.

![AIContentSafety](../../../../../translated_images/sr/01.AIcontentsafety.a288819b8ce8da1a.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 видео записа**

Услуга Azure AI Content Safety детектује штетни садржај генерисан корисницима и вештачком интелигенцијом у апликацијама и услугама. Укључује текстуалне и сликовне API-је који омогућавају детекцију штетног или неодговарајућег материјала.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Одрицање од одговорности**:
Овај документ је преведен коришћењем услуге за аутоматски превод [Co-op Translator](https://github.com/Azure/co-op-translator). Иако тежимо прецизности, молимо имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетом. За критичне информације препоручује се професионални превод од стране стручног човека. Нисмо одговорни за било какве неспоразуме или погрешна тумачења настала коришћењем овог превода.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->