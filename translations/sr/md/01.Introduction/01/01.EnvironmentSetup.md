<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:19:36+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "sr"
}
-->
# Početak rada sa Phi-3 lokalno

Ovaj vodič će vam pomoći da podesite lokalno okruženje za pokretanje Phi-3 modela koristeći Ollama. Model možete pokrenuti na nekoliko različitih načina, uključujući GitHub Codespaces, VS Code Dev Containers ili vaše lokalno okruženje.

## Podešavanje okruženja

### GitHub Codespaces

Ovu šablonu možete pokrenuti virtuelno koristeći GitHub Codespaces. Dugme će otvoriti VS Code instancu u vašem pregledaču:

1. Otvorite šablon (ovo može potrajati nekoliko minuta):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otvorite terminal prozor

### VS Code Dev Containers

⚠️ Ova opcija će raditi samo ako vaš Docker Desktop ima dodeljeno najmanje 16 GB RAM-a. Ako imate manje od 16 GB RAM-a, možete probati [GitHub Codespaces opciju](../../../../../md/01.Introduction/01) ili [podesiti lokalno](../../../../../md/01.Introduction/01).

Povezana opcija su VS Code Dev Containers, koji će otvoriti projekat u vašem lokalnom VS Code koristeći [Dev Containers ekstenziju](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Pokrenite Docker Desktop (ako nije instaliran, instalirajte ga)
2. Otvorite projekat:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. U VS Code prozoru koji se otvori, kada se fajlovi projekta pojave (ovo može potrajati nekoliko minuta), otvorite terminal prozor.
4. Nastavite sa [koracima za deployment](../../../../../md/01.Introduction/01)

### Lokalno okruženje

1. Proverite da li su sledeći alati instalirani:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testiranje modela

1. Zamolite Ollama da preuzme i pokrene phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Preuzimanje modela može potrajati nekoliko minuta.

2. Kada u izlazu vidite "success", možete poslati poruku tom modelu iz prompta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Nakon nekoliko sekundi, trebalo bi da vidite da model šalje odgovor u vidu strima.

4. Da biste naučili o različitim tehnikama koje se koriste sa jezičkim modelima, otvorite Python notbuk [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) i pokrenite svaku ćeliju. Ako ste koristili model drugačiji od 'phi3:mini', promenite `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` na početku fajla po potrebi, a takođe možete izmeniti sistemsku poruku ili dodati few-shot primere ako želite.

**Ограничење одговорности**:  
Овај документ је преведен помоћу AI преводилачке услуге [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, имајте у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетним извором. За критичне информације препоручује се професионални људски превод. Нисмо одговорни за било каква неспоразума или погрешна тумачења која произлазе из коришћења овог превода.