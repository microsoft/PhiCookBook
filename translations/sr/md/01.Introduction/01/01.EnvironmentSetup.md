# Почните са Phi-3 локално

Овај водич ће вам помоћи да подесите своје локално окружење за покретање Phi-3 модела користећи Ollama. Модел можете покренути на неколико различитих начина, укључујући коришћење GitHub Codespaces, VS Code Dev Containers или вашег локалног окружења.

## Подешавање окружења

### GitHub Codespaces

Овај шаблон можете покренути виртуелно користећи GitHub Codespaces. Дугме ће отворити VS Code у вашем прегледачу:

1. Отворите шаблон (ово може потрајати неколико минута):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Отворите терминал

### VS Code Dev Containers

⚠️ Ова опција ће радити само ако је вашем Docker Desktop-у додељено најмање 16 GB RAM-а. Ако имате мање од 16 GB RAM-а, можете пробати [GitHub Codespaces опцију](../../../../../md/01.Introduction/01) или [подесити локално](../../../../../md/01.Introduction/01).

Повезана опција су VS Code Dev Containers, која ће отворити пројекат у вашем локалном VS Code-у користећи [Dev Containers екстензију](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Покрените Docker Desktop (инсталирајте га ако већ није инсталиран)
2. Отворите пројекат:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. У VS Code прозору који се отвори, када се појаве фајлови пројекта (ово може потрајати неколико минута), отворите терминал.
4. Наставите са [корацима за деплојмент](../../../../../md/01.Introduction/01)

### Локално окружење

1. Уверите се да су следећи алати инсталирани:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Тестирање модела

1. Затражите од Ollama да преузме и покрене phi3:mini модел:

    ```shell
    ollama run phi3:mini
    ```

    Преузимање модела ће потрајати неколико минута.

2. Када у излазу видите "success", можете послати поруку том моделу из командне линије.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Након неколико секунди, требало би да видите одговор који стиже из модела.

4. Да бисте научили о различитим техникама коришћеним са језичким моделима, отворите Python notebook [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) и покрените сваки ћелију. Ако сте користили модел другачији од 'phi3:mini', промените `MODEL_NAME` у првој ћелији.

5. Да бисте водили разговор са phi3:mini моделом из Python-а, отворите Python фајл [chat.py](../../../../../code/01.Introduce/chat.py) и покрените га. Можете променити `MODEL_NAME` на врху фајла по потреби, као и модификовати системску поруку или додати few-shot примере ако желите.

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем AI сервиса за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетним извором. За критичне информације препоручује се професионални људски превод. Нисмо одговорни за било каква неспоразума или погрешна тумачења која произилазе из коришћења овог превода.