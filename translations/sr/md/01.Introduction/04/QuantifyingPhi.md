<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d658062de70b131ef4c0bff69b5fc70e",
  "translation_date": "2025-07-16T21:50:43+00:00",
  "source_file": "md/01.Introduction/04/QuantifyingPhi.md",
  "language_code": "sr"
}
-->
# **Квантификација Phi породице**

Квантификација модела односи се на процес мапирања параметара (као што су тежине и вредности активације) у неуронској мрежи са широког опсега вредности (обично континуираног опсега) на мањи, коначни опсег вредности. Ова технологија може смањити величину и рачунску сложеност модела и побољшати ефикасност рада модела у окружењима са ограниченим ресурсима, као што су мобилни уређаји или уграђени системи. Квантификација модела постиже компресију смањењем прецизности параметара, али уводи и одређени губитак прецизности. Због тога је у процесу квантификације неопходно постићи баланс између величине модела, рачунске сложености и прецизности. Уобичајене методе квантификације укључују квантификацију фиксне тачке, квантификацију покретне тачке и слично. Можете одабрати одговарајућу стратегију квантификације у зависности од конкретног сценарија и потреба.

Надамо се да ћемо GenAI модел моћи да имплементирамо на ивици мреже (edge devices) и омогућимо више уређаја да уђу у GenAI сценарије, као што су мобилни уређаји, AI PC/Copilot+PC и традиционални IoT уређаји. Кроз квантификацију модела можемо га распоредити на различите ивичне уређаје у зависности од уређаја. У комбинацији са оквиром за убрзање модела и квантификационим моделом који пружају произвођачи хардвера, можемо изградити боље SLM апликационе сценарије.

У сценарију квантификације имамо различите прецизности (INT4, INT8, FP16, FP32). Испод је објашњење најчешће коришћених прецизности квантификације.

### **INT4**

INT4 квантификација је радикалан метод који квантификује тежине и вредности активације модела у 4-битне целобројне вредности. INT4 квантификација обично доводи до већег губитка прецизности због мањег опсега представљања и ниже прецизности. Међутим, у поређењу са INT8 квантификацијом, INT4 може додатно смањити захтеве за складиштењем и рачунску сложеност модела. Треба напоменути да је INT4 квантификација релативно ретка у практичним применама, јер превише ниска прецизност може значајно утицати на перформансе модела. Поред тога, неки хардвер не подржава INT4 операције, па је потребно узети у обзир компатибилност хардвера приликом избора методе квантификације.

### **INT8**

INT8 квантификација је процес претварања тежина и активација модела из покретне тачке у 8-битне целобројне вредности. Иако је нумерички опсег који INT8 представља мањи и мање прецизан, овај метод значајно смањује захтеве за складиштењем и рачунањем. У INT8 квантификацији, тежине и вредности активације пролазе кроз процес квантификације који укључује скалирање и офсет како би се што више сачувале оригиналне информације из покретне тачке. Током извођења, ове квантификоване вредности се деквантификују назад у вредности покретне тачке за израчунавање, а затим поново квантификују у INT8 за следећи корак. Овај метод пружа довољну прецизност у већини апликација уз одржавање високе рачунске ефикасности.

### **FP16**

FP16 формат, односно 16-битни бројеви покретне тачке (float16), смањује заузетост меморије за половину у односу на 32-битне бројеве покретне тачке (float32), што има значајне предности у великим дубоким учењима. FP16 формат омогућава учитавање већих модела или обраду више података у оквиру истих ограничења GPU меморије. Како савремени GPU хардвер све више подржава FP16 операције, коришћење FP16 формата може донети и побољшања у брзини израчунавања. Међутим, FP16 формат има и своје урођене недостатке, односно нижу прецизност, што може довести до нумеричке нестабилности или губитка прецизности у неким случајевима.

### **FP32**

FP32 формат пружа већу прецизност и може тачно представити широк опсег вредности. У сценаријима где се изводе сложене математичке операције или је потребан висок ниво прецизности, FP32 формат је пожељан. Међутим, висока прецизност такође значи већу потрошњу меморије и дужи временски период израчунавања. За велике дубоке моделе, посебно када има много параметара и огромну количину података, FP32 формат може изазвати недостатак GPU меморије или смањење брзине извођења.

На мобилним уређајима или IoT уређајима можемо конвертовати Phi-3.x моделе у INT4, док AI PC / Copilot PC могу користити већу прецизност као што су INT8, FP16, FP32.

Тренутно различити произвођачи хардвера имају различите оквире за подршку генеративним моделима, као што су Intel OpenVINO, Qualcomm QNN, Apple MLX и Nvidia CUDA, итд., у комбинацији са квантификацијом модела за локалну имплементацију.

У технолошком смислу, након квантификације подржавамо различите формате, као што су PyTorch / Tensorflow формат, GGUF и ONNX. Направио сам поређење формата и сценарија примене између GGUF и ONNX. Овде препоручујем ONNX квантификациони формат, који има добру подршку од оквира модела до хардвера. У овом поглављу ћемо се фокусирати на ONNX Runtime за GenAI, OpenVINO и Apple MLX за извођење квантификације модела (ако имате бољи начин, можете нам га послати кроз PR).

**Ово поглавље укључује**

1. [Квантификација Phi-3.5 / 4 коришћењем llama.cpp](./UsingLlamacppQuantifyingPhi.md)

2. [Квантификација Phi-3.5 / 4 коришћењем Generative AI екстензија за onnxruntime](./UsingORTGenAIQuantifyingPhi.md)

3. [Квантификација Phi-3.5 / 4 коришћењем Intel OpenVINO](./UsingIntelOpenVINOQuantifyingPhi.md)

4. [Квантификација Phi-3.5 / 4 коришћењем Apple MLX Framework](./UsingAppleMLXQuantifyingPhi.md)

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетним извором. За критичне информације препоручује се професионални људски превод. Нисмо одговорни за било каква неспоразума или погрешна тумачења која произилазе из коришћења овог превода.