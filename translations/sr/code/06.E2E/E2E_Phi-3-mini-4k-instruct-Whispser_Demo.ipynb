{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерактивни Phi 3 Mini 4K Инструкт Четбот са Whisper\n",
    "\n",
    "### Увод:\n",
    "Интерактивни Phi 3 Mini 4K Инструкт Четбот је алат који омогућава корисницима да комуницирају са Microsoft Phi 3 Mini 4K Инструкт демо уз помоћ текстуалног или аудио уноса. Четбот се може користити за различите задатке, као што су превођење, ажурирање временских услова и прикупљање општих информација.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "[Направите свој Huggingface приступни токен](https://huggingface.co/settings/tokens)\n",
    "\n",
    "Направите нови токен  \n",
    "Унесите ново име  \n",
    "Изаберите дозволе за писање  \n",
    "Копирајте токен и сачувајте га на безбедном месту\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следећи Python код обавља два главна задатка: увоз модула `os` и постављање променљиве окружења.\n",
    "\n",
    "1. Увоз модула `os`:\n",
    "   - Модул `os` у Python-у пружа начин за интеракцију са оперативним системом. Омогућава вам да извршите различите задатке повезане са оперативним системом, као што су приступ променљивим окружења, рад са датотекама и директоријумима, итд.\n",
    "   - У овом коду, модул `os` се увози помоћу наредбе `import`. Ова наредба омогућава функционалност модула `os` за употребу у тренутном Python скрипту.\n",
    "\n",
    "2. Постављање променљиве окружења:\n",
    "   - Променљива окружења је вредност којој програми који раде на оперативном систему могу приступити. То је начин за чување конфигурационих подешавања или других информација које могу користити више програма.\n",
    "   - У овом коду, нова променљива окружења се поставља помоћу речника `os.environ`. Кључ речника је `'HF_TOKEN'`, а вредност се додељује из променљиве `HUGGINGFACE_TOKEN`.\n",
    "   - Променљива `HUGGINGFACE_TOKEN` је дефинисана непосредно изнад овог исечка кода и додељује јој се стринг вредност `\"hf_**************\"` помоћу синтаксе `#@param`. Ова синтакса се често користи у Jupyter нотебуковима како би се омогућио унос корисника и конфигурација параметара директно у интерфејсу нотебука.\n",
    "   - Постављањем променљиве окружења `'HF_TOKEN'`, она може бити доступна другим деловима програма или другим програмима који раде на истом оперативном систему.\n",
    "\n",
    "Укратко, овај код увози модул `os` и поставља променљиву окружења под именом `'HF_TOKEN'` са вредношћу која је наведена у променљивој `HUGGINGFACE_TOKEN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Овај кодни исечак дефинише функцију под називом clear_output која се користи за брисање излазних података тренутне ћелије у Jupyter Notebook-у или IPython-у. Хајде да разложимо код и разумемо његову функционалност:\n",
    "\n",
    "Функција clear_output прихвата један параметар под називом wait, који је булова вредност. Подразумевано, wait је постављен на False. Овај параметар одређује да ли функција треба да сачека док нови излаз не буде доступан за замену постојећег излаза пре него што га обрише.\n",
    "\n",
    "Сама функција се користи за брисање излазних података тренутне ћелије. У Jupyter Notebook-у или IPython-у, када ћелија генерише излаз, као што је одштампани текст или графички прикази, тај излаз се приказује испод ћелије. Функција clear_output омогућава брисање тог излаза.\n",
    "\n",
    "Имплементација функције није дата у кодном исечку, што је назначено елипсом (...). Елипса представља место за стварни код који извршава брисање излазних података. Имплементација функције може укључивати интеракцију са Jupyter Notebook или IPython API-јем ради уклањања постојећег излаза из ћелије.\n",
    "\n",
    "Укратко, ова функција пружа практичан начин за брисање излазних података тренутне ћелије у Jupyter Notebook-у или IPython-у, чиме се олакшава управљање и ажурирање приказаног излаза током интерактивних сесија кодирања.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извршите текст-у-говор (TTS) користећи Edge TTS услугу. Хајде да прођемо кроз релевантне имплементације функција једну по једну:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: Ова функција узима улазну вредност и израчунава стринг брзине за TTS глас. Улазна вредност представља жељену брзину говора, где вредност 1 представља нормалну брзину. Функција израчунава стринг брзине одузимањем 1 од улазне вредности, множењем са 100, и затим одређује знак на основу тога да ли је улазна вредност већа или једнака 1. Функција враћа стринг брзине у формату \"{sign}{rate}\".\n",
    "\n",
    "2. `make_chunks(input_text, language)`: Ова функција узима улазни текст и језик као параметре. Делује тако што дели улазни текст на делове на основу језичких правила. У овој имплементацији, ако је језик \"English\", функција дели текст на свакој тачки (\".\"), уклањајући било који водећи или завршни размак. Затим додаје тачку на крај сваког дела и враћа филтрирану листу делова.\n",
    "\n",
    "3. `tts_file_name(text)`: Ова функција генерише име датотеке за TTS аудио на основу улазног текста. Извршава неколико трансформација на тексту: уклања завршну тачку (ако постоји), претвара текст у мала слова, уклања водеће и завршне размаке, и замењује размаке са доњим цртама. Затим скраћује текст на максимално 25 карактера (ако је дужи) или користи цео текст ако је празан. На крају, генерише насумични стринг користећи модул [`uuid`] и комбинује га са скраћеним текстом да би креирала име датотеке у формату \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\".\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: Ова функција спаја више аудио датотека у једну аудио датотеку. Узима листу путања аудио датотека и излазну путању као параметре. Функција иницијализује празан објекат `AudioSegment` назван [`merged_audio`]. Затим пролази кроз сваку путању аудио датотеке, учитава аудио датотеку користећи метод `AudioSegment.from_file()` из библиотеке `pydub`, и додаје тренутну аудио датотеку у објекат [`merged_audio`]. На крају, извози спојени аудио у специфицирану излазну путању у MP3 формату.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: Ова функција извршава TTS операцију користећи Edge TTS услугу. Узима листу текстуалних делова, брзину говора, име гласа и путању за чување као параметре. Ако је број делова већи од 1, функција креира директоријум за чување појединачних аудио датотека делова. Затим пролази кроз сваки део, конструише Edge TTS команду користећи функцију `calculate_rate_string()`, име гласа и текст дела, и извршава команду користећи функцију `os.system()`. Ако је извршење команде успешно, додаје путању генерисане аудио датотеке у листу. Након обраде свих делова, спаја појединачне аудио датотеке користећи функцију `merge_audio_files()` и чува спојени аудио у специфицираној путањи за чување. Ако постоји само један део, директно генерише Edge TTS команду и чува аудио у путањи за чување. На крају, враћа путању за чување генерисане аудио датотеке.\n",
    "\n",
    "6. `random_audio_name_generate()`: Ова функција генерише насумично име аудио датотеке користећи модул [`uuid`]. Генерише насумични UUID, претвара га у стринг, узима првих 8 карактера, додаје екстензију \".mp3\", и враћа насумично име аудио датотеке.\n",
    "\n",
    "7. `talk(input_text)`: Ова функција је главна тачка уласка за извршавање TTS операције. Узима улазни текст као параметар. Прво проверава дужину улазног текста да би утврдила да ли је реч о дугачкој реченици (већој или једнакој 600 карактера). На основу дужине и вредности променљиве `translate_text_flag`, одређује језик и генерише листу текстуалних делова користећи функцију `make_chunks()`. Затим генерише путању за чување аудио датотеке користећи функцију `random_audio_name_generate()`. На крају, позива функцију `edge_free_tts()` да изврши TTS операцију и враћа путању за чување генерисане аудио датотеке.\n",
    "\n",
    "Укратко, ове функције раде заједно да би поделиле улазни текст на делове, генерисале име датотеке за аудио, извршиле TTS операцију користећи Edge TTS услугу, и спојиле појединачне аудио датотеке у једну аудио датотеку.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементација две функције: convert_to_text и run_text_prompt, као и декларација две класе: str и Audio.\n",
    "\n",
    "Функција convert_to_text узима audio_path као улаз и транскрибује аудио у текст користећи модел назван whisper_model. Функција прво проверава да ли је gpu флаг постављен на True. Ако јесте, whisper_model се користи са одређеним параметрима као што су word_timestamps=True, fp16=True, language='English', и task='translate'. Ако је gpu флаг False, whisper_model се користи са fp16=False. Добијена транскрипција се затим чува у датотеци названој 'scan.txt' и враћа као текст.\n",
    "\n",
    "Функција run_text_prompt узима message и chat_history као улаз. Користи функцију phi_demo за генерисање одговора од чатбота на основу улазне поруке. Генерисани одговор се затим прослеђује функцији talk, која конвертује одговор у аудио датотеку и враћа путању до те датотеке. Класа Audio се користи за приказивање и репродукцију аудио датотеке. Аудио се приказује користећи функцију display из модула IPython.display, а објекат Audio се креира са параметром autoplay=True, тако да аудио аутоматски почиње да се репродукује. chat_history се ажурира са улазном поруком и генерисаним одговором, а враћају се празан стринг и ажурирани chat_history.\n",
    "\n",
    "Класа str је уграђена класа у Python-у која представља секвенцу карактера. Пружа различите методе за манипулацију и рад са стринговима, као што су capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill, и још много тога. Ове методе омогућавају извршавање операција као што су претрага, замена, форматирање и манипулација стринговима.\n",
    "\n",
    "Класа Audio је прилагођена класа која представља аудио објекат. Користи се за креирање аудио плејера у Jupyter Notebook окружењу. Класа прихвата различите параметре као што су data, filename, url, embed, rate, autoplay, и normalize. Параметар data може бити numpy низ, листа узорака, стринг који представља име датотеке или URL, или сирови PCM подаци. Параметар filename се користи за спецификацију локалне датотеке из које се учитавају аудио подаци, а параметар url се користи за спецификацију URL-а са којег се преузимају аудио подаци. Параметар embed одређује да ли аудио подаци треба да буду уграђени користећи data URI или референцирани из оригиналног извора. Параметар rate спецификује брзину узорковања аудио података. Параметар autoplay одређује да ли аудио треба аутоматски да почне да се репродукује. Параметар normalize спецификује да ли аудио подаци треба да буду нормализовани (преразмерени) на максимални могући опсег. Класа Audio такође пружа методе као што је reload за поновно учитавање аудио података из датотеке или URL-а, и атрибуте као што су src_attr, autoplay_attr, и element_id_attr за преузимање одговарајућих атрибута за аудио елемент у HTML-у.\n",
    "\n",
    "Укратко, ове функције и класе се користе за транскрипцију аудио записа у текст, генерисање аудио одговора од чатбота, и приказивање и репродукцију аудио записа у Jupyter Notebook окружењу.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Одрицање од одговорности**:  \nОвај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-13T07:03:30+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}