<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:12:05+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "cs"
}
-->
# Začněte s Phi-3 lokálně

Tento průvodce vám pomůže nastavit lokální prostředí pro spuštění modelu Phi-3 pomocí Ollama. Model můžete spustit několika způsoby, včetně GitHub Codespaces, VS Code Dev Containers nebo přímo ve vašem lokálním prostředí.

## Nastavení prostředí

### GitHub Codespaces

Tento šablonu můžete spustit virtuálně pomocí GitHub Codespaces. Tlačítko otevře webovou verzi VS Code přímo ve vašem prohlížeči:

1. Otevřete šablonu (může to trvat několik minut):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otevřete terminálové okno

### VS Code Dev Containers

⚠️ Tato možnost funguje pouze pokud má váš Docker Desktop přiděleno alespoň 16 GB RAM. Pokud máte méně než 16 GB RAM, můžete zkusit [GitHub Codespaces](../../../../../md/01.Introduction/01) nebo [nastavit prostředí lokálně](../../../../../md/01.Introduction/01).

Související možností jsou VS Code Dev Containers, které otevřou projekt ve vašem lokálním VS Code pomocí [Dev Containers rozšíření](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Spusťte Docker Desktop (pokud není nainstalován, nejprve jej nainstalujte)
2. Otevřete projekt:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Ve VS Code, které se otevře, jakmile se načtou soubory projektu (může to trvat několik minut), otevřete terminálové okno.
4. Pokračujte podle [kroků nasazení](../../../../../md/01.Introduction/01)

### Lokální prostředí

1. Ujistěte se, že máte nainstalované následující nástroje:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Otestujte model

1. Požádejte Ollama, aby stáhl a spustil model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Stažení modelu může chvíli trvat.

2. Jakmile se v výstupu objeví "success", můžete modelu poslat zprávu z příkazového řádku.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Po několika sekundách byste měli vidět odpověď plynoucí z modelu.

4. Pokud se chcete seznámit s různými technikami používanými u jazykových modelů, otevřete Python notebook [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) a spusťte jednotlivé buňky. Pokud jste použili jiný model než 'phi3:mini', změňte `MODEL_NAME` v první buňce.

5. Pro konverzaci s modelem phi3:mini z Pythonu otevřete soubor [chat.py](../../../../../code/01.Introduce/chat.py) a spusťte ho. V případě potřeby můžete změnit `MODEL_NAME` v horní části souboru a také upravit systémovou zprávu nebo přidat příklady few-shot.

**Prohlášení o vyloučení odpovědnosti**:  
Tento dokument byl přeložen pomocí AI překladatelské služby [Co-op Translator](https://github.com/Azure/co-op-translator). I když usilujeme o přesnost, mějte prosím na paměti, že automatické překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho mateřském jazyce by měl být považován za autoritativní zdroj. Pro důležité informace se doporučuje profesionální lidský překlad. Nejsme odpovědní za jakékoliv nedorozumění nebo nesprávné výklady vyplývající z použití tohoto překladu.