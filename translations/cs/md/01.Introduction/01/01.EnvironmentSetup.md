<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:17:01+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "cs"
}
-->
# Начало работы с Phi-3 локально

Это руководство поможет вам настроить локальную среду для запуска модели Phi-3 с помощью Ollama. Вы можете запускать модель несколькими способами, включая использование GitHub Codespaces, VS Code Dev Containers или вашей локальной среды.

## Настройка окружения

### GitHub Codespaces

Вы можете запустить этот шаблон виртуально, используя GitHub Codespaces. Кнопка откроет веб-версию VS Code в вашем браузере:

1. Откройте шаблон (это может занять несколько минут):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Откройте окно терминала

### VS Code Dev Containers

⚠️ Этот вариант будет работать только если Docker Desktop выделено не менее 16 ГБ оперативной памяти. Если у вас меньше 16 ГБ, вы можете попробовать [вариант с GitHub Codespaces](../../../../../md/01.Introduction/01) или [настроить локально](../../../../../md/01.Introduction/01).

Связанный вариант — VS Code Dev Containers, который откроет проект в локальном VS Code с помощью [расширения Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Запустите Docker Desktop (установите, если еще не установлен)
2. Откройте проект:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. В открывшемся окне VS Code, когда появятся файлы проекта (это может занять несколько минут), откройте окно терминала.
4. Продолжайте с [шагами развертывания](../../../../../md/01.Introduction/01)

### Локальная среда

1. Убедитесь, что установлены следующие инструменты:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Тестирование модели

1. Попросите Ollama скачать и запустить модель phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Загрузка модели займет несколько минут.

2. Как только в выводе появится "success", вы можете отправлять сообщения этой модели через командную строку.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Через несколько секунд вы должны увидеть поток ответа от модели.

4. Чтобы узнать о различных техниках работы с языковыми моделями, откройте Python ноутбук [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) и выполните каждую ячейку. Если вы использовали модель, отличную от 'phi3:mini', измените `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` в начале файла по необходимости, а также можете изменить системное сообщение или добавить few-shot примеры, если хотите.

**Prohlášení o vyloučení odpovědnosti**:  
Tento dokument byl přeložen pomocí AI překladatelské služby [Co-op Translator](https://github.com/Azure/co-op-translator). I když usilujeme o přesnost, mějte prosím na paměti, že automatizované překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho mateřském jazyce by měl být považován za závazný zdroj. Pro důležité informace se doporučuje profesionální lidský překlad. Nejsme odpovědní za jakékoli nedorozumění nebo nesprávné výklady vzniklé použitím tohoto překladu.