<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3139a6a82f357a9f90f1fe51c4caf65a",
  "translation_date": "2025-07-16T22:03:51+00:00",
  "source_file": "md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "cs"
}
-->
# **Kvantilace Phi-3.5 pomoc√≠ Intel OpenVINO**

Intel je nejtradiƒçnƒõj≈°√≠ v√Ωrobce CPU s mnoha u≈æivateli. S n√°stupem strojov√©ho uƒçen√≠ a hlubok√©ho uƒçen√≠ se Intel tak√© zapojil do soutƒõ≈æe o akceleraci AI. Pro inferenci model≈Ø Intel vyu≈æ√≠v√° nejen GPU a CPU, ale tak√© NPU.

Douf√°me, ≈æe nasad√≠me rodinu Phi-3.x na koncovou stranu, s c√≠lem st√°t se nejd≈Øle≈æitƒõj≈°√≠ souƒç√°st√≠ AI PC a Copilot PC. Naƒç√≠t√°n√≠ modelu na koncov√©m za≈ô√≠zen√≠ z√°vis√≠ na spolupr√°ci r≈Øzn√Ωch v√Ωrobc≈Ø hardwaru. Tato kapitola se zamƒõ≈ôuje p≈ôedev≈°√≠m na aplikaƒçn√≠ sc√©n√°≈ô Intel OpenVINO jako kvantitativn√≠ho modelu.

## **Co je OpenVINO**

OpenVINO je open-source sada n√°stroj≈Ø pro optimalizaci a nasazen√≠ model≈Ø hlubok√©ho uƒçen√≠ od cloudu a≈æ po edge. Urychluje inferenci hlubok√©ho uƒçen√≠ v r≈Øzn√Ωch p≈ô√≠padech pou≈æit√≠, jako je generativn√≠ AI, video, audio a jazyk, s modely z popul√°rn√≠ch framework≈Ø jako PyTorch, TensorFlow, ONNX a dal≈°√≠ch. P≈ôev√°d√≠ a optimalizuje modely a nasazuje je na r≈Øznorod√Ω Intel¬Æ hardware a prost≈ôed√≠, lok√°lnƒõ i na za≈ô√≠zen√≠, v prohl√≠≈æeƒçi nebo v cloudu.

S OpenVINO nyn√≠ m≈Ø≈æete rychle kvantizovat GenAI model na Intel hardwaru a zrychlit referenƒçn√≠ model.

OpenVINO nyn√≠ podporuje kvantizaƒçn√≠ p≈ôevod Phi-3.5-Vision a Phi-3.5 Instruct.

### **Nastaven√≠ prost≈ôed√≠**

Ujistƒõte se, ≈æe m√°te nainstalovan√© n√°sleduj√≠c√≠ z√°vislosti, jedn√° se o requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Kvantilace Phi-3.5-Instruct pomoc√≠ OpenVINO**

V termin√°lu spus≈•te tento skript

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Kvantilace Phi-3.5-Vision pomoc√≠ OpenVINO**

Spus≈•te tento skript v Pythonu nebo Jupyter labu

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ü§ñ Uk√°zky pro Phi-3.5 s Intel OpenVINO**

| Laborato≈ôe    | Popis | J√≠t |
| -------- | ------- |  ------- |
| üöÄ Lab-Introduce Phi-3.5 Instruct  | Nauƒçte se, jak pou≈æ√≠vat Phi-3.5 Instruct ve va≈°em AI PC    |  [J√≠t](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| üöÄ Lab-Introduce Phi-3.5 Vision (obr√°zek) | Nauƒçte se, jak pou≈æ√≠vat Phi-3.5 Vision k anal√Ωze obr√°zk≈Ø ve va≈°em AI PC      |  [J√≠t](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| üöÄ Lab-Introduce Phi-3.5 Vision (video)   | Nauƒçte se, jak pou≈æ√≠vat Phi-3.5 Vision k anal√Ωze videa ve va≈°em AI PC    |  [J√≠t](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Zdroje**

1. V√≠ce o Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub Repo [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Prohl√°≈°en√≠ o vylouƒçen√≠ odpovƒõdnosti**:  
Tento dokument byl p≈ôelo≈æen pomoc√≠ AI p≈ôekladatelsk√© slu≈æby [Co-op Translator](https://github.com/Azure/co-op-translator). I kdy≈æ usilujeme o p≈ôesnost, mƒõjte pros√≠m na pamƒõti, ≈æe automatick√© p≈ôeklady mohou obsahovat chyby nebo nep≈ôesnosti. P≈Øvodn√≠ dokument v jeho mate≈ôsk√©m jazyce by mƒõl b√Ωt pova≈æov√°n za z√°vazn√Ω zdroj. Pro d≈Øle≈æit√© informace se doporuƒçuje profesion√°ln√≠ lidsk√Ω p≈ôeklad. Nejsme odpovƒõdn√≠ za jak√©koliv nedorozumƒõn√≠ nebo nespr√°vn√© v√Ωklady vypl√Ωvaj√≠c√≠ z pou≈æit√≠ tohoto p≈ôekladu.