<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-09T08:42:25+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "cs"
}
-->
# **Using Phi Family in Hugging Face**


[Hugging Face](https://huggingface.co/) es una comunidad de IA muy popular con abundantes datos y recursos de modelos de código abierto. Diferentes fabricantes lanzan modelos LLM y SLM de código abierto a través de Hugging Face, como Microsoft, Meta, Mistral, Apple, Google, etc.

La familia Microsoft Phi se ha publicado en Hugging Face. Los desarrolladores pueden descargar el modelo correspondiente de Phi Family según los escenarios y negocios. Además de desplegar los modelos Phi en Pytorch en Hugging Face, también lanzamos modelos cuantificados, utilizando los formatos GGUF y ONNX para ofrecer opciones a los usuarios finales.


## **Descargar modelos en Hugging Face**

Puedes descargar el modelo de la familia Phi con este enlace

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Puedes descargar el modelo de diferentes maneras, como instalando el ***Hugging Face CLI SDK*** o usando ***git clone***.

### **Usar Hugging Face CLI para descargar el modelo Phi Family**

- Instalar Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Usar huggingface-cli para iniciar sesión

Inicia sesión en Hugging Face con tu [User Access Token](https://huggingface.co/docs/hub/security-tokens) desde tu [página de Configuración](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Descargar


Puedes descargar el modelo y guardarlo en caché

```bash

huggingface-cli download microsoft/phi-4

```

Puedes configurar la ubicación en un directorio específico


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Usar git clone para descargar el modelo Phi Family**

También puedes usar ***git clone*** para descargar el modelo

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Ejemplos - Inferencia con Microsoft Phi-4**

- **Instalar la librería transformers**

```bash

pip install transformers -U

```

- **Ejecutar este código en VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Prohlášení o vyloučení odpovědnosti**:  
Tento dokument byl přeložen pomocí AI překladatelské služby [Co-op Translator](https://github.com/Azure/co-op-translator). Přestože usilujeme o přesnost, mějte prosím na paměti, že automatické překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho mateřském jazyce by měl být považován za autoritativní zdroj. Pro důležité informace se doporučuje profesionální lidský překlad. Nejsme odpovědní za jakékoliv nedorozumění nebo chybné interpretace vyplývající z použití tohoto překladu.