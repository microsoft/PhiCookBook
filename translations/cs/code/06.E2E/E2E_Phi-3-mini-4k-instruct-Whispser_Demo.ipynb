{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktivní Phi 3 Mini 4K Instruct Chatbot s Whisper\n",
    "\n",
    "### Úvod:\n",
    "Interaktivní Phi 3 Mini 4K Instruct Chatbot je nástroj, který uživatelům umožňuje komunikovat s ukázkou Microsoft Phi 3 Mini 4K Instruct pomocí textového nebo zvukového vstupu. Chatbot lze využít pro různé úkoly, jako je překlad, informace o počasí a obecné získávání informací.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "[Vytvořte svůj Huggingface Access Token](https://huggingface.co/settings/tokens)\n",
    "\n",
    "Vytvořte nový token  \n",
    "Zadejte nový název  \n",
    "Vyberte oprávnění k zápisu  \n",
    "Zkopírujte token a uložte jej na bezpečné místo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následující Python kód provádí dvě hlavní úlohy: importuje modul `os` a nastavuje proměnnou prostředí.\n",
    "\n",
    "1. Import modulu `os`:\n",
    "   - Modul `os` v Pythonu poskytuje způsob, jak komunikovat s operačním systémem. Umožňuje provádět různé úkoly související s operačním systémem, jako je přístup k proměnným prostředí, práce se soubory a adresáři atd.\n",
    "   - V tomto kódu je modul `os` importován pomocí příkazu `import`. Tento příkaz zpřístupňuje funkce modulu `os` pro použití v aktuálním Python skriptu.\n",
    "\n",
    "2. Nastavení proměnné prostředí:\n",
    "   - Proměnná prostředí je hodnota, ke které mohou přistupovat programy běžící na operačním systému. Je to způsob, jak ukládat konfigurační nastavení nebo jiné informace, které mohou být využity více programy.\n",
    "   - V tomto kódu je nastavena nová proměnná prostředí pomocí slovníku `os.environ`. Klíčem slovníku je `'HF_TOKEN'` a hodnota je přiřazena z proměnné `HUGGINGFACE_TOKEN`.\n",
    "   - Proměnná `HUGGINGFACE_TOKEN` je definována těsně nad tímto úryvkem kódu a je jí přiřazena řetězcová hodnota `\"hf_**************\"` pomocí syntaxe `#@param`. Tato syntaxe se často používá v Jupyter noteboocích, aby umožnila uživatelský vstup a konfiguraci parametrů přímo v rozhraní notebooku.\n",
    "   - Nastavením proměnné prostředí `'HF_TOKEN'` je možné k této hodnotě přistupovat z jiných částí programu nebo z jiných programů běžících na stejném operačním systému.\n",
    "\n",
    "Celkově tento kód importuje modul `os` a nastavuje proměnnou prostředí s názvem `'HF_TOKEN'` na hodnotu poskytnutou v proměnné `HUGGINGFACE_TOKEN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tento úryvek kódu definuje funkci nazvanou clear_output, která slouží k vymazání výstupu aktuální buňky v Jupyter Notebooku nebo IPythonu. Pojďme si rozebrat kód a pochopit jeho funkčnost:\n",
    "\n",
    "Funkce clear_output přijímá jeden parametr nazvaný wait, což je logická hodnota (boolean). Ve výchozím nastavení je wait nastaven na hodnotu False. Tento parametr určuje, zda by funkce měla počkat, dokud nebude k dispozici nový výstup, který nahradí stávající výstup, před jeho vymazáním.\n",
    "\n",
    "Samotná funkce slouží k vymazání výstupu aktuální buňky. V Jupyter Notebooku nebo IPythonu, když buňka generuje výstup, například vytištěný text nebo grafické vizualizace, tento výstup se zobrazí pod buňkou. Funkce clear_output umožňuje tento výstup vymazat.\n",
    "\n",
    "Implementace funkce není v úryvku kódu uvedena, jak naznačuje trojtečka (...). Trojtečka představuje zástupný symbol pro skutečný kód, který provádí vymazání výstupu. Implementace funkce může zahrnovat interakci s API Jupyter Notebooku nebo IPythonu za účelem odstranění stávajícího výstupu z buňky.\n",
    "\n",
    "Celkově tato funkce poskytuje pohodlný způsob, jak vymazat výstup aktuální buňky v Jupyter Notebooku nebo IPythonu, což usnadňuje správu a aktualizaci zobrazeného výstupu během interaktivních programovacích sezení.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proveďte převod textu na řeč (TTS) pomocí služby Edge TTS. Pojďme si projít relevantní implementace funkcí jednu po druhé:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: Tato funkce přijímá vstupní hodnotu a vypočítává řetězec rychlosti pro hlas TTS. Vstupní hodnota představuje požadovanou rychlost řeči, kde hodnota 1 odpovídá normální rychlosti. Funkce vypočítává řetězec rychlosti odečtením 1 od vstupní hodnoty, násobením výsledku číslem 100 a následným určením znaménka na základě toho, zda je vstupní hodnota větší nebo rovna 1. Funkce vrací řetězec rychlosti ve formátu \"{sign}{rate}\".\n",
    "\n",
    "2. `make_chunks(input_text, language)`: Tato funkce přijímá vstupní text a jazyk jako parametry. Rozděluje vstupní text na části na základě pravidel specifických pro daný jazyk. V této implementaci, pokud je jazyk \"English\", funkce rozdělí text na každé tečce (\".\"), odstraní jakékoli počáteční nebo koncové mezery, přidá tečku ke každé části a vrátí filtrovaný seznam částí.\n",
    "\n",
    "3. `tts_file_name(text)`: Tato funkce generuje název souboru pro audio soubor TTS na základě vstupního textu. Provádí několik transformací na text: odstraní koncovou tečku (pokud je přítomna), převede text na malá písmena, odstraní počáteční a koncové mezery a nahradí mezery podtržítky. Poté text zkrátí na maximálně 25 znaků (pokud je delší) nebo použije celý text, pokud je prázdný. Nakonec vygeneruje náhodný řetězec pomocí modulu [`uuid`] a spojí jej se zkráceným textem, aby vytvořil název souboru ve formátu \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\".\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: Tato funkce sloučí více audio souborů do jednoho. Přijímá seznam cest k audio souborům a výstupní cestu jako parametry. Funkce inicializuje prázdný objekt `AudioSegment` nazvaný [`merged_audio`]. Poté iteruje přes každou cestu k audio souboru, načte audio soubor pomocí metody `AudioSegment.from_file()` z knihovny `pydub` a připojí aktuální audio soubor k objektu [`merged_audio`]. Nakonec exportuje sloučené audio do zadané výstupní cesty ve formátu MP3.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: Tato funkce provádí operaci TTS pomocí služby Edge TTS. Přijímá seznam textových částí, rychlost řeči, název hlasu a cestu pro uložení jako parametry. Pokud je počet částí větší než 1, funkce vytvoří adresář pro uložení jednotlivých audio souborů částí. Poté iteruje přes každou část, sestaví příkaz Edge TTS pomocí funkce `calculate_rate_string()`, názvu hlasu a textu části a provede příkaz pomocí funkce `os.system()`. Pokud je provedení příkazu úspěšné, přidá cestu k vygenerovanému audio souboru do seznamu. Po zpracování všech částí sloučí jednotlivé audio soubory pomocí funkce `merge_audio_files()` a uloží sloučené audio do zadané cesty. Pokud je pouze jedna část, přímo vygeneruje příkaz Edge TTS a uloží audio do zadané cesty. Nakonec vrátí cestu k vygenerovanému audio souboru.\n",
    "\n",
    "6. `random_audio_name_generate()`: Tato funkce generuje náhodný název audio souboru pomocí modulu [`uuid`]. Vygeneruje náhodné UUID, převede jej na řetězec, vezme prvních 8 znaků, připojí příponu \".mp3\" a vrátí náhodný název audio souboru.\n",
    "\n",
    "7. `talk(input_text)`: Tato funkce je hlavním vstupním bodem pro provedení operace TTS. Přijímá vstupní text jako parametr. Nejprve zkontroluje délku vstupního textu, aby určila, zda se jedná o dlouhou větu (větší nebo rovnou 600 znaků). Na základě délky a hodnoty proměnné `translate_text_flag` určí jazyk a vygeneruje seznam textových částí pomocí funkce `make_chunks()`. Poté vygeneruje cestu pro uložení audio souboru pomocí funkce `random_audio_name_generate()`. Nakonec zavolá funkci `edge_free_tts()` pro provedení operace TTS a vrátí cestu k vygenerovanému audio souboru.\n",
    "\n",
    "Celkově tyto funkce spolupracují na rozdělení vstupního textu na části, generování názvu souboru pro audio soubor, provedení operace TTS pomocí služby Edge TTS a sloučení jednotlivých audio souborů do jednoho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementace dvou funkcí: convert_to_text a run_text_prompt, stejně jako deklarace dvou tříd: str a Audio.\n",
    "\n",
    "Funkce convert_to_text přijímá jako vstup audio_path a přepisuje zvuk na text pomocí modelu nazvaného whisper_model. Funkce nejprve ověřuje, zda je příznak gpu nastaven na True. Pokud ano, whisper_model se použije s určitými parametry, jako jsou word_timestamps=True, fp16=True, language='English' a task='translate'. Pokud je příznak gpu nastaven na False, whisper_model se použije s fp16=False. Výsledný přepis je poté uložen do souboru s názvem 'scan.txt' a vrácen jako text.\n",
    "\n",
    "Funkce run_text_prompt přijímá jako vstup message a chat_history. Používá funkci phi_demo k vygenerování odpovědi od chatbotu na základě vstupní zprávy. Vygenerovaná odpověď je poté předána funkci talk, která odpověď převede na zvukový soubor a vrátí cestu k souboru. Třída Audio se používá k zobrazení a přehrání zvukového souboru. Zvuk je zobrazen pomocí funkce display z modulu IPython.display a objekt Audio je vytvořen s parametrem autoplay=True, takže zvuk začne automaticky přehrávat. chat_history je aktualizován o vstupní zprávu a vygenerovanou odpověď, a vrácen je prázdný řetězec a aktualizovaný chat_history.\n",
    "\n",
    "Třída str je vestavěná třída v Pythonu, která reprezentuje sekvenci znaků. Poskytuje různé metody pro manipulaci a práci s řetězci, jako jsou capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill a další. Tyto metody umožňují provádět operace jako vyhledávání, nahrazování, formátování a manipulaci s řetězci.\n",
    "\n",
    "Třída Audio je vlastní třída, která reprezentuje zvukový objekt. Používá se k vytvoření přehrávače zvuku v prostředí Jupyter Notebook. Třída přijímá různé parametry, jako jsou data, filename, url, embed, rate, autoplay a normalize. Parametr data může být numpy pole, seznam vzorků, řetězec reprezentující název souboru nebo URL, nebo surová PCM data. Parametr filename se používá k určení místního souboru, ze kterého se načtou zvuková data, a parametr url se používá k určení URL, ze kterého se stáhnou zvuková data. Parametr embed určuje, zda by zvuková data měla být vložena pomocí data URI nebo odkazována z původního zdroje. Parametr rate specifikuje vzorkovací frekvenci zvukových dat. Parametr autoplay určuje, zda by se zvuk měl začít automaticky přehrávat. Parametr normalize specifikuje, zda by zvuková data měla být normalizována (přepočítána) na maximální možný rozsah. Třída Audio také poskytuje metody jako reload pro opětovné načtení zvukových dat ze souboru nebo URL, a atributy jako src_attr, autoplay_attr a element_id_attr pro získání odpovídajících atributů pro zvukový prvek v HTML.\n",
    "\n",
    "Celkově jsou tyto funkce a třídy používány k přepisu zvuku na text, generování zvukových odpovědí od chatbotu a zobrazení a přehrání zvuku v prostředí Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Prohlášení**:  \nTento dokument byl přeložen pomocí služby pro automatický překlad [Co-op Translator](https://github.com/Azure/co-op-translator). I když se snažíme o přesnost, mějte prosím na paměti, že automatické překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho původním jazyce by měl být považován za autoritativní zdroj. Pro důležité informace se doporučuje profesionální lidský překlad. Neodpovídáme za žádná nedorozumění nebo nesprávné interpretace vyplývající z použití tohoto překladu.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-13T07:00:54+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "cs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}