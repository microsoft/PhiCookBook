<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-03-27T12:21:57+00:00",
  "source_file": "md\\02.Application\\02.Code\\Phi3\\VSCodeExt\\HOL\\Apple\\02.PromptflowWithMLX.md",
  "language_code": "fa"
}
-->
# **آزمایش 2 - اجرای Prompt flow با Phi-3-mini در AIPC**

## **Prompt flow چیست**

Prompt flow مجموعه‌ای از ابزارهای توسعه است که برای ساده‌سازی چرخه کامل توسعه برنامه‌های هوش مصنوعی مبتنی بر LLM طراحی شده است. این چرخه شامل ایده‌پردازی، نمونه‌سازی، آزمایش، ارزیابی، استقرار در تولید و نظارت می‌شود. این ابزار مهندسی پرامپت را بسیار ساده‌تر کرده و به شما امکان می‌دهد برنامه‌های LLM با کیفیت تولید بسازید.

با استفاده از Prompt flow، شما قادر خواهید بود:

- جریان‌هایی ایجاد کنید که LLMها، پرامپت‌ها، کد پایتون و ابزارهای دیگر را در یک جریان کاری اجرایی به هم متصل کند.

- به‌راحتی جریان‌های خود، به‌ویژه تعامل با LLMها را اشکال‌زدایی و تکرار کنید.

- جریان‌های خود را ارزیابی کنید و معیارهای کیفیت و عملکرد را با مجموعه داده‌های بزرگ‌تر محاسبه کنید.

- آزمایش و ارزیابی را در سیستم CI/CD خود ادغام کنید تا از کیفیت جریان خود اطمینان حاصل کنید.

- جریان‌های خود را به پلتفرم سرویس‌دهی موردنظر خود استقرار دهید یا به‌راحتی در کد پایه برنامه خود ادغام کنید.

- (اختیاری اما به شدت توصیه می‌شود) با استفاده از نسخه ابری Prompt flow در Azure AI با تیم خود همکاری کنید.



## **ساخت جریان‌های کد تولیدی روی Apple Silicon**

***توجه***: اگر نصب محیط را کامل نکرده‌اید، لطفاً به [آزمایش 0 - نصب‌ها](./01.Installations.md) مراجعه کنید.

1. افزونه Prompt flow را در Visual Studio Code باز کرده و یک پروژه جریان خالی ایجاد کنید.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.fa.png)

2. پارامترهای ورودی و خروجی اضافه کنید و کد پایتون را به‌عنوان یک جریان جدید اضافه کنید.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.fa.png)

می‌توانید از این ساختار (flow.dag.yaml) برای ساخت جریان خود استفاده کنید:

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. مدل phi-3-mini را کمیت‌بندی کنید.

ما امیدواریم SLM را بهتر روی دستگاه‌های محلی اجرا کنیم. به طور کلی، مدل را کمیت‌بندی می‌کنیم (INT4، FP16، FP32).

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**توجه:** پوشه پیش‌فرض mlx_model است.

4. کد را در فایل ***Chat_With_Phi3.py*** اضافه کنید.

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. می‌توانید جریان را از طریق Debug یا Run آزمایش کنید تا بررسی کنید که کد تولیدی درست کار می‌کند یا خیر.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.fa.png)

5. جریان را به‌عنوان API توسعه در ترمینال اجرا کنید.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

می‌توانید آن را در Postman / Thunder Client آزمایش کنید.


### **نکات مهم**

1. اجرای اولیه زمان زیادی می‌برد. توصیه می‌شود مدل phi-3 را از طریق Hugging Face CLI دانلود کنید.

2. با توجه به محدودیت قدرت محاسباتی Intel NPU، توصیه می‌شود از Phi-3-mini-4k-instruct استفاده کنید.

3. ما از شتاب‌دهی Intel NPU برای تبدیل کمیت‌بندی INT4 استفاده می‌کنیم، اما اگر سرویس را دوباره اجرا کنید، باید پوشه‌های cache و nc_workshop را حذف کنید.



## **منابع**

1. یادگیری Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. یادگیری شتاب‌دهی Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. کد نمونه، دانلود [کد نمونه عامل محلی NPU](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم تا دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل اشتباهات یا نادرستی‌هایی باشد. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، توصیه می‌شود از ترجمه انسانی حرفه‌ای استفاده کنید. ما هیچ مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای اشتباه ناشی از استفاده از این ترجمه نداریم.