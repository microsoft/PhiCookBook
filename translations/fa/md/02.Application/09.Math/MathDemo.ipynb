{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e7ac41",
   "metadata": {},
   "source": [
    "## وارد کردن کتابخانه‌های مورد نیاز  \n",
    "کتابخانه‌های PyTorch و transformers را که برای بارگذاری و استفاده از مدل Phi-4 لازم هستند، وارد کنید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6caaf7",
   "metadata": {},
   "source": [
    "## تنظیم بذر تصادفی  \n",
    "بذر تصادفی را تنظیم کنید تا نتایج قابل تکرار در اجراهای مختلف تضمین شود.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ce6d9",
   "metadata": {},
   "source": [
    "## بارگذاری مدل و توکنایزر Phi-4-mini-flash-reasoning\n",
    "مدل Microsoft Phi-4-mini-flash-reasoning و توکنایزر مربوط به آن را از Hugging Face بارگذاری کنید. این مدل برای افزایش سرعت استنتاج روی CUDA بارگذاری خواهد شد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-4-mini-flash-reasoning\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"cuda\",\n",
    "   torch_dtype=\"auto\",\n",
    "   trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8789ea8",
   "metadata": {},
   "source": [
    "## آماده‌سازی پیام ورودی  \n",
    "یک پیام مکالمه‌ای با یک مسئله ریاضی معادله درجه دوم ایجاد کنید و آن را با قالب چت برای مدل قالب‌بندی کنید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "   \"role\": \"user\",\n",
    "   \"content\": \"How to solve 3*x^2+4*x+5=1?\"\n",
    "}]   \n",
    "inputs = tokenizer.apply_chat_template(\n",
    "   messages,\n",
    "   add_generation_prompt=True,\n",
    "   return_dict=True,\n",
    "   return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b87bf8",
   "metadata": {},
   "source": [
    "## تولید پاسخ  \n",
    "ایجاد یک پاسخ از مدل با استفاده از پارامترهای مشخص شده مانند دما و top_p برای کنترل تصادفی بودن خروجی.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "   **inputs.to(model.device),\n",
    "   max_new_tokens=32768,\n",
    "   temperature=0.6,\n",
    "   top_p=0.95,\n",
    "   do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088f0d",
   "metadata": {},
   "source": [
    "## تبدیل خروجی به متن\n",
    "تبدیل رشته‌های توکن تولید شده به متن قابل خواندن برای انسان، بدون نمایش توکن‌های ورودی اصلی، به‌طوری که فقط پاسخ مدل نمایش داده شود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "93d4d22a7a9ec7e7e668474526477813",
   "translation_date": "2025-09-12T15:26:11+00:00",
   "source_file": "md/02.Application/09.Math/MathDemo.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}