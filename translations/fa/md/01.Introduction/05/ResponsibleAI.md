<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "805b96b20152936d8f4c587d90d6e06e",
  "translation_date": "2025-05-07T14:43:30+00:00",
  "source_file": "md/01.Introduction/05/ResponsibleAI.md",
  "language_code": "fa"
}
-->
# **معرفی هوش مصنوعی مسئولانه**

[Microsoft Responsible AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=aiml-138114-kinfeylo) ابتکاری است که هدف آن کمک به توسعه‌دهندگان و سازمان‌ها برای ساخت سیستم‌های هوش مصنوعی شفاف، قابل اعتماد و پاسخگو است. این ابتکار راهنمایی‌ها و منابعی برای توسعه راه‌حل‌های هوش مصنوعی مسئولانه ارائه می‌دهد که با اصول اخلاقی مانند حریم خصوصی، انصاف و شفافیت همسو باشند. همچنین به برخی از چالش‌ها و بهترین روش‌های مرتبط با ساخت سیستم‌های هوش مصنوعی مسئولانه خواهیم پرداخت.

## مروری بر Microsoft Responsible AI

![RAIPrinciples](../../../../../translated_images/RAIPrinciples.bf9c9bc6ca160d336830630939a5130a22b3f9e1f633773562f83fed08a50520.fa.png)

**اصول اخلاقی**

Microsoft Responsible AI بر پایه مجموعه‌ای از اصول اخلاقی مانند حریم خصوصی، انصاف، شفافیت، پاسخگویی و ایمنی هدایت می‌شود. این اصول برای اطمینان از توسعه سیستم‌های هوش مصنوعی به روشی اخلاقی و مسئولانه طراحی شده‌اند.

**هوش مصنوعی شفاف**

Microsoft Responsible AI اهمیت شفافیت در سیستم‌های هوش مصنوعی را برجسته می‌کند. این شامل ارائه توضیحات واضح درباره نحوه عملکرد مدل‌های هوش مصنوعی و همچنین اطمینان از در دسترس بودن عمومی منابع داده و الگوریتم‌ها است.

**هوش مصنوعی پاسخگو**

[Microsoft Responsible AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=aiml-138114-kinfeylo) توسعه سیستم‌های هوش مصنوعی پاسخگو را ترویج می‌کند که می‌توانند بینشی درباره نحوه تصمیم‌گیری مدل‌های هوش مصنوعی ارائه دهند. این امر به کاربران کمک می‌کند تا خروجی‌های سیستم‌های هوش مصنوعی را بهتر درک کرده و به آن‌ها اعتماد کنند.

**شمولیت**

سیستم‌های هوش مصنوعی باید به گونه‌ای طراحی شوند که برای همه سودمند باشند. مایکروسافت هدف دارد هوش مصنوعی فراگیری ایجاد کند که دیدگاه‌های متنوع را در نظر گرفته و از تعصب یا تبعیض جلوگیری کند.

**قابلیت اطمینان و ایمنی**

اطمینان از اینکه سیستم‌های هوش مصنوعی قابل اعتماد و ایمن هستند، بسیار مهم است. مایکروسافت بر ساخت مدل‌های مقاوم که عملکرد ثابتی داشته و از نتایج مضر جلوگیری می‌کنند تمرکز دارد.

**انصاف در هوش مصنوعی**

Microsoft Responsible AI به این نکته واقف است که سیستم‌های هوش مصنوعی ممکن است اگر بر داده‌ها یا الگوریتم‌های مغرضانه آموزش ببینند، تعصبات را تداوم بخشند. این ابتکار راهنمایی‌هایی برای توسعه سیستم‌های هوش مصنوعی عادلانه ارائه می‌دهد که بر اساس عواملی مانند نژاد، جنسیت یا سن تبعیض قائل نشوند.

**حریم خصوصی و امنیت**

Microsoft Responsible AI اهمیت حفاظت از حریم خصوصی کاربران و امنیت داده‌ها در سیستم‌های هوش مصنوعی را تأکید می‌کند. این شامل پیاده‌سازی رمزگذاری قوی داده‌ها و کنترل‌های دسترسی، و همچنین بررسی منظم سیستم‌های هوش مصنوعی برای شناسایی آسیب‌پذیری‌ها است.

**پاسخگویی و مسئولیت‌پذیری**

Microsoft Responsible AI پاسخگویی و مسئولیت‌پذیری در توسعه و استقرار هوش مصنوعی را ترویج می‌کند. این شامل اطمینان از این است که توسعه‌دهندگان و سازمان‌ها از ریسک‌های بالقوه مرتبط با سیستم‌های هوش مصنوعی آگاه بوده و اقداماتی برای کاهش این ریسک‌ها انجام دهند.

## بهترین روش‌ها برای ساخت سیستم‌های هوش مصنوعی مسئولانه

**توسعه مدل‌های هوش مصنوعی با استفاده از داده‌های متنوع**

برای جلوگیری از تعصب در سیستم‌های هوش مصنوعی، استفاده از مجموعه داده‌های متنوع که نمایانگر دیدگاه‌ها و تجربیات مختلف باشد، اهمیت دارد.

**استفاده از تکنیک‌های هوش مصنوعی قابل توضیح**

تکنیک‌های هوش مصنوعی قابل توضیح می‌توانند به کاربران کمک کنند تا بفهمند مدل‌های هوش مصنوعی چگونه تصمیم‌گیری می‌کنند، که این امر اعتماد به سیستم را افزایش می‌دهد.

**بررسی منظم سیستم‌های هوش مصنوعی برای آسیب‌پذیری‌ها**

بازرسی‌های منظم سیستم‌های هوش مصنوعی می‌تواند به شناسایی ریسک‌ها و آسیب‌پذیری‌های احتمالی که نیاز به رسیدگی دارند کمک کند.

**پیاده‌سازی رمزگذاری قوی داده‌ها و کنترل‌های دسترسی**

رمزگذاری داده‌ها و کنترل‌های دسترسی می‌توانند به حفاظت از حریم خصوصی و امنیت کاربران در سیستم‌های هوش مصنوعی کمک کنند.

**رعایت اصول اخلاقی در توسعه هوش مصنوعی**

رعایت اصول اخلاقی مانند انصاف، شفافیت و پاسخگویی می‌تواند به ایجاد اعتماد در سیستم‌های هوش مصنوعی کمک کرده و اطمینان حاصل کند که آن‌ها به روشی مسئولانه توسعه یافته‌اند.

## استفاده از AI Foundry برای هوش مصنوعی مسئولانه

[Azure AI Foundry](https://ai.azure.com?WT.mc_id=aiml-138114-kinfeylo) یک پلتفرم قدرتمند است که به توسعه‌دهندگان و سازمان‌ها امکان می‌دهد برنامه‌های هوشمند، پیشرفته، آماده بازار و مسئولانه را به سرعت ایجاد کنند. در ادامه برخی از ویژگی‌ها و قابلیت‌های کلیدی Azure AI Foundry آورده شده است:

**APIها و مدل‌های آماده استفاده**

Azure AI Foundry APIها و مدل‌های پیش‌ساخته و قابل تنظیم ارائه می‌دهد. این موارد طیف وسیعی از وظایف هوش مصنوعی را پوشش می‌دهند، از جمله هوش مصنوعی مولد، پردازش زبان طبیعی برای گفتگوها، جستجو، نظارت، ترجمه، گفتار، بینایی و تصمیم‌گیری.

**Prompt Flow**

Prompt Flow در Azure AI Foundry به شما امکان می‌دهد تجربه‌های هوش مصنوعی مکالمه‌ای بسازید. این قابلیت به شما اجازه می‌دهد جریان‌های مکالمه را طراحی و مدیریت کنید، که ساخت چت‌بات‌ها، دستیارهای مجازی و سایر برنامه‌های تعاملی را آسان‌تر می‌کند.

**Retrieval Augmented Generation (RAG)**

RAG تکنیکی است که رویکردهای مبتنی بر بازیابی و مولد را ترکیب می‌کند. این روش کیفیت پاسخ‌های تولید شده را با بهره‌گیری از دانش پیشین (بازیابی) و تولید خلاقانه (تولید) بهبود می‌بخشد.

**معیارهای ارزیابی و نظارت برای هوش مصنوعی مولد**

Azure AI Foundry ابزارهایی برای ارزیابی و نظارت بر مدل‌های هوش مصنوعی مولد ارائه می‌دهد. می‌توانید عملکرد، انصاف و سایر معیارهای مهم را بررسی کنید تا استقرار مسئولانه را تضمین نمایید. علاوه بر این، اگر داشبوردی ساخته‌اید، می‌توانید از رابط کاربری بدون کد در Azure Machine Learning Studio برای سفارشی‌سازی و ایجاد داشبورد هوش مصنوعی مسئولانه و کارت امتیازی مرتبط بر اساس [Responsible AI Toolbox](https://responsibleaitoolbox.ai/?WT.mc_id=aiml-138114-kinfeylo) کتابخانه‌های پایتون استفاده کنید. این کارت امتیازی به شما کمک می‌کند نکات کلیدی مرتبط با انصاف، اهمیت ویژگی‌ها و سایر ملاحظات استقرار مسئولانه را با ذینفعان فنی و غیر فنی به اشتراک بگذارید.

برای استفاده از AI Foundry با هوش مصنوعی مسئولانه، می‌توانید این بهترین روش‌ها را دنبال کنید:

**تعریف مسئله و اهداف سیستم هوش مصنوعی خود**

قبل از شروع فرآیند توسعه، مهم است که مسئله یا هدفی که سیستم هوش مصنوعی شما قصد حل آن را دارد به‌وضوح تعریف کنید. این کار به شما کمک می‌کند داده‌ها، الگوریتم‌ها و منابع لازم برای ساخت مدل مؤثر را شناسایی کنید.

**جمع‌آوری و پیش‌پردازش داده‌های مرتبط**

کیفیت و کمیت داده‌های استفاده شده در آموزش سیستم هوش مصنوعی تأثیر زیادی بر عملکرد آن دارد. بنابراین، مهم است که داده‌های مرتبط جمع‌آوری، پاک‌سازی، پیش‌پردازش شده و اطمینان حاصل شود که نماینده جمعیت یا مسئله مورد نظر هستند.

**انتخاب ارزیابی مناسب**

الگوریتم‌های مختلفی برای ارزیابی وجود دارد. انتخاب مناسب‌ترین الگوریتم بر اساس داده‌ها و مسئله شما اهمیت دارد.

**ارزیابی و تفسیر مدل**

پس از ساخت مدل هوش مصنوعی، مهم است که عملکرد آن را با استفاده از معیارهای مناسب ارزیابی کرده و نتایج را به صورت شفاف تفسیر کنید. این کار به شما کمک می‌کند هرگونه تعصب یا محدودیت در مدل را شناسایی کرده و در صورت نیاز بهبود دهید.

**اطمینان از شفافیت و قابلیت توضیح**

سیستم‌های هوش مصنوعی باید شفاف و قابل توضیح باشند تا کاربران بتوانند درک کنند چگونه کار می‌کنند و چگونه تصمیم‌گیری می‌شود. این موضوع به ویژه برای کاربردهایی که تأثیرات قابل توجهی بر زندگی انسان‌ها دارند، مانند حوزه سلامت، مالی و حقوقی اهمیت دارد.

**نظارت و به‌روزرسانی مدل**

سیستم‌های هوش مصنوعی باید به طور مداوم نظارت و به‌روزرسانی شوند تا اطمینان حاصل شود که در طول زمان دقیق و مؤثر باقی می‌مانند. این امر نیازمند نگهداری، آزمایش و آموزش مجدد مدل به صورت مستمر است.

در پایان، Microsoft Responsible AI ابتکاری است که به توسعه‌دهندگان و سازمان‌ها کمک می‌کند سیستم‌های هوش مصنوعی شفاف، قابل اعتماد و پاسخگو بسازند. به یاد داشته باشید که اجرای هوش مصنوعی مسئولانه حیاتی است و Azure AI Foundry هدف دارد آن را برای سازمان‌ها عملی کند. با پیروی از اصول اخلاقی و بهترین روش‌ها، می‌توانیم اطمینان حاصل کنیم که سیستم‌های هوش مصنوعی به روشی مسئولانه توسعه یافته و به کار گرفته می‌شوند که به نفع کل جامعه است.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطا یا نواقص باشند. سند اصلی به زبان مادری خود به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئول هیچ گونه سوء تفاهم یا تفسیر نادرستی که از استفاده از این ترجمه ناشی شود، نیستیم.