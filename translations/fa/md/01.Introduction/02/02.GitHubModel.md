<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-07-16T18:57:21+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "fa"
}
-->
## خانواده Phi در مدل‌های GitHub

به [مدل‌های GitHub](https://github.com/marketplace/models) خوش آمدید! همه چیز آماده است تا شما مدل‌های هوش مصنوعی میزبانی شده روی Azure AI را کاوش کنید.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.aa43c51c36454747ca1cc1ffa799db02cc66b4fb7e8495311701adb072442df8.fa.png)

برای اطلاعات بیشتر درباره مدل‌های موجود در مدل‌های GitHub، به [بازار مدل‌های GitHub](https://github.com/marketplace/models) مراجعه کنید.

## مدل‌های موجود

هر مدل دارای یک محیط آزمایشی اختصاصی و کد نمونه است

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.cf6a9f1106e048535478f17ed0078551c3959884e4083eb62a895bb089dd831c.fa.png)

### خانواده Phi در کاتالوگ مدل‌های GitHub

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## شروع به کار

چند نمونه پایه آماده اجرا برای شما وجود دارد. می‌توانید آن‌ها را در پوشه samples پیدا کنید. اگر می‌خواهید مستقیماً به زبان مورد علاقه‌تان بروید، نمونه‌ها در زبان‌های زیر موجود هستند:

- Python  
- JavaScript  
- C#  
- Java  
- cURL  

همچنین یک محیط Codespaces اختصاصی برای اجرای نمونه‌ها و مدل‌ها وجود دارد.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.150220a802da6fb67944ad93c1a4c7b8a9811e43d77879a149ecf54c02928c6b.fa.png)

## کد نمونه

در ادامه چند قطعه کد نمونه برای چند مورد استفاده آورده شده است. برای اطلاعات بیشتر درباره Azure AI Inference SDK، مستندات کامل و نمونه‌ها را ببینید.

## راه‌اندازی

1. یک توکن دسترسی شخصی بسازید  
نیازی نیست به توکن هیچ دسترسی‌ای بدهید. توجه داشته باشید که توکن به یک سرویس مایکروسافت ارسال خواهد شد.

برای استفاده از قطعات کد زیر، یک متغیر محیطی بسازید و توکن خود را به عنوان کلید برای کد کلاینت تنظیم کنید.

اگر از bash استفاده می‌کنید:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
اگر در powershell هستید:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

اگر از خط فرمان ویندوز استفاده می‌کنید:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## نمونه Python

### نصب وابستگی‌ها  
Azure AI Inference SDK را با pip نصب کنید (نیازمند: Python >=3.8):

```
pip install azure-ai-inference
```  
### اجرای یک نمونه کد ساده

این نمونه یک فراخوانی ساده به API تکمیل چت را نشان می‌دهد. این نمونه از نقطه انتهایی استنتاج مدل هوش مصنوعی GitHub و توکن GitHub شما استفاده می‌کند. فراخوانی به صورت همزمان است.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### اجرای یک مکالمه چند مرحله‌ای

این نمونه یک مکالمه چند مرحله‌ای با API تکمیل چت را نشان می‌دهد. هنگام استفاده از مدل برای یک برنامه چت، باید تاریخچه آن مکالمه را مدیریت کرده و آخرین پیام‌ها را به مدل ارسال کنید.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### پخش خروجی به صورت جریان

برای تجربه کاربری بهتر، می‌خواهید پاسخ مدل را به صورت جریان دریافت کنید تا اولین توکن زودتر نمایش داده شود و مجبور نباشید برای پاسخ‌های طولانی منتظر بمانید.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## استفاده رایگان و محدودیت‌های نرخ برای مدل‌های GitHub

![Model Catalog](../../../../../translated_images/GitHub_Model.ca6c125cb3117d0ea7c2e204b066ee4619858d28e7b1a419c262443c5e9a2d5b.fa.png)

[محدودیت‌های نرخ برای محیط آزمایشی و استفاده رایگان از API](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) به شما کمک می‌کند تا با مدل‌ها آزمایش کنید و برنامه هوش مصنوعی خود را نمونه‌سازی کنید. برای استفاده فراتر از این محدودیت‌ها و مقیاس‌بندی برنامه خود، باید منابع را از یک حساب Azure تهیه کنید و به جای توکن دسترسی شخصی GitHub، از آنجا احراز هویت کنید. نیازی به تغییر چیز دیگری در کد خود ندارید. برای آشنایی با نحوه عبور از محدودیت‌های رایگان در Azure AI، این لینک را ببینید.

### افشاسازی‌ها

به یاد داشته باشید هنگام تعامل با مدل، در حال آزمایش هوش مصنوعی هستید، بنابراین امکان اشتباه در محتوا وجود دارد.

این ویژگی محدودیت‌های مختلفی دارد (از جمله درخواست‌ها در دقیقه، درخواست‌ها در روز، توکن‌ها در هر درخواست و درخواست‌های همزمان) و برای استفاده در موارد تولیدی طراحی نشده است.

مدل‌های GitHub از Azure AI Content Safety استفاده می‌کنند. این فیلترها به عنوان بخشی از تجربه مدل‌های GitHub قابل غیرفعال شدن نیستند. اگر تصمیم دارید مدل‌ها را از طریق یک سرویس پولی به کار ببرید، لطفاً فیلترهای محتوای خود را مطابق نیازهای خود تنظیم کنید.

این سرویس تحت شرایط پیش‌انتشار GitHub قرار دارد.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما در تلاش برای دقت هستیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان بومی خود باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئول هیچ گونه سوءتفاهم یا تفسیر نادرستی که از استفاده از این ترجمه ناشی شود، نیستیم.