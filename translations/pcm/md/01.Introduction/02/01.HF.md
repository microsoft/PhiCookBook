<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-12-22T00:10:17+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "pcm"
}
-->
# **How to take use Phi Family for Hugging Face**

[Hugging Face](https://huggingface.co/) na one popular AI community wey get plenti data and open-source model resources. Different manufacturers dey release open-source LLM and SLM for Hugging Face, like Microsoft, Meta, Mistral, Apple, Google, and so on.

Microsoft Phi Family don release for Hugging Face. Developers fit download the Phi Family model wey match dia scenarios and businessesã€‚Besides deploying Phi Pytorch models on Hugging Face, we also don release quantized models, using GGUF and ONNX formats make end users get choice.

## **How to download models for Hugging Face**

You fit download Phi family model with dis link

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

You fit download the model in different ways, like install the ***Hugging face CLI SDK*** or use ***git clone***.

### **How to use Hugging Face CLI to download Phi Family model**

- Install Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Use huggingface-cli to login

Login to Hugging Face with [User Access Token](https://huggingface.co/docs/hub/security-tokens) wey dey your [Settings page](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Download 

You fit download di model and save am to cache 

```bash

huggingface-cli download microsoft/phi-4

```

You fit set di location to your own special location


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **How to use git clone to download Phi Family model**

You fit use ***git clone*** to download di model too

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Sample dem - Inference Microsoft Phi-4**

- **How to install the transformers library**

```bash

pip install transformers -U

```

- **How to run dis code for VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Disclaimer:
Dis document don translate wit AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). We dey try make am correct, but abeg note say automatic machine translations fit get mistakes or no too accurate. Di original document for im own language suppose be di main/official source. If na important information, make professional human translator handle am. We no go responsible for any misunderstanding or wrong interpretation wey fit happen because of this translation.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->