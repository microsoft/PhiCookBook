<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-12-21T23:36:54+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "pcm"
}
-->
## How to Start wit Phi-Family Models for Foundry Local

### Intro to Foundry Local

Foundry Local na powerful on-device AI inference solution wey dey bring enterprise-grade AI capabilities straight to your local hardware. Dis tutorial go guide you step-by-step how to set up and use Phi-Family models with Foundry Local, so you go get full control of your AI workloads, keep privacy, and cut cost.

Foundry Local dey give better performance, privacy, customization, and cost benefits by running AI models for your own device. E dey integrate well with your current workflows and apps through an easy CLI, SDK, and REST API.


![architecture](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7d68815ddb0153503587142ff32e6997041c7cf0c9df24b49.pcm.png)

### Why You Go Choose Foundry Local?

Make you sabi the benefits wey Foundry Local get so you fit choose correct strategy for your AI deployment:

- **Inference wey dey for device:** Run models locally for your own hardware, so you go reduce cost and keep all your data for your device.

- **Model Customization:** Choose from preset models or use your own make e match your specific requirements and use cases.

- **Cost Efficiency:** Remove the ongoing cloud service costs by using the hardware wey you don get, make AI dey more affordable.

- **Seamless Integration:** Connect to your apps via SDK, API endpoints, or the CLI, and e easy to scale go Azure AI Foundry when your needs dey grow.

> **Getting Started Note:** Dis tutorial dey focus on using Foundry Local with CLI and SDK. You go learn both ways make you fit pick the best method for your use case.

## Part 1: Setting Up Foundry Local CLI

### Step 1: Installation

The Foundry Local CLI na the gateway wey go help you manage and run AI models locally. Make we start by installing am for your system.

**Supported Platforms:** Windows and macOS

For detailed installation instructions, please refer to the [official Foundry Local documentation](https://github.com/microsoft/Foundry-Local/blob/main/README.md).

### Step 2: Exploring Available Models

Once you don install Foundry Local CLI, you fit check wetin models dey available for your use case. This command go show you all the models wey dem support:


```bash
foundry model list
```

### Step 3: Understanding Phi Family Models

The Phi Family get different models wey dem optimize for different use cases and hardware setups. Below na the Phi models wey dey available inside Foundry Local:

**Available Phi Models:** 

- **phi-3.5-mini** - Small model for basic tasks
- **phi-3-mini-128k** - Extended context version for longer conversations
- **phi-3-mini-4k** - Standard context model for general use
- **phi-4** - Advanced model with better capabilities
- **phi-4-mini** - Lightweight version of Phi-4
- **phi-4-mini-reasoning** - Special model for complex reasoning tasks

> **Hardware Compatibility:** Each model fit configure to use different hardware acceleration (CPU, GPU) based on wetin your system fit do.

### Step 4: Running Your First Phi Model

Make we start with one practical example. We go run the `phi-4-mini-reasoning` model, because e sharp for solving complex problems step-by-step.


**Command to run the model:**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **First-Time Setup:** When you dey run model for the first time, Foundry Local go automatically download am to your local device. Download time go depend on your network speed, so make you patient during the initial setup.

### Step 5: Testing the Model with a Real Problem

Now make we test the model with one classic logic problem to see how e dey do step-by-step reasoning:

**Example Problem:**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**Expected Behavior:** The model suppose break this problem down into logical steps, use the fact say pheasants get 2 legs and rabbits get 4 legs to solve the system of equations.

**Results:**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d916093866d4df99190150d4198fd33ab79e586f9d6f5403089.pcm.png)

## Part 2: Building Applications with Foundry Local SDK

### Why Use the SDK?

Even though CLI perfect for testing and quick interactions, the SDK make you fit integrate Foundry Local inside your apps programmatically. Dis one open plenty possibilities like:

- Build custom AI-powered applications
- Create automated workflows
- Add AI capabilities into systems wey don already dey
- Develop chatbots and interactive tools

### Supported Programming Languages

Foundry Local dey provide SDK support for different programming languages to match how you like develop:

**ðŸ“¦ Available SDKs:**

- **C# (.NET):** [SDK Docs & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)
- **Python:** [SDK Docs & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **JavaScript:** [SDK Docs & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)
- **Rust:** [SDK Docs & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### Next Steps

1. **Choose your preferred SDK** based on the development environment wey you dey use
2. **Follow the SDK-specific documentation** for step-by-step implementation guides
3. **Start with simple examples** before you build complex applications
4. **Explore the sample code** wey each SDK repository provide

## Conclusion

You don now learn how to:
- âœ… Install and set up Foundry Local CLI
- âœ… Discover and run Phi Family models
- âœ… Test models with real-world problems
- âœ… Understand SDK options for building applications

Foundry Local na solid foundation to bring AI capabilities straight to your local environment, give you control over performance, privacy, and cost, and still give you the flexibility to scale to cloud solutions when you need am.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Small warning:
Dis document na AI translation service Co-op Translator (https://github.com/Azure/co-op-translator) translate. We dey try make am correct, but make you sabi say automated translations fit get mistakes or no too correct. The original document for im original language na the main official source. If na important information, better make professional human translator translate am. We no go responsible for any misunderstanding or wrong meaning wey fit come because you use this translation.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->