<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8cdc17ce0f10535da30b53d23fe1a795",
  "translation_date": "2025-12-21T23:11:04+00:00",
  "source_file": "md/01.Introduction/01/01.Hardwaresupport.md",
  "language_code": "pcm"
}
-->
# Phi Hardware Sapot

Microsoft Phi don optimize for ONNX Runtime and e dey support Windows DirectML. E dey work well across different kain hardware, including GPUs, CPUs, and even mobile devices. 

## Device Hardware 
Specifically, the supported hardware includes:

- GPU SKU: RTX 4090 (DirectML)
- GPU SKU: 1 A100 80GB (CUDA)
- CPU SKU: Standard F64s v2 (64 vCPUs, 128 GiB memory)

## Mobile SKU

- Android - Samsung Galaxy S21
- Apple iPhone 14 or higher A16/A17 Processor

## Phi Hardware Specification

- Minimum configuration wey you need.
- Windows: DirectX 12-capable GPU and at least 4GB of combined RAM

CUDA: NVIDIA GPU wey get Compute Capability >= 7.02

![Hardware Sapot](../../../../../translated_images/01.phihardware.5d51b2377cba18afc6949074542f290c56bb278dac3f4f86302aca6d80fffeb9.pcm.png)

## How to run onnxruntime for many GPUs

Right now, Phi ONNX models wey dey available na only for 1 GPU. E possible to support multi-gpu for Phi model, but ORT with 2 gpu no dey guarantee say e go give more throughput compared to 2 instance of ort. Please see [ONNX Runtime](https://onnxruntime.ai/) for the latest updates.

For [Build 2024 the GenAI ONNX Team](https://youtu.be/WLW4SE8M9i8?si=EtG04UwDvcjunyfC) dem announce say dem don enable multi-instance instead of multi-gpu for Phi models. 

At present this allow you run one onnnxruntime or onnxruntime-genai instance with CUDA_VISIBLE_DEVICES environment variable like this.

```Python
CUDA_VISIBLE_DEVICES=0 python infer.py
CUDA_VISIBLE_DEVICES=1 python infer.py
```

You fit explore Phi more for [Azure AI Foundry](https://ai.azure.com)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Disclaimer:
Dis document don translate wit AI translation service [Co-op Translator] (https://github.com/Azure/co-op-translator). Even though we dey try make am correct, abeg note say automatic translations fit get errors or wrong parts. Di original document for im own language na im be di authoritative source. If na important information, better make professional human translator do am. We no dey liable for any misunderstanding or wrong interpretation wey fit come from this translation.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->