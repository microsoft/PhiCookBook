<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:46:12+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "vi"
}
-->
# Tinh chá»‰nh Phi3 báº±ng Olive

Trong vÃ­ dá»¥ nÃ y, báº¡n sáº½ sá»­ dá»¥ng Olive Ä‘á»ƒ:

1. Tinh chá»‰nh má»™t adapter LoRA Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c cá»¥m tá»« thÃ nh Buá»“n, Vui, Sá»£, Ngáº¡c nhiÃªn.
1. Gá»™p trá»ng sá»‘ adapter vÃ o mÃ´ hÃ¬nh gá»‘c.
1. Tá»‘i Æ°u vÃ  lÆ°á»£ng tá»­ hÃ³a mÃ´ hÃ¬nh thÃ nh `int4`.

ChÃºng tÃ´i cÅ©ng sáº½ hÆ°á»›ng dáº«n báº¡n cÃ¡ch suy luáº­n mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c tinh chá»‰nh báº±ng ONNX Runtime (ORT) Generate API.

> **âš ï¸ Äá»ƒ tinh chá»‰nh, báº¡n cáº§n cÃ³ GPU phÃ¹ há»£p â€“ vÃ­ dá»¥ nhÆ° A10, V100, A100.**

## ğŸ’¾ CÃ i Ä‘áº·t

Táº¡o má»™t mÃ´i trÆ°á»ng áº£o Python má»›i (vÃ­ dá»¥, sá»­ dá»¥ng `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Tiáº¿p theo, cÃ i Ä‘áº·t Olive vÃ  cÃ¡c phá»¥ thuá»™c cho quy trÃ¬nh tinh chá»‰nh:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## ğŸ§ª Tinh chá»‰nh Phi3 báº±ng Olive
[Táº­p tin cáº¥u hÃ¬nh Olive](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) chá»©a má»™t *quy trÃ¬nh* vá»›i cÃ¡c *bÆ°á»›c* sau:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

á» cáº¥p Ä‘á»™ tá»•ng quan, quy trÃ¬nh nÃ y sáº½:

1. Tinh chá»‰nh Phi3 (trong 150 bÆ°á»›c, báº¡n cÃ³ thá»ƒ thay Ä‘á»•i) sá»­ dá»¥ng dá»¯ liá»‡u [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. Gá»™p trá»ng sá»‘ adapter LoRA vÃ o mÃ´ hÃ¬nh gá»‘c. Káº¿t quáº£ lÃ  báº¡n sáº½ cÃ³ má»™t mÃ´ hÃ¬nh duy nháº¥t á»Ÿ Ä‘á»‹nh dáº¡ng ONNX.
1. Model Builder sáº½ tá»‘i Æ°u mÃ´ hÃ¬nh cho ONNX runtime *vÃ * lÆ°á»£ng tá»­ hÃ³a mÃ´ hÃ¬nh thÃ nh `int4`.

Äá»ƒ cháº¡y quy trÃ¬nh, thá»±c thi:

```bash
olive run --config phrase-classification.json
```

Khi Olive hoÃ n thÃ nh, mÃ´ hÃ¬nh Phi3 Ä‘Ã£ Ä‘Æ°á»£c tinh chá»‰nh vÃ  tá»‘i Æ°u á»Ÿ Ä‘á»‹nh dáº¡ng `int4` sáº½ cÃ³ táº¡i: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## ğŸ§‘â€ğŸ’» TÃ­ch há»£p Phi3 Ä‘Ã£ tinh chá»‰nh vÃ o á»©ng dá»¥ng cá»§a báº¡n

Äá»ƒ cháº¡y á»©ng dá»¥ng:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Pháº£n há»“i sáº½ lÃ  má»™t phÃ¢n loáº¡i Ä‘Æ¡n giáº£n cho cá»¥m tá»« (Buá»“n/Vui/Sá»£/Ngáº¡c nhiÃªn).

**TuyÃªn bá»‘ tá»« chá»‘i trÃ¡ch nhiá»‡m**:  
TÃ i liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch báº±ng dá»‹ch vá»¥ dá»‹ch thuáº­t AI [Co-op Translator](https://github.com/Azure/co-op-translator). Máº·c dÃ¹ chÃºng tÃ´i cá»‘ gáº¯ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c, xin lÆ°u Ã½ ráº±ng báº£n dá»‹ch tá»± Ä‘á»™ng cÃ³ thá»ƒ chá»©a lá»—i hoáº·c khÃ´ng chÃ­nh xÃ¡c. TÃ i liá»‡u gá»‘c báº±ng ngÃ´n ngá»¯ gá»‘c nÃªn Ä‘Æ°á»£c xem lÃ  nguá»“n tham kháº£o chÃ­nh thá»©c. Äá»‘i vá»›i thÃ´ng tin quan trá»ng, nÃªn sá»­ dá»¥ng dá»‹ch vá»¥ dá»‹ch thuáº­t chuyÃªn nghiá»‡p do con ngÆ°á»i thá»±c hiá»‡n. ChÃºng tÃ´i khÃ´ng chá»‹u trÃ¡ch nhiá»‡m Ä‘á»‘i vá»›i báº¥t ká»³ sá»± hiá»ƒu láº§m hoáº·c giáº£i thÃ­ch sai nÃ o phÃ¡t sinh tá»« viá»‡c sá»­ dá»¥ng báº£n dá»‹ch nÃ y.