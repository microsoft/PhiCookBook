<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-05-09T19:23:34+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "el"
}
-->
# **Εργαστήριο 2 - Εκτέλεση Prompt flow με Phi-3-mini σε AIPC**

## **Τι είναι το Prompt flow**

Το Prompt flow είναι μια σουίτα εργαλείων ανάπτυξης σχεδιασμένη να απλοποιεί τον πλήρη κύκλο ανάπτυξης εφαρμογών AI βασισμένων σε LLM, από τη σύλληψη ιδέας, το πρωτότυπο, τη δοκιμή, την αξιολόγηση μέχρι την παραγωγική ανάπτυξη και την παρακολούθηση. Κάνει την τεχνική δημιουργία prompts πολύ πιο εύκολη και σου επιτρέπει να φτιάχνεις εφαρμογές LLM με ποιότητα παραγωγής.

Με το prompt flow, θα μπορείς να:

- Δημιουργείς ροές που συνδέουν LLMs, prompts, κώδικα Python και άλλα εργαλεία σε μια εκτελέσιμη ροή εργασίας.

- Εντοπίζεις σφάλματα και επαναλαμβάνεις τις ροές σου, ειδικά την αλληλεπίδραση με τα LLMs, με ευκολία.

- Αξιολογείς τις ροές σου, υπολογίζοντας δείκτες ποιότητας και απόδοσης με μεγαλύτερα σύνολα δεδομένων.

- Ενσωματώνεις τη δοκιμή και αξιολόγηση στο CI/CD σύστημά σου για να εξασφαλίσεις την ποιότητα της ροής σου.

- Αναπτύσσεις τις ροές σου στην πλατφόρμα εξυπηρέτησης που επιλέγεις ή τις ενσωματώνεις εύκολα στον κώδικα της εφαρμογής σου.

- (Προαιρετικά αλλά πολύ συνιστώμενο) Συνεργάζεσαι με την ομάδα σου αξιοποιώντας την cloud έκδοση του Prompt flow στο Azure AI.

## **Τι είναι το AIPC**

Ένας AI PC διαθέτει CPU, GPU και NPU, καθένα με συγκεκριμένες δυνατότητες επιτάχυνσης AI. Το NPU, ή νευρωνική μονάδα επεξεργασίας, είναι ένας εξειδικευμένος επιταχυντής που αναλαμβάνει εργασίες τεχνητής νοημοσύνης (AI) και μηχανικής μάθησης (ML) απευθείας στον υπολογιστή σου, αντί να στέλνει δεδομένα για επεξεργασία στο cloud. Η GPU και η CPU μπορούν επίσης να χειριστούν αυτά τα φορτία εργασίας, αλλά το NPU είναι ιδιαίτερα αποτελεσματικό σε υπολογισμούς AI χαμηλής κατανάλωσης ενέργειας. Ο AI PC αντιπροσωπεύει μια θεμελιώδη αλλαγή στον τρόπο λειτουργίας των υπολογιστών μας. Δεν είναι μια λύση για πρόβλημα που δεν υπήρχε πριν, αλλά υπόσχεται μεγάλη βελτίωση στην καθημερινή χρήση του υπολογιστή.

Πώς λειτουργεί; Σε σύγκριση με την γενετική AI και τα τεράστια μεγάλα γλωσσικά μοντέλα (LLMs) που έχουν εκπαιδευτεί σε τεράστια δημόσια δεδομένα, η AI που τρέχει στον υπολογιστή σου είναι πιο προσιτή σε κάθε επίπεδο. Η ιδέα είναι πιο κατανοητή και επειδή εκπαιδεύεται στα δικά σου δεδομένα, χωρίς να χρειάζεται πρόσβαση στο cloud, τα οφέλη είναι άμεσα ελκυστικά σε ένα ευρύτερο κοινό.

Βραχυπρόθεσμα, ο κόσμος του AI PC περιλαμβάνει προσωπικούς βοηθούς και μικρότερα μοντέλα AI που τρέχουν απευθείας στον υπολογιστή σου, χρησιμοποιώντας τα δεδομένα σου για να προσφέρουν προσωπικές, ιδιωτικές και πιο ασφαλείς βελτιώσεις AI σε καθημερινές εργασίες – όπως η λήψη πρακτικών συναντήσεων, η οργάνωση πρωταθλήματος fantasy football, η αυτοματοποίηση βελτιώσεων σε φωτογραφίες και βίντεο, ή η δημιουργία του τέλειου προγράμματος για οικογενειακές συγκεντρώσεις βάσει των ωρών άφιξης και αναχώρησης όλων.

## **Δημιουργία ροών κώδικα γεννήτριας σε AIPC**

***Note*** ：Αν δεν έχεις ολοκληρώσει την εγκατάσταση του περιβάλλοντος, παρακαλώ επισκέψου [Lab 0 -Installations](./01.Installations.md)

1. Άνοιξε την επέκταση Prompt flow στο Visual Studio Code και δημιούργησε ένα κενό project ροής

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.el.png)

2. Πρόσθεσε παραμέτρους Inputs και Outputs και πρόσθεσε Python Code ως νέα ροή

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.el.png)

Μπορείς να ανατρέξεις σε αυτή τη δομή (flow.dag.yaml) για να κατασκευάσεις τη ροή σου

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Πρόσθεσε κώδικα στο ***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Μπορείς να δοκιμάσεις τη ροή από το Debug ή Run για να ελέγξεις αν ο κώδικας γεννήθηκε σωστά

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.el.png)

5. Τρέξε τη ροή ως development API στο τερματικό

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Μπορείς να το δοκιμάσεις στο Postman / Thunder Client

### **Note**

1. Η πρώτη εκτέλεση διαρκεί αρκετά. Συνιστάται να κατεβάσεις το μοντέλο phi-3 μέσω Hugging face CLI.

2. Λόγω των περιορισμένων υπολογιστικών δυνατοτήτων του Intel NPU, προτείνεται η χρήση Phi-3-mini-4k-instruct

3. Χρησιμοποιούμε την επιτάχυνση Intel NPU για την ποσοτικοποίηση σε INT4, αλλά αν ξανατρέξεις την υπηρεσία, χρειάζεται να διαγράψεις τους φακέλους cache και nc_workshop.

## **Πόροι**

1. Μάθε για το Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Μάθε για την Επιτάχυνση Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Δείγμα Κώδικα, κατέβασε [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Αποποίηση ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που προσπαθούμε για ακρίβεια, παρακαλούμε να λάβετε υπόψη ότι οι αυτόματες μεταφράσεις μπορεί να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη γλώσσα του θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για οποιεσδήποτε παρεξηγήσεις ή λανθασμένες ερμηνείες προκύψουν από τη χρήση αυτής της μετάφρασης.