<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "92e7dac1e5af0dd7c94170fdaf6860fe",
  "translation_date": "2025-05-09T18:52:53+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md",
  "language_code": "el"
}
-->
# Χρήση Windows GPU για τη δημιουργία λύσης Prompt flow με Phi-3.5-Instruct ONNX

Το ακόλουθο έγγραφο είναι ένα παράδειγμα για το πώς να χρησιμοποιήσετε το PromptFlow με ONNX (Open Neural Network Exchange) για την ανάπτυξη εφαρμογών AI βασισμένων σε μοντέλα Phi-3.

Το PromptFlow είναι ένα σύνολο εργαλείων ανάπτυξης σχεδιασμένο να απλοποιεί τον πλήρη κύκλο ανάπτυξης εφαρμογών AI βασισμένων σε LLM (Large Language Model), από τη σύλληψη ιδέας και το πρωτότυπο μέχρι τον έλεγχο και την αξιολόγηση.

Με την ενσωμάτωση του PromptFlow με το ONNX, οι προγραμματιστές μπορούν:

- Να βελτιστοποιήσουν την απόδοση του μοντέλου: Να αξιοποιήσουν το ONNX για αποδοτική εκτέλεση και ανάπτυξη μοντέλων.
- Να απλοποιήσουν την ανάπτυξη: Να χρησιμοποιήσουν το PromptFlow για τη διαχείριση της ροής εργασιών και την αυτοματοποίηση επαναλαμβανόμενων εργασιών.
- Να ενισχύσουν τη συνεργασία: Να διευκολύνουν καλύτερη συνεργασία μεταξύ των μελών της ομάδας παρέχοντας ένα ενιαίο περιβάλλον ανάπτυξης.

**Prompt flow** είναι ένα σύνολο εργαλείων ανάπτυξης που απλοποιεί τον πλήρη κύκλο ανάπτυξης εφαρμογών AI βασισμένων σε LLM, από τη σύλληψη ιδέας, το πρωτότυπο, τον έλεγχο, την αξιολόγηση μέχρι την παραγωγική ανάπτυξη και παρακολούθηση. Κάνει την τεχνική της prompt engineering πολύ πιο εύκολη και σας επιτρέπει να δημιουργήσετε εφαρμογές LLM με ποιότητα παραγωγής.

Το Prompt flow μπορεί να συνδεθεί με OpenAI, Azure OpenAI Service, και προσαρμόσιμα μοντέλα (Huggingface, τοπικά LLM/SLM). Ελπίζουμε να αναπτύξουμε το κβαντισμένο μοντέλο Phi-3.5 ONNX σε τοπικές εφαρμογές. Το Prompt flow μπορεί να μας βοηθήσει να σχεδιάσουμε καλύτερα την επιχείρησή μας και να ολοκληρώσουμε τοπικές λύσεις βασισμένες σε Phi-3.5. Σε αυτό το παράδειγμα, θα συνδυάσουμε τη Βιβλιοθήκη ONNX Runtime GenAI για να ολοκληρώσουμε τη λύση Prompt flow βασισμένη σε Windows GPU.

## **Εγκατάσταση**

### **ONNX Runtime GenAI για Windows GPU**

Διαβάστε αυτόν τον οδηγό για να ρυθμίσετε το ONNX Runtime GenAI για Windows GPU [click here](./ORTWindowGPUGuideline.md)

### **Ρύθμιση Prompt flow στο VSCode**

1. Εγκαταστήστε την επέκταση Prompt flow για VS Code

![pfvscode](../../../../../../translated_images/pfvscode.79f42ae5dd93ed35c19d6d978ae75831fef40e0b8440ee48b893b5a0597d2260.el.png)

2. Μετά την εγκατάσταση της επέκτασης Prompt flow για VS Code, κάντε κλικ στην επέκταση και επιλέξτε **Installation dependencies**. Ακολουθήστε αυτόν τον οδηγό για να εγκαταστήσετε το Prompt flow SDK στο περιβάλλον σας.

![pfsetup](../../../../../../translated_images/pfsetup.0c82d99c7760aac29833b37faf4329e67e22279b1c5f37a73724dfa9ebaa32ee.el.png)

3. Κατεβάστε τον [Sample Code](../../../../../../code/09.UpdateSamples/Aug/pf/onnx_inference_pf) και ανοίξτε το δείγμα με το VS Code

![pfsample](../../../../../../translated_images/pfsample.7bf40b133a558d86356dd6bc0e480bad2659d9c5364823dae9b3e6784e6f2d25.el.png)

4. Ανοίξτε το **flow.dag.yaml** για να επιλέξετε το περιβάλλον Python σας

![pfdag](../../../../../../translated_images/pfdag.c5eb356fa3a96178cd594de9a5da921c4bbe646a9946f32aa20d344ccbeb51a0.el.png)

   Ανοίξτε το **chat_phi3_ort.py** για να αλλάξετε τη θέση του μοντέλου Phi-3.5-instruct ONNX

![pfphi](../../../../../../translated_images/pfphi.fff4b0afea47c92c8481174dbf3092823906fca5b717fc642f78947c3e5bbb39.el.png)

5. Εκτελέστε το prompt flow για δοκιμή

Ανοίξτε το **flow.dag.yaml** και κάντε κλικ στον οπτικό επεξεργαστή

![pfv](../../../../../../translated_images/pfv.7af6ecd65784a98558b344ba69b5ba6233876823fb435f163e916a632394fc1e.el.png)

Μετά το κλικ, τρέξτε το για να το δοκιμάσετε

![pfflow](../../../../../../translated_images/pfflow.9697e0fda67794bb0cf4b78d52e6f5a42002eec935bc2519933064afbbdd34f0.el.png)

1. Μπορείτε να τρέξετε batch στο τερματικό για να δείτε περισσότερα αποτελέσματα


```bash

pf run create --file batch_run.yaml --stream --name 'Your eval qa name'    

```

Μπορείτε να δείτε τα αποτελέσματα στον προεπιλεγμένο περιηγητή σας


![pfresult](../../../../../../translated_images/pfresult.972eb57dd5bec646e1aa01148991ba8959897efea396e42cf9d7df259444878d.el.png)

**Αποποίηση ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που προσπαθούμε για ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν σφάλματα ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται η επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.