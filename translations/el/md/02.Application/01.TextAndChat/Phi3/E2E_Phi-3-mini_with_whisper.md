<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "006e8cf75211d3297f24e1b22e38955f",
  "translation_date": "2025-07-17T02:18:44+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "el"
}
-->
# Interactive Phi 3 Mini 4K Instruct Chatbot με Whisper

## Επισκόπηση

Το Interactive Phi 3 Mini 4K Instruct Chatbot είναι ένα εργαλείο που επιτρέπει στους χρήστες να αλληλεπιδρούν με το Microsoft Phi 3 Mini 4K instruct demo χρησιμοποιώντας κείμενο ή φωνητική είσοδο. Το chatbot μπορεί να χρησιμοποιηθεί για διάφορες εργασίες, όπως μετάφραση, ενημερώσεις καιρού και γενική συλλογή πληροφοριών.

### Ξεκινώντας

Για να χρησιμοποιήσετε αυτό το chatbot, απλώς ακολουθήστε τις παρακάτω οδηγίες:

1. Ανοίξτε το νέο [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb)
2. Στο κύριο παράθυρο του notebook, θα δείτε μια διεπαφή chatbox με πεδίο εισαγωγής κειμένου και κουμπί "Send".
3. Για να χρησιμοποιήσετε το chatbot με βάση το κείμενο, απλώς πληκτρολογήστε το μήνυμά σας στο πεδίο εισαγωγής κειμένου και πατήστε το κουμπί "Send". Το chatbot θα απαντήσει με ένα αρχείο ήχου που μπορεί να αναπαραχθεί απευθείας μέσα στο notebook.

**Note**: Αυτό το εργαλείο απαιτεί GPU και πρόσβαση στα μοντέλα Microsoft Phi-3 και OpenAI Whisper, τα οποία χρησιμοποιούνται για αναγνώριση ομιλίας και μετάφραση.

### Απαιτήσεις GPU

Για να τρέξετε αυτό το demo χρειάζεστε 12GB μνήμης GPU.

Οι απαιτήσεις μνήμης για την εκτέλεση του **Microsoft-Phi-3-Mini-4K instruct** demo σε GPU εξαρτώνται από διάφορους παράγοντες, όπως το μέγεθος των δεδομένων εισόδου (ήχος ή κείμενο), η γλώσσα που χρησιμοποιείται για μετάφραση, η ταχύτητα του μοντέλου και η διαθέσιμη μνήμη στην GPU.

Γενικά, το μοντέλο Whisper έχει σχεδιαστεί για να τρέχει σε GPUs. Η προτεινόμενη ελάχιστη μνήμη GPU για το μοντέλο Whisper είναι 8 GB, αλλά μπορεί να διαχειριστεί και μεγαλύτερα μεγέθη μνήμης αν χρειαστεί.

Είναι σημαντικό να σημειωθεί ότι η εκτέλεση μεγάλου όγκου δεδομένων ή υψηλού αριθμού αιτημάτων στο μοντέλο μπορεί να απαιτήσει περισσότερη μνήμη GPU και/ή να προκαλέσει προβλήματα απόδοσης. Συνιστάται να δοκιμάσετε το σενάριό σας με διαφορετικές ρυθμίσεις και να παρακολουθείτε τη χρήση μνήμης για να βρείτε τις βέλτιστες ρυθμίσεις για τις συγκεκριμένες ανάγκες σας.

## Παράδειγμα E2E για Interactive Phi 3 Mini 4K Instruct Chatbot με Whisper

Το jupyter notebook με τίτλο [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) δείχνει πώς να χρησιμοποιήσετε το Microsoft Phi 3 Mini 4K instruct Demo για να δημιουργήσετε κείμενο από φωνητική ή γραπτή είσοδο. Το notebook ορίζει αρκετές συναρτήσεις:

1. `tts_file_name(text)`: Αυτή η συνάρτηση δημιουργεί ένα όνομα αρχείου βασισμένο στο κείμενο εισόδου για την αποθήκευση του παραγόμενου αρχείου ήχου.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: Αυτή η συνάρτηση χρησιμοποιεί το Edge TTS API για να δημιουργήσει ένα αρχείο ήχου από μια λίστα τμημάτων κειμένου. Οι παράμετροι εισόδου είναι η λίστα τμημάτων, η ταχύτητα ομιλίας, το όνομα φωνής και η διαδρομή αποθήκευσης του παραγόμενου αρχείου ήχου.
1. `talk(input_text)`: Αυτή η συνάρτηση δημιουργεί ένα αρχείο ήχου χρησιμοποιώντας το Edge TTS API και το αποθηκεύει με τυχαίο όνομα στο φάκελο /content/audio. Η παράμετρος εισόδου είναι το κείμενο που θα μετατραπεί σε ομιλία.
1. `run_text_prompt(message, chat_history)`: Αυτή η συνάρτηση χρησιμοποιεί το Microsoft Phi 3 Mini 4K instruct demo για να δημιουργήσει ένα αρχείο ήχου από ένα μήνυμα και το προσθέτει στο ιστορικό συνομιλίας.
1. `run_audio_prompt(audio, chat_history)`: Αυτή η συνάρτηση μετατρέπει ένα αρχείο ήχου σε κείμενο χρησιμοποιώντας το Whisper model API και το περνάει στη συνάρτηση `run_text_prompt()`.
1. Ο κώδικας εκκινεί μια εφαρμογή Gradio που επιτρέπει στους χρήστες να αλληλεπιδρούν με το Phi 3 Mini 4K instruct demo είτε πληκτρολογώντας μηνύματα είτε ανεβάζοντας αρχεία ήχου. Η έξοδος εμφανίζεται ως μήνυμα κειμένου μέσα στην εφαρμογή.

## Αντιμετώπιση Προβλημάτων

Εγκατάσταση οδηγών Cuda GPU

1. Βεβαιωθείτε ότι οι εφαρμογές Linux είναι ενημερωμένες

    ```bash
    sudo apt update
    ```

1. Εγκαταστήστε τους οδηγούς Cuda

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. Καταχωρήστε τη θέση του οδηγού cuda

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Έλεγχος μεγέθους μνήμης Nvidia GPU (Απαιτούνται 12GB μνήμης GPU)

    ```bash
    nvidia-smi
    ```

1. Άδειασμα Cache: Αν χρησιμοποιείτε PyTorch, μπορείτε να καλέσετε torch.cuda.empty_cache() για να απελευθερώσετε όλη την αχρησιμοποίητη μνήμη cache ώστε να μπορεί να χρησιμοποιηθεί από άλλες εφαρμογές GPU

    ```python
    torch.cuda.empty_cache() 
    ```

1. Έλεγχος Nvidia Cuda

    ```bash
    nvcc --version
    ```

1. Εκτελέστε τις παρακάτω ενέργειες για να δημιουργήσετε ένα token Hugging Face.

    - Μεταβείτε στη σελίδα [Hugging Face Token Settings](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo).
    - Επιλέξτε **New token**.
    - Εισάγετε το όνομα του έργου που θέλετε να χρησιμοποιήσετε.
    - Επιλέξτε **Type** ως **Write**.

> **Note**
>
> Αν αντιμετωπίσετε το παρακάτω σφάλμα:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> Για να το διορθώσετε, πληκτρολογήστε την παρακάτω εντολή στο τερματικό σας.
>
> ```bash
> sudo ldconfig
> ```

**Αποποίηση ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που επιδιώκουμε την ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη γλώσσα του θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.