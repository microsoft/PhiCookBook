<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f72d7981ed3640865700f51ae407da4",
  "translation_date": "2026-01-14T15:40:16+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "el"
}
-->
# Διαδραστικό Phi 3 Mini 4K Instruct Chatbot με Whisper

## Επισκόπηση

Το Διαδραστικό Phi 3 Mini 4K Instruct Chatbot είναι ένα εργαλείο που επιτρέπει στους χρήστες να αλληλεπιδρούν με την επίδειξη Microsoft Phi 3 Mini 4K instruct χρησιμοποιώντας κείμενο ή φωνητική είσοδο. Το chatbot μπορεί να χρησιμοποιηθεί για μια ποικιλία εργασιών, όπως μετάφραση, ενημερώσεις καιρού και γενική συλλογή πληροφοριών.

### Ξεκινώντας

Για να χρησιμοποιήσετε αυτό το chatbot, απλώς ακολουθήστε αυτές τις οδηγίες:

1. Ανοίξτε ένα νέο [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb)
2. Στο κύριο παράθυρο του τετραδίου, θα δείτε μια διεπαφή chatbox με πλαίσιο εισαγωγής κειμένου και ένα κουμπί «Αποστολή».
3. Για να χρησιμοποιήσετε το chatbot βασισμένο σε κείμενο, απλώς πληκτρολογήστε το μήνυμά σας στο πλαίσιο εισαγωγής κειμένου και πατήστε το κουμπί «Αποστολή». Το chatbot θα απαντήσει με ένα αρχείο ήχου που μπορεί να αναπαραχθεί απευθείας μέσα στο τετράδιο.

**Σημείωση**: Αυτό το εργαλείο απαιτεί GPU και πρόσβαση στα μοντέλα Microsoft Phi-3 και OpenAI Whisper, το οποίο χρησιμοποιείται για αναγνώριση ομιλίας και μετάφραση.

### Απαιτήσεις GPU

Για να εκτελέσετε αυτήν την επίδειξη χρειάζεστε 12Gb μνήμη GPU.

Οι απαιτήσεις μνήμης για την εκτέλεση της επίδειξης **Microsoft-Phi-3-Mini-4K instruct** σε GPU εξαρτώνται από διάφορους παράγοντες, όπως το μέγεθος των εισερχόμενων δεδομένων (ήχος ή κείμενο), η γλώσσα που χρησιμοποιείται για μετάφραση, η ταχύτητα του μοντέλου και η διαθέσιμη μνήμη στην GPU.

Γενικά, το μοντέλο Whisper έχει σχεδιαστεί για να εκτελείται σε GPUs. Η προτεινόμενη ελάχιστη ποσότητα μνήμης GPU για την εκτέλεση του Whisper μοντέλου είναι 8 GB, αλλά μπορεί να χειριστεί μεγαλύτερα ποσά μνήμης αν χρειαστεί.

Είναι σημαντικό να σημειωθεί ότι η εκτέλεση μεγάλου όγκου δεδομένων ή μεγάλης ποσότητας αιτημάτων στο μοντέλο μπορεί να απαιτεί περισσότερη μνήμη GPU και/ή να προκαλέσει ζητήματα απόδοσης. Συνιστάται να δοκιμάσετε το σενάριό σας με διάφορες ρυθμίσεις και να παρακολουθείτε τη χρήση μνήμης για να καθορίσετε τις βέλτιστες ρυθμίσεις για τις συγκεκριμένες ανάγκες σας.

## Δείγμα E2E για Διαδραστικό Phi 3 Mini 4K Instruct Chatbot με Whisper

Το jupyter notebook με τίτλο [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) παρουσιάζει πώς να χρησιμοποιήσετε την επίδειξη Microsoft Phi 3 Mini 4K instruct για να δημιουργήσετε κείμενο από φωνητική ή γραπτή είσοδο. Το notebook ορίζει αρκετές συναρτήσεις:

1. `tts_file_name(text)`: Αυτή η συνάρτηση δημιουργεί ένα όνομα αρχείου βασισμένο στο κείμενο εισόδου για να αποθηκεύσει το παραγόμενο αρχείο ήχου.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: Αυτή η συνάρτηση χρησιμοποιεί το Edge TTS API για να δημιουργήσει ένα αρχείο ήχου από μια λίστα τμημάτων κειμένου εισόδου. Οι παράμετροι εισόδου είναι η λίστα τμημάτων, ο ρυθμός ομιλίας, το όνομα φωνής και η διαδρομή εξόδου για την αποθήκευση του παραγόμενου αρχείου ήχου.
1. `talk(input_text)`: Αυτή η συνάρτηση δημιουργεί ένα αρχείο ήχου χρησιμοποιώντας το Edge TTS API και το αποθηκεύει με τυχαίο όνομα αρχείου στον φάκελο /content/audio. Η παράμετρος εισόδου είναι το κείμενο που θα μετατραπεί σε ομιλία.
1. `run_text_prompt(message, chat_history)`: Αυτή η συνάρτηση χρησιμοποιεί την επίδειξη Microsoft Phi 3 Mini 4K instruct για να παράγει ένα αρχείο ήχου από ένα μήνυμα εισόδου και το προσθέτει στο ιστορικό συνομιλίας.
1. `run_audio_prompt(audio, chat_history)`: Αυτή η συνάρτηση μετατρέπει ένα αρχείο ήχου σε κείμενο χρησιμοποιώντας το Whisper μοντέλο API και το περνά στη συνάρτηση `run_text_prompt()`.
1. Ο κώδικας εκκινεί μια εφαρμογή Gradio που επιτρέπει στους χρήστες να αλληλεπιδρούν με την επίδειξη Phi 3 Mini 4K instruct είτε πληκτρολογώντας μηνύματα είτε ανεβάζοντας αρχεία ήχου. Το αποτέλεσμα εμφανίζεται ως κείμενο μέσα στην εφαρμογή.

## Αντιμετώπιση Προβλημάτων

Εγκατάσταση οδηγών Cuda GPU

1. Βεβαιωθείτε ότι η εφαρμογή Linux είναι ενημερωμένη

    ```bash
    sudo apt update
    ```

1. Εγκαταστήστε οδηγούς Cuda

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. Καταχωρήστε τη θέση του οδηγού cuda

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Έλεγχος μεγέθους μνήμης Nvidia GPU (Απαιτείται 12GB μνήμης GPU)

    ```bash
    nvidia-smi
    ```

1. Άδειασμα Cache: Αν χρησιμοποιείτε PyTorch, μπορείτε να καλέσετε torch.cuda.empty_cache() για να απελευθερώσετε όλη την αχρησιμοποίητη μνήμη cache ώστε να μπορεί να χρησιμοποιηθεί από άλλες εφαρμογές GPU

    ```python
    torch.cuda.empty_cache() 
    ```

1. Έλεγχος Nvidia Cuda

    ```bash
    nvcc --version
    ```

1. Εκτελέστε τις ακόλουθες εργασίες για να δημιουργήσετε ένα token Hugging Face.

    - Πλοηγηθείτε στην [σελίδα ρυθμίσεων token του Hugging Face](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo).
    - Επιλέξτε **Νέο token**.
    - Εισαγάγετε το **Όνομα** του project που θέλετε να χρησιμοποιήσετε.
    - Επιλέξτε **Τύπο** σε **Write**.

> [!NOTE]
>
> Αν αντιμετωπίσετε το ακόλουθο σφάλμα:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> Για να το επιλύσετε, πληκτρολογήστε την ακόλουθη εντολή στο τερματικό σας.
>
> ```bash
> sudo ldconfig
> ```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Αποποίηση ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, να έχετε υπόψη ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν σφάλματα ή ανακρίβειες. Το πρωτότυπο έγγραφο στη γλώσσα του θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες συνιστάται επαγγελματική μετάφραση από άνθρωπο. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->