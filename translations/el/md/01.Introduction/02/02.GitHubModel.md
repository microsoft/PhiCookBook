<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-05-09T08:50:10+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "el"
}
-->
## Phi Family in GitHub Models

Καλώς ήρθατε στο [GitHub Models](https://github.com/marketplace/models)! Έχουμε όλα έτοιμα για να εξερευνήσετε τα AI Models που φιλοξενούνται στο Azure AI.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.4fc858ab26afe64c43f5e423ad0c5c733878bb536fdb027a5bcf1f80c41b0633.el.png)

Για περισσότερες πληροφορίες σχετικά με τα διαθέσιμα Models στο GitHub Models, δείτε το [GitHub Model Marketplace](https://github.com/marketplace/models)

## Διαθέσιμα Models

Κάθε μοντέλο έχει το δικό του playground και δείγματα κώδικα

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.998e294f6ee69c3ca174c880b32af9feec4221d0d787de899ad9bb2da3b58981.el.png)

### Phi Family στον Κατάλογο Μοντέλων GitHub

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## Ξεκινώντας

Υπάρχουν μερικά βασικά παραδείγματα έτοιμα για να τα εκτελέσετε. Μπορείτε να τα βρείτε στον φάκελο samples. Αν θέλετε να πάτε κατευθείαν στη γλώσσα που προτιμάτε, τα παραδείγματα είναι διαθέσιμα στις εξής γλώσσες:

- Python  
- JavaScript  
- C#  
- Java  
- cURL  

Υπάρχει επίσης ένα ειδικό περιβάλλον Codespaces για την εκτέλεση των δειγμάτων και των μοντέλων.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.b4b839a081583da39bc976c2f0d8ac4603d3b8c23194b16cc9e0a1014f5611d0.el.png)

## Παράδειγμα Κώδικα

Παρακάτω θα βρείτε αποσπάσματα κώδικα για μερικές περιπτώσεις χρήσης. Για περισσότερες πληροφορίες σχετικά με το Azure AI Inference SDK, δείτε την πλήρη τεκμηρίωση και τα δείγματα.

## Ρύθμιση

1. Δημιουργήστε ένα personal access token  
Δεν χρειάζεται να δώσετε δικαιώματα στο token. Σημειώστε ότι το token θα σταλεί σε υπηρεσία της Microsoft.

Για να χρησιμοποιήσετε τα παρακάτω αποσπάσματα κώδικα, δημιουργήστε μια μεταβλητή περιβάλλοντος και ορίστε το token σας ως κλειδί για τον client κώδικα.

Αν χρησιμοποιείτε bash:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
Αν βρίσκεστε σε powershell:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

Αν χρησιμοποιείτε το Windows command prompt:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## Παράδειγμα Python

### Εγκατάσταση εξαρτήσεων  
Εγκαταστήστε το Azure AI Inference SDK με pip (Απαιτείται: Python >=3.8):

```
pip install azure-ai-inference
```  
### Εκτέλεση βασικού παραδείγματος κώδικα

Αυτό το παράδειγμα δείχνει μια βασική κλήση στο chat completion API. Χρησιμοποιεί το GitHub AI model inference endpoint και το GitHub token σας. Η κλήση είναι συγχρονισμένη.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### Εκτέλεση συνομιλίας πολλαπλών γύρων

Αυτό το παράδειγμα δείχνει μια συνομιλία πολλαπλών γύρων με το chat completion API. Όταν χρησιμοποιείτε το μοντέλο για εφαρμογή συνομιλίας, πρέπει να διαχειρίζεστε το ιστορικό της συνομιλίας και να στέλνετε τα πιο πρόσφατα μηνύματα στο μοντέλο.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### Ροή εξόδου (streaming)

Για καλύτερη εμπειρία χρήστη, θα θέλετε να κάνετε streaming την απόκριση του μοντέλου ώστε το πρώτο token να εμφανίζεται νωρίς και να μην περιμένετε για μεγάλες απαντήσεις.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## ΔΩΡΕΑΝ Χρήση και Όρια Ροής για GitHub Models

![Model Catalog](../../../../../translated_images/GitHub_Model.0c2abb992151c5407046e2b763af51505ff709f04c0950785e0300fdc8c55a0c.el.png)

Τα [όρια ροής για το playground και τη δωρεάν χρήση API](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) έχουν στόχο να σας βοηθήσουν να πειραματιστείτε με τα μοντέλα και να κάνετε πρωτότυπα για την AI εφαρμογή σας. Για χρήση πέρα από αυτά τα όρια, και για να κλιμακώσετε την εφαρμογή σας, πρέπει να προμηθευτείτε πόρους από λογαριασμό Azure και να αυθεντικοποιηθείτε από εκεί αντί για το προσωπικό GitHub access token σας. Δεν χρειάζεται να αλλάξετε κάτι άλλο στον κώδικά σας. Χρησιμοποιήστε αυτόν τον σύνδεσμο για να μάθετε πώς να ξεπεράσετε τα όρια δωρεάν επιπέδου στο Azure AI.

### Αποκαλύψεις

Να θυμάστε ότι όταν αλληλεπιδράτε με ένα μοντέλο, πειραματίζεστε με AI, οπότε είναι πιθανές λάθος απαντήσεις.

Η λειτουργία υπόκειται σε διάφορα όρια (συμπεριλαμβανομένων των αιτήσεων ανά λεπτό, αιτήσεων ανά ημέρα, tokens ανά αίτημα και ταυτόχρονων αιτήσεων) και δεν έχει σχεδιαστεί για παραγωγική χρήση.

Τα GitHub Models χρησιμοποιούν το Azure AI Content Safety. Αυτοί οι φίλτροι δεν μπορούν να απενεργοποιηθούν ως μέρος της εμπειρίας GitHub Models. Αν αποφασίσετε να χρησιμοποιήσετε μοντέλα μέσω επί πληρωμή υπηρεσίας, παρακαλούμε να ρυθμίσετε τα φίλτρα περιεχομένου ώστε να καλύπτουν τις ανάγκες σας.

Αυτή η υπηρεσία λειτουργεί υπό τους Όρους Προ-κυκλοφορίας (Pre-release Terms) του GitHub.

**Αποποίηση Ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης με τεχνητή νοημοσύνη [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που προσπαθούμε για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτοματοποιημένες μεταφράσεις μπορεί να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα πρέπει να θεωρείται η επίσημη πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική μετάφραση από άνθρωπο. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.