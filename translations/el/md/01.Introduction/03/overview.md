Στο πλαίσιο του Phi-3-mini, η inference αναφέρεται στη διαδικασία χρήσης του μοντέλου για να γίνουν προβλέψεις ή να παραχθούν αποτελέσματα βάσει των εισερχόμενων δεδομένων. Ας δώσω περισσότερες λεπτομέρειες για το Phi-3-mini και τις δυνατότητες inference που προσφέρει.

Το Phi-3-mini αποτελεί μέρος της σειράς μοντέλων Phi-3 που κυκλοφόρησε η Microsoft. Αυτά τα μοντέλα έχουν σχεδιαστεί για να επαναπροσδιορίσουν το τι είναι εφικτό με τα Small Language Models (SLMs).

Ακολουθούν μερικά βασικά σημεία σχετικά με το Phi-3-mini και τις δυνατότητες inference του:

## **Επισκόπηση του Phi-3-mini:**
- Το Phi-3-mini έχει μέγεθος παραμέτρων 3,8 δισεκατομμυρίων.
- Μπορεί να τρέξει όχι μόνο σε παραδοσιακές συσκευές υπολογιστών, αλλά και σε edge συσκευές όπως κινητά και IoT συσκευές.
- Η κυκλοφορία του Phi-3-mini επιτρέπει σε ιδιώτες και επιχειρήσεις να αναπτύξουν SLMs σε διαφορετικές συσκευές υλικού, ειδικά σε περιβάλλοντα με περιορισμένους πόρους.
- Υποστηρίζει διάφορες μορφές μοντέλων, συμπεριλαμβανομένης της παραδοσιακής μορφής PyTorch, της κβαντισμένης έκδοσης της μορφής gguf και της κβαντισμένης έκδοσης βασισμένης σε ONNX.

## **Πρόσβαση στο Phi-3-mini:**
Για να αποκτήσετε πρόσβαση στο Phi-3-mini, μπορείτε να χρησιμοποιήσετε το [Semantic Kernel](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) σε μια εφαρμογή Copilot. Το Semantic Kernel είναι γενικά συμβατό με το Azure OpenAI Service, ανοιχτά μοντέλα στο Hugging Face και τοπικά μοντέλα.  
Μπορείτε επίσης να χρησιμοποιήσετε το [Ollama](https://ollama.com) ή το [LlamaEdge](https://llamaedge.com) για να καλέσετε κβαντισμένα μοντέλα. Το Ollama επιτρέπει σε μεμονωμένους χρήστες να καλέσουν διάφορα κβαντισμένα μοντέλα, ενώ το LlamaEdge παρέχει διαλειτουργικότητα για μοντέλα GGUF.

## **Κβαντισμένα Μοντέλα:**
Πολλοί χρήστες προτιμούν να χρησιμοποιούν κβαντισμένα μοντέλα για τοπική inference. Για παράδειγμα, μπορείτε να τρέξετε απευθείας το Ollama run Phi-3 ή να το ρυθμίσετε εκτός σύνδεσης χρησιμοποιώντας ένα Modelfile. Το Modelfile καθορίζει τη διαδρομή του αρχείου GGUF και τη μορφή του prompt.

## **Δυνατότητες Γεννητικής Τεχνητής Νοημοσύνης:**
Ο συνδυασμός SLMs όπως το Phi-3-mini ανοίγει νέες δυνατότητες για γεννητική τεχνητή νοημοσύνη. Η inference είναι μόνο το πρώτο βήμα· αυτά τα μοντέλα μπορούν να χρησιμοποιηθούν για διάφορες εργασίες σε περιβάλλοντα με περιορισμένους πόρους, περιορισμένη καθυστέρηση και περιορισμένο κόστος.

## **Ξεκλειδώνοντας τη Γεννητική Τεχνητή Νοημοσύνη με το Phi-3-mini: Ένας Οδηγός για Inference και Ανάπτυξη**  
Μάθετε πώς να χρησιμοποιείτε το Semantic Kernel, το Ollama/LlamaEdge και το ONNX Runtime για να αποκτήσετε πρόσβαση και να κάνετε inference σε μοντέλα Phi-3-mini, και εξερευνήστε τις δυνατότητες της γεννητικής τεχνητής νοημοσύνης σε διάφορα σενάρια εφαρμογών.

**Χαρακτηριστικά**  
Inference μοντέλου phi3-mini σε:

- [Semantic Kernel](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo)  
- [Ollama](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)  
- [LlamaEdge WASM](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo)  
- [ONNX Runtime](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/onnx?WT.mc_id=aiml-138114-kinfeylo)  
- [iOS](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ios?WT.mc_id=aiml-138114-kinfeylo)  

Συνοψίζοντας, το Phi-3-mini επιτρέπει στους προγραμματιστές να εξερευνήσουν διαφορετικές μορφές μοντέλων και να αξιοποιήσουν τη γεννητική τεχνητή νοημοσύνη σε διάφορα σενάρια εφαρμογών.

**Αποποίηση ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που επιδιώκουμε την ακρίβεια, παρακαλούμε να λάβετε υπόψη ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται η επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.