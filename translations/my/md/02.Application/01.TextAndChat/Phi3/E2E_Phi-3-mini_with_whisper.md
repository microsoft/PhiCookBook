# Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper

## အကျဉ်းချုပ်

Interactive Phi 3 Mini 4K Instruct Chatbot သည် Microsoft Phi 3 Mini 4K instruct ဒမ်းိုနဲ့ စာသား သို့မဟုတ် အသံထည့်သွင်းမှု များကို အသုံးပြု၍ တွဲဖက် ဆက်သွယ်နိုင်စေသော ကိရိယာတစ်ခု ဖြစ်သည်။ ဤ chatbot ကို ဘာသာပြန်၊ ရာသီအခြေအနေ နောက်ဆုံးသတင်းများနှင့် အထွေထွေ သတင်းအချက်အလက် ရယူမှု စသော အမျိုးမျိုးသော တာဝန်များ အတွက် အသုံးပြုနိုင်သည်။

### စတင်အသုံးပြုရန်

ဤ chatbot ကိုအသုံးပြုရန် အောက်ပါ လမ်းညွှန်ချက်များကို လိုက်နာပါ-

1. [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) ကိုဖွင့်ပါ။
2. notebook ၏ အဓိက ပြတင်းပေါ်တွင် စာသားထည့်သွင်းရန် ဘောင်နှင့် "Send" ခလုတ် ပါရှိသည့် chatbox အင်တာဖေ့စ်ကို တွေ့မြင်ရပါမည်။
3. စာသားအခြေပြု chatbot ကို အသုံးပြုလိုပါက၊ စာသားထည့်သွင်းဘောက်စ်တွင် သင်၏စာကို ရိုက်ထည့်ပြီး "Send" ခလုတ်ကို နှိပ်ပါ။ chatbot သည် notebook အတွင်းမှ တိုက်ရိုက် ဖွင့်၍ ကြည့်ရှုနိုင်သည့် အသံဖိုင်ဖြင့် တုံ့ပြန် ပေးမည်ဖြစ်သည်။

**မှတ်ချက်**: ဤကိရိယာသည် GPU နှင့် Microsoft Phi-3 နှင့် OpenAI Whisper မော်ဒယ်များ အတွက် လက်လှမ်းရောက်မှု လိုအပ်ပါသည်၊ ၎င်းကို အသံသိမြင်ခြင်းနှင့် ဘာသာပြန်ရန် အသုံးပြုသည်။

### GPU လိုအပ်ချက်များ

ဤဒမ်းိုကို စတင်အသုံးပြုရန် 12GB တောင့် GPU မှတ်ဉာဏ် လိုအပ်ပါသည်။

**Microsoft-Phi-3-Mini-4K instruct** ဒမ်းိုကို GPU ပေါ်တွင် အသုံးပြုရာတွင် အသံ သို့မဟုတ် စာသား ထည့်သွင်းမှု အကြီးအကျယ်၊ ဘာသာပြန်မည့် ဘာသာစကား၊ မော်ဒယ်၏မြန်နှုန်းနှင့် GPU မှတ်ဉာဏ် ရရှိနိုင်မှု အပေါ် မူတည်၍ မတ်မြတ်တည်မှု ရှိပါသည်။

အားလုံးတွင် Whisper မော်ဒယ်သည် GPU ပေါ်တွင် လည်ပတ်နိုင်ရန် ဒီဇိုင်းရေးဆွဲထားပါသည်။ Whisper မော်ဒယ်ကို လည်ပတ်ရန်အတွက် အနိမ့်ဆုံး GPU မှတ်ဉာဏ် အကြံပြုထားသည်မှာ 8GB ဖြစ်ပြီး လိုအပ်ပါက ပိုမိုကြီးမားသော မှတ်ဉာဏ်ကို ရှိ၍ ပြုလုပ်နိုင်ပါသည်။

မာဒယ်ပေါ်တွင် အချက်အလက် အတော်ကြီး သို့မဟုတ် တောင်းဆိုမှု များများလာပါက ပိုမိုအများပြားသော GPU မှတ်ဉာဏ် လိုအပ်နိုင်ခြင်းနှင့် စွမ်းဆောင်ရည် ပြတ်တောက်မှုများ ဖြစ်ပေါ်နိုင်ပါသည်။ သင့်အသုံးပြုမှုကို ကြိုးစားစမ်းသပ်ပြီး မတူညီသည့် အဆင့်ဆင့်များဖြင့် မှတ်ဉာဏ် အသုံးပြုမှုကို စောင့်ကြည့်ရန် အကြံပြုပါသည်။

## E2E နမူနာ - Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper

[Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) အမည်ရှိ jupyter notebook သည် Microsoft Phi 3 Mini 4K instruct ဒမ်းိုကို အသံ သို့မဟုတ် စာသား ထည့်သွင်းမှုမှ စာသားကို ရရှိစေခြင်းကို ပြသသည်။ notebook သည် ဤအလုပ်လုပ်ဆောင်မှုများ အချို့ကို ဖော်ပြသည်-

1. `tts_file_name(text)`: ဖန်တီးမည့် အသံဖိုင်အတွက် အသုံးပြုမည့် ဖိုင်နာမည် ကို စာသားအပေါ် မူတည်၍ ဖန်တီးသည်။
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: Edge TTS API ကို အသုံးပြုပြီး စာသားchunk များ၏ စာရင်းမှ အသံဖိုင်ဖြစ်အောင် ဖန်တီးသည်။ input parameters တွင် chunks များ စာရင်း၊ မိနစ်နှုန်း၊ အသံနာမည်နှင့် output ဖိုင်မှတ်တမ်း ရှိသည်။
1. `talk(input_text)`: Edge TTS API ကိုအသုံးပြုပြီး /content/audio ဖိုင်လမ်းကြောင်းတွင် ဖိုင်နာမည်တစ်ခု အဖြစ် သိမ်းဆည်းသော အသံဖိုင်ဖန်တီးသည်။ input parameter မှာ အသံသို့ ပြောင်းလဲမည့် စာသားဖြစ်သည်။
1. `run_text_prompt(message, chat_history)`: Microsoft Phi 3 Mini 4K instruct ဒမ်းိုကို အသုံးပြုပြီး စာတိုက်မှ စာသား မှဖန်တီးသော အသံဖိုင်ဖြစ်အောင် ပြုလုပ်ကာ chat history တွင် ထပ်မံထည့်သည်။
1. `run_audio_prompt(audio, chat_history)`: Whisper မော်ဒယ် API အသုံးပြုပြီး အသံဖိုင်အား စာသားသို့ ပြောင်းပြီး `run_text_prompt()` ကို ဖြစ်စေသည်။
1. ကုဒ်အပိုင်းသည် အသုံးပြုသူများကို စာတိုက်ဖြင့် ဖြေဆိုခြင်း သို့မဟုတ် အသံဖိုင်များ တင်သွင်းခြင်းဖြင့် Phi 3 Mini 4K instruct ဒမ်းိုနှင့် ဆက်သွယ်နိုင်သည့် Gradio app ကိုစတင်ပေးသည်။ output သည် အက်ပ်တွင် စာတိုက်နည်းဖြင့် ပြသထားသည်။

## ပြဿနာများ ဖြေရှင်းခြင်း

Cuda GPU ဒရိုင်ဘာများ ထည့်သွင်းခြင်း

1. သင့် Linux အပလီ케ရှင်းများအား နောက်ဆုံးဖြတ်ထားရန်အတည်ပြုပါ

    ```bash
    sudo apt update
    ```

1. Cuda Drivers ထည့်သွင်းပါ

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. cuda driver ဖြစ်နေသည့်နေရာမှတ်ပုံတင်ပါ

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Nvidia GPU မှတ်ဉာဏ်အရွယ်အစား စစ်ဆေးခြင်း (12GB GPU မှတ်ဉာဏ် လိုအပ်ချက်)

    ```bash
    nvidia-smi
    ```

1. Cache သန့်ရှင်းခြင်း: PyTorch ကို သုံးပါက torch.cuda.empty_cache() ကို ခေါ်ယူကာ မသုံးသော cache မှတ်ဉာဏ်အားလုံး ဖြုတ်ပစ်နိုင်သည်၊ အခြား GPU app များနောက်ထပ်အသုံးပြုနိုင်ရန်

    ```python
    torch.cuda.empty_cache() 
    ```

1. Nvidia Cuda စစ်ဆေးခြင်း

    ```bash
    nvcc --version
    ```

1. Hugging Face token တစ်ခု ဖန်တီးရန် အောက်ဖော်ပြပါကို လုပ်ဆောင်ပါ။

    - [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo) သို့ သွားပါ။
    - **New token** ကို ရွေးချယ်ပါ။
    - သင့်လုပ်ဆောင်လိုသော project **Name** ထည့်ပါ။
    - **Type** ကို **Write** ဟူ၍ ရွေးပါ။

> [!NOTE]
>
> အောက်ပါအမှားပြပါက-
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> ဤအမှားကို ဖြေရှင်းရန်၊ terminal တွင် အောက်ပါ command ကို ရိုက်ထည့်ပါ။
>
> ```bash
> sudo ldconfig
> ```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**အကြောင်းကြားချက်**  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှုဖြစ်သော [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှုအတွက် ကြိုးစားသော်လည်း၊ အလိုအလျောက် ဘာသာပြန်ခြင်းဖြင့် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ဖြစ်ရှိနိုင်သည်ကို စဥ်းစားကြပါရန် အကြံပေးပါသည်။ မူရင်းစာရွက်စာတမ်းကို မိခင်ဘာသာဖြင့် အတည်ပြုသော အရင်းအမြစ်အဖြစ် ယူဆရမည်ဖြစ်သည်။ အရေးကြီးသော သတင်းအချက်အလက်များအတွက် လူ့ဘာသာပြန်ချက်ပညာရှင်၏ အတည်ပြုမှုကို သုံးသင့်ပါသည်။ ဤဘာသာပြန်ချက်ကို အသုံးပြုရာတွင် ဖြစ်ပေါ်နိုင်သည့် နားလည်မှုလွဲမှားမှုများ သို့မဟုတ် မှားယွင်းဖတ်ရှုမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။
<!-- CO-OP TRANSLATOR DISCLAIMER END -->