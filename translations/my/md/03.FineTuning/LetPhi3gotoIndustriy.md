<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "743d7e9cb9c4e8ea642d77bee657a7fa",
  "translation_date": "2025-07-09T19:04:10+00:00",
  "source_file": "md/03.FineTuning/LetPhi3gotoIndustriy.md",
  "language_code": "my"
}
-->
# **Phi-3 ကို စက်မှုလုပ်ငန်းကျွမ်းကျင်သူအဖြစ် ဖွံ့ဖြိုးစေခြင်း**

Phi-3 မော်ဒယ်ကို စက်မှုလုပ်ငန်းတစ်ခုတွင် အသုံးပြုရန်အတွက်၊ စက်မှုလုပ်ငန်းဆိုင်ရာ စီးပွားရေးဒေတာများကို Phi-3 မော်ဒယ်ထဲသို့ ထည့်သွင်းရပါမည်။ ကျွန်ုပ်တို့တွင် ရွေးချယ်စရာ နှစ်မျိုးရှိပြီး၊ ပထမတစ်ခုမှာ RAG (Retrieval Augmented Generation) ဖြစ်ပြီး ဒုတိယမှာ Fine Tuning ဖြစ်သည်။

## **RAG နှင့် Fine-Tuning နှိုင်းယှဉ်ခြင်း**

### **Retrieval Augmented Generation**

RAG သည် ဒေတာ ရှာဖွေခြင်းနှင့် စာသား ဖန်တီးခြင်းတို့ ပေါင်းစပ်ထားခြင်းဖြစ်သည်။ စက်မှုလုပ်ငန်း၏ ဖွဲ့စည်းထားသော ဒေတာနှင့် ဖွဲ့စည်းမထားသော ဒေတာများကို vector database တွင် သိမ်းဆည်းထားသည်။ သက်ဆိုင်ရာ အကြောင်းအရာကို ရှာဖွေနေစဉ်၊ သက်ဆိုင်ရာ အကျဉ်းချုပ်နှင့် အကြောင်းအရာများကို ရှာဖွေ၍ context တစ်ခု ဖန်တီးပြီး LLM/SLM ၏ စာသား ပြည့်စုံစွမ်းရည်နှင့် ပေါင်းစပ်ကာ အကြောင်းအရာကို ဖန်တီးပေးသည်။

### **Fine-tuning**

Fine-tuning သည် မော်ဒယ်တစ်ခုကို တိုးတက်အောင် ပြုလုပ်ခြင်းဖြစ်သည်။ မော်ဒယ် အယ်လ်ဂိုရီသမ်မှ စတင်ရန် မလိုအပ်ပေမယ့် ဒေတာကို ဆက်လက် စုဆောင်းရမည်။ စက်မှုလုပ်ငန်းတွင် ပိုမိုတိကျသော စကားလုံးအသုံးအနှုန်းနှင့် ဘာသာစကားဖော်ပြချက်လိုအပ်ပါက Fine-tuning သည် သင့်အတွက် ပိုမိုသင့်တော်သော ရွေးချယ်မှုဖြစ်သည်။ သို့သော် ဒေတာများ မကြာခဏ ပြောင်းလဲလျှင် Fine-tuning သည် ရှုပ်ထွေးနိုင်သည်။

### **ရွေးချယ်နည်း**

1. ကျွန်ုပ်တို့၏ ဖြေကြားချက်တွင် ပြင်ပဒေတာ ထည့်သွင်းရန် လိုအပ်ပါက RAG သည် အကောင်းဆုံး ရွေးချယ်မှုဖြစ်သည်။

2. စက်မှုလုပ်ငန်း အသိပညာကို တည်ငြိမ်ပြီး တိကျစွာ ထုတ်ပေးရန် လိုအပ်ပါက Fine-tuning သည် ကောင်းမွန်သော ရွေးချယ်မှုဖြစ်သည်။ RAG သည် သက်ဆိုင်ရာ အကြောင်းအရာကို ရှာဖွေရာတွင် ဦးစားပေးသော်လည်း အထူးပြု အသေးစိတ်များကို မမြောက်မြားစွာ ဖော်ထုတ်နိုင်ပါ။

3. Fine-tuning သည် အရည်အသွေးမြင့် ဒေတာစုစည်းမှု လိုအပ်ပြီး ဒေတာအတိုင်းအတာ သေးငယ်လျှင် ထူးခြားမှု မရှိနိုင်ပါ။ RAG သည် ပိုမိုလွယ်ကူ သက်တောင့်သက်သာ ဖြစ်သည်။

4. Fine-tuning သည် အတွင်းစိတ်ကို နားလည်ရခက်သော မျက်နှာဖုံးတစ်ခုကဲ့သို့ဖြစ်ပြီး၊ RAG သည် ဒေတာရင်းမြစ်ကို ရှာဖွေရာတွင် ပိုမိုလွယ်ကူစေကာ hallucination သို့မဟုတ် အကြောင်းအရာ အမှားများကို ထိရောက်စွာ ပြင်ဆင်နိုင်ပြီး ပိုမိုထင်ရှားသော သက်သေခံမှု ပေးနိုင်သည်။

### **အသုံးပြုမှု အခြေအနေများ**

1. အထူးပြု စက်မှုလုပ်ငန်းများတွင် ပရော်ဖက်ရှင်နယ် စကားလုံးနှင့် ဖော်ပြချက်များ လိုအပ်ပါက ***Fine-tuning*** သည် အကောင်းဆုံး ရွေးချယ်မှုဖြစ်သည်။

2. မေးမြန်းဖြေကြား စနစ်တွင် အမျိုးမျိုးသော အသိပညာများ ပေါင်းစပ်ရန် လိုအပ်ပါက ***RAG*** သည် အကောင်းဆုံး ရွေးချယ်မှုဖြစ်သည်။

3. အလိုအလျောက် စီးပွားရေး လည်ပတ်မှု ပေါင်းစပ်မှုတွင် ***RAG + Fine-tuning*** သည် အကောင်းဆုံး ရွေးချယ်မှုဖြစ်သည်။

## **RAG ကို အသုံးပြုနည်း**

![rag](../../../../imgs/03/intro/rag.png)

Vector database သည် သင်္ချာပုံစံဖြင့် သိမ်းဆည်းထားသော ဒေတာစုစည်းမှုဖြစ်သည်။ Vector database များသည် စက်မှုသင်ယူမှု မော်ဒယ်များအတွက် ယခင်ထည့်သွင်းချက်များကို မှတ်မိရန် ပိုမိုလွယ်ကူစေပြီး၊ ရှာဖွေမှု၊ အကြံပြုမှုနှင့် စာသား ဖန်တီးမှုကဲ့သို့သော အသုံးပြုမှုများကို ထောက်ပံ့နိုင်စေသည်။ ဒေတာများကို တိကျစွာ မကိုက်ညီပေမယ့် ဆင်တူမှု အတိုင်းအတာများအပေါ် အခြေခံ၍ ဖော်ထုတ်နိုင်ပြီး ကွန်ပျူတာ မော်ဒယ်များသည် ဒေတာ၏ context ကို နားလည်နိုင်သည်။

Vector database သည် RAG ကို အကောင်အထည်ဖော်ရာတွင် အဓိကဖြစ်သည်။ ကျွန်ုပ်တို့သည် text-embedding-3, jina-ai-embedding ကဲ့သို့သော vector မော်ဒယ်များမှတဆင့် ဒေတာများကို vector သိမ်းဆည်းမှုသို့ ပြောင်းလဲနိုင်သည်။

RAG application ဖန်တီးခြင်းအကြောင်း ပိုမိုလေ့လာရန် [https://github.com/microsoft/Phi-3CookBook](https://github.com/microsoft/Phi-3CookBook?WT.mc_id=aiml-138114-kinfeylo) ကို ကြည့်ရှုနိုင်ပါသည်။

## **Fine-tuning ကို အသုံးပြုနည်း**

Fine-tuning တွင် အသုံးများသော အယ်လ်ဂိုရီသမ်များမှာ Lora နှင့် QLora ဖြစ်သည်။ ဘယ်လို ရွေးချယ်မလဲ?
- [ဤနမူနာ notebook ဖြင့် ပိုမိုလေ့လာရန်](../../../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python FineTuning နမူနာ ဥပမာ](../../../../code/04.Finetuning/FineTrainingScript.py)

### **Lora နှင့် QLora**

![lora](../../../../imgs/03/intro/qlora.png)

LoRA (Low-Rank Adaptation) နှင့် QLoRA (Quantized Low-Rank Adaptation) သည် Parameter Efficient Fine Tuning (PEFT) ကို အသုံးပြု၍ ကြီးမားသော ဘာသာစကား မော်ဒယ်များ (LLMs) ကို fine-tune ပြုလုပ်ရာတွင် အသုံးပြုသော နည်းပညာများဖြစ်သည်။ PEFT နည်းပညာများသည် ရိုးရာနည်းလမ်းများထက် ပိုမိုထိရောက်စွာ မော်ဒယ်များကို လေ့ကျင့်ရန် ရည်ရွယ်သည်။

LoRA သည် standalone finetuning နည်းလမ်းတစ်ခုဖြစ်ပြီး weight update matrix တွင် low-rank approximation ကို အသုံးပြုကာ မှတ်ဉာဏ် အသုံးပြုမှုကို လျော့ချပေးသည်။ လေ့ကျင့်ချိန် မြန်ဆန်ပြီး ရိုးရာ fine-tuning နည်းလမ်းများနှင့် ဆင်တူသော စွမ်းဆောင်ရည်ကို ထိန်းသိမ်းပေးသည်။

QLoRA သည် LoRA ၏ တိုးချဲ့ထားသော ဗားရှင်းဖြစ်ပြီး memory အသုံးပြုမှုကို ပိုမိုလျော့ချပေးရန် quantization နည်းပညာများကို ထည့်သွင်းထားသည်။ QLoRA သည် pre-trained LLM ၏ weight parameters များကို 4-bit precision သို့ quantize ပြုလုပ်ပြီး LoRA ထက် memory အသုံးပြုမှုပိုသက်သာစေသည်။ သို့သော် QLoRA လေ့ကျင့်မှုသည် quantization နှင့် dequantization အဆင့်များကြောင့် LoRA လေ့ကျင့်မှုထက် ၃၀% ခန့် နှေးကွေးသည်။

QLoRA သည် quantization မှ ဖြစ်ပေါ်လာသော အမှားများကို ပြင်ဆင်ရန် LoRA ကို အကူအညီအဖြစ် အသုံးပြုသည်။ QLoRA သည် ဘီလီယံပမာဏရှိသော parameter မော်ဒယ်များကို သေးငယ်ပြီး ရရှိနိုင်သော GPU များပေါ်တွင် fine-tune ပြုလုပ်နိုင်စေသည်။ ဥပမာအားဖြင့် QLoRA သည် ၃၆ GPU လိုအပ်သည့် 70B parameter မော်ဒယ်ကို GPU ၂ လုံးဖြင့် fine-tune ပြုလုပ်နိုင်သည်။

**အကြောင်းကြားချက်**  
ဤစာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ဖြင့် ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှန်ကန်မှုအတွက် ကြိုးပမ်းသော်လည်း အလိုအလျောက် ဘာသာပြန်ခြင်းတွင် အမှားများ သို့မဟုတ် မှားယွင်းမှုများ ပါဝင်နိုင်ကြောင်း သတိပြုပါရန် မေတ္တာရပ်ခံအပ်ပါသည်။ မူရင်းစာတမ်းကို မိမိဘာသာစကားဖြင့်သာ တရားဝင်အချက်အလက်အဖြစ် ယူဆသင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်မှ ဘာသာပြန်ခြင်းကို အကြံပြုပါသည်။ ဤဘာသာပြန်ချက်ကို အသုံးပြုရာမှ ဖြစ်ပေါ်လာနိုင်သည့် နားလည်မှုမှားယွင်းမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။