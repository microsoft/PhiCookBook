### Guidance-AI 和 Phi 模型即服务 (MaaS)
我们将 [Guidance](https://github.com/guidance-ai/guidance) 引入 Azure AI Foundry 中的 Phi-3.5-mini 无服务器端点，通过定义适合应用的结构，使输出更加可预测。借助 Guidance，您可以避免昂贵的重试，例如限制模型从预定义列表中选择（如医疗代码）、将输出限制为提供上下文中的直接引用，或遵循任意正则表达式。Guidance 在推理过程中逐个标记引导模型，降低了 30-50% 的成本和延迟，这使其成为 [Phi-3-mini 无服务器端点](https://aka.ms/try-phi3.5mini) 的独特且有价值的附加功能。

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) 是一个帮助开发者高效创建和部署 AI 模型的框架。它专注于提供构建稳健 AI 应用的工具和最佳实践。

结合 **Phi 模型即服务 (MaaS)**，它为部署既经济又高效的小型语言模型（SLM）提供了强大解决方案。

**Guidance-AI** 是一个编程框架，旨在帮助开发者更有效地控制和引导大型语言模型（LLM）。它允许精确构建输出结构，相较于传统的提示或微调方法，能减少延迟和成本。

### Guidance-AI 的主要特点：
- **高效控制**：使开发者能够掌控语言模型的文本生成，确保输出高质量且相关。
- **降低成本和延迟**：优化生成过程，更加经济且快速。
- **灵活集成**：支持多种后端，包括 Transformers、llama.cpp、AzureAI、VertexAI 和 OpenAI。
- **丰富的输出结构**：支持条件语句、循环和工具使用等复杂结构，便于生成清晰且易解析的结果。
- **兼容性强**：同一 Guidance 程序可在多个后端运行，提升灵活性和易用性。

### 示例用例：
- **受限生成**：使用正则表达式和上下文无关文法引导模型输出。
- **工具集成**：自动交替控制和生成，例如在文本生成任务中使用计算器。

更多详细信息和示例，请访问 [Guidance-AI GitHub 仓库](https://github.com/guidance-ai/guidance)。

[查看 Phi-3.5 示例](../../../../../code/01.Introduce/guidance.ipynb)

### Phi 模型的主要特点：
1. **经济实惠**：设计时兼顾成本效益和高性能。
2. **低延迟**：适合需要快速响应的实时应用。
3. **灵活性强**：可部署于云端、边缘和离线环境。
4. **可定制**：可通过领域特定数据微调模型以提升性能。
5. **安全合规**：遵循微软的 AI 原则，确保责任、透明、公平、可靠、安全、隐私和包容性。

### Phi 模型即服务 (MaaS)：
Phi 模型通过按需付费的推理 API 提供，方便将其集成到应用中，无需大量前期投入。

### 开始使用 Phi-3：
您可以浏览 [Azure AI 模型目录](https://ai.azure.com/explore/models) 或 [GitHub Marketplace Models](https://github.com/marketplace/models)，这里提供预构建和可定制的模型。此外，还可以使用 [Azure AI Foundry](https://ai.azure.com) 开发和部署 AI 应用。

### 资源
[Guidance 入门示例笔记本](../../../../../code/01.Introduce/guidance.ipynb)

**免责声明**：  
本文件使用 AI 翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。虽然我们力求准确，但请注意，自动翻译可能包含错误或不准确之处。原始文件的母语版本应被视为权威来源。对于重要信息，建议使用专业人工翻译。对于因使用本翻译而产生的任何误解或误释，我们概不负责。