<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3139a6a82f357a9f90f1fe51c4caf65a",
  "translation_date": "2025-07-16T22:01:24+00:00",
  "source_file": "md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "pl"
}
-->
# **Kwotowanie Phi-3.5 za pomocÄ… Intel OpenVINO**

Intel to najbardziej tradycyjny producent procesorÃ³w CPU z wieloma uÅ¼ytkownikami. Wraz z rozwojem uczenia maszynowego i gÅ‚Ä™bokiego uczenia, Intel doÅ‚Ä…czyÅ‚ rÃ³wnieÅ¼ do rywalizacji o przyspieszenie AI. Do inferencji modeli Intel wykorzystuje nie tylko GPU i CPU, ale takÅ¼e NPU.

Mamy nadziejÄ™ wdroÅ¼yÄ‡ rodzinÄ™ Phi-3.x na urzÄ…dzeniach koÅ„cowych, liczÄ…c na to, Å¼e stanie siÄ™ ona najwaÅ¼niejszÄ… czÄ™Å›ciÄ… AI PC i Copilot PC. Åadowanie modelu na urzÄ…dzeniu koÅ„cowym zaleÅ¼y od wspÃ³Å‚pracy rÃ³Å¼nych producentÃ³w sprzÄ™tu. Ten rozdziaÅ‚ koncentruje siÄ™ gÅ‚Ã³wnie na scenariuszu zastosowania Intel OpenVINO jako modelu kwantowego.

## **Czym jest OpenVINO**

OpenVINO to otwartoÅºrÃ³dÅ‚owy zestaw narzÄ™dzi do optymalizacji i wdraÅ¼ania modeli gÅ‚Ä™bokiego uczenia od chmury po urzÄ…dzenia brzegowe. Przyspiesza inferencjÄ™ gÅ‚Ä™bokiego uczenia w rÃ³Å¼nych zastosowaniach, takich jak generatywna AI, wideo, audio i jÄ™zyk, z modelami z popularnych frameworkÃ³w, takich jak PyTorch, TensorFlow, ONNX i innych. Konwertuj i optymalizuj modele oraz wdraÅ¼aj je na rÃ³Å¼nych urzÄ…dzeniach i Å›rodowiskach IntelÂ®, lokalnie i na urzÄ…dzeniach, w przeglÄ…darce lub w chmurze.

DziÄ™ki OpenVINO moÅ¼esz szybko skwantowaÄ‡ model GenAI na sprzÄ™cie Intela i przyspieszyÄ‡ referencyjny model.

Obecnie OpenVINO obsÅ‚uguje konwersjÄ™ kwantyzacji Phi-3.5-Vision oraz Phi-3.5 Instruct.

### **Konfiguracja Å›rodowiska**

Upewnij siÄ™, Å¼e zainstalowane sÄ… nastÄ™pujÄ…ce zaleÅ¼noÅ›ci Å›rodowiskowe, to jest requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Kwotowanie Phi-3.5-Instruct za pomocÄ… OpenVINO**

W terminalu uruchom ten skrypt

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Kwotowanie Phi-3.5-Vision za pomocÄ… OpenVINO**

Uruchom ten skrypt w Pythonie lub Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ðŸ¤– PrzykÅ‚ady dla Phi-3.5 z Intel OpenVINO**

| Laboratoria    | Opis | PrzejdÅº |
| -------- | ------- |  ------- |
| ðŸš€ Lab-Introduce Phi-3.5 Instruct  | Naucz siÄ™, jak uÅ¼ywaÄ‡ Phi-3.5 Instruct na swoim AI PC    |  [PrzejdÅº](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| ðŸš€ Lab-Introduce Phi-3.5 Vision (obraz) | Naucz siÄ™, jak uÅ¼ywaÄ‡ Phi-3.5 Vision do analizy obrazÃ³w na swoim AI PC      |  [PrzejdÅº](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| ðŸš€ Lab-Introduce Phi-3.5 Vision (wideo)   | Naucz siÄ™, jak uÅ¼ywaÄ‡ Phi-3.5 Vision do analizy wideo na swoim AI PC    |  [PrzejdÅº](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Zasoby**

1. Dowiedz siÄ™ wiÄ™cej o Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Repozytorium Intel OpenVINO na GitHub [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**ZastrzeÅ¼enie**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony przy uÅ¼yciu usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do dokÅ‚adnoÅ›ci, prosimy mieÄ‡ na uwadze, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji o kluczowym znaczeniu zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.