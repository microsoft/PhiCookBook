<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3139a6a82f357a9f90f1fe51c4caf65a",
  "translation_date": "2025-05-09T13:55:16+00:00",
  "source_file": "md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "pl"
}
-->
# **Kwantozowanie Phi-3.5 za pomoc Intel OpenVINO**

Intel jest najbardziej tradycyjnym producentem procesor贸w CPU z du偶 liczb u偶ytkownik贸w. Wraz z rozwojem uczenia maszynowego i gbokiego uczenia, Intel r贸wnie偶 doczy do rywalizacji o przyspieszenie AI. Do inferencji modeli Intel wykorzystuje nie tylko GPU i CPU, ale tak偶e NPU.

Mamy nadziej wdro偶y rodzin Phi-3.x na urzdzeniach kocowych, aby staa si najwa偶niejsz czci AI PC oraz Copilot PC. adowanie modelu na urzdzeniu kocowym zale偶y od wsp贸pracy r贸偶nych producent贸w sprztu. Ten rozdzia skupia si g贸wnie na zastosowaniu Intel OpenVINO jako narzdzia do kwantyzacji modelu.

## **Czym jest OpenVINO**

OpenVINO to otwarto藕r贸dowy zestaw narzdzi do optymalizacji i wdra偶ania modeli gbokiego uczenia od chmury po urzdzenia brzegowe. Przyspiesza inferencj deep learning w r贸偶nych zastosowaniach, takich jak generatywna AI, wideo, audio czy jzyk, obsugujc modele z popularnych framework贸w jak PyTorch, TensorFlow, ONNX i innych. Konwertuj i optymalizuj modele, a nastpnie wdra偶aj je na mieszance sprztu i rodowisk Intel庐, zar贸wno lokalnie, na urzdzeniach, w przegldarce, jak i w chmurze.

Dziki OpenVINO mo偶esz szybko wykona kwantyzacj modelu GenAI na sprzcie Intela i przyspieszy jego dziaanie.

Obecnie OpenVINO wspiera konwersj kwantyzacji dla Phi-3.5-Vision oraz Phi-3.5 Instruct.

### **Konfiguracja rodowiska**

Upewnij si, 偶e zainstalowano nastpujce zale偶noci rodowiskowe, jest to requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Kwantozowanie Phi-3.5-Instruct za pomoc OpenVINO**

W terminalu uruchom ten skrypt

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Kwantozowanie Phi-3.5-Vision za pomoc OpenVINO**

Uruchom ten skrypt w Pythonie lub Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### ** Przykady dla Phi-3.5 z Intel OpenVINO**

| Laboratorium    | Wprowadzenie | Przejd藕 |
| -------- | ------- |  ------- |
|  Lab-Wprowadzenie Phi-3.5 Instruct  | Naucz si, jak korzysta z Phi-3.5 Instruct na swoim AI PC    |  [Przejd藕](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
|  Lab-Wprowadzenie Phi-3.5 Vision (obraz) | Naucz si, jak korzysta z Phi-3.5 Vision do analizy obrazu na swoim AI PC      |  [Przejd藕](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
|  Lab-Wprowadzenie Phi-3.5 Vision (wideo)   | Naucz si, jak korzysta z Phi-3.5 Vision do analizy wideo na swoim AI PC    |  [Przejd藕](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Zasoby**

1. Dowiedz si wicej o Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Repozytorium Intel OpenVINO na GitHub [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Zastrze偶enie**:  
Niniejszy dokument zosta przetumaczony przy u偶yciu automatycznej usugi tumaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo 偶e d偶ymy do jak najwikszej dokadnoci, prosimy mie na uwadze, 偶e tumaczenia automatyczne mog zawiera bdy lub niecisoci. Oryginalny dokument w jzyku 藕r贸dowym powinien by traktowany jako autorytatywne 藕r贸do. W przypadku informacji o kluczowym znaczeniu zaleca si skorzystanie z profesjonalnego tumaczenia wykonanego przez czowieka. Nie ponosimy odpowiedzialnoci za jakiekolwiek nieporozumienia lub bdne interpretacje wynikajce z korzystania z tego tumaczenia.