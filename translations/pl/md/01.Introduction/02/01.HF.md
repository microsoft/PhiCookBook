<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-09T08:37:08+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "pl"
}
-->
# **Korzystanie z Phi Family w Hugging Face**


[Hugging Face](https://huggingface.co/) to bardzo popularna społeczność AI z bogatymi zasobami danych i otwartoźródłowymi modelami. Różni producenci udostępniają otwartoźródłowe modele LLM i SLM za pośrednictwem Hugging Face, takie jak Microsoft, Meta, Mistral, Apple, Google i inni.

Microsoft Phi Family zostało udostępnione na Hugging Face. Deweloperzy mogą pobierać odpowiednie modele Phi Family w zależności od scenariuszy i zastosowań biznesowych. Oprócz wdrażania modeli Phi w PyTorch na Hugging Face, udostępniliśmy również modele kwantyzowane, korzystające z formatów GGUF i ONNX, dając użytkownikom końcowym wybór.


## **Pobieranie modeli na Hugging Face**

Model Phi Family można pobrać pod tym linkiem

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Model można pobrać na różne sposoby, na przykład instalując ***Hugging face CLI SDK*** lub używając ***git clone***.

### **Pobieranie modelu Phi Family za pomocą Hugging face CLI**

- Instalacja Hugging face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Logowanie za pomocą huggingface-cli

Zaloguj się do Hugging Face używając [User Access Token](https://huggingface.co/docs/hub/security-tokens) ze swojej [strony ustawień](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Pobieranie 


Możesz pobrać model i zapisać go w pamięci podręcznej 

```bash

huggingface-cli download microsoft/phi-4

```

Możesz ustawić lokalizację w wybranym przez siebie miejscu


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Pobieranie modelu Phi Family za pomocą git clone**

Model można również pobrać za pomocą ***git clone***

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Przykłady - Inference Microsoft Phi-4**

- **Instalacja biblioteki transformers**

```bash

pip install transformers -U

```

- **Uruchomienie tego kodu w VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Zastrzeżenie**:  
Niniejszy dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy starań, aby tłumaczenie było precyzyjne, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w języku źródłowym powinien być uznawany za wiarygodne źródło. W przypadku informacji krytycznych zaleca się skorzystanie z profesjonalnego tłumaczenia wykonanego przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z korzystania z tego tłumaczenia.