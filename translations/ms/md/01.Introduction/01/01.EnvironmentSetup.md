<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:14:28+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "ms"
}
-->
# התחילו עם Phi-3 באופן מקומי

מדריך זה יסייע לכם להגדיר את סביבת העבודה המקומית שלכם כדי להריץ את מודל Phi-3 באמצעות Ollama. ניתן להריץ את המודל בכמה דרכים שונות, כולל שימוש ב-GitHub Codespaces, VS Code Dev Containers, או בסביבה המקומית שלכם.

## הגדרת הסביבה

### GitHub Codespaces

ניתן להריץ את התבנית הזו באופן וירטואלי באמצעות GitHub Codespaces. הכפתור יפתח מופע של VS Code מבוסס דפדפן:

1. פתחו את התבנית (זה עשוי לקחת כמה דקות):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. פתחו חלון טרמינל

### VS Code Dev Containers

⚠️ אפשרות זו תעבוד רק אם ל-Docker Desktop שלכם מוקצה לפחות 16 גיגה-בייט זיכרון RAM. אם יש לכם פחות מ-16 גיגה-בייט RAM, תוכלו לנסות את [אפשרות GitHub Codespaces](../../../../../md/01.Introduction/01) או [להגדיר את זה מקומית](../../../../../md/01.Introduction/01).

אפשרות קשורה היא VS Code Dev Containers, שתפתח את הפרויקט ב-VS Code המקומי שלכם באמצעות [הרחבת Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. הפעילו את Docker Desktop (התקינו אם עדיין לא מותקן)
2. פתחו את הפרויקט:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. בחלון VS Code שנפתח, ברגע שקבצי הפרויקט ייטענו (זה עשוי לקחת כמה דקות), פתחו חלון טרמינל.
4. המשיכו עם [שלבי הפריסה](../../../../../md/01.Introduction/01)

### סביבה מקומית

1. ודאו שכלים הבאים מותקנים:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## בדיקת המודל

1. בקשו מ-Ollama להוריד ולהריץ את מודל phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    זה ייקח כמה דקות להוריד את המודל.

2. ברגע שתראו "success" ביציאה, תוכלו לשלוח הודעה למודל דרך השורת הפקודה.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. לאחר מספר שניות, אמורה להופיע תגובה זורמת מהמודל.

4. כדי ללמוד על טכניקות שונות בשימוש במודלי שפה, פתחו את פנקס הפייתון [ollama.ipynb](../../../code/01.Introduce/ollama.ipynb והפעילו כל תא. אם השתמשתם במודל שונה מ-'phi3:mini', שנו את ה-`MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` בראש הקובץ לפי הצורך, וניתן גם לשנות את הודעת המערכת או להוסיף דוגמאות few-shot במידת הרצון.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sahih. Untuk maklumat kritikal, terjemahan profesional oleh manusia adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.