# Mula dengan Phi-3 secara tempatan

Panduan ini akan membantu anda menyediakan persekitaran tempatan untuk menjalankan model Phi-3 menggunakan Ollama. Anda boleh menjalankan model ini dengan beberapa cara berbeza, termasuk menggunakan GitHub Codespaces, VS Code Dev Containers, atau persekitaran tempatan anda.

## Penyediaan persekitaran

### GitHub Codespaces

Anda boleh menjalankan templat ini secara maya dengan menggunakan GitHub Codespaces. Butang ini akan membuka instans VS Code berasaskan web dalam pelayar anda:

1. Buka templat (ini mungkin mengambil masa beberapa minit):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buka tetingkap terminal

### VS Code Dev Containers

⚠️ Pilihan ini hanya akan berfungsi jika Docker Desktop anda diperuntukkan sekurang-kurangnya 16 GB RAM. Jika anda mempunyai kurang daripada 16 GB RAM, anda boleh cuba [pilihan GitHub Codespaces](../../../../../md/01.Introduction/01) atau [sediakan secara tempatan](../../../../../md/01.Introduction/01).

Pilihan berkaitan ialah VS Code Dev Containers, yang akan membuka projek dalam VS Code tempatan anda menggunakan [sambungan Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Mulakan Docker Desktop (pasang jika belum dipasang)
2. Buka projek:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Dalam tetingkap VS Code yang terbuka, setelah fail projek dipaparkan (ini mungkin mengambil masa beberapa minit), buka tetingkap terminal.
4. Teruskan dengan [langkah penyebaran](../../../../../md/01.Introduction/01)

### Persekitaran Tempatan

1. Pastikan alat berikut dipasang:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Uji model

1. Minta Ollama memuat turun dan menjalankan model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Ini akan mengambil masa beberapa minit untuk memuat turun model.

2. Setelah anda melihat "success" dalam output, anda boleh menghantar mesej ke model itu dari prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Selepas beberapa saat, anda sepatutnya melihat aliran respons dari model.

4. Untuk mempelajari teknik berbeza yang digunakan dengan model bahasa, buka notebook Python [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) dan jalankan setiap sel. Jika anda menggunakan model selain daripada 'phi3:mini', tukar `MODEL_NAME` dalam sel pertama.

5. Untuk berbual dengan model phi3:mini dari Python, buka fail Python [chat.py](../../../../../code/01.Introduce/chat.py) dan jalankan. Anda boleh menukar `MODEL_NAME` di bahagian atas fail mengikut keperluan, dan anda juga boleh mengubah mesej sistem atau menambah contoh few-shot jika mahu.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sahih. Untuk maklumat penting, terjemahan profesional oleh manusia adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.