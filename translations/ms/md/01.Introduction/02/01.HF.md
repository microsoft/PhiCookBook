<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-07-16T18:54:10+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "ms"
}
-->
# **Menggunakan Phi Family di Hugging Face**


[Hugging Face](https://huggingface.co/) adalah komuniti AI yang sangat popular dengan data yang kaya dan sumber model sumber terbuka. Pelbagai pengeluar akan mengeluarkan LLM dan SLM sumber terbuka melalui Hugging Face, seperti Microsoft, Meta, Mistral, Apple, Google, dan lain-lain.

Microsoft Phi Family telah dikeluarkan di Hugging Face. Pembangun boleh memuat turun model Phi Family yang sesuai berdasarkan senario dan perniagaan. Selain daripada menggunakan model Phi Pytorch di Hugging Face, kami juga mengeluarkan model yang telah dikuantisasi, menggunakan format GGUF dan ONNX untuk memberi pilihan kepada pengguna akhir.


## **Muat Turun Model di Hugging Face**

Anda boleh memuat turun model Phi family melalui pautan ini

[Model Microsoft di Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Anda boleh memuat turun model dengan pelbagai cara, seperti memasang ***Hugging face CLI SDK*** atau menggunakan ***git clone***.

### **Menggunakan Hugging face CLI untuk Memuat Turun model Phi Family**

- Pasang Hugging face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Menggunakan huggingface-cli untuk log masuk

Log masuk ke Hugging face dengan [User Access Token](https://huggingface.co/docs/hub/security-tokens) dari [halaman Tetapan anda](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Muat turun 


Anda boleh memuat turun model dan menyimpannya ke cache 

```bash

huggingface-cli download microsoft/phi-4

```

Anda boleh menetapkan lokasi di lokasi khas anda


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Menggunakan git clone untuk Memuat Turun model Phi Family**

Anda juga boleh menggunakan ***git clone*** untuk memuat turun model

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Contoh - Inferens Microsoft Phi-4**

- **Memasang perpustakaan transformers**

```bash

pip install transformers -U

```

- **Menjalankan kod ini di VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sahih. Untuk maklumat penting, terjemahan profesional oleh manusia adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.