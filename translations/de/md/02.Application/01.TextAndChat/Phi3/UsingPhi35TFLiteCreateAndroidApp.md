<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c4fe7f589d179be96a5577b0b8cba6aa",
  "translation_date": "2025-03-27T11:05:03+00:00",
  "source_file": "md\\02.Application\\01.TextAndChat\\Phi3\\UsingPhi35TFLiteCreateAndroidApp.md",
  "language_code": "de"
}
-->
# **Verwendung von Microsoft Phi-3.5 tflite zur Erstellung einer Android-App**

Dies ist ein Android-Beispiel, das Microsoft Phi-3.5 tflite-Modelle verwendet.

## **üìö Wissen**

Die Android LLM Inference API erm√∂glicht es, gro√üe Sprachmodelle (LLMs) vollst√§ndig auf Android-Ger√§ten auszuf√ºhren. Sie k√∂nnen damit eine Vielzahl von Aufgaben durchf√ºhren, wie beispielsweise das Generieren von Text, das Abrufen von Informationen in nat√ºrlicher Sprache und das Zusammenfassen von Dokumenten. Die API bietet integrierte Unterst√ºtzung f√ºr mehrere Text-zu-Text-Sprachmodelle, sodass Sie die neuesten generativen KI-Modelle direkt auf Ihren Android-Apps anwenden k√∂nnen.

Googld AI Edge Torch ist eine Python-Bibliothek, die die Umwandlung von PyTorch-Modellen in das .tflite-Format unterst√ºtzt. Diese Modelle k√∂nnen dann mit TensorFlow Lite und MediaPipe ausgef√ºhrt werden. Dies erm√∂glicht Anwendungen f√ºr Android, iOS und IoT, die Modelle vollst√§ndig auf dem Ger√§t ausf√ºhren k√∂nnen. AI Edge Torch bietet eine breite CPU-Abdeckung, mit anf√§nglicher Unterst√ºtzung f√ºr GPU und NPU. AI Edge Torch strebt eine enge Integration mit PyTorch an, baut auf torch.export() auf und bietet eine gute Abdeckung der Core ATen-Operatoren.

## **ü™¨ Anleitung**

### **üî• Microsoft Phi-3.5 in tflite konvertieren**

0. Dieses Beispiel ist f√ºr Android 14+

1. Python 3.10.12 installieren

***Empfehlung:*** Verwenden Sie conda, um Ihre Python-Umgebung zu installieren.

2. Ubuntu 20.04 / 22.04 (bitte konzentrieren Sie sich auf [google ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch))

***Empfehlung:*** Verwenden Sie eine Azure Linux VM oder eine VM eines Drittanbieters, um Ihre Umgebung zu erstellen.

3. Wechseln Sie zu Ihrer Linux-Bash, um die Python-Bibliothek zu installieren.

```bash

git clone https://github.com/google-ai-edge/ai-edge-torch.git

cd ai-edge-torch

pip install -r requirements.txt -U 

pip install tensorflow-cpu -U

pip install -e .

```

4. Laden Sie Microsoft-3.5-Instruct von Hugging Face herunter.

```bash

git lfs install

git clone  https://huggingface.co/microsoft/Phi-3.5-mini-instruct

```

5. Konvertieren Sie Microsoft Phi-3.5 in tflite.

```bash

python ai-edge-torch/ai_edge_torch/generative/examples/phi/convert_phi3_to_tflite.py --checkpoint_path  Your Microsoft Phi-3.5-mini-instruct path --tflite_path Your Microsoft Phi-3.5-mini-instruct tflite path  --prefill_seq_len 1024 --kv_cache_max_len 1280 --quantize True

```

### **üî• Microsoft Phi-3.5 in Android Mediapipe Bundle konvertieren**

Installieren Sie zuerst Mediapipe.

```bash

pip install mediapipe

```

F√ºhren Sie diesen Code in [Ihrem Notebook](../../../../../../code/09.UpdateSamples/Aug/Android/convert/convert_phi.ipynb) aus.

```python

import mediapipe as mp
from mediapipe.tasks.python.genai import bundler

config = bundler.BundleConfig(
    tflite_model='Your Phi-3.5 tflite model path',
    tokenizer_model='Your Phi-3.5 tokenizer model path',
    start_token='start_token',
    stop_tokens=[STOP_TOKENS],
    output_filename='Your Phi-3.5 task model path',
    enable_bytes_to_unicode_mapping=True or Flase,
)
bundler.create_bundle(config)

```

### **üî• Modell mit adb push auf den Pfad Ihres Android-Ger√§ts √ºbertragen**

```bash

adb shell rm -r /data/local/tmp/llm/ # Remove any previously loaded models

adb shell mkdir -p /data/local/tmp/llm/

adb push 'Your Phi-3.5 task model path' /data/local/tmp/llm/phi3.task

```

### **üî• Ihren Android-Code ausf√ºhren**

![demo](../../../../../../translated_images/demo.8981711efb5a9cee5dcd835f66b3b31b94b4f3e527300e15a98a0d48863b9fbd.de.png)

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die durch die Nutzung dieser √úbersetzung entstehen.