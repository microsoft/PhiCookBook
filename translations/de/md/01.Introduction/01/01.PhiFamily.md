<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5d936ffe4dfbab2244f6eb21b11f3b3",
  "translation_date": "2025-05-07T10:50:36+00:00",
  "source_file": "md/01.Introduction/01/01.PhiFamily.md",
  "language_code": "de"
}
-->
# Microsofts Phi-Familie

Die Phi-Modelle sind die leistungsfähigsten und kosteneffektivsten Small Language Models (SLMs) auf dem Markt. Sie übertreffen Modelle derselben Größe sowie die nächstgrößeren Modelle in verschiedenen Bereichen wie Sprache, logischem Denken, Programmierung, Audio, Bildverarbeitung und Mathematik. Diese Veröffentlichung erweitert die Auswahl an hochwertigen Modellen für Kunden und bietet praktischere Optionen für die Erstellung und Entwicklung generativer KI-Anwendungen.

Die Phi-Familie begann mit Phi-1 für die Python-Code-Generierung, setzte sich mit Phi-1.5 / 2 basierend auf Text- und Chat-Vervollständigung fort, gefolgt von Phi-3-mini/small/medium-instruct und Phi-3.5/4-mini-instruct, entwickelte sich weiter zu Phi-3/3.5-vision für Bildverarbeitung, Phi-4 mit starkem logischem Denken, Phi-3.5-MoE für MoE und nun zum vollmodalen Modell Phi-4-multimodal. Durch hochwertige Datensätze kann das Benchmark-Training Modelle mit größeren Trainingsparametern erreichen.

## Phi-Familienmodelle

<div style="font-size:8px">

| Model Card |Parameter|Programmierung|Text-/Chat-Vervollständigung|Fortgeschrittenes logisches Denken| Bildverarbeitung | Audio | MoE
| - | -  | - | - |- |- |- |- |
|[Phi-1](https://huggingface.co/microsoft/phi-1)|1.3B| JA| NEIN | NEIN |NEIN |NEIN |NEIN |
|[Phi-1.5](https://huggingface.co/microsoft/phi-1_5)|1.3B| JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-2](https://huggingface.co/microsoft/phi-1_5)|2.7B| JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)<br/>[Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)|3.8B| JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-3-small-8k-instruct](https://huggingface.co/microsoft/Phi-3-small-8k-instruct)<br/>[Phi-3-small-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct)<br/>|7B| JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-3-mediumn-4k-instruct](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)<br>[Phi-3-mediumn-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)|14B|JA|NEIN| NEIN |NEIN |NEIN |NEIN |
|[Phi-3-vision-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)|4.2B|JA|JA|NEIN |NEIN |NEIN |NEIN |
|[Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)|3.8B|JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct)|42B|JA|JA| NEIN |NEIN |NEIN |JA |
|[Phi-3.5-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3.5-vision-instruct)|4.2B|JA|JA| NEIN |JA |NEIN |NEIN |
|[Phi-4](https://huggingface.co/microsoft/phi-4)|14B|JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-4-mini](https://huggingface.co/microsoft/Phi-4-mini-instruct)|3.8B|JA|JA| NEIN |NEIN |NEIN |NEIN |
|[Phi-4-multimodal](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)|5.6B|JA|JA| NEIN |JA |JA |NEIN |
|[Phi-4-reasoning](../../../../../md/01.Introduction/01)|3.8B|JA|JA| JA |NEIN |NEIN |NEIN |
|[Phi-4-mini-reasoning](../../../../../md/01.Introduction/01)|3.8B|JA|JA| JA |NEIN |NEIN |NEIN |

</div>

## **Finde alle Phi-Modelle auf verschiedenen Modellplattformen**

- [Azure AI Foundry Model catalog](https://ai.azure.com/explore/models?selectedCollection=phi)
- [GitHub Models](https://github.com/marketplace?query=Phi&type=models)
- Hugging Face
  - [Phi-1 /1.5](https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572)
  - [Phi-2](https://huggingface.co/microsoft/phi-2)
  - [Phi-3](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)
  - [Phi-4](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4) 
- [NVIDIA NIM](https://build.nvidia.com/search?q=Phi)

## Beispiel für die Modellauswahl

| | | | |
|-|-|-|-|
|Kundenbedarf|Aufgabe|Start mit|Weitere Details|
|Benötigt ein Modell, das einfach eine Nachrichtenkette zusammenfasst|Gesprächszusammenfassung|Phi-3 / 3.5 Textmodell|Entscheidend ist hier, dass der Kunde eine klar definierte und unkomplizierte Sprachaufgabe hat|
|Eine kostenlose Mathe-Nachhilfe-App für Kinder|Mathematik und logisches Denken|Phi-3 / 3.5 / 4 Textmodelle|Da die App kostenlos ist, wünschen sich Kunden eine Lösung ohne wiederkehrende Kosten|
|Selbstüberwachende Autokamera|Bildanalyse|Phi-3 /3.5 -Vision oder Phi-4-multimodal|Es wird eine Lösung benötigt, die ohne Internet am Randgerät funktioniert|
|Möchte einen KI-basierten Reisebuchungsagenten entwickeln|Benötigt komplexe Planung, Funktionsaufrufe und Orchestrierung|GPT-Modelle|Benötigt die Fähigkeit, zu planen, APIs zur Informationsbeschaffung aufzurufen und auszuführen|
|Möchte einen Copiloten für ihre Mitarbeiter entwickeln|RAG, mehrere Domänen, komplex und offen|GPT-Modelle + Phi-Familie|Offenes Szenario, benötigt breiteres Weltwissen, daher ist ein größeres Modell besser geeignet. Das Wissen muss eventuell in Teile zerlegt werden, vielleicht ist SLM dafür gut geeignet|

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe des KI-Übersetzungsdienstes [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir auf Genauigkeit achten, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ursprungssprache ist als maßgebliche Quelle zu betrachten. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die durch die Nutzung dieser Übersetzung entstehen.