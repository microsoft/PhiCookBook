<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd049872f37c3079c87d4fe17109cea0",
  "translation_date": "2025-07-16T18:14:00+00:00",
  "source_file": "md/01.Introduction/01/01.Guidance.md",
  "language_code": "de"
}
-->
### Guidance-AI und Phi-Modelle als Service (MaaS)  
Wir bringen [Guidance](https://github.com/guidance-ai/guidance) zum Phi-3.5-mini serverlosen Endpunkt-Angebot in Azure AI Foundry, um die Ausgaben durch eine anwendungsspezifische Strukturvorlage vorhersehbarer zu machen. Mit Guidance können teure Wiederholungen vermieden werden, und es ist beispielsweise möglich, das Modell darauf zu beschränken, aus vordefinierten Listen auszuwählen (z. B. medizinische Codes), Ausgaben auf direkte Zitate aus dem bereitgestellten Kontext zu begrenzen oder beliebigen Regex-Regeln zu folgen. Guidance steuert das Modell Token für Token im Inferenz-Stack, was Kosten und Latenz um 30-50 % reduziert und es zu einer einzigartigen und wertvollen Ergänzung des [Phi-3-mini serverlosen Endpunkts](https://aka.ms/try-phi3.5mini) macht.

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) ist ein Framework, das Entwicklern hilft, KI-Modelle effizient zu erstellen und bereitzustellen. Es bietet Werkzeuge und bewährte Methoden, um robuste KI-Anwendungen zu entwickeln.

In Kombination mit **Phi Models as a Service (MaaS)** bietet es eine leistungsstarke Lösung für den Einsatz kleiner Sprachmodelle (SLMs), die sowohl kosteneffizient als auch leistungsstark sind.

**Guidance-AI** ist ein Programmier-Framework, das Entwicklern ermöglicht, große Sprachmodelle (LLMs) gezielter zu steuern. Es erlaubt eine präzise Strukturierung der Ausgaben und reduziert Latenz und Kosten im Vergleich zu herkömmlichen Prompting- oder Fine-Tuning-Methoden.

### Hauptmerkmale von Guidance-AI:  
- **Effiziente Steuerung**: Ermöglicht Entwicklern, die Textgenerierung des Sprachmodells zu kontrollieren und so qualitativ hochwertige und relevante Ausgaben sicherzustellen.  
- **Kosten- und Latenzreduktion**: Optimiert den Generierungsprozess, um kostengünstiger und schneller zu sein.  
- **Flexible Integration**: Funktioniert mit verschiedenen Backends, darunter Transformers, llama.cpp, AzureAI, VertexAI und OpenAI.  
- **Umfangreiche Ausgabe-Strukturen**: Unterstützt komplexe Ausgabestrukturen wie Bedingungen, Schleifen und Werkzeugnutzung, was die Erstellung klarer und parsbarer Ergebnisse erleichtert.  
- **Kompatibilität**: Ermöglicht die Ausführung eines einzigen Guidance-Programms auf mehreren Backends, was Flexibilität und Benutzerfreundlichkeit erhöht.

### Beispielanwendungen:  
- **Eingeschränkte Generierung**: Verwendung von regulären Ausdrücken und kontextfreien Grammatiken zur Steuerung der Modellausgabe.  
- **Werkzeugintegration**: Automatisches Wechseln zwischen Steuerung und Generierung, z. B. die Nutzung eines Taschenrechners innerhalb einer Textgenerierungsaufgabe.

Für detailliertere Informationen und Beispiele besuchen Sie das [Guidance-AI GitHub-Repository](https://github.com/guidance-ai/guidance).

[Schauen Sie sich das Phi-3.5-Beispiel an](../../../../../code/01.Introduce/guidance.ipynb)

### Hauptmerkmale der Phi-Modelle:  
1. **Kosteneffizient**: Entwickelt, um erschwinglich zu sein und gleichzeitig hohe Leistung zu bieten.  
2. **Niedrige Latenz**: Ideal für Echtzeitanwendungen, die schnelle Antworten erfordern.  
3. **Flexibilität**: Kann in verschiedenen Umgebungen eingesetzt werden, einschließlich Cloud, Edge und Offline-Szenarien.  
4. **Anpassbarkeit**: Modelle können mit domänenspezifischen Daten feinjustiert werden, um die Leistung zu verbessern.  
5. **Sicherheit und Compliance**: Entwickelt nach den KI-Prinzipien von Microsoft, die Verantwortlichkeit, Transparenz, Fairness, Zuverlässigkeit, Sicherheit, Datenschutz und Inklusivität gewährleisten.

### Phi Models as a Service (MaaS):  
Phi-Modelle sind über ein nutzungsbasiertes Abrechnungssystem über Inferenz-APIs verfügbar, was die Integration in Anwendungen ohne hohe Vorabkosten erleichtert.

### Einstieg mit Phi-3:  
Um mit Phi-Modellen zu starten, können Sie den [Azure AI Modelkatalog](https://ai.azure.com/explore/models) oder den [GitHub Marketplace Models](https://github.com/marketplace/models) erkunden, die vorgefertigte und anpassbare Modelle anbieten. Zusätzlich können Sie Tools wie [Azure AI Foundry](https://ai.azure.com) nutzen, um Ihre KI-Anwendungen zu entwickeln und bereitzustellen.

### Ressourcen  
[Beispiel-Notebook zum Einstieg mit Guidance](../../../../../code/01.Introduce/guidance.ipynb)

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ursprungssprache ist als maßgebliche Quelle zu betrachten. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die aus der Nutzung dieser Übersetzung entstehen.