<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd049872f37c3079c87d4fe17109cea0",
  "translation_date": "2025-03-27T05:46:10+00:00",
  "source_file": "md\\01.Introduction\\01\\01.Guidance.md",
  "language_code": "de"
}
-->
### Guidance-AI und Phi-Modelle als Service (MaaS)
Wir bringen [Guidance](https://github.com/guidance-ai/guidance) zum serverlosen Phi-3.5-mini-Endpunktangebot in Azure AI Foundry, um Ausgaben durch die Definition einer auf die Anwendung zugeschnittenen Struktur vorhersehbarer zu machen. Mit Guidance können Sie teure Wiederholungen vermeiden und beispielsweise das Modell darauf beschränken, aus vordefinierten Listen auszuwählen (z. B. medizinische Codes), Ausgaben auf direkte Zitate aus bereitgestelltem Kontext zu beschränken oder beliebige Regex-Muster zu befolgen. Guidance steuert das Modell Token für Token im Inferenz-Stack, wodurch die Kosten und Latenz um 30-50 % reduziert werden, was es zu einer einzigartigen und wertvollen Ergänzung des [Phi-3-mini serverlosen Endpunkts](https://aka.ms/try-phi3.5mini) macht.

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) ist ein Framework, das Entwicklern helfen soll, KI-Modelle effizient zu erstellen und bereitzustellen. Es konzentriert sich darauf, Werkzeuge und bewährte Verfahren für den Aufbau robuster KI-Anwendungen bereitzustellen.

In Kombination mit **Phi Models as a Service (MaaS)** bietet es eine leistungsstarke Lösung für die Bereitstellung kleiner Sprachmodelle (SLMs), die sowohl kosteneffizient als auch leistungsstark sind.

**Guidance-AI** ist ein Programmier-Framework, das Entwicklern hilft, große Sprachmodelle (LLMs) effektiver zu steuern und zu lenken. Es ermöglicht eine präzise Strukturierung der Ausgaben und reduziert Latenz und Kosten im Vergleich zu herkömmlichen Prompting- oder Fine-Tuning-Methoden.

### Hauptmerkmale von Guidance-AI:
- **Effiziente Steuerung**: Ermöglicht Entwicklern, die Textgenerierung des Sprachmodells zu kontrollieren und qualitativ hochwertige und relevante Ausgaben zu gewährleisten.
- **Kosten- und Latenzreduktion**: Optimiert den Generierungsprozess, um kosteneffizienter und schneller zu sein.
- **Flexible Integration**: Funktioniert mit verschiedenen Backends wie Transformers, llama.cpp, AzureAI, VertexAI und OpenAI.
- **Vielfältige Ausgabeformate**: Unterstützt komplexe Ausgabeformate wie Bedingungen, Schleifen und Tool-Nutzung, wodurch klare und interpretierbare Ergebnisse leichter generiert werden können.
- **Kompatibilität**: Erlaubt die Ausführung eines einzigen Guidance-Programms auf mehreren Backends, was Flexibilität und Benutzerfreundlichkeit erhöht.

### Anwendungsbeispiele:
- **Eingeschränkte Generierung**: Verwendung von regulären Ausdrücken und kontextfreien Grammatiken, um die Ausgabe des Modells zu steuern.
- **Tool-Integration**: Automatische Verknüpfung von Steuerung und Generierung, beispielsweise die Nutzung eines Rechners innerhalb einer Textgenerierungsaufgabe.

Für detailliertere Informationen und Beispiele können Sie das [Guidance-AI GitHub Repository](https://github.com/guidance-ai/guidance) besuchen.

[Phi-3.5 Beispiel ansehen](../../../../../code/01.Introduce/guidance.ipynb)

### Hauptmerkmale der Phi-Modelle:
1. **Kosteneffizienz**: Entwickelt, um erschwinglich zu sein und gleichzeitig hohe Leistung zu bieten.
2. **Niedrige Latenz**: Ideal für Echtzeitanwendungen, die schnelle Antworten erfordern.
3. **Flexibilität**: Kann in verschiedenen Umgebungen wie Cloud, Edge und Offline-Szenarien eingesetzt werden.
4. **Anpassbarkeit**: Modelle können mit domänenspezifischen Daten feinabgestimmt werden, um die Leistung zu verbessern.
5. **Sicherheit und Compliance**: Entwickelt nach den KI-Prinzipien von Microsoft, um Verantwortlichkeit, Transparenz, Fairness, Zuverlässigkeit, Sicherheit, Datenschutz und Inklusivität zu gewährleisten.

### Phi-Modelle als Service (MaaS):
Phi-Modelle sind über ein nutzungsbasiertes Abrechnungssystem über Inferenz-APIs verfügbar, was die Integration in Ihre Anwendungen ohne erhebliche Vorabkosten erleichtert.

### Erste Schritte mit Phi-3:
Um Phi-Modelle zu nutzen, können Sie den [Azure AI Modellkatalog](https://ai.azure.com/explore/models) oder den [GitHub Marketplace Models](https://github.com/marketplace/models) erkunden, der vorgefertigte und anpassbare Modelle bietet. Außerdem können Sie Tools wie [Azure AI Foundry](https://ai.azure.com) verwenden, um Ihre KI-Anwendungen zu entwickeln und bereitzustellen.

### Ressourcen
[Beispiel-Notebook für den Einstieg in Guidance](../../../../../code/01.Introduce/guidance.ipynb)

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe des KI-Übersetzungsdienstes [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die durch die Nutzung dieser Übersetzung entstehen.