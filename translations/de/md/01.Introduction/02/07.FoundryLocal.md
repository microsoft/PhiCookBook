<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-06-27T13:31:43+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "de"
}
-->
## Einstieg in Phi-Family-Modelle mit Foundry Local

### Einf√ºhrung in Foundry Local

Foundry Local ist eine leistungsstarke On-Device-AI-Inferenzl√∂sung, die KI-Funktionen in Unternehmensqualit√§t direkt auf Ihre lokale Hardware bringt. Dieses Tutorial f√ºhrt Sie durch die Einrichtung und Nutzung von Phi-Family-Modellen mit Foundry Local und bietet Ihnen vollst√§ndige Kontrolle √ºber Ihre KI-Workloads bei gleichzeitiger Wahrung der Privatsph√§re und Kostensenkung.

Foundry Local bietet Vorteile in Leistung, Datenschutz, Anpassung und Kosten, indem KI-Modelle lokal auf Ihrem Ger√§t ausgef√ºhrt werden. Es l√§sst sich nahtlos in Ihre bestehenden Workflows und Anwendungen integrieren ‚Äì √ºber eine intuitive CLI, SDK und REST API.


![arch](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7d68815ddb0153503587142ff32e6997041c7cf0c9df24b49.de.png)

### Warum Foundry Local w√§hlen?

Die Vorteile von Foundry Local zu kennen, hilft Ihnen dabei, fundierte Entscheidungen f√ºr Ihre KI-Einsatzstrategie zu treffen:

- **On-Device-Inferenz:** F√ºhren Sie Modelle lokal auf Ihrer eigenen Hardware aus, reduzieren Sie Kosten und behalten Sie alle Daten auf Ihrem Ger√§t.

- **Modellanpassung:** W√§hlen Sie aus voreingestellten Modellen oder nutzen Sie eigene Modelle, um spezifische Anforderungen und Anwendungsf√§lle abzudecken.

- **Kosteneffizienz:** Vermeiden Sie wiederkehrende Cloud-Service-Kosten, indem Sie Ihre vorhandene Hardware verwenden ‚Äì so wird KI zug√§nglicher.

- **Nahtlose Integration:** Verbinden Sie sich mit Ihren Anwendungen √ºber SDK, API-Endpunkte oder die CLI und skalieren Sie bei Bedarf problemlos zu Azure AI Foundry.

> **Getting Started Note:** Dieses Tutorial konzentriert sich auf die Nutzung von Foundry Local √ºber CLI- und SDK-Schnittstellen. Sie lernen beide Methoden kennen, um die beste L√∂sung f√ºr Ihren Anwendungsfall auszuw√§hlen.

## Teil 1: Einrichtung der Foundry Local CLI

### Schritt 1: Installation

Die Foundry Local CLI ist Ihr Einstiegspunkt, um KI-Modelle lokal zu verwalten und auszuf√ºhren. Beginnen wir mit der Installation auf Ihrem System.

**Unterst√ºtzte Plattformen:** Windows und macOS

Detaillierte Installationsanweisungen finden Sie in der [offiziellen Foundry Local Dokumentation](https://github.com/microsoft/Foundry-Local/blob/main/README.md).

### Schritt 2: Verf√ºgbare Modelle erkunden

Nachdem Sie die Foundry Local CLI installiert haben, k√∂nnen Sie herausfinden, welche Modelle f√ºr Ihren Anwendungsfall verf√ºgbar sind. Mit diesem Befehl sehen Sie alle unterst√ºtzten Modelle:


```bash
foundry model list
```

### Schritt 3: Phi Family Modelle verstehen

Die Phi Family bietet eine Reihe von Modellen, die f√ºr unterschiedliche Anwendungsf√§lle und Hardwarekonfigurationen optimiert sind. Hier sind die in Foundry Local verf√ºgbaren Phi-Modelle:

**Verf√ºgbare Phi-Modelle:** 

- **phi-3.5-mini** ‚Äì Kompaktes Modell f√ºr einfache Aufgaben
- **phi-3-mini-128k** ‚Äì Version mit erweitertem Kontext f√ºr l√§ngere Gespr√§che
- **phi-3-mini-4k** ‚Äì Standardmodell mit mittlerem Kontext f√ºr allgemeine Nutzung
- **phi-4** ‚Äì Fortgeschrittenes Modell mit verbesserten F√§higkeiten
- **phi-4-mini** ‚Äì Leichtgewichtige Variante von Phi-4
- **phi-4-mini-reasoning** ‚Äì Speziell f√ºr komplexe logische Aufgaben

> **Hardware-Kompatibilit√§t:** Jedes Modell kann je nach Systemkapazit√§t f√ºr verschiedene Hardwarebeschleunigungen (CPU, GPU) konfiguriert werden.

### Schritt 4: Ihr erstes Phi-Modell ausf√ºhren

Beginnen wir mit einem praktischen Beispiel. Wir f√ºhren das Modell `phi-4-mini-reasoning` aus, das sich besonders gut f√ºr die schrittweise L√∂sung komplexer Probleme eignet.


**Befehl zum Ausf√ºhren des Modells:**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **Erstmalige Einrichtung:** Beim ersten Ausf√ºhren eines Modells l√§dt Foundry Local dieses automatisch auf Ihr Ger√§t herunter. Die Downloadzeit h√§ngt von Ihrer Netzwerkgeschwindigkeit ab, bitte haben Sie w√§hrend der Einrichtung etwas Geduld.

### Schritt 5: Modell mit einem echten Problem testen

Testen wir nun unser Modell mit einem klassischen Logikproblem, um zu sehen, wie es schrittweises logisches Denken anwendet:

**Beispielproblem:**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**Erwartetes Verhalten:** Das Modell sollte dieses Problem in logische Schritte zerlegen und dabei die Tatsache nutzen, dass Fasane 2 Beine und Kaninchen 4 Beine haben, um das Gleichungssystem zu l√∂sen.

**Ergebnisse:**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d916093866d4df99190150d4198fd33ab79e586f9d6f5403089.de.png)

## Teil 2: Anwendungen mit Foundry Local SDK entwickeln

### Warum das SDK verwenden?

W√§hrend die CLI ideal f√ºr Tests und schnelle Interaktionen ist, erm√∂glicht das SDK die programmgesteuerte Integration von Foundry Local in Ihre Anwendungen. Dadurch er√∂ffnen sich M√∂glichkeiten wie:

- Entwicklung ma√ügeschneiderter KI-gest√ºtzter Anwendungen
- Erstellung automatisierter Workflows
- Einbindung von KI-Funktionen in bestehende Systeme
- Entwicklung von Chatbots und interaktiven Tools

### Unterst√ºtzte Programmiersprachen

Foundry Local bietet SDK-Unterst√ºtzung f√ºr mehrere Programmiersprachen, um Ihren Entwicklungspr√§ferenzen gerecht zu werden:

**üì¶ Verf√ºgbare SDKs:**

- **C# (.NET):** [SDK-Dokumentation & Beispiele](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)
- **Python:** [SDK-Dokumentation & Beispiele](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **JavaScript:** [SDK-Dokumentation & Beispiele](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)
- **Rust:** [SDK-Dokumentation & Beispiele](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### N√§chste Schritte

1. **W√§hlen Sie das f√ºr Sie passende SDK** basierend auf Ihrer Entwicklungsumgebung
2. **Folgen Sie der SDK-spezifischen Dokumentation** f√ºr detaillierte Implementierungsanleitungen
3. **Starten Sie mit einfachen Beispielen**, bevor Sie komplexe Anwendungen entwickeln
4. **Erkunden Sie den Beispielcode**, der in jedem SDK-Repository bereitgestellt wird

## Fazit

Sie haben jetzt gelernt, wie Sie:
- ‚úÖ Foundry Local CLI installieren und einrichten
- ‚úÖ Phi Family Modelle entdecken und ausf√ºhren
- ‚úÖ Modelle mit realen Problemen testen
- ‚úÖ SDK-Optionen f√ºr die Anwendungsentwicklung verstehen

Foundry Local bietet eine leistungsstarke Grundlage, um KI-Funktionen direkt in Ihre lokale Umgebung zu bringen. So behalten Sie die Kontrolle √ºber Leistung, Datenschutz und Kosten und bleiben gleichzeitig flexibel, bei Bedarf auf Cloud-L√∂sungen zu skalieren.

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache ist als ma√ügebliche Quelle zu betrachten. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die durch die Verwendung dieser √úbersetzung entstehen.