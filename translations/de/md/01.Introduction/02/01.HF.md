<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-07T10:38:45+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "de"
}
-->
# **Verwendung der Phi-Familie in Hugging Face**


[Hugging Face](https://huggingface.co/) ist eine sehr beliebte KI-Community mit umfangreichen Daten und Open-Source-Modellressourcen. Verschiedene Hersteller veröffentlichen über Hugging Face Open-Source-LLM- und SLM-Modelle, wie Microsoft, Meta, Mistral, Apple, Google usw.

Die Microsoft Phi-Familie wurde auf Hugging Face veröffentlicht. Entwickler können das passende Modell der Phi-Familie je nach Szenario und Geschäftsfeld herunterladen. Neben der Bereitstellung von Phi-Pytorch-Modellen auf Hugging Face haben wir auch quantisierte Modelle veröffentlicht, die im GGUF- und ONNX-Format vorliegen, um Endnutzern eine Auswahlmöglichkeit zu bieten.


## **Modelle bei Hugging Face herunterladen**

Du kannst das Phi-Familienmodell über diesen Link herunterladen

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Du kannst das Modell auf verschiedene Arten herunterladen, zum Beispiel durch Installation des ***Hugging face CLI SDK*** oder mit ***git clone***.

### **Hugging face CLI zur Modell-Installation der Phi-Familie verwenden**

- Hugging face CLI installieren

```bash

pip install -U "huggingface_hub[cli]"

```

- Mit huggingface-cli anmelden

Melde dich bei Hugging Face mit deinem [User Access Token](https://huggingface.co/docs/hub/security-tokens) von deiner [Einstellungsseite](https://huggingface.co/settings/tokens) an


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Herunterladen


Du kannst das Modell herunterladen und im Cache speichern

```bash

huggingface-cli download microsoft/phi-4

```

Du kannst den Speicherort auch an einem eigenen Ort festlegen


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Modell mit git clone herunterladen**

Du kannst das Modell auch mit ***git clone*** herunterladen

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Beispiele – Inferenz mit Microsoft Phi-4**

- **Installation der transformers-Bibliothek**

```bash

pip install transformers -U

```

- **Ausführen dieses Codes in VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe des KI-Übersetzungsdienstes [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir auf Genauigkeit achten, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ursprungssprache ist als maßgebliche Quelle zu betrachten. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die aus der Nutzung dieser Übersetzung entstehen.