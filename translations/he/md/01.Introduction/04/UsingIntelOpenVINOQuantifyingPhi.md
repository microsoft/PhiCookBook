# **转 Phi-3.5 爪注转 Intel OpenVINO**

Intel  爪专转 注 住专转转 转专 注 砖转砖 专. 注 注转    注拽, Intel 爪专驻   转专转 爪转 AI. 注专 驻专住 砖 , Intel  砖转砖转 专拽 -GPUs -CPUs,   -NPUs.

 拽 驻专住 转 砖驻转 Phi-3.x 爪 拽爪, 转拽 砖转驻 拽 砖 转专 砖 AI 砖 Copilot. 注转  爪 拽爪 转 砖转祝 驻注  爪专 专 砖. 驻专拽  转拽 注拽专 转专砖 砖砖 砖 Intel OpenVINO  转.

## **  OpenVINO**

OpenVINO  注专转  拽 驻转 驻爪 驻专住 砖   注拽 注 注 拽爪.  抓 驻专住 砖  注拽  转专砖,  AI 专, ,  砖驻, 注  住专转 驻驻专转  PyTorch, TensorFlow, ONNX 注. 专 驻 , 驻专住 注  专转 住转 砖 Intel庐,  拽转  砖专, 驻驻  注.

注转 注 OpenVINO, 转 专转 转 转  -GenAI 专转 Intel 抓 转 专驻专住 .

注转 OpenVINO 转 专转 转 砖 Phi-3.5-Vision -Phi-3.5 Instruct

### **专转 住**

  砖转拽转 转 转转 转 住,  拽抓 requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **转 Phi-3.5-Instruct 爪注转 OpenVINO**

专,  专抓 转 住拽专驻 

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **转 Phi-3.5-Vision 爪注转 OpenVINO**

 专抓 转 住拽专驻  -Python  -Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### ** 转 -Phi-3.5 注 Intel OpenVINO**

| 注转    | 拽 | 注专 |
| -------- | ------- |  ------- |
|  Lab-Introduce Phi-3.5 Instruct  |  爪 砖转砖 -Phi-3.5 Instruct 砖 -AI 砖    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
|  Lab-Introduce Phi-3.5 Vision (转) |  爪 砖转砖 -Phi-3.5 Vision 转 转转 砖 -AI 砖      |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
|  Lab-Introduce Phi-3.5 Vision ()   |  爪 砖转砖 -Phi-3.5 Vision 转  砖 -AI 砖    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **砖**

1. 注 住祝 注 Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. 专 GitHub 砖 Intel OpenVINO [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**转 转专**:  
住  转专 爪注转 砖专转 转专 住住  转转 [Co-op Translator](https://github.com/Azure/co-op-translator). 专转 砖 砖驻 拽, 砖 拽转 砖  转专  注  砖转  -拽. 住 拽专 砖驻转 拽专 砖 砖 拽专 住转. 注 拽专 抓 砖转砖 转专 拽爪注 注  转专 砖.   砖 专转  -  驻专砖转 砖 注转 砖砖 转专 .