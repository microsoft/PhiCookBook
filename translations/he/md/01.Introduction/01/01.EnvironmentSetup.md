<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:12:45+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "he"
}
-->
# התחילו עם Phi-3 מקומית

המדריך הזה יעזור לכם להגדיר את הסביבה המקומית שלכם כדי להריץ את מודל Phi-3 באמצעות Ollama. תוכלו להריץ את המודל בכמה דרכים שונות, כולל שימוש ב-GitHub Codespaces, VS Code Dev Containers, או בסביבה המקומית שלכם.

## הגדרת סביבה

### GitHub Codespaces

ניתן להריץ את התבנית הזו באופן וירטואלי באמצעות GitHub Codespaces. הכפתור יפתח מופע VS Code מבוסס דפדפן בדפדפן שלכם:

1. פתחו את התבנית (זה עשוי לקחת כמה דקות):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. פתחו חלון טרמינל

### VS Code Dev Containers

⚠️ אפשרות זו תעבוד רק אם ל-Docker Desktop שלכם מוקצה לפחות 16 גיגה-בייט זיכרון RAM. אם יש לכם פחות מ-16 גיגה-בייט RAM, תוכלו לנסות את [אפשרות GitHub Codespaces](../../../../../md/01.Introduction/01) או [להגדיר את זה מקומית](../../../../../md/01.Introduction/01).

אפשרות קשורה היא VS Code Dev Containers, שתפתח את הפרויקט ב-VS Code המקומי שלכם באמצעות [תוסף Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. הפעלו את Docker Desktop (התקינו אותו אם עדיין לא מותקן)
2. פתחו את הפרויקט:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. בחלון VS Code שנפתח, לאחר שהקבצים של הפרויקט יופיעו (זה עשוי לקחת כמה דקות), פתחו חלון טרמינל.
4. המשיכו עם [שלבי הפריסה](../../../../../md/01.Introduction/01)

### סביבה מקומית

1. ודאו שהכלים הבאים מותקנים:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## בדיקת המודל

1. בקשו מ-Ollama להוריד ולהריץ את המודל phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    זה ייקח כמה דקות להוריד את המודל.

2. ברגע שתראו "success" בתוצאה, תוכלו לשלוח הודעה למודל הזה דרך הפרומפט.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. לאחר כמה שניות, אמור להופיע זרם תגובות מהמודל.

4. כדי ללמוד על טכניקות שונות שמשתמשות במודלים של שפה, פתחו את פנקס הפייתון [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) והריצו כל תא. אם השתמשתם במודל שונה מ-'phi3:mini', שנו את `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` בראש הקובץ לפי הצורך, ואתם יכולים גם לשנות את הודעת המערכת או להוסיף דוגמאות של few-shot אם תרצו.

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון כי תרגומים אוטומטיים עלולים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפת המקור שלו צריך להיחשב למקור הסמכותי. עבור מידע קריטי, מומלץ תרגום מקצועי על ידי מתרגם אנושי. אנו לא נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעת מהשימוש בתרגום זה.