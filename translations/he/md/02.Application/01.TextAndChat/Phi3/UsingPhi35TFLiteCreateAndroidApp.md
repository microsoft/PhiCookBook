<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c4fe7f589d179be96a5577b0b8cba6aa",
  "translation_date": "2025-05-09T18:49:42+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md",
  "language_code": "he"
}
-->
# **砖砖 -Microsoft Phi-3.5 tflite 爪专转 驻拽爪转 专**

  专 砖转砖转  砖 Microsoft Phi-3.5 tflite.

## ** 注**

Android LLM Inference API 驻砖专 专抓   砖 砖驻 (LLMs) 爪专  砖专 注专 驻拽爪转 专,  砖转 砖转砖  爪注  专 砖 砖转,  爪专转 拽住, 砖驻转 注 爪专 砖 砖驻 注转, 住 住. 砖 转转 驻    砖 拽住-拽住,  砖转  转  -AI 专 注 转专 砖专 注 驻拽爪转 砖.

Googld AI Edge Torch  住驻专转 驻转 转转 专转  -PyTorch 驻专 .tflite, 砖转 专抓 注 TensorFlow Lite -MediaPipe.  驻砖专 驻拽爪转 专, iOS -IoT 砖转 专抓  爪专  砖专. AI Edge Torch 爪注 转 专 -CPU, 注 转 专砖转 -GPU -NPU. AI Edge Torch 砖驻转 砖转  注 PyTorch, 转住住转 注 torch.export() 住驻拽转 转  驻专爪转 Core ATen.

## ** 转**

### ** 专转 Microsoft Phi-3.5 转 -tflite**

0.  注转 -Android 14+

1. 转拽 Python 3.10.12

***爪:*** 砖转砖 -conda 转拽转 住转 驻转 砖

2. Ubuntu 20.04 / 22.04 (砖 转拽 -[google ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch))

***爪:*** 砖转砖 -Azure Linux VM  -VM 注 爪 砖砖 爪专转 住 砖

3. 注专 专 拽住 砖, 转拽转 住驻专转 驻转

```bash

git clone https://github.com/google-ai-edge/ai-edge-torch.git

cd ai-edge-torch

pip install -r requirements.txt -U 

pip install tensorflow-cpu -U

pip install -e .

```

4. 专 转 Microsoft-3.5-Instruct -Hugging face

```bash

git lfs install

git clone  https://huggingface.co/microsoft/Phi-3.5-mini-instruct

```

5. 专 转 Microsoft Phi-3.5 -tflite

```bash

python ai-edge-torch/ai_edge_torch/generative/examples/phi/convert_phi3_to_tflite.py --checkpoint_path  Your Microsoft Phi-3.5-mini-instruct path --tflite_path Your Microsoft Phi-3.5-mini-instruct tflite path  --prefill_seq_len 1024 --kv_cache_max_len 1280 --quantize True

```

### ** 专转 Microsoft Phi-3.5 -Mediapipe Bundle 专**

 转拽 转 mediapipe 转

```bash

pip install mediapipe

```

驻注 转 拽  -[专转 砖](../../../../../../code/09.UpdateSamples/Aug/Android/convert/convert_phi.ipynb)

```python

import mediapipe as mp
from mediapipe.tasks.python.genai import bundler

config = bundler.BundleConfig(
    tflite_model='Your Phi-3.5 tflite model path',
    tokenizer_model='Your Phi-3.5 tokenizer model path',
    start_token='start_token',
    stop_tokens=[STOP_TOKENS],
    output_filename='Your Phi-3.5 task model path',
    enable_bytes_to_unicode_mapping=True or Flase,
)
bundler.create_bundle(config)

```

### ** 注专转  砖 砖专 专 砖 爪注转 adb push**

```bash

adb shell rm -r /data/local/tmp/llm/ # Remove any previously loaded models

adb shell mkdir -p /data/local/tmp/llm/

adb push 'Your Phi-3.5 task model path' /data/local/tmp/llm/phi3.task

```

### ** 专爪转 拽 专 砖**

![demo](../../../../../../translated_images/demo.8981711efb5a9cee5dcd835f66b3b31b94b4f3e527300e15a98a0d48863b9fbd.he.png)

**转 转专**:  
住  转专 爪注转 砖专转 转专 住住  转转 [Co-op Translator](https://github.com/Azure/co-op-translator). 专转 砖 砖驻 拽, 砖 转 注  砖转专  注  砖转  -拽. 住 拽专 砖驻转 拽专 砖 爪专 砖 拽专 住转. 注 拽专 抓 砖转砖 转专 拽爪注 砖 .   专  -转  驻专砖转 砖转 注转 砖砖 转专 .