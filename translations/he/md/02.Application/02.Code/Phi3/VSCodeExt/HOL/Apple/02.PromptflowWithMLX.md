<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-05-09T19:40:15+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/Apple/02.PromptflowWithMLX.md",
  "language_code": "he"
}
-->
# **מעבדה 2 - הפעלת Prompt flow עם Phi-3-mini ב-AIPC**

## **מה זה Prompt flow**

Prompt flow היא חבילת כלים לפיתוח שנועדה לפשט את מחזור הפיתוח המלא של אפליקציות AI מבוססות LLM, מהרעיון, דרך יצירת אבטיפוס, בדיקות, הערכה ועד לפריסה ומעקב בייצור. היא הופכת את הנדסת הפרומפטים לקלה יותר ומאפשרת לך לבנות אפליקציות LLM באיכות ייצור.

עם prompt flow תוכל:

- ליצור זרימות שמקשרות בין LLMים, פרומפטים, קוד פייתון וכלים נוספים יחד בזרימת עבודה שניתן להריץ.

- לבצע דיבאג ואיטרציה על הזרימות שלך, במיוחד את האינטראקציה עם ה-LLM בקלות.

- להעריך את הזרימות שלך, לחשב מדדי איכות וביצועים עם מערכי נתונים גדולים יותר.

- לשלב את הבדיקות וההערכה במערכת ה-CI/CD שלך כדי להבטיח איכות הזרימה.

- לפרוס את הזרימות לפלטפורמת השרתים שתבחר או לשלב אותן בבסיס הקוד של האפליקציה שלך בקלות.

- (אופציונלי אך מומלץ מאוד) לשתף פעולה עם הצוות שלך באמצעות גרסת הענן של Prompt flow ב-Azure AI.



## **בניית זרימות קוד גנרציה על Apple Silicon**

***הערה*** ：אם לא השלמת את התקנת הסביבה, אנא בקר ב-[Lab 0 -Installations](./01.Installations.md)

1. פתח את תוסף Prompt flow ב-Visual Studio Code וצור פרויקט זרימה ריק

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.he.png)

2. הוסף פרמטרים של קלט ופלט והוסף קוד פייתון כזרימה חדשה

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.he.png)


אתה יכול להיעזר במבנה הזה (flow.dag.yaml) כדי לבנות את הזרימה שלך

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. כוונן את phi-3-mini

אנו שואפים להריץ טוב יותר SLM במכשירים מקומיים. בדרך כלל, אנו מכווננים את המודל (INT4, FP16, FP32)


```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**הערה:** התיקייה ברירת המחדל היא mlx_model 

4. הוסף קוד ב-***Chat_With_Phi3.py***


```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. תוכל לבדוק את הזרימה דרך Debug או Run כדי לוודא שהקוד הגנרציה עובד כראוי

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.he.png)

5. הפעל את הזרימה כ-API לפיתוח בטרמינל

```

pf flow serve --source ./ --port 8080 --host localhost   

```

תוכל לבדוק זאת ב-Postman / Thunder Client


### **הערה**

1. הריצה הראשונה לוקחת זמן רב. מומלץ להוריד את מודל phi-3 דרך Hugging face CLI.

2. בהתחשב במגבלות כוח המחשוב של Intel NPU, מומלץ להשתמש ב-Phi-3-mini-4k-instruct

3. אנו משתמשים בהאצת Intel NPU לכוונון המרה ל-INT4, אך אם אתה מפעיל את השירות שוב, יש למחוק את תיקיות המטמון ו-nc_workshop.



## **משאבים**

1. ללמוד על Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. ללמוד על האצת Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. קוד לדוגמה, הורדה [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון כי תרגומים אוטומטיים עלולים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפת המקור שלו הוא המקור הסמכותי. למידע קריטי מומלץ להשתמש בתרגום מקצועי של אדם. אנו לא נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעים משימוש בתרגום זה.