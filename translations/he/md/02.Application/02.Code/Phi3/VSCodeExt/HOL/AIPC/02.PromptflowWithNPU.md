<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-05-09T19:24:48+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "he"
}
-->
# **מעבדה 2 - הרצת Prompt flow עם Phi-3-mini ב-AIPC**

## **מה זה Prompt flow**

Prompt flow היא חבילת כלים לפיתוח שנועדה לייעל את מחזור הפיתוח המלא של יישומי AI מבוססי LLM, מהרעיון, דרך יצירת אב-טיפוס, בדיקות, הערכה ועד לפריסה במערכת הפקה ומעקב. היא הופכת את הנדסת הפרומפט לפשוטה יותר ומאפשרת לבנות אפליקציות LLM באיכות הפקה.

עם Prompt flow תוכל:

- ליצור זרימות שמקשרות בין LLMים, פרומפטים, קוד Python וכלים נוספים בזרימת עבודה ניתנת להרצה.

- לבצע דיבאג ואיטרציה על הזרימות שלך, במיוחד על האינטראקציה עם LLMים, בקלות.

- להעריך את הזרימות, לחשב מדדי איכות וביצועים עם מערכי נתונים גדולים יותר.

- לשלב את הבדיקות וההערכה במערכת ה-CI/CD שלך כדי להבטיח איכות של הזרימה.

- לפרוס את הזרימות לפלטפורמת השירות שבחרת או לשלב אותן בקוד האפליקציה שלך בקלות.

- (אופציונלי אך מומלץ מאוד) לשתף פעולה עם הצוות שלך באמצעות גרסת הענן של Prompt flow ב-Azure AI.

## **מה זה AIPC**

מחשב AI כולל מעבד (CPU), מעבד גרפי (GPU) ומעבד נוירוני (NPU), כאשר לכל אחד מהם יכולות האצה ספציפיות ל-AI. NPU, או יחידת עיבוד נוירונית, הוא מאיץ ייחודי המטפל במשימות בינה מלאכותית ולמידת מכונה ישירות במחשב שלך, במקום לשלוח את הנתונים לעיבוד בענן. ה-GPU וה-CPU יכולים גם לעבד את העומסים האלה, אך ה-NPU מצטיין במיוחד בחישובי AI עם צריכת חשמל נמוכה. מחשב ה-AI מייצג שינוי יסודי באופן שבו המחשבים שלנו פועלים. הוא לא פתרון לבעיה שלא הייתה קיימת קודם, אלא הבטחה לשיפור משמעותי בשימוש היומיומי במחשב.

אז איך זה עובד? בהשוואה ל-AI גנרטיבי ולמודלים גדולים של שפה (LLMs) המאומנים על כמות עצומה של נתונים ציבוריים, ה-AI שיתבצע במחשב שלך יהיה נגיש יותר ברמות שונות. הקונספט קל יותר לעיכול, ומכיוון שהוא מאומן על הנתונים שלך, מבלי צורך בגישה לענן, היתרונות שלו מושכים מיידית קהל רחב יותר.

בטווח הקרוב, עולם ה-AI PC כולל עוזרים אישיים ומודלים קטנים יותר של AI שרצים ישירות במחשב שלך, משתמשים בנתונים שלך כדי להציע שיפורים אישיים, פרטיים ובטוחים יותר לדברים שאתה עושה כל יום – כמו תיעוד פגישות, ארגון ליגת פנטזי כדורגל, אוטומציה של שיפורים בעריכת תמונות ווידאו, או תכנון מסלול מושלם למפגש משפחתי בהתבסס על זמני הגעה ועזיבה של כולם.

## **בניית זרימות קוד גנרציה ב-AIPC**

***Note*** ：אם לא השלמת את התקנת הסביבה, אנא בקר ב-[Lab 0 -Installations](./01.Installations.md)

1. פתח את התוסף Prompt flow ב-Visual Studio Code וצור פרויקט זרימה ריק

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.he.png)

2. הוסף פרמטרים של קלט ופלט והוסף קוד Python כזרימה חדשה

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.he.png)

אתה יכול להתייחס למבנה הזה (flow.dag.yaml) כדי לבנות את הזרימה שלך

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. הוסף קוד ב-***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. תוכל לבדוק את הזרימה דרך דיבאג או הרצה כדי לוודא שהקוד הגנרטיבי עובד

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.he.png)

5. הרץ את הזרימה כ-API לפיתוח בטרמינל

```

pf flow serve --source ./ --port 8080 --host localhost   

```

תוכל לבדוק זאת ב-Postman / Thunder Client

### **Note**

1. ההרצה הראשונה אורכת זמן רב. מומלץ להוריד את מודל phi-3 דרך Hugging face CLI.

2. בהתחשב בכוח המחשוב המוגבל של Intel NPU, מומלץ להשתמש ב-Phi-3-mini-4k-instruct

3. אנו משתמשים בהאצת Intel NPU כדי לכמת להמרת INT4, אך אם תריץ מחדש את השירות, יש למחוק את תיקיות הקאש ו-nc_workshop.

## **משאבים**

1. ללמוד על Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. ללמוד על האצת Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. קוד לדוגמה, הורדה [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון כי תרגומים אוטומטיים עלולים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית הוא המקור הסמכותי שיש להסתמך עליו. למידע קריטי מומלץ להיעזר בתרגום מקצועי אנושי. אנו לא נושאים באחריות לכל אי הבנה או פרשנות שגויה הנובעת משימוש בתרגום זה.