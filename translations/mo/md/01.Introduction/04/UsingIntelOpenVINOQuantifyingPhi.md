<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8f766ec7e68d97f6009b58794b471d66",
  "translation_date": "2025-04-04T12:13:37+00:00",
  "source_file": "md\\01.Introduction\\04\\UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "mo"
}
-->
# **Quantizing Phi-3.5 using Intel OpenVINO**

Intel Ã«shtÃ« njÃ« nga prodhuesit mÃ« tradicionalÃ« tÃ« CPU-ve me shumÃ« pÃ«rdorues. Me rritjen e mÃ«simit tÃ« makinerive dhe tÃ« thellÃ«, Intel ka hyrÃ« gjithashtu nÃ« garÃ«n pÃ«r pÃ«rshpejtimin e AI-sÃ«. PÃ«r inferencÃ«n e modeleve, Intel jo vetÃ«m qÃ« pÃ«rdor GPU dhe CPU, por edhe NPU.

Ne shpresojmÃ« tÃ« shpÃ«rndajmÃ« Familjen Phi-3.x nÃ« pajisjet fundore, duke synuar tÃ« bÃ«het pjesa mÃ« e rÃ«ndÃ«sishme e PC-ve AI dhe PC-ve Copilot. Ngarkimi i modelit nÃ« pajisjet fundore varet nga bashkÃ«punimi i prodhuesve tÃ« ndryshÃ«m tÃ« harduerit. Ky kapitull fokusohet kryesisht nÃ« skenarin e aplikimit tÃ« Intel OpenVINO si model i kuantifikuar.

## **Ã‡farÃ« Ã«shtÃ« OpenVINO**

OpenVINO Ã«shtÃ« njÃ« mjet me burim tÃ« hapur pÃ«r optimizimin dhe shpÃ«rndarjen e modeleve tÃ« mÃ«simit tÃ« thellÃ« nga cloud-i te pajisjet fundore. Ai pÃ«rshpejton inferencÃ«n e mÃ«simit tÃ« thellÃ« nÃ« pÃ«rdorime tÃ« ndryshme, si AI gjenerues, video, audio dhe gjuhÃ« me modele nga kornizat e njohura si PyTorch, TensorFlow, ONNX dhe mÃ« shumÃ«. Konvertoni dhe optimizoni modele, dhe shpÃ«rndajini nÃ« njÃ« kombinim tÃ« harduerÃ«ve dhe mjediseve IntelÂ®, nÃ« premisa dhe nÃ« pajisje, nÃ« shfletues ose nÃ« cloud.

Tani me OpenVINO, ju mund tÃ« kuantifikoni shpejt modelin GenAI nÃ« harduerin Intel dhe tÃ« pÃ«rshpejtoni referencÃ«n e modelit.

Tani OpenVINO mbÃ«shtet konvertimin e kuantifikimit tÃ« Phi-3.5-Vision dhe Phi-3.5 Instruct.

### **Konfigurimi i Mjedisit**

Ju lutemi sigurohuni qÃ« varÃ«sitÃ« e mjedisit tÃ« mÃ«poshtÃ«m tÃ« jenÃ« instaluar, kjo Ã«shtÃ« requirement.txt 

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Kuantifikimi i Phi-3.5-Instruct duke pÃ«rdorur OpenVINO**

NÃ« Terminal, ju lutemi ekzekutoni kÃ«tÃ« skript

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Kuantifikimi i Phi-3.5-Vision duke pÃ«rdorur OpenVINO**

Ju lutemi ekzekutoni kÃ«tÃ« skript nÃ« Python ose Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ðŸ¤– Shembuj pÃ«r Phi-3.5 me Intel OpenVINO**

| LaboratorÃ«    | Prezantim | Shko |
| -------- | ------- |  ------- |
| ðŸš€ Laborator-Prezanto Phi-3.5 Instruct  | MÃ«soni si tÃ« pÃ«rdorni Phi-3.5 Instruct nÃ« PC-nÃ« tuaj AI    |  [Shko](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| ðŸš€ Laborator-Prezanto Phi-3.5 Vision (imazh) | MÃ«soni si tÃ« pÃ«rdorni Phi-3.5 Vision pÃ«r tÃ« analizuar imazhe nÃ« PC-nÃ« tuaj AI      |  [Shko](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| ðŸš€ Laborator-Prezanto Phi-3.5 Vision (video)   | MÃ«soni si tÃ« pÃ«rdorni Phi-3.5 Vision pÃ«r tÃ« analizuar video nÃ« PC-nÃ« tuaj AI    |  [Shko](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Burime**

1. MÃ«soni mÃ« shumÃ« rreth Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Repo-ja GitHub e Intel OpenVINO [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

It seems like you want the text translated into "mo," but could you clarify what "mo" refers to? Are you asking for a translation into a specific language, such as Maori, Mongolian, or another language? Let me know so I can assist you accurately!