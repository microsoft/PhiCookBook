<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T17:22:03+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "mo"
}
-->
# Phi 模型的 AI 安全性
Phi 系列模型係根據 [Microsoft 負責任 AI 標準](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard) 開發，該標準係一個涵蓋全公司的要求集，基於以下六項原則：問責制、透明度、公平性、可靠性與安全、私隱與安全，以及包容性，形成 [Microsoft 的負責任 AI 原則](https://www.microsoft.com/ai/responsible-ai)。

如同之前的 Phi 模型，採用了多方面嘅安全評估同安全後訓練方法，並採取額外措施以考慮呢個版本嘅多語言能力。我哋嘅安全訓練同評估方法，包括跨多語言與風險類別嘅測試，已喺 [Phi 安全後訓練論文](https://arxiv.org/abs/2407.13833) 中作詳細說明。雖然 Phi 模型受惠於此方法，開發者仍應實施負責任 AI 嘅最佳實踐，包括繪製、衡量及緩解與佢哋特定使用案例同文化語言環境相關嘅風險。

## 最佳實務

如同其他模型，Phi 系列模型都有可能表現出不公平、不可靠或冒犯性嘅行為。

需要注意嘅 SLM 同 LLM 限制性行為包括：

- **服務質量：** Phi 模型主要喺英語文本上進行訓練。非英語語言表現會較差。訓練數據中代表較少嘅英語語言變種，表現可能比標準美式英語更差。
- **傷害嘅表達及刻板印象嘅延續：** 這些模型可能過度或不足地表達某啲群體，抹除部分群體嘅代表性，或強化貶義或負面刻板印象。儘管有安全後訓練，呢啲限制仍可能存在，因為不同群體嘅代表程度不一，或者訓練數據中負面刻板印象嘅例子反映現實世界嘅模式同社會偏見。
- **不適當或冒犯性內容：** 這些模型有可能產生其他類型嘅不適當或冒犯性內容，喺無針對性用例嘅額外緩解措施之下，可能唔適合喺敏感場合使用。
資訊可靠度：語言模型可能產生荒謬嘅內容，或者捏造聽起來合理但係不準確或過時嘅內容。
- **程式碼範圍有限：** 多數 Phi-3 訓練資料係基於 Python，同使用常用套件如 "typing, math, random, collections, datetime, itertools"。如果模型產生利用其他套件或其他語言嘅 Python 腳本，強烈建議用戶手動驗證所有 API 嘅使用情況。

開發者應採用負責任 AI 嘅最佳實踐，並有責任確保特定使用案例遵守相關法律法規（例如私隱、貿易等）。

## 負責任 AI 考量

如同其他語言模型，Phi 系列模型有可能表現出不公平、不可靠或冒犯性行為。需要注意嘅限制性行為包括：

**服務質量：** Phi 模型主要喺英語文本上訓練。非英語語言嘅表現會較差。喺訓練資料中代表較少嘅英語語言變種表現可能比標準美式英語更差。

**傷害嘅表達及刻板印象嘅延續：** 這些模型可能過度或不足地表達某啲群體，抹除部分群體嘅代表性，或強化貶義或負面刻板印象。儘管有安全後訓練，因為不同群體嘅代表性不一，或訓練中負面刻板印象嘅例子反映現實模式同社會偏見，呢啲限制仍可能存在。

**不適當或冒犯性內容：** 模型可能產生其他類型嘅不適當或冒犯性內容，無針對用例嘅額外緩解措施可能令其唔適合用喺敏感場景。
資訊可靠度：語言模型可能產生荒謬或捏造嘅內容，聽落合理但其實不準確或過時。

**程式碼範圍有限：** 多數 Phi-3 訓練資料以 Python 為主，使用嘅常用套件包括 "typing, math, random, collections, datetime, itertools"。模型如果生成利用其他套件或其他語言嘅 Python 腳本，強烈建議用戶手動驗證所有 API。

開發者應用負責任 AI 最佳實踐，並負責確保其特定使用符合相關法律法規（例如私隱、貿易等）。重要考慮範疇包括：

**分配：** 模型可能唔適合用於可能對法律地位或資源、生活機會嘅分配產生重要影響嘅場景（例如：住房、僱傭、信貸等），除非經過進一步評估及額外去偏見技術。

**高風險場景：** 開發者應評估模型喺高風險場景使用嘅適合性，喺呢啲場景中不公平、不可靠或冒犯性輸出可能導致極大成本或損害。此包括喺敏感或專家領域提供建議，喺此類領域準確性同可靠性至關重要（例如：法律或健康建議）。應根據部署場景喺應用層面實施額外防範措施。

**錯誤資訊：** 模型可能產生不準確資料。開發者應遵從透明度最佳實踐，並告知最終用戶其係與 AI 系統互動。喺應用層面，開發者可以建立反饋機制及管道，將回應基於用例專屬嘅上下文資訊，一種稱為檢索增強生成（Retrieval Augmented Generation，RAG）嘅技術。

**產生有害內容：** 開發者應根據背景評估輸出內容，並使用可用嘅安全分類器或適合用例嘅自訂方案。

**誤用：** 其他誤用形式，如詐騙、垃圾訊息或惡意軟件製作都有可能，開發者應確保其應用唔違反適用嘅法律法規。

### 微調及 AI 內容安全

模型完成微調後，我哋強烈建議利用 [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) 措施監控模型生成嘅內容，識別並阻擋潛在風險、威脅及質量問題。

![Phi3AISafety](../../../../../translated_images/mo/01.phi3aisafety.c0d7fc42f5a5c405.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) 支援文本及圖像內容，可喺雲端、離線容器及邊緣/嵌入式設備部署。

## Azure AI 內容安全概述

Azure AI 內容安全並非一個通用解決方案；它可以針對企業嘅具體政策進行自訂。此外，其多語言模型使其能夠同時理解多種語言。

![AIContentSafety](../../../../../translated_images/mo/01.AIcontentsafety.a288819b8ce8da1a.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 videos**

Azure AI 內容安全服務可檢測應用程序及服務中用戶生成及 AI 生成嘅有害內容。它包含文字及圖像 API，允許你偵測有害或不適當嘅材料。

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**免責聲明**：
本文件係使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 翻譯所得。雖然我們致力於確保準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件之原文版本應被視為權威來源。對於重要資訊，建議聘請專業人工翻譯。本公司概不對因使用本翻譯所引致之任何誤解或誤釋負責。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->