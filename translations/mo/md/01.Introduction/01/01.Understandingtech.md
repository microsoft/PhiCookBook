<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "583e1ebd3884b47b43c883072eb8fa03",
  "translation_date": "2025-04-04T11:50:14+00:00",
  "source_file": "md\\01.Introduction\\01\\01.Understandingtech.md",
  "language_code": "mo"
}
-->
# Key technologies mentioned include

1. [DirectML](https://learn.microsoft.com/windows/ai/directml/dml?WT.mc_id=aiml-138114-kinfeylo) - API ya haɓaka koyon na'ura ta amfani da kayan aikin GPU, wanda aka gina a saman DirectX 12.
2. [CUDA](https://blogs.nvidia.com/blog/what-is-cuda-2/) - dandamali na lissafi na layi daya da API wanda Nvidia ta haɓaka don sarrafa jan aiki a kan GPUs.
3. [ONNX](https://onnx.ai/) (Open Neural Network Exchange) - tsari mai buɗewa da aka ƙirƙira don wakiltar samfuran koyon na'ura, yana ba da damar aiki tare tsakanin tsarin ML daban-daban.
4. [GGUF](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md) (Generic Graph Update Format) - tsari da ake amfani da shi wajen wakilta da sabunta samfuran koyon na'ura, musamman masu amfani da CPUs tare da ƙananan ƙima na 4-8bit.

## DirectML

DirectML API ce mai matakin ƙasa wacce ke ba da damar koyon na'ura ta kayan aikin GPU. An gina ta a saman DirectX 12 don amfani da GPU don haɓaka aiki, kuma tana aiki tare da GPUs daban-daban ba tare da buƙatar sauya lambar ba. Ana amfani da ita musamman wajen horar da samfurori da yin hasashen aiki a kan GPUs.

A bangaren kayan aiki, DirectML an tsara ta don aiki da nau'ikan GPUs daban-daban, ciki har da AMD, Intel, da NVIDIA. Tana cikin Windows AI Platform kuma tana tallafi akan Windows 10 & 11, wanda ke ba da damar horar da samfurori da yin hasashen aiki a kan kowanne na'urar Windows.

Akwai sabuntawa da damar da suka shafi DirectML, kamar tallafi ga sama da 150 ONNX operators, da amfani da shi a cikin ONNX runtime da WinML. Tana samun goyon baya daga manyan masu samar da kayan aikin (IHVs), kowane yana aiwatar da umarni na musamman.

## CUDA

CUDA, wanda ke nufin Compute Unified Device Architecture, dandamali ne na lissafi na layi daya da API wanda Nvidia ta haɓaka. Yana ba masu haɓaka software damar amfani da GPUs masu tallafi na CUDA don sarrafa jan aiki gabaɗaya – wani tsari da ake kira GPGPU (General-Purpose computing on Graphics Processing Units). CUDA tana da mahimmanci wajen haɓaka GPU na Nvidia kuma ana amfani da ita sosai a fannonin koyon na'ura, lissafi na kimiyya, da sarrafa bidiyo.

Tallafin kayan aikin CUDA ya shafi GPUs na Nvidia kawai, saboda fasaha ce ta mallaka wacce Nvidia ta haɓaka. Kowanne tsarin GPU yana tallafi ga nau'ikan CUDA toolkit daban-daban, wanda ke ba da ɗakunan karatu da kayan aikin da ake buƙata don masu haɓaka su gina da gudanar da aikace-aikacen CUDA.

## ONNX

ONNX (Open Neural Network Exchange) tsari ne mai buɗewa wanda aka ƙirƙira don wakiltar samfuran koyon na'ura. Yana ba da bayanin zane-zanen lissafi mai faɗi, tare da bayanan masu aiki da nau'ikan bayanai na yau da kullun. ONNX yana ba masu haɓaka damar sauya samfuran tsakanin tsarin ML daban-daban, yana sauƙaƙa ƙirƙira da amfani da aikace-aikacen AI.

Phi3 mini na iya gudana tare da ONNX Runtime akan CPU da GPU a kan na'urori daban-daban, ciki har da dandamali na uwar garke, Windows, Linux da Mac, da CPUs na wayar hannu.
Matsar da aka inganta sun haɗa da:

- ONNX samfura don int4 DML: An rage zuwa int4 ta AWQ
- ONNX samfurin don fp16 CUDA
- ONNX samfurin don int4 CUDA: An rage zuwa int4 ta RTN
- ONNX samfurin don int4 CPU da Mobile: An rage zuwa int4 ta RTN

## Llama.cpp

Llama.cpp laburare ce ta software mai buɗewa da aka rubuta cikin C++. Yana yin hasashen aiki akan nau'ikan Large Language Models (LLMs), ciki har da Llama. An haɓaka shi tare da laburaren ggml (laburare na tensor na gabaɗaya), Llama.cpp yana nufin bayar da hasashen aiki cikin sauri da ƙarancin amfani da ƙwaƙwalwa idan aka kwatanta da aiwatarwar Python na asali. Yana tallafi don ingantaccen kayan aiki, rage girma, kuma yana ba da API mai sauƙi da misalai. Idan kuna sha'awar ingantaccen hasashen LLM, Llama.cpp ya cancanci bincike, musamman ma Phi3 na iya gudanar da Llama.cpp.

## GGUF

GGUF (Generic Graph Update Format) tsari ne da ake amfani da shi wajen wakilta da sabunta samfuran koyon na'ura. Yana da amfani musamman ga ƙananan samfuran harshe (SLMs) waɗanda za su iya gudana yadda ya kamata a kan CPUs tare da ƙananan ƙima na 4-8bit. GGUF yana da fa'ida wajen gwaji cikin sauri da gudanar da samfuran a kan na'urorin kan iyaka ko a cikin ayyukan batch kamar CI/CD pipelines.

It seems like you are asking for the text to be translated into "mo," but could you clarify what "mo" refers to? Are you referring to a specific language or dialect? If so, please provide more details so I can assist you accurately.