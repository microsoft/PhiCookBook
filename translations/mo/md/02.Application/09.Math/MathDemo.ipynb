{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e7ac41",
   "metadata": {},
   "source": [
    "## 匯入所需的函式庫  \n",
    "匯入 PyTorch 和 transformers 函式庫，用於載入和使用 Phi-4 模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6caaf7",
   "metadata": {},
   "source": [
    "## 設定隨機種子  \n",
    "設定隨機種子以確保不同執行結果的一致性。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ce6d9",
   "metadata": {},
   "source": [
    "## 加載 Phi-4-mini-flash-reasoning 模型和分詞器\n",
    "從 Hugging Face 加載 Microsoft Phi-4-mini-flash-reasoning 模型及其對應的分詞器。該模型將被加載到 CUDA 上以加快推理速度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-4-mini-flash-reasoning\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"cuda\",\n",
    "   torch_dtype=\"auto\",\n",
    "   trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8789ea8",
   "metadata": {},
   "source": [
    "## 準備輸入訊息  \n",
    "使用聊天範本為模型建立一個包含二次方程數學問題的對話訊息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "   \"role\": \"user\",\n",
    "   \"content\": \"How to solve 3*x^2+4*x+5=1?\"\n",
    "}]   \n",
    "inputs = tokenizer.apply_chat_template(\n",
    "   messages,\n",
    "   add_generation_prompt=True,\n",
    "   return_dict=True,\n",
    "   return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b87bf8",
   "metadata": {},
   "source": [
    "## 生成回應  \n",
    "使用指定的參數（例如溫度和 top_p）來控制輸出中的隨機性，生成模型回應。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "   **inputs.to(model.device),\n",
    "   max_new_tokens=32768,\n",
    "   temperature=0.6,\n",
    "   top_p=0.95,\n",
    "   do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088f0d",
   "metadata": {},
   "source": [
    "## 解碼輸出為文字\n",
    "將生成的標記序列轉換回人類可讀的文字，排除原始輸入標記，只顯示模型的回應。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責聲明**：  \n本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵信息，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "93d4d22a7a9ec7e7e668474526477813",
   "translation_date": "2025-09-12T18:49:38+00:00",
   "source_file": "md/02.Application/09.Math/MathDemo.ipynb",
   "language_code": "mo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}