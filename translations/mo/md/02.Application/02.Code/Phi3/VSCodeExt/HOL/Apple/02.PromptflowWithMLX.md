<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-05-07T13:53:38+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/Apple/02.PromptflowWithMLX.md",
  "language_code": "mo"
}
-->
# **Lab 2 -  Run Prompt flow with Phi-3-mini in AIPC**

## **What's Prompt flow**

Prompt flow 是一套开发工具，旨在简化基于大语言模型（LLM）的 AI 应用从构思、原型设计、测试、评估到生产部署和监控的端到端开发流程。它让提示工程变得更加简单，助你构建具备生产质量的 LLM 应用。

通过 prompt flow，你可以：

- 创建将 LLM、提示、Python 代码及其他工具连接在一起的可执行工作流。

- 轻松调试和迭代你的工作流，特别是与 LLM 的交互部分。

- 评估你的工作流，利用更大数据集计算质量和性能指标。

- 将测试和评估集成到 CI/CD 系统中，确保工作流质量。

- 将工作流部署到你选择的服务平台，或轻松集成到应用代码库中。

- （可选但强烈推荐）通过 Azure AI 云端版本的 Prompt flow 与团队协作。

## **Building generation code flows on Apple Silicon**

***Note*** ：如果尚未完成环境安装，请访问 [Lab 0 -Installations](./01.Installations.md)

1. 在 Visual Studio Code 中打开 Prompt flow 扩展，创建一个空的 flow 项目

![create](../../../../../../../../../translated_images/pf_create.bde888dc83502eba082a058175bbf1eee6791219795393a386b06fd3043ec54d.mo.png)

2. 添加 Inputs 和 Outputs 参数，并添加 Python 代码作为新的 flow

![flow](../../../../../../../../../translated_images/pf_flow.520824c0969f2a94f17e947f86bdc4b4c6c88a2efa394fe3bcfb58c0dbc578a7.mo.png)

你可以参考此结构（flow.dag.yaml）来构建你的工作流

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. 对 phi-3-mini 进行量化

我们希望能更好地在本地设备上运行 SLM。通常，我们对模型进行量化（INT4、FP16、FP32）

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Note:** 默认文件夹为 mlx_model

4. 在 ***Chat_With_Phi3.py*** 中添加代码

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. 你可以通过 Debug 或 Run 来测试工作流，检查生成代码是否正常

![RUN](../../../../../../../../../translated_images/pf_run.4239e8a0b420a58284edf6ee1471c1697c345670313c8e7beac0edaee15b9a9d.mo.png)

5. 在终端以开发 API 方式运行工作流

```

pf flow serve --source ./ --port 8080 --host localhost   

```

你可以在 Postman / Thunder Client 中测试

### **Note**

1. 首次运行时间较长，建议通过 Hugging face CLI 下载 phi-3 模型。

2. 考虑到 Intel NPU 计算能力有限，建议使用 Phi-3-mini-4k-instruct。

3. 我们使用 Intel NPU 加速进行 INT4 量化转换，但如果重新运行服务，需要删除 cache 和 nc_workshop 文件夹。

## **Resources**

1. 学习 Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. 学习 Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. 示例代码，下载 [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**Disclaimer**:  
This document has been translated using AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). While we strive for accuracy, please be aware that automated translations may contain errors or inaccuracies. The original document in its native language should be considered the authoritative source. For critical information, professional human translation is recommended. We are not liable for any misunderstandings or misinterpretations arising from the use of this translation.

---

Could you please clarify what language or code "mo" refers to? There are multiple possibilities (e.g., Moldovan, a constructed language, or a specific code). Providing this will help me give you the correct translation.