<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "469e2c58e8d576f8bfdf9e4ca2218897",
  "translation_date": "2025-05-06T11:06:06+00:00",
  "source_file": "README.md",
  "language_code": "mo"
}
-->
# Phi Cookbook: Hands-On Examples with Microsoft's Phi Models

[![Open and use the samples in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phicookbook)
[![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook)

[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub issues](https://img.shields.io/github/issues/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub forks](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub stars](https://img.shields.io/github/stars/microsoft/phicookbook?style=social&label=Star)](https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)


[![Azure AI Community Discord](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

Phi цШпх╛ош╜пх╝АхПСчЪДф╕Ач│╗хИЧх╝Ац║Р AI цибхЮЛуАВ

Phi чЫохЙНцШпцЬАх╝║хдзф╕ФцАзф╗╖цпФцЬАщлШчЪДх░ПхЮЛшпншиАцибхЮЛя╝ИSLMя╝Йя╝МхЬихдЪшпншиАуАБцОичРЖуАБцЦЗцЬм/шБКхдйчФЯцИРуАБч╝ЦчаБуАБхЫ╛хГПуАБщЯ│щвСчнЙхдЪчзНхЬ║цЩпф╕ншбичО░ф╝Шх╝ВуАВ

ф╜ахПпф╗ех░Ж Phi щГич╜▓хИ░ф║СчлпцИЦш╛╣ч╝Шшо╛хдЗя╝Мх╣╢ф╕ФхПпф╗еш╜╗цЭ╛цЮДх╗║шобчоЧш╡Дц║РцЬЙщЩРчЪДчФЯцИРх╝П AI х║ФчФиуАВ

цМЙчЕзф╗еф╕Лцнещкдх╝АхзЛф╜┐чФиш┐Щф║Ыш╡Дц║Ря╝Ъ
1. **Fork ф╗Ух║У**я╝ЪчВ╣хЗ╗ [![GitHub forks](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
2. **хЕЛщЪЖф╗Ух║У**я╝Ъ   `git clone https://github.com/microsoft/PhiCookBook.git`
3. [**хКахЕе Microsoft AI Discord чд╛хМ║я╝Мч╗УшпЖф╕Ухо╢хТМх╝АхПСшАЕхРМшбМ**](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

![cover](../../translated_images/cover.2595d43b382944c601aebf88583314636768eece3d94e8e4448e03a4e5bedef4.mo.png)

## ЁЯМР хдЪшпншиАцФпцМБ

### щАЪш┐З GitHub Action цФпцМБя╝ИшЗкхКиф╕ФхзЛч╗Иф┐ЭцМБцЬАцЦ░я╝Й

[French](../fr/README.md) | [Spanish](../es/README.md) | [German](../de/README.md) | [Russian](../ru/README.md) | [Arabic](../ar/README.md) | [Persian (Farsi)](../fa/README.md) | [Urdu](../ur/README.md) | [Chinese (Simplified)](../zh/README.md) | [Chinese (Traditional, Macau)](./README.md) | [Chinese (Traditional, Hong Kong)](../hk/README.md) | [Chinese (Traditional, Taiwan)](../tw/README.md) | [Japanese](../ja/README.md) | [Korean](../ko/README.md) | [Hindi](../hi/README.md)

### щАЪш┐З CLI цФпцМБ - ш┐ЫшбМф╕н
[Bengali](../bn/README.md) | [Marathi](../mr/README.md) | [Nepali](../ne/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Portuguese (Portugal)](../pt/README.md) | [Portuguese (Brazil)](../br/README.md) | [Italian](../it/README.md) | [Polish](../pl/README.md) | [Turkish](../tr/README.md) | [Greek](../el/README.md) | [Thai](../th/README.md) | [Swedish](../sv/README.md) | [Danish](../da/README.md) | [Norwegian](../no/README.md) | [Finnish](../fi/README.md) | [Dutch](../nl/README.md) | [Hebrew](../he/README.md) | [Vietnamese](../vi/README.md) | [Indonesian](../id/README.md) | [Malay](../ms/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Swahili](../sw/README.md) | [Hungarian](../hu/README.md) | [Czech](../cs/README.md) | [Slovak](../sk/README.md) | [Romanian](../ro/README.md) | [Bulgarian](../bg/README.md) | [Serbian (Cyrillic)](../sr/README.md) | [Croatian](../hr/README.md) | [Slovenian](../sl/README.md)


## Table of Contents

- рдкрд░рд┐рдЪрдп
- [Phi рдкрд░рд┐рд╡рд╛рд░рдорд╛ рд╕реНрд╡рд╛рдЧрдд рдЫ](./md/01.Introduction/01/01.PhiFamily.md)
  - [рдЖрдлреНрдиреЛ рд╡рд╛рддрд╛рд╡рд░рдг рд╕реЗрдЯ рдЕрдк рдЧрд░реНрджреИ](./md/01.Introduction/01/01.EnvironmentSetup.md)
  - [рдореБрдЦреНрдп рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ рдмреБрдЭреНрджреИ](./md/01.Introduction/01/01.Understandingtech.md)
  - [Phi рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ AI рд╕реБрд░рдХреНрд╖рд╛](./md/01.Introduction/01/01.AISafety.md)
  - [Phi рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕рдорд░реНрдерди](./md/01.Introduction/01/01.Hardwaresupport.md)
  - [Phi рдореЛрдбреЗрд▓рд╣рд░реВ рд░ рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВрдорд╛ рдЙрдкрд▓рдмреНрдзрддрд╛](./md/01.Introduction/01/01.Edgeandcloud.md)
  - [Guidance-ai рд░ Phi рдХреЛ рдкреНрд░рдпреЛрдЧ](./md/01.Introduction/01/01.Guidance.md)
  - [GitHub Marketplace рдореЛрдбреЗрд▓рд╣рд░реВ](https://github.com/marketplace/models)
  - [Azure AI рдореЛрдбреЗрд▓ рдХреНрдпрд╛рдЯрд▓рдЧ](https://ai.azure.com)

- рд╡рд┐рднрд┐рдиреНрди рд╡рд╛рддрд╛рд╡рд░рдгрдорд╛ Phi рдХреЛ inference
    -  [Hugging face](./md/01.Introduction/02/01.HF.md)
    -  [GitHub рдореЛрдбреЗрд▓рд╣рд░реВ](./md/01.Introduction/02/02.GitHubModel.md)
    -  [Azure AI Foundry рдореЛрдбреЗрд▓ рдХреНрдпрд╛рдЯрд▓рдЧ](./md/01.Introduction/02/03.AzureAIFoundry.md)
    -  [Ollama](./md/01.Introduction/02/04.Ollama.md)
    -  [AI Toolkit VSCode (AITK)](./md/01.Introduction/02/05.AITK.md)
    -  [NVIDIA NIM](./md/01.Introduction/02/06.NVIDIA.md)

- Phi рдкрд░рд┐рд╡рд╛рд░рдорд╛ inference
    - [iOS рдорд╛ Phi рдХреЛ inference](./md/01.Introduction/03/iOS_Inference.md)
    - [Android рдорд╛ Phi рдХреЛ inference](./md/01.Introduction/03/Android_Inference.md)
    - [Jetson рдорд╛ Phi рдХреЛ inference](./md/01.Introduction/03/Jetson_Inference.md)
    - [AI PC рдорд╛ Phi рдХреЛ inference](./md/01.Introduction/03/AIPC_Inference.md)
    - [Apple MLX Framework рд╕рдБрдЧ Phi рдХреЛ inference](./md/01.Introduction/03/MLX_Inference.md)
    - [рд╕реНрдерд╛рдиреАрдп рд╕рд░реНрднрд░рдорд╛ Phi рдХреЛ inference](./md/01.Introduction/03/Local_Server_Inference.md)
    - [AI Toolkit рдкреНрд░рдпреЛрдЧ рдЧрд░реА рд░рд┐рдореЛрдЯ рд╕рд░реНрднрд░рдорд╛ Phi рдХреЛ inference](./md/01.Introduction/03/Remote_Interence.md)
    - [Rust рд╕рдБрдЧ Phi рдХреЛ inference](./md/01.Introduction/03/Rust_Inference.md)
    - [рд╕реНрдерд╛рдиреАрдпрдорд╛ Phi--Vision рдХреЛ inference](./md/01.Introduction/03/Vision_Inference.md)
    - [Kaito AKS, Azure Containers (рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕рдорд░реНрдерди) рд╕рдБрдЧ Phi рдХреЛ inference](./md/01.Introduction/03/Kaito_Inference.md)
-  [Phi рдкрд░рд┐рд╡рд╛рд░рдХреЛ рдХреНрд╡рд╛рдиреНрдЯрд┐рдлрд╛рдЗрдЩ](./md/01.Introduction/04/QuantifyingPhi.md)
    - [llama.cpp рдкреНрд░рдпреЛрдЧ рдЧрд░реА Phi-3.5 / 4 рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬрд┐рдЩ](./md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md)
    - [onnxruntime рдХреЛ рд▓рд╛рдЧрд┐ Generative AI рдПрдХреНрд╕рдЯреЗрдиреНрд╕рдирд╣рд░реВ рдкреНрд░рдпреЛрдЧ рдЧрд░реА Phi-3.5 / 4 рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬрд┐рдЩ](./md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md)
    - [Intel OpenVINO рдкреНрд░рдпреЛрдЧ рдЧрд░реА Phi-3.5 / 4 рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬрд┐рдЩ](./md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md)
    - [Apple MLX Framework рдкреНрд░рдпреЛрдЧ рдЧрд░реА Phi-3.5 / 4 рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬрд┐рдЩ](./md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md)

- Phi рдХреЛ рдореВрд▓реНрдпрд╛рдВрдХрди
- [Response AI](./md/01.Introduction/05/ResponsibleAI.md)
    - [Azure AI Foundry for Evaluation](./md/01.Introduction/05/AIFoundry.md)
    - [Using Promptflow for Evaluation](./md/01.Introduction/05/Promptflow.md)
 
- RAG with Azure AI Search
    - [How to use Phi-4-mini and Phi-4-multimodal(RAG) with Azure AI Search](https://github.com/microsoft/PhiCookBook/blob/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb)

- Phi application development samples
  - Text & Chat Applications
    - Phi-4 Samples ЁЯЖХ
      - [ЁЯУУ] [Chat With Phi-4-mini ONNX Model](./md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md)
      - [Chat with Phi-4 local ONNX Model .NET](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime)
      - [Chat .NET Console App with Phi-4 ONNX using Sementic Kernel](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK)
    - Phi-3 / 3.5 Samples
      - [Local Chatbot in the browser using Phi3, ONNX Runtime Web and WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)
      - [OpenVino Chat](./md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md)
      - [Multi Model - Interactive Phi-3-mini and OpenAI Whisper](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md)
      - [MLFlow - Building a wrapper and using Phi-3 with MLFlow](./md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md)
      - [Model Optimization - How to optimize Phi-3-min model for ONNX Runtime Web with Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)
      - [WinUI3 App with Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)
      -[WinUI3 Multi Model AI Powered Notes App Sample](https://github.com/microsoft/ai-powered-notes-winui3-sample)
      - [Fine-tune and Integrate custom Phi-3 models with Prompt flow](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)
      - [Fine-tune and Integrate custom Phi-3 models with Prompt flow in Azure AI Foundry](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md)
      - [Evaluate the Fine-tuned Phi-3 / Phi-3.5 Model in Azure AI Foundry Focusing on Microsoft's Responsible AI Principles](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md)
      - [ЁЯУУ] [Phi-3.5-mini-instruct language prediction sample (Chinese/English)](../../md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb)
      - [Phi-3.5-Instruct WebGPU RAG Chatbot](./md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md)
      - [Using Windows GPU to create Prompt flow solution with Phi-3.5-Instruct ONNX](./md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md)
      - [Using Microsoft Phi-3.5 tflite to create Android app](./md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md)
      - [Q&A .NET Example using local ONNX Phi-3 model using the Microsoft.ML.OnnxRuntime](../../md/04.HOL/dotnet/src/LabsPhi301)
      - [Console chat .NET app with Semantic Kernel and Phi-3](../../md/04.HOL/dotnet/src/LabsPhi302)

  - Azure AI Inference SDK Code Based Samples 
    - Phi-4 Samples ЁЯЖХ
      - [ЁЯУУ] [Generate project code using Phi-4-multimodal](./md/02.Application/02.Code/Phi4/GenProjectCode/README.md)
    - Phi-3 / 3.5 Samples
      - [Build your own Visual Studio Code GitHub Copilot Chat with Microsoft Phi-3 Family](./md/02.Application/02.Code/Phi3/VSCodeExt/README.md)
      - [Create your own Visual Studio Code Chat Copilot Agent with Phi-3.5 by GitHub Models](/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md)

  - Advanced Reasoning Samples
    - Phi-4 Samples ЁЯЖХ
      - [ЁЯУУ] [Phi-4-mini-reasoning or Phi-4-reasoning Samples](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md)
      - [ЁЯУУ] [Fine-tuning Phi-4-mini-reasoning with Microsoft Olive](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb)
      - [ЁЯУУ] [Fine-tuning Phi-4-mini-reasoning with Apple MLX](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/mlx_ft_phi_4_reasoning_with_medicaldata.ipynb)
      - [ЁЯУУ] [Phi-4-mini-reasoning with GitHub Models](../../md/02.Application/02.Code/Phi4r/github_models_inference.ipynb)
- [ЁЯУУ] [Phi-4-mini reasoning with Azure AI Foundry Models](../../md/02.Application/02.Code/Phi4r/azure_models_inference.ipynb)
  - ╫У╫Ю╫Х╫Щ╫Э
      - [Phi-4-mini ╫У╫Ю╫Х╫Щ╫Э ╫Ю╫Р╫Х╫Ч╫б╫а╫Щ╫Э ╫С-Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo)
      - [Phi-4-multimodal ╫У╫Ю╫Х╫Щ╫Э ╫Ю╫Р╫Х╫Ч╫б╫а╫Щ╫Э ╫С-Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo)
  - ╫У╫Х╫Т╫Ю╫Р╫Х╫к ╫Ч╫Ц╫Х╫к╫Щ╫Х╫к
    - ╫У╫Х╫Т╫Ю╫Р╫Х╫к Phi-4 ЁЯЖХ
      - [ЁЯУУ] [╫й╫Щ╫Ю╫Х╫й ╫С-Phi-4-multimodal ╫Ь╫з╫и╫Щ╫Р╫к ╫к╫Ю╫Х╫а╫Х╫к ╫Х╫Ь╫Щ╫ж╫Щ╫и╫к ╫з╫Х╫У](./md/02.Application/04.Vision/Phi4/CreateFrontend/README.md) 
    - ╫У╫Х╫Т╫Ю╫Р╫Х╫к Phi-3 / 3.5
      -  [ЁЯУУ][Phi-3-vision - ╫Ф╫Ю╫и╫к ╫Ш╫з╫б╫Ш ╫Ю╫к╫Ю╫Х╫а╫Ф ╫Ь╫Ш╫з╫б╫Ш](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)
      - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)
      - [ЁЯУУ][Phi-3-vision CLIP Embedding](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)
      - [╫У╫Ю╫Х: ╫Ю╫Ч╫Ц╫Х╫и Phi-3](https://github.com/jennifermarsman/PhiRecycling/)
      - [Phi-3-vision - ╫в╫Х╫Ц╫и ╫й╫д╫Ф ╫Ч╫Ц╫Х╫к╫Щ╫к - ╫в╫Э Phi3-Vision ╫Х-OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)
      - [Phi-3 Vision Nvidia NIM](./md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md)
      - [Phi-3 Vision OpenVino](./md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md)
      - [ЁЯУУ][╫У╫Х╫Т╫Ю╫к Phi-3.5 Vision ╫в╫Э ╫д╫и╫Щ╫Щ╫Ю╫Щ╫Э ╫Ю╫и╫Х╫С╫Щ╫Э ╫Р╫Х ╫к╫Ю╫Х╫а╫Х╫к ╫Ю╫и╫Х╫С╫Х╫к](../../md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb)
      - [╫Ю╫Х╫У╫Ь ONNX ╫Ю╫з╫Х╫Ю╫Щ ╫й╫Ь Phi-3 Vision ╫С╫Р╫Ю╫ж╫в╫Х╫к Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi303)
      - [╫Ю╫Х╫У╫Ь ONNX ╫Ю╫з╫Х╫Ю╫Щ ╫Ю╫С╫Х╫б╫б ╫к╫д╫и╫Щ╫Ш ╫й╫Ь Phi-3 Vision ╫С╫Р╫Ю╫ж╫в╫Х╫к Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi304)

  - ╫У╫Х╫Т╫Ю╫Р╫Х╫к ╫й╫Ю╫в
    - ╫У╫Х╫Т╫Ю╫Р╫Х╫к Phi-4 ЁЯЖХ
      - [ЁЯУУ] [╫Ч╫Щ╫Ь╫Х╫е ╫к╫Ю╫Ь╫Х╫Ь╫Щ╫Э ╫Ю╫з╫С╫ж╫Щ ╫й╫Ю╫в ╫в╫Э Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Transciption/README.md)
      - [ЁЯУУ] [╫У╫Х╫Т╫Ю╫к ╫й╫Ю╫в ╫й╫Ь Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Siri/demo.ipynb)
      - [ЁЯУУ] [╫У╫Х╫Т╫Ю╫к ╫к╫и╫Т╫Х╫Э ╫У╫Щ╫С╫Х╫и ╫й╫Ь Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Translate/demo.ipynb)
      - [╫Щ╫Щ╫й╫Х╫Э ╫з╫Х╫а╫б╫Х╫Ь .NET ╫Ф╫Ю╫й╫к╫Ю╫й ╫С-Phi-4-multimodal ╫Ь╫а╫Щ╫к╫Х╫Ч ╫з╫Х╫С╫е ╫й╫Ю╫в ╫Х╫Щ╫ж╫Щ╫и╫к ╫к╫Ю╫Ь╫Х╫Ь](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio)

  - ╫У╫Х╫Т╫Ю╫Р╫Х╫к MOE
    - ╫У╫Х╫Т╫Ю╫Р╫Х╫к Phi-3 / 3.5
      - [ЁЯУУ] [╫У╫Х╫Т╫Ю╫к ╫Ю╫Х╫У╫Ь╫Щ╫Э ╫Ю╫в╫Х╫и╫С╫Щ╫Э ╫й╫Ь ╫Ю╫Х╫Ю╫Ч╫Щ╫Э (MoEs) ╫й╫Ь Phi-3.5 ╫С╫и╫й╫к╫Х╫к ╫Ч╫С╫и╫к╫Щ╫Х╫к](../../md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb)
      - [ЁЯУУ] [╫С╫а╫Щ╫Щ╫к ╫ж╫Щ╫а╫Х╫и Retrieval-Augmented Generation (RAG) ╫в╫Э NVIDIA NIM Phi-3 MOE, Azure AI Search, ╫Х-LlamaIndex](../../md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb)
  - ╫У╫Х╫Т╫Ю╫Р╫Х╫к ╫з╫и╫Щ╫Р╫Ф ╫Ь╫д╫Х╫а╫з╫ж╫Щ╫Х╫к
    - ╫У╫Х╫Т╫Ю╫Р╫Х╫к Phi-4 ЁЯЖХ
      -  [ЁЯУУ] [╫й╫Щ╫Ю╫Х╫й ╫С╫з╫и╫Щ╫Р╫Ф ╫Ь╫д╫Х╫а╫з╫ж╫Щ╫Х╫к ╫в╫Э Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md)
      -  [ЁЯУУ] [╫й╫Щ╫Ю╫Х╫й ╫С╫з╫и╫Щ╫Р╫Ф ╫Ь╫д╫Х╫а╫з╫ж╫Щ╫Х╫к ╫Ь╫Щ╫ж╫Щ╫и╫к ╫б╫Х╫Ы╫а╫Щ╫Э ╫Ю╫и╫Х╫С╫Щ╫Э ╫в╫Э Phi-4-mini](../../md/02.Application/07.FunctionCalling/Phi4/Multiagents/Phi_4_mini_multiagent.ipynb)
      -  [ЁЯУУ] [╫й╫Щ╫Ю╫Х╫й ╫С╫з╫и╫Щ╫Р╫Ф ╫Ь╫д╫Х╫а╫з╫ж╫Щ╫Х╫к ╫в╫Э Ollama](../../md/02.Application/07.FunctionCalling/Phi4/Ollama/ollama_functioncalling.ipynb)
  - ╫У╫Х╫Т╫Ю╫Р╫Х╫к ╫Ю╫Щ╫з╫б ╫Ю╫Х╫Ь╫Ш╫Щ╫Ю╫Х╫У╫Ь╫Щ
    - ╫У╫Х╫Т╫Ю╫Р╫Х╫к Phi-4 ЁЯЖХ
      -  [ЁЯУУ] [╫й╫Щ╫Ю╫Х╫й ╫С-Phi-4-multimodal ╫Ы╫в╫Щ╫к╫Х╫а╫Р╫Щ ╫Ш╫Ы╫а╫Х╫Ь╫Х╫Т╫Щ╫Ф](../../md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb)
      - [╫Щ╫Щ╫й╫Х╫Э ╫з╫Х╫а╫б╫Х╫Ь .NET ╫Ф╫Ю╫й╫к╫Ю╫й ╫С-Phi-4-multimodal ╫Ь╫а╫Щ╫к╫Х╫Ч ╫к╫Ю╫Х╫а╫Х╫к](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images)

- ╫У╫Х╫Т╫Ю╫Р╫Х╫к ╫Ы╫Щ╫Х╫Х╫а╫Х╫Я ╫в╫У╫Щ╫Я ╫й╫Ь Phi
  - [╫к╫и╫Ч╫Щ╫й╫Щ ╫Ы╫Щ╫Х╫Х╫а╫Х╫Я ╫в╫У╫Щ╫Я](./md/03.FineTuning/FineTuning_Scenarios.md)
  - [╫Ы╫Щ╫Х╫Х╫а╫Х╫Я ╫в╫У╫Щ╫Я ╫Ю╫Х╫Ь RAG](./md/03.FineTuning/FineTuning_vs_RAG.md)
  - [╫Ы╫Щ╫Х╫Х╫а╫Х╫Я ╫в╫У╫Щ╫Я: ╫Ь╫Ф╫д╫Х╫Ъ ╫Р╫к Phi-3 ╫Ь╫Ю╫Х╫Ю╫Ч╫Ф ╫к╫в╫й╫Щ╫Щ╫к╫Щ](./md/03.FineTuning/LetPhi3gotoIndustriy.md)
  - [╫Ы╫Щ╫Х╫Х╫а╫Х╫Я ╫в╫У╫Щ╫Я ╫й╫Ь Phi-3 ╫в╫Э AI Toolkit ╫Ь-VS Code](./md/03.FineTuning/Finetuning_VSCodeaitoolkit.md)
  - [╫Ы╫Щ╫Х╫Х╫а╫Х╫Я ╫в╫У╫Щ╫Я ╫й╫Ь Phi-3 ╫в╫Э Azure Machine Learning Service](./md/03.FineTuning/Introduce_AzureML.md)
- [Fine-tuning Phi-3 with Lora](./md/03.FineTuning/FineTuning_Lora.md)
  - [Fine-tuning Phi-3 with QLora](./md/03.FineTuning/FineTuning_Qlora.md)
  - [Fine-tuning Phi-3 with Azure AI Foundry](./md/03.FineTuning/FineTuning_AIFoundry.md)
  - [Fine-tuning Phi-3 with Azure ML CLI/SDK](./md/03.FineTuning/FineTuning_MLSDK.md)
  - [Fine-tuning with Microsoft Olive](./md/03.FineTuning/FineTuning_MicrosoftOlive.md)
  - [Fine-tuning with Microsoft Olive Hands-On Lab](./md/03.FineTuning/olive-lab/readme.md)
  - [Fine-tuning Phi-3-vision with Weights and Bias](./md/03.FineTuning/FineTuning_Phi-3-visionWandB.md)
  - [Fine-tuning Phi-3 with Apple MLX Framework](./md/03.FineTuning/FineTuning_MLX.md)
  - [Fine-tuning Phi-3-vision (official support)](./md/03.FineTuning/FineTuning_Vision.md)
  - [Fine-Tuning Phi-3 with Kaito AKS , Azure Containers(official Support)](./md/03.FineTuning/FineTuning_Kaito.md)
  - [Fine-Tuning Phi-3 and 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)

- Hands on Lab
  - [Exploring cutting-edge models: LLMs, SLMs, local development and more](https://github.com/microsoft/aitour-exploring-cutting-edge-models)
  - [Unlocking NLP Potential: Fine-Tuning with Microsoft Olive](https://github.com/azure/Ignite_FineTuning_workshop)

- Academic Research Papers and Publications
  - [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463)
  - [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)
  - [Phi-4 Technical Report](https://arxiv.org/abs/2412.08905)
  - [Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs](https://arxiv.org/abs/2503.01743)
  - [Optimizing Small Language Models for In-Vehicle Function-Calling](https://arxiv.org/abs/2501.02342)
  - [(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges](https://arxiv.org/abs/2501.01588)
  - [Phi-4-reasoning Technical Report](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf)
  - [Phi-4-mini-reasoning Technical Report](https://huggingface.co/microsoft/Phi-4-mini-reasoning/blob/main/Phi-4-Mini-Reasoning.pdf)

## Using Phi Models

### Phi on Azure AI Foundry

You can learn how to use Microsoft Phi and how to build E2E solutions in your different hardware devices. To experience Phi for yourself, start by playing with the models and customizing Phi for your scenarios using theтАп[Azure AI Foundry Azure AI Model Catalog](https://aka.ms/phi3-azure-ai) you can learn more at Getting Started with [Azure AI Foundry](/md/02.QuickStart/AzureAIFoundry_QuickStart.md)

**Playground**
Each model has a dedicated playground to test the model [Azure AI Playground](https://aka.ms/try-phi3).

### Phi on GitHub Models

You can learn how to use Microsoft Phi and how to build E2E solutions in your different hardware devices. To experience Phi for yourself, start by playing with the model and customizing Phi for your scenarios using theтАп[GitHub Model Catalog](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo) you can learn more at Getting Started with [GitHub Model Catalog](/md/02.QuickStart/GitHubModel_QuickStart.md)

**Playground**
Each model has a dedicated [playground to test the model](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi on Hugging Face

You can also find the model on the [Hugging Face](https://huggingface.co/microsoft)

**Playground**
 [Hugging Chat playground](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

## Responsible AI 

Microsoft is committed to helping our customers use our AI products responsibly, sharing our learnings, and building trust-based partnerships through tools like Transparency Notes and Impact Assessments. Many of these resources can be found at [https://aka.ms/RAI](https://aka.ms/RAI).
MicrosoftтАЩs approach to responsible AI is grounded in ourтАпAI principles of fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability.
Large-scale natural language, image, and speech models - like the ones used in this sample - can potentially behave in ways that are unfair, unreliable, or offensive, in turn causing harms. Please consult the [Azure OpenAI service Transparency note](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) to be informed about risks and limitations.

The recommended approach to mitigating these risks is to include a safety system in your architecture that can detect and prevent harmful behavior. [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) provides an independent layer of protection, able to detect harmful user-generated and AI-generated content in applications and services. Azure AI Content Safety includes text and image APIs that allow you to detect material that is harmful. Within Azure AI Foundry, the Content Safety service allows you to view, explore and try out sample code for detecting harmful content across different modalities. The following [quickstart documentation](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) guides you through making requests to the service.

Another aspect to take into account is the overall application performance. With multi-modal and multi-models applications, we consider performance to mean that the system performs as you and your users expect, including not generating harmful outputs. It's important to assess the performance of your overall application using [Performance and Quality and Risk and Safety evaluators](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in). You also have the ability to create and evaluate with [custom evaluators](https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators).

You can evaluate your AI application in your development environment using the [Azure AI Evaluation SDK](https://microsoft.github.io/promptflow/index.html). Given either a test dataset or a target, your generative AI application generations are quantitatively measured with built-in evaluators or custom evaluators of your choice. To get started with the azure ai evaluation sdk to evaluate your system, you can follow the [quickstart guide](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk). Once you execute an evaluation run, you can [visualize the results in Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results). 

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.

**Disclaimer**:  
Thi document haz bin translaytid yuzing AI translaytion servis [Co-op Translator](https://github.com/Azure/co-op-translator). Whil wi striv for akyurasi, pliz bi aware dat otomaytid translaytions mei contain erors or inakuryasis. Thi orijinal document in its naytiv langwij shud bi konsiderd thi authoritativ sors. For kritikal informayshun, profeshunal hyuman translaytion is rekomended. Wi ar not laybl for eni misunderstandingz or misinterpretayshuns arising from thi yuz of this translaytion.