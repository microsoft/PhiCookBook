<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "469e2c58e8d576f8bfdf9e4ca2218897",
  "translation_date": "2025-05-06T11:06:06+00:00",
  "source_file": "README.md",
  "language_code": "mo"
}
-->
# Phi Cookbook: Hands-On Examples with Microsoft's Phi Models

[![Open and use the samples in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phicookbook)
[![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook)

[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub issues](https://img.shields.io/github/issues/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub forks](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
[![GitHub stars](https://img.shields.io/github/stars/microsoft/phicookbook?style=social&label=Star)](https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)


[![Azure AI Community Discord](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

Phi æ˜¯å¾®è½¯å¼€å‘çš„ä¸€ç³»åˆ—å¼€æº AI æ¨¡å‹ã€‚

Phi ç›®å‰æ˜¯æœ€å¼ºå¤§ä¸”æ€§ä»·æ¯”æœ€é«˜çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ï¼Œåœ¨å¤šè¯­è¨€ã€æ¨ç†ã€æ–‡æœ¬/èŠå¤©ç”Ÿæˆã€ç¼–ç ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

ä½ å¯ä»¥å°† Phi éƒ¨ç½²åˆ°äº‘ç«¯æˆ–è¾¹ç¼˜è®¾å¤‡ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ„å»ºè®¡ç®—èµ„æºæœ‰é™çš„ç”Ÿæˆå¼ AI åº”ç”¨ã€‚

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¼€å§‹ä½¿ç”¨è¿™äº›èµ„æºï¼š
1. **Fork ä»“åº“**ï¼šç‚¹å‡» [![GitHub forks](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
2. **å…‹éš†ä»“åº“**ï¼š   `git clone https://github.com/microsoft/PhiCookBook.git`
3. [**åŠ å…¥ Microsoft AI Discord ç¤¾åŒºï¼Œç»“è¯†ä¸“å®¶å’Œå¼€å‘è€…åŒè¡Œ**](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

![cover](../../translated_images/cover.2595d43b382944c601aebf88583314636768eece3d94e8e4448e03a4e5bedef4.mo.png)

## ğŸŒ å¤šè¯­è¨€æ”¯æŒ

### é€šè¿‡ GitHub Action æ”¯æŒï¼ˆè‡ªåŠ¨ä¸”å§‹ç»ˆä¿æŒæœ€æ–°ï¼‰

[French](../fr/README.md) | [Spanish](../es/README.md) | [German](../de/README.md) | [Russian](../ru/README.md) | [Arabic](../ar/README.md) | [Persian (Farsi)](../fa/README.md) | [Urdu](../ur/README.md) | [Chinese (Simplified)](../zh/README.md) | [Chinese (Traditional, Macau)](./README.md) | [Chinese (Traditional, Hong Kong)](../hk/README.md) | [Chinese (Traditional, Taiwan)](../tw/README.md) | [Japanese](../ja/README.md) | [Korean](../ko/README.md) | [Hindi](../hi/README.md)

### é€šè¿‡ CLI æ”¯æŒ - è¿›è¡Œä¸­
[Bengali](../bn/README.md) | [Marathi](../mr/README.md) | [Nepali](../ne/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Portuguese (Portugal)](../pt/README.md) | [Portuguese (Brazil)](../br/README.md) | [Italian](../it/README.md) | [Polish](../pl/README.md) | [Turkish](../tr/README.md) | [Greek](../el/README.md) | [Thai](../th/README.md) | [Swedish](../sv/README.md) | [Danish](../da/README.md) | [Norwegian](../no/README.md) | [Finnish](../fi/README.md) | [Dutch](../nl/README.md) | [Hebrew](../he/README.md) | [Vietnamese](../vi/README.md) | [Indonesian](../id/README.md) | [Malay](../ms/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Swahili](../sw/README.md) | [Hungarian](../hu/README.md) | [Czech](../cs/README.md) | [Slovak](../sk/README.md) | [Romanian](../ro/README.md) | [Bulgarian](../bg/README.md) | [Serbian (Cyrillic)](../sr/README.md) | [Croatian](../hr/README.md) | [Slovenian](../sl/README.md)


## Table of Contents

- à¤ªà¤°à¤¿à¤šà¤¯
- [Phi à¤ªà¤°à¤¿à¤µà¤¾à¤°à¤®à¤¾ à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤›](./md/01.Introduction/01/01.PhiFamily.md)
  - [à¤†à¤«à¥à¤¨à¥‹ à¤µà¤¾à¤¤à¤¾à¤µà¤°à¤£ à¤¸à¥‡à¤Ÿ à¤…à¤ª à¤—à¤°à¥à¤¦à¥ˆ](./md/01.Introduction/01/01.EnvironmentSetup.md)
  - [à¤®à¥à¤–à¥à¤¯ à¤ªà¥à¤°à¤µà¤¿à¤§à¤¿à¤¹à¤°à¥‚ à¤¬à¥à¤à¥à¤¦à¥ˆ](./md/01.Introduction/01/01.Understandingtech.md)
  - [Phi à¤®à¥‹à¤¡à¥‡à¤²à¤¹à¤°à¥‚à¤•à¥‹ à¤²à¤¾à¤—à¤¿ AI à¤¸à¥à¤°à¤•à¥à¤·à¤¾](./md/01.Introduction/01/01.AISafety.md)
  - [Phi à¤¹à¤¾à¤°à¥à¤¡à¤µà¥‡à¤¯à¤° à¤¸à¤®à¤°à¥à¤¥à¤¨](./md/01.Introduction/01/01.Hardwaresupport.md)
  - [Phi à¤®à¥‹à¤¡à¥‡à¤²à¤¹à¤°à¥‚ à¤° à¤ªà¥à¤²à¥‡à¤Ÿà¤«à¤°à¥à¤®à¤¹à¤°à¥‚à¤®à¤¾ à¤‰à¤ªà¤²à¤¬à¥à¤§à¤¤à¤¾](./md/01.Introduction/01/01.Edgeandcloud.md)
  - [Guidance-ai à¤° Phi à¤•à¥‹ à¤ªà¥à¤°à¤¯à¥‹à¤—](./md/01.Introduction/01/01.Guidance.md)
  - [GitHub Marketplace à¤®à¥‹à¤¡à¥‡à¤²à¤¹à¤°à¥‚](https://github.com/marketplace/models)
  - [Azure AI à¤®à¥‹à¤¡à¥‡à¤² à¤•à¥à¤¯à¤¾à¤Ÿà¤²à¤—](https://ai.azure.com)

- à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤µà¤¾à¤¤à¤¾à¤µà¤°à¤£à¤®à¤¾ Phi à¤•à¥‹ inference
    -  [Hugging face](./md/01.Introduction/02/01.HF.md)
    -  [GitHub à¤®à¥‹à¤¡à¥‡à¤²à¤¹à¤°à¥‚](./md/01.Introduction/02/02.GitHubModel.md)
    -  [Azure AI Foundry à¤®à¥‹à¤¡à¥‡à¤² à¤•à¥à¤¯à¤¾à¤Ÿà¤²à¤—](./md/01.Introduction/02/03.AzureAIFoundry.md)
    -  [Ollama](./md/01.Introduction/02/04.Ollama.md)
    -  [AI Toolkit VSCode (AITK)](./md/01.Introduction/02/05.AITK.md)
    -  [NVIDIA NIM](./md/01.Introduction/02/06.NVIDIA.md)

- Phi à¤ªà¤°à¤¿à¤µà¤¾à¤°à¤®à¤¾ inference
    - [iOS à¤®à¤¾ Phi à¤•à¥‹ inference](./md/01.Introduction/03/iOS_Inference.md)
    - [Android à¤®à¤¾ Phi à¤•à¥‹ inference](./md/01.Introduction/03/Android_Inference.md)
    - [Jetson à¤®à¤¾ Phi à¤•à¥‹ inference](./md/01.Introduction/03/Jetson_Inference.md)
    - [AI PC à¤®à¤¾ Phi à¤•à¥‹ inference](./md/01.Introduction/03/AIPC_Inference.md)
    - [Apple MLX Framework à¤¸à¤à¤— Phi à¤•à¥‹ inference](./md/01.Introduction/03/MLX_Inference.md)
    - [à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤¸à¤°à¥à¤­à¤°à¤®à¤¾ Phi à¤•à¥‹ inference](./md/01.Introduction/03/Local_Server_Inference.md)
    - [AI Toolkit à¤ªà¥à¤°à¤¯à¥‹à¤— à¤—à¤°à¥€ à¤°à¤¿à¤®à¥‹à¤Ÿ à¤¸à¤°à¥à¤­à¤°à¤®à¤¾ Phi à¤•à¥‹ inference](./md/01.Introduction/03/Remote_Interence.md)
    - [Rust à¤¸à¤à¤— Phi à¤•à¥‹ inference](./md/01.Introduction/03/Rust_Inference.md)
    - [à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯à¤®à¤¾ Phi--Vision à¤•à¥‹ inference](./md/01.Introduction/03/Vision_Inference.md)
    - [Kaito AKS, Azure Containers (à¤†à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤• à¤¸à¤®à¤°à¥à¤¥à¤¨) à¤¸à¤à¤— Phi à¤•à¥‹ inference](./md/01.Introduction/03/Kaito_Inference.md)
-  [Phi à¤ªà¤°à¤¿à¤µà¤¾à¤°à¤•à¥‹ à¤•à¥à¤µà¤¾à¤¨à¥à¤Ÿà¤¿à¤«à¤¾à¤‡à¤™](./md/01.Introduction/04/QuantifyingPhi.md)
    - [llama.cpp à¤ªà¥à¤°à¤¯à¥‹à¤— à¤—à¤°à¥€ Phi-3.5 / 4 à¤•à¥à¤µà¤¾à¤¨à¥à¤Ÿà¤¾à¤‡à¤œà¤¿à¤™](./md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md)
    - [onnxruntime à¤•à¥‹ à¤²à¤¾à¤—à¤¿ Generative AI à¤à¤•à¥à¤¸à¤Ÿà¥‡à¤¨à¥à¤¸à¤¨à¤¹à¤°à¥‚ à¤ªà¥à¤°à¤¯à¥‹à¤— à¤—à¤°à¥€ Phi-3.5 / 4 à¤•à¥à¤µà¤¾à¤¨à¥à¤Ÿà¤¾à¤‡à¤œà¤¿à¤™](./md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md)
    - [Intel OpenVINO à¤ªà¥à¤°à¤¯à¥‹à¤— à¤—à¤°à¥€ Phi-3.5 / 4 à¤•à¥à¤µà¤¾à¤¨à¥à¤Ÿà¤¾à¤‡à¤œà¤¿à¤™](./md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md)
    - [Apple MLX Framework à¤ªà¥à¤°à¤¯à¥‹à¤— à¤—à¤°à¥€ Phi-3.5 / 4 à¤•à¥à¤µà¤¾à¤¨à¥à¤Ÿà¤¾à¤‡à¤œà¤¿à¤™](./md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md)

- Phi à¤•à¥‹ à¤®à¥‚à¤²à¥à¤¯à¤¾à¤‚à¤•à¤¨
- [Response AI](./md/01.Introduction/05/ResponsibleAI.md)
    - [Azure AI Foundry for Evaluation](./md/01.Introduction/05/AIFoundry.md)
    - [Using Promptflow for Evaluation](./md/01.Introduction/05/Promptflow.md)
 
- RAG with Azure AI Search
    - [How to use Phi-4-mini and Phi-4-multimodal(RAG) with Azure AI Search](https://github.com/microsoft/PhiCookBook/blob/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb)

- Phi application development samples
  - Text & Chat Applications
    - Phi-4 Samples ğŸ†•
      - [ğŸ““] [Chat With Phi-4-mini ONNX Model](./md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md)
      - [Chat with Phi-4 local ONNX Model .NET](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime)
      - [Chat .NET Console App with Phi-4 ONNX using Sementic Kernel](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK)
    - Phi-3 / 3.5 Samples
      - [Local Chatbot in the browser using Phi3, ONNX Runtime Web and WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)
      - [OpenVino Chat](./md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md)
      - [Multi Model - Interactive Phi-3-mini and OpenAI Whisper](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md)
      - [MLFlow - Building a wrapper and using Phi-3 with MLFlow](./md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md)
      - [Model Optimization - How to optimize Phi-3-min model for ONNX Runtime Web with Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)
      - [WinUI3 App with Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)
      -[WinUI3 Multi Model AI Powered Notes App Sample](https://github.com/microsoft/ai-powered-notes-winui3-sample)
      - [Fine-tune and Integrate custom Phi-3 models with Prompt flow](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)
      - [Fine-tune and Integrate custom Phi-3 models with Prompt flow in Azure AI Foundry](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md)
      - [Evaluate the Fine-tuned Phi-3 / Phi-3.5 Model in Azure AI Foundry Focusing on Microsoft's Responsible AI Principles](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md)
      - [ğŸ““] [Phi-3.5-mini-instruct language prediction sample (Chinese/English)](../../md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb)
      - [Phi-3.5-Instruct WebGPU RAG Chatbot](./md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md)
      - [Using Windows GPU to create Prompt flow solution with Phi-3.5-Instruct ONNX](./md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md)
      - [Using Microsoft Phi-3.5 tflite to create Android app](./md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md)
      - [Q&A .NET Example using local ONNX Phi-3 model using the Microsoft.ML.OnnxRuntime](../../md/04.HOL/dotnet/src/LabsPhi301)
      - [Console chat .NET app with Semantic Kernel and Phi-3](../../md/04.HOL/dotnet/src/LabsPhi302)

  - Azure AI Inference SDK Code Based Samples 
    - Phi-4 Samples ğŸ†•
      - [ğŸ““] [Generate project code using Phi-4-multimodal](./md/02.Application/02.Code/Phi4/GenProjectCode/README.md)
    - Phi-3 / 3.5 Samples
      - [Build your own Visual Studio Code GitHub Copilot Chat with Microsoft Phi-3 Family](./md/02.Application/02.Code/Phi3/VSCodeExt/README.md)
      - [Create your own Visual Studio Code Chat Copilot Agent with Phi-3.5 by GitHub Models](/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md)

  - Advanced Reasoning Samples
    - Phi-4 Samples ğŸ†•
      - [ğŸ““] [Phi-4-mini-reasoning or Phi-4-reasoning Samples](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md)
      - [ğŸ““] [Fine-tuning Phi-4-mini-reasoning with Microsoft Olive](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb)
      - [ğŸ““] [Fine-tuning Phi-4-mini-reasoning with Apple MLX](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/mlx_ft_phi_4_reasoning_with_medicaldata.ipynb)
      - [ğŸ““] [Phi-4-mini-reasoning with GitHub Models](../../md/02.Application/02.Code/Phi4r/github_models_inference.ipynb)
- [ğŸ““] [Phi-4-mini reasoning with Azure AI Foundry Models](../../md/02.Application/02.Code/Phi4r/azure_models_inference.ipynb)
  - ×“××•×™×
      - [Phi-4-mini ×“××•×™× ×××•×—×¡× ×™× ×‘-Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo)
      - [Phi-4-multimodal ×“××•×™× ×××•×—×¡× ×™× ×‘-Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo)
  - ×“×•×’×××•×ª ×—×–×•×ª×™×•×ª
    - ×“×•×’×××•×ª Phi-4 ğŸ†•
      - [ğŸ““] [×©×™××•×© ×‘-Phi-4-multimodal ×œ×§×¨×™××ª ×ª××•× ×•×ª ×•×œ×™×¦×™×¨×ª ×§×•×“](./md/02.Application/04.Vision/Phi4/CreateFrontend/README.md) 
    - ×“×•×’×××•×ª Phi-3 / 3.5
      -  [ğŸ““][Phi-3-vision - ×”××¨×ª ×˜×§×¡×˜ ××ª××•× ×” ×œ×˜×§×¡×˜](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)
      - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)
      - [ğŸ““][Phi-3-vision CLIP Embedding](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)
      - [×“××•: ××—×–×•×¨ Phi-3](https://github.com/jennifermarsman/PhiRecycling/)
      - [Phi-3-vision - ×¢×•×–×¨ ×©×¤×” ×—×–×•×ª×™×ª - ×¢× Phi3-Vision ×•-OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)
      - [Phi-3 Vision Nvidia NIM](./md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md)
      - [Phi-3 Vision OpenVino](./md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md)
      - [ğŸ““][×“×•×’××ª Phi-3.5 Vision ×¢× ×¤×¨×™×™××™× ××¨×•×‘×™× ××• ×ª××•× ×•×ª ××¨×•×‘×•×ª](../../md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb)
      - [××•×“×œ ONNX ××§×•××™ ×©×œ Phi-3 Vision ×‘×××¦×¢×•×ª Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi303)
      - [××•×“×œ ONNX ××§×•××™ ××‘×•×¡×¡ ×ª×¤×¨×™×˜ ×©×œ Phi-3 Vision ×‘×××¦×¢×•×ª Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi304)

  - ×“×•×’×××•×ª ×©××¢
    - ×“×•×’×××•×ª Phi-4 ğŸ†•
      - [ğŸ““] [×—×™×œ×•×¥ ×ª××œ×•×œ×™× ××§×‘×¦×™ ×©××¢ ×¢× Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Transciption/README.md)
      - [ğŸ““] [×“×•×’××ª ×©××¢ ×©×œ Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Siri/demo.ipynb)
      - [ğŸ““] [×“×•×’××ª ×ª×¨×’×•× ×“×™×‘×•×¨ ×©×œ Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Translate/demo.ipynb)
      - [×™×™×©×•× ×§×•× ×¡×•×œ .NET ×”××©×ª××© ×‘-Phi-4-multimodal ×œ× ×™×ª×•×— ×§×•×‘×¥ ×©××¢ ×•×™×¦×™×¨×ª ×ª××œ×•×œ](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio)

  - ×“×•×’×××•×ª MOE
    - ×“×•×’×××•×ª Phi-3 / 3.5
      - [ğŸ““] [×“×•×’××ª ××•×“×œ×™× ××¢×•×¨×‘×™× ×©×œ ××•××—×™× (MoEs) ×©×œ Phi-3.5 ×‘×¨×©×ª×•×ª ×—×‘×¨×ª×™×•×ª](../../md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb)
      - [ğŸ““] [×‘× ×™×™×ª ×¦×™× ×•×¨ Retrieval-Augmented Generation (RAG) ×¢× NVIDIA NIM Phi-3 MOE, Azure AI Search, ×•-LlamaIndex](../../md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb)
  - ×“×•×’×××•×ª ×§×¨×™××” ×œ×¤×•× ×§×¦×™×•×ª
    - ×“×•×’×××•×ª Phi-4 ğŸ†•
      -  [ğŸ““] [×©×™××•×© ×‘×§×¨×™××” ×œ×¤×•× ×§×¦×™×•×ª ×¢× Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md)
      -  [ğŸ““] [×©×™××•×© ×‘×§×¨×™××” ×œ×¤×•× ×§×¦×™×•×ª ×œ×™×¦×™×¨×ª ×¡×•×›× ×™× ××¨×•×‘×™× ×¢× Phi-4-mini](../../md/02.Application/07.FunctionCalling/Phi4/Multiagents/Phi_4_mini_multiagent.ipynb)
      -  [ğŸ““] [×©×™××•×© ×‘×§×¨×™××” ×œ×¤×•× ×§×¦×™×•×ª ×¢× Ollama](../../md/02.Application/07.FunctionCalling/Phi4/Ollama/ollama_functioncalling.ipynb)
  - ×“×•×’×××•×ª ××™×§×¡ ××•×œ×˜×™××•×“×œ×™
    - ×“×•×’×××•×ª Phi-4 ğŸ†•
      -  [ğŸ““] [×©×™××•×© ×‘-Phi-4-multimodal ×›×¢×™×ª×•× ××™ ×˜×›× ×•×œ×•×’×™×”](../../md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb)
      - [×™×™×©×•× ×§×•× ×¡×•×œ .NET ×”××©×ª××© ×‘-Phi-4-multimodal ×œ× ×™×ª×•×— ×ª××•× ×•×ª](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images)

- ×“×•×’×××•×ª ×›×™×•×•× ×•×Ÿ ×¢×“×™×Ÿ ×©×œ Phi
  - [×ª×¨×—×™×©×™ ×›×™×•×•× ×•×Ÿ ×¢×“×™×Ÿ](./md/03.FineTuning/FineTuning_Scenarios.md)
  - [×›×™×•×•× ×•×Ÿ ×¢×“×™×Ÿ ××•×œ RAG](./md/03.FineTuning/FineTuning_vs_RAG.md)
  - [×›×™×•×•× ×•×Ÿ ×¢×“×™×Ÿ: ×œ×”×¤×•×š ××ª Phi-3 ×œ××•××—×” ×ª×¢×©×™×™×ª×™](./md/03.FineTuning/LetPhi3gotoIndustriy.md)
  - [×›×™×•×•× ×•×Ÿ ×¢×“×™×Ÿ ×©×œ Phi-3 ×¢× AI Toolkit ×œ-VS Code](./md/03.FineTuning/Finetuning_VSCodeaitoolkit.md)
  - [×›×™×•×•× ×•×Ÿ ×¢×“×™×Ÿ ×©×œ Phi-3 ×¢× Azure Machine Learning Service](./md/03.FineTuning/Introduce_AzureML.md)
- [Fine-tuning Phi-3 with Lora](./md/03.FineTuning/FineTuning_Lora.md)
  - [Fine-tuning Phi-3 with QLora](./md/03.FineTuning/FineTuning_Qlora.md)
  - [Fine-tuning Phi-3 with Azure AI Foundry](./md/03.FineTuning/FineTuning_AIFoundry.md)
  - [Fine-tuning Phi-3 with Azure ML CLI/SDK](./md/03.FineTuning/FineTuning_MLSDK.md)
  - [Fine-tuning with Microsoft Olive](./md/03.FineTuning/FineTuning_MicrosoftOlive.md)
  - [Fine-tuning with Microsoft Olive Hands-On Lab](./md/03.FineTuning/olive-lab/readme.md)
  - [Fine-tuning Phi-3-vision with Weights and Bias](./md/03.FineTuning/FineTuning_Phi-3-visionWandB.md)
  - [Fine-tuning Phi-3 with Apple MLX Framework](./md/03.FineTuning/FineTuning_MLX.md)
  - [Fine-tuning Phi-3-vision (official support)](./md/03.FineTuning/FineTuning_Vision.md)
  - [Fine-Tuning Phi-3 with Kaito AKS , Azure Containers(official Support)](./md/03.FineTuning/FineTuning_Kaito.md)
  - [Fine-Tuning Phi-3 and 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)

- Hands on Lab
  - [Exploring cutting-edge models: LLMs, SLMs, local development and more](https://github.com/microsoft/aitour-exploring-cutting-edge-models)
  - [Unlocking NLP Potential: Fine-Tuning with Microsoft Olive](https://github.com/azure/Ignite_FineTuning_workshop)

- Academic Research Papers and Publications
  - [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463)
  - [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)
  - [Phi-4 Technical Report](https://arxiv.org/abs/2412.08905)
  - [Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs](https://arxiv.org/abs/2503.01743)
  - [Optimizing Small Language Models for In-Vehicle Function-Calling](https://arxiv.org/abs/2501.02342)
  - [(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges](https://arxiv.org/abs/2501.01588)
  - [Phi-4-reasoning Technical Report](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf)
  - [Phi-4-mini-reasoning Technical Report](https://huggingface.co/microsoft/Phi-4-mini-reasoning/blob/main/Phi-4-Mini-Reasoning.pdf)

## Using Phi Models

### Phi on Azure AI Foundry

You can learn how to use Microsoft Phi and how to build E2E solutions in your different hardware devices. To experience Phi for yourself, start by playing with the models and customizing Phi for your scenarios using theâ€¯[Azure AI Foundry Azure AI Model Catalog](https://aka.ms/phi3-azure-ai) you can learn more at Getting Started with [Azure AI Foundry](/md/02.QuickStart/AzureAIFoundry_QuickStart.md)

**Playground**
Each model has a dedicated playground to test the model [Azure AI Playground](https://aka.ms/try-phi3).

### Phi on GitHub Models

You can learn how to use Microsoft Phi and how to build E2E solutions in your different hardware devices. To experience Phi for yourself, start by playing with the model and customizing Phi for your scenarios using theâ€¯[GitHub Model Catalog](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo) you can learn more at Getting Started with [GitHub Model Catalog](/md/02.QuickStart/GitHubModel_QuickStart.md)

**Playground**
Each model has a dedicated [playground to test the model](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi on Hugging Face

You can also find the model on the [Hugging Face](https://huggingface.co/microsoft)

**Playground**
 [Hugging Chat playground](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

## Responsible AI 

Microsoft is committed to helping our customers use our AI products responsibly, sharing our learnings, and building trust-based partnerships through tools like Transparency Notes and Impact Assessments. Many of these resources can be found at [https://aka.ms/RAI](https://aka.ms/RAI).
Microsoftâ€™s approach to responsible AI is grounded in ourâ€¯AI principles of fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability.
Large-scale natural language, image, and speech models - like the ones used in this sample - can potentially behave in ways that are unfair, unreliable, or offensive, in turn causing harms. Please consult the [Azure OpenAI service Transparency note](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) to be informed about risks and limitations.

The recommended approach to mitigating these risks is to include a safety system in your architecture that can detect and prevent harmful behavior. [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) provides an independent layer of protection, able to detect harmful user-generated and AI-generated content in applications and services. Azure AI Content Safety includes text and image APIs that allow you to detect material that is harmful. Within Azure AI Foundry, the Content Safety service allows you to view, explore and try out sample code for detecting harmful content across different modalities. The following [quickstart documentation](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) guides you through making requests to the service.

Another aspect to take into account is the overall application performance. With multi-modal and multi-models applications, we consider performance to mean that the system performs as you and your users expect, including not generating harmful outputs. It's important to assess the performance of your overall application using [Performance and Quality and Risk and Safety evaluators](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in). You also have the ability to create and evaluate with [custom evaluators](https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators).

You can evaluate your AI application in your development environment using the [Azure AI Evaluation SDK](https://microsoft.github.io/promptflow/index.html). Given either a test dataset or a target, your generative AI application generations are quantitatively measured with built-in evaluators or custom evaluators of your choice. To get started with the azure ai evaluation sdk to evaluate your system, you can follow the [quickstart guide](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk). Once you execute an evaluation run, you can [visualize the results in Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results). 

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.

**Disclaimer**:  
Thi document haz bin translaytid yuzing AI translaytion servis [Co-op Translator](https://github.com/Azure/co-op-translator). Whil wi striv for akyurasi, pliz bi aware dat otomaytid translaytions mei contain erors or inakuryasis. Thi orijinal document in its naytiv langwij shud bi konsiderd thi authoritativ sors. For kritikal informayshun, profeshunal hyuman translaytion is rekomended. Wi ar not laybl for eni misunderstandingz or misinterpretayshuns arising from thi yuz of this translaytion.