<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:20:11+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "hr"
}
-->
# Početak rada s Phi-3 lokalno

Ovaj vodič pomoći će vam da postavite svoje lokalno okruženje za pokretanje Phi-3 modela koristeći Ollama. Model možete pokrenuti na nekoliko različitih načina, uključujući GitHub Codespaces, VS Code Dev Containers ili vaše lokalno okruženje.

## Postavljanje okruženja

### GitHub Codespaces

Ovaj predložak možete pokrenuti virtualno koristeći GitHub Codespaces. Gumb će otvoriti web verziju VS Code-a u vašem pregledniku:

1. Otvorite predložak (ovo može potrajati nekoliko minuta):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otvorite terminal

### VS Code Dev Containers

⚠️ Ova opcija će raditi samo ako vaš Docker Desktop ima dodijeljeno barem 16 GB RAM-a. Ako imate manje od 16 GB RAM-a, možete pokušati s [GitHub Codespaces opcijom](../../../../../md/01.Introduction/01) ili [postaviti lokalno](../../../../../md/01.Introduction/01).

Povezana opcija su VS Code Dev Containers, koji će otvoriti projekt u vašem lokalnom VS Code-u koristeći [Dev Containers ekstenziju](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Pokrenite Docker Desktop (ako nije instaliran, instalirajte ga)
2. Otvorite projekt:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. U otvorenom VS Code prozoru, kada se pojave datoteke projekta (ovo može potrajati nekoliko minuta), otvorite terminal.
4. Nastavite s [koracima za implementaciju](../../../../../md/01.Introduction/01)

### Lokalno okruženje

1. Provjerite imate li instalirane sljedeće alate:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testirajte model

1. Zamolite Ollamu da preuzme i pokrene phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Preuzimanje modela može potrajati nekoliko minuta.

2. Kada u izlazu vidite "success", možete poslati poruku tom modelu putem prompta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Nakon nekoliko sekundi trebali biste vidjeti odgovor modela u obliku streama.

4. Da biste naučili o različitim tehnikama koje se koriste s jezičnim modelima, otvorite Python bilježnicu [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) i pokrenite svaku ćeliju. Ako ste koristili model osim 'phi3:mini', promijenite `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` na početku datoteke prema potrebi, a također možete izmijeniti sistemsku poruku ili dodati few-shot primjere ako želite.

**Odricanje od odgovornosti**:  
Ovaj je dokument preveden korištenjem AI prevoditeljskog servisa [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo postići točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba se smatrati službenim i autoritativnim izvorom. Za važne informacije preporučuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakve nesporazume ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.