<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:12:51+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "hr"
}
-->
# Početak rada s Phi-3 lokalno

Ovaj vodič će vam pomoći postaviti lokalno okruženje za pokretanje Phi-3 modela koristeći Ollama. Model možete pokrenuti na nekoliko različitih načina, uključujući GitHub Codespaces, VS Code Dev Containers ili vaše lokalno okruženje.

## Postavljanje okruženja

### GitHub Codespaces

Ovaj predložak možete pokrenuti virtualno koristeći GitHub Codespaces. Gumb će otvoriti VS Code u web pregledniku:

1. Otvorite predložak (ovo može potrajati nekoliko minuta):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otvorite terminal

### VS Code Dev Containers

⚠️ Ova opcija će raditi samo ako vaš Docker Desktop ima dodijeljeno barem 16 GB RAM-a. Ako imate manje od 16 GB RAM-a, možete isprobati [GitHub Codespaces opciju](../../../../../md/01.Introduction/01) ili [postaviti lokalno](../../../../../md/01.Introduction/01).

Srodna opcija su VS Code Dev Containers, koji će otvoriti projekt u vašem lokalnom VS Code-u koristeći [Dev Containers ekstenziju](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Pokrenite Docker Desktop (ako nije instaliran, instalirajte ga)
2. Otvorite projekt:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. U VS Code prozoru koji se otvori, nakon što se prikažu datoteke projekta (ovo može potrajati nekoliko minuta), otvorite terminal.
4. Nastavite s [koracima za implementaciju](../../../../../md/01.Introduction/01)

### Lokalno okruženje

1. Provjerite imate li instalirane sljedeće alate:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testirajte model

1. Zamolite Ollamu da preuzme i pokrene phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Preuzimanje modela može potrajati nekoliko minuta.

2. Kada u izlazu vidite "success", možete poslati poruku tom modelu iz prompta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Nakon nekoliko sekundi trebali biste vidjeti odgovor modela u streamu.

4. Za učenje o različitim tehnikama korištenim s jezičnim modelima, otvorite Python bilježnicu [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) i pokrenite svaku ćeliju. Ako ste koristili model različit od 'phi3:mini', promijenite `MODEL_NAME` u prvoj ćeliji.

5. Za vođenje razgovora s phi3:mini modelom iz Pythona, otvorite Python datoteku [chat.py](../../../../../code/01.Introduce/chat.py) i pokrenite je. Po potrebi možete promijeniti `MODEL_NAME` na vrhu datoteke, kao i izmijeniti sistemsku poruku ili dodati few-shot primjere.

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden korištenjem AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo postići točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritične informacije preporučuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakva nesporazuma ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.