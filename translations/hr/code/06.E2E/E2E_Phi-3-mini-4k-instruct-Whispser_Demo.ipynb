{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktivni Phi 3 Mini 4K Instruct Chatbot s Whisperom\n",
    "\n",
    "### Uvod:\n",
    "Interaktivni Phi 3 Mini 4K Instruct Chatbot je alat koji korisnicima omogućuje interakciju s Microsoft Phi 3 Mini 4K instruct demo koristeći tekstualni ili audio unos. Chatbot se može koristiti za razne zadatke, poput prijevoda, ažuriranja vremenske prognoze i prikupljanja općih informacija.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "[Stvorite svoj Huggingface pristupni token](https://huggingface.co/settings/tokens)\n",
    "\n",
    "Stvorite novi token  \n",
    "Unesite novo ime  \n",
    "Odaberite dozvole za pisanje  \n",
    "Kopirajte token i spremite ga na sigurno mjesto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sljedeći Python kod obavlja dva glavna zadatka: uvoz modula `os` i postavljanje varijable okruženja.\n",
    "\n",
    "1. Uvoz modula `os`:\n",
    "   - Modul `os` u Pythonu omogućuje interakciju s operativnim sustavom. Omogućuje izvođenje raznih zadataka vezanih uz operativni sustav, poput pristupa varijablama okruženja, rada s datotekama i direktorijima itd.\n",
    "   - U ovom kodu, modul `os` se uvozi pomoću naredbe `import`. Ova naredba omogućuje korištenje funkcionalnosti modula `os` u trenutnom Python skriptu.\n",
    "\n",
    "2. Postavljanje varijable okruženja:\n",
    "   - Varijabla okruženja je vrijednost kojoj mogu pristupiti programi koji se izvode na operativnom sustavu. To je način pohrane postavki konfiguracije ili drugih informacija koje mogu koristiti više programa.\n",
    "   - U ovom kodu, nova varijabla okruženja se postavlja pomoću rječnika `os.environ`. Ključ rječnika je `'HF_TOKEN'`, a vrijednost se dodjeljuje iz varijable `HUGGINGFACE_TOKEN`.\n",
    "   - Varijabla `HUGGINGFACE_TOKEN` definirana je neposredno iznad ovog isječka koda, i dodjeljuje joj se string vrijednost `\"hf_**************\"` pomoću sintakse `#@param`. Ova sintaksa se često koristi u Jupyter bilježnicama kako bi se omogućio unos korisnika i konfiguracija parametara direktno u sučelju bilježnice.\n",
    "   - Postavljanjem varijable okruženja `'HF_TOKEN'`, ona postaje dostupna drugim dijelovima programa ili drugim programima koji se izvode na istom operativnom sustavu.\n",
    "\n",
    "Sveukupno, ovaj kod uvozi modul `os` i postavlja varijablu okruženja pod nazivom `'HF_TOKEN'` s vrijednošću koja je definirana u varijabli `HUGGINGFACE_TOKEN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovaj isječak koda definira funkciju pod nazivom clear_output koja se koristi za brisanje izlaza trenutne ćelije u Jupyter Notebooku ili IPythonu. Razmotrimo kod i razumimo njegovu funkcionalnost:\n",
    "\n",
    "Funkcija clear_output prima jedan parametar nazvan wait, koji je logička vrijednost (boolean). Po zadanim postavkama, wait je postavljen na False. Ovaj parametar određuje treba li funkcija čekati dok novi izlaz ne bude dostupan za zamjenu postojećeg izlaza prije nego što ga obriše.\n",
    "\n",
    "Sama funkcija koristi se za brisanje izlaza trenutne ćelije. U Jupyter Notebooku ili IPythonu, kada ćelija generira izlaz, poput ispisanog teksta ili grafičkih prikaza, taj izlaz se prikazuje ispod ćelije. Funkcija clear_output omogućuje brisanje tog izlaza.\n",
    "\n",
    "Implementacija funkcije nije navedena u isječku koda, što je naznačeno s tri točke (...). Tri točke predstavljaju rezervirano mjesto za stvarni kod koji obavlja brisanje izlaza. Implementacija funkcije može uključivati interakciju s API-jem Jupyter Notebooka ili IPythona kako bi se uklonio postojeći izlaz iz ćelije.\n",
    "\n",
    "Sveukupno, ova funkcija pruža praktičan način za brisanje izlaza trenutne ćelije u Jupyter Notebooku ili IPythonu, olakšavajući upravljanje i ažuriranje prikazanog izlaza tijekom interaktivnih sesija kodiranja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izvedite pretvorbu teksta u govor (TTS) koristeći Edge TTS uslugu. Prođimo kroz relevantne implementacije funkcija jednu po jednu:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: Ova funkcija prima ulaznu vrijednost i izračunava brzinu govora za TTS glas. Ulazna vrijednost predstavlja željenu brzinu govora, gdje vrijednost 1 označava normalnu brzinu. Funkcija izračunava brzinu tako da oduzme 1 od ulazne vrijednosti, pomnoži rezultat sa 100 i zatim odredi znak na temelju toga je li ulazna vrijednost veća ili jednaka 1. Funkcija vraća brzinu u formatu \"{sign}{rate}\".\n",
    "\n",
    "2. `make_chunks(input_text, language)`: Ova funkcija prima ulazni tekst i jezik kao parametre. Dijeli ulazni tekst na dijelove prema pravilima specifičnim za jezik. U ovoj implementaciji, ako je jezik \"English\", funkcija dijeli tekst na mjestima gdje se nalazi točka (\".\"), uklanja sve vodeće ili završne razmake, dodaje točku svakom dijelu i vraća filtrirani popis dijelova.\n",
    "\n",
    "3. `tts_file_name(text)`: Ova funkcija generira naziv datoteke za TTS audio datoteku na temelju ulaznog teksta. Izvršava nekoliko transformacija na tekstu: uklanja završnu točku (ako postoji), pretvara tekst u mala slova, uklanja vodeće i završne razmake te zamjenjuje razmake s donjim crticama. Zatim skraćuje tekst na maksimalno 25 znakova (ako je dulji) ili koristi cijeli tekst ako je prazan. Na kraju generira nasumični niz koristeći modul [`uuid`] i kombinira ga sa skraćenim tekstom kako bi stvorila naziv datoteke u formatu \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\".\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: Ova funkcija spaja više audio datoteka u jednu. Prima popis putanja audio datoteka i izlaznu putanju kao parametre. Funkcija inicijalizira prazan objekt `AudioSegment` nazvan [`merged_audio`]. Zatim iterira kroz svaku putanju audio datoteke, učitava audio datoteku koristeći metodu `AudioSegment.from_file()` iz biblioteke `pydub` i dodaje trenutnu audio datoteku u objekt [`merged_audio`]. Na kraju, izvozi spojeni audio na specificiranu izlaznu putanju u MP3 formatu.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: Ova funkcija izvodi TTS operaciju koristeći Edge TTS uslugu. Prima popis dijelova teksta, brzinu govora, naziv glasa i putanju za spremanje kao parametre. Ako je broj dijelova veći od 1, funkcija kreira direktorij za pohranu pojedinačnih audio datoteka dijelova. Zatim iterira kroz svaki dio, konstruira Edge TTS naredbu koristeći funkciju `calculate_rate_string()`, naziv glasa i tekst dijela te izvršava naredbu koristeći funkciju `os.system()`. Ako je izvršenje naredbe uspješno, dodaje putanju generirane audio datoteke u popis. Nakon obrade svih dijelova, spaja pojedinačne audio datoteke koristeći funkciju `merge_audio_files()` i sprema spojeni audio na specificiranu putanju za spremanje. Ako postoji samo jedan dio, direktno generira Edge TTS naredbu i sprema audio na putanju za spremanje. Na kraju, vraća putanju generirane audio datoteke.\n",
    "\n",
    "6. `random_audio_name_generate()`: Ova funkcija generira nasumični naziv audio datoteke koristeći modul [`uuid`]. Generira nasumični UUID, pretvara ga u niz, uzima prvih 8 znakova, dodaje ekstenziju \".mp3\" i vraća nasumični naziv audio datoteke.\n",
    "\n",
    "7. `talk(input_text)`: Ova funkcija je glavni ulaz za izvođenje TTS operacije. Prima ulazni tekst kao parametar. Prvo provjerava duljinu ulaznog teksta kako bi odredila je li to duga rečenica (dulja ili jednaka 600 znakova). Na temelju duljine i vrijednosti varijable `translate_text_flag`, određuje jezik i generira popis dijelova teksta koristeći funkciju `make_chunks()`. Zatim generira putanju za spremanje audio datoteke koristeći funkciju `random_audio_name_generate()`. Na kraju, poziva funkciju `edge_free_tts()` za izvođenje TTS operacije i vraća putanju generirane audio datoteke.\n",
    "\n",
    "Sveukupno, ove funkcije rade zajedno kako bi podijelile ulazni tekst na dijelove, generirale naziv datoteke za audio datoteku, izvele TTS operaciju koristeći Edge TTS uslugu i spojile pojedinačne audio datoteke u jednu audio datoteku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacija dviju funkcija: convert_to_text i run_text_prompt, kao i deklaracija dviju klasa: str i Audio.\n",
    "\n",
    "Funkcija convert_to_text prima audio_path kao ulaz i transkribira audio u tekst koristeći model nazvan whisper_model. Funkcija prvo provjerava je li gpu zastavica postavljena na True. Ako jest, whisper_model se koristi s određenim parametrima kao što su word_timestamps=True, fp16=True, language='English' i task='translate'. Ako je gpu zastavica False, whisper_model se koristi s fp16=False. Dobivena transkripcija zatim se sprema u datoteku pod nazivom 'scan.txt' i vraća kao tekst.\n",
    "\n",
    "Funkcija run_text_prompt prima poruku i chat_history kao ulaz. Koristi funkciju phi_demo za generiranje odgovora od chatbota na temelju ulazne poruke. Generirani odgovor zatim se prosljeđuje funkciji talk, koja pretvara odgovor u audio datoteku i vraća putanju do datoteke. Klasa Audio koristi se za prikaz i reprodukciju audio datoteke. Audio se prikazuje pomoću funkcije display iz modula IPython.display, a Audio objekt se kreira s parametrom autoplay=True, tako da audio automatski počinje s reprodukcijom. chat_history se ažurira s ulaznom porukom i generiranim odgovorom, te se vraćaju prazan string i ažurirani chat_history.\n",
    "\n",
    "Klasa str je ugrađena klasa u Pythonu koja predstavlja niz znakova. Pruža razne metode za manipulaciju i rad s stringovima, kao što su capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill i još mnogo toga. Ove metode omogućuju izvođenje operacija poput pretraživanja, zamjene, formatiranja i manipulacije stringovima.\n",
    "\n",
    "Klasa Audio je prilagođena klasa koja predstavlja audio objekt. Koristi se za kreiranje audio playera u Jupyter Notebook okruženju. Klasa prihvaća razne parametre kao što su data, filename, url, embed, rate, autoplay i normalize. Parametar data može biti numpy niz, lista uzoraka, string koji predstavlja naziv datoteke ili URL, ili sirovi PCM podaci. Parametar filename koristi se za specificiranje lokalne datoteke iz koje se učitavaju audio podaci, a parametar url koristi se za specificiranje URL-a s kojeg se preuzimaju audio podaci. Parametar embed određuje hoće li audio podaci biti ugrađeni pomoću data URI-ja ili referencirani iz izvornog izvora. Parametar rate specificira brzinu uzorkovanja audio podataka. Parametar autoplay određuje hoće li audio automatski početi s reprodukcijom. Parametar normalize specificira hoće li audio podaci biti normalizirani (prilagođeni) na maksimalni mogući raspon. Klasa Audio također pruža metode poput reload za ponovno učitavanje audio podataka iz datoteke ili URL-a, te atribute poput src_attr, autoplay_attr i element_id_attr za dohvaćanje odgovarajućih atributa za audio element u HTML-u.\n",
    "\n",
    "Sve u svemu, ove funkcije i klase koriste se za transkripciju audio zapisa u tekst, generiranje audio odgovora od chatbota, te prikaz i reprodukciju audio zapisa u Jupyter Notebook okruženju.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Odricanje od odgovornosti**:  \nOvaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za bilo kakve nesporazume ili pogrešne interpretacije koje proizlaze iz korištenja ovog prijevoda.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-13T07:04:04+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "hr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}