<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-07-16T17:44:58+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "hi"
}
-->
# Phi मॉडल्स के लिए AI सुरक्षा  
Phi मॉडल्स का परिवार [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) के अनुसार विकसित किया गया है, जो कंपनी-व्यापी आवश्यकताओं का एक सेट है और निम्नलिखित छह सिद्धांतों पर आधारित है: जवाबदेही, पारदर्शिता, निष्पक्षता, विश्वसनीयता और सुरक्षा, गोपनीयता और सुरक्षा, तथा समावेशन, जो [Microsoft के Responsible AI सिद्धांतों](https://www.microsoft.com/ai/responsible-ai) का हिस्सा हैं।  

पिछले Phi मॉडल्स की तरह, एक बहुआयामी सुरक्षा मूल्यांकन और पोस्ट-ट्रेनिंग सुरक्षा दृष्टिकोण अपनाया गया है, जिसमें इस रिलीज की बहुभाषी क्षमताओं को ध्यान में रखते हुए अतिरिक्त उपाय किए गए हैं। हमारी सुरक्षा प्रशिक्षण और मूल्यांकन की प्रक्रिया, जिसमें कई भाषाओं और जोखिम श्रेणियों में परीक्षण शामिल है, [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) में विस्तार से बताई गई है। जबकि Phi मॉडल्स इस दृष्टिकोण से लाभान्वित होते हैं, डेवलपर्स को अपने विशिष्ट उपयोग मामले और सांस्कृतिक व भाषाई संदर्भ के अनुसार जोखिमों का मानचित्रण, मापन और शमन करने सहित जिम्मेदार AI सर्वोत्तम प्रथाओं को लागू करना चाहिए।  

## सर्वोत्तम प्रथाएं  

अन्य मॉडलों की तरह, Phi मॉडल्स भी संभावित रूप से ऐसे व्यवहार कर सकते हैं जो अनुचित, अविश्वसनीय या आपत्तिजनक हो सकते हैं।  

SLM और LLM के कुछ सीमित व्यवहार जिनसे आपको अवगत रहना चाहिए, वे हैं:  

- **सेवा की गुणवत्ता:** Phi मॉडल्स मुख्य रूप से अंग्रेजी टेक्स्ट पर प्रशिक्षित हैं। अंग्रेजी के अलावा अन्य भाषाओं में प्रदर्शन खराब हो सकता है। प्रशिक्षण डेटा में कम प्रतिनिधित्व वाली अंग्रेजी की विभिन्न बोलियाँ मानक अमेरिकी अंग्रेजी की तुलना में खराब प्रदर्शन कर सकती हैं।  
- **हानि का प्रतिनिधित्व और रूढ़ियों का निरंतरता:** ये मॉडल्स कुछ समूहों का अधिक या कम प्रतिनिधित्व कर सकते हैं, कुछ समूहों का प्रतिनिधित्व मिटा सकते हैं, या अपमानजनक या नकारात्मक रूढ़ियों को मजबूत कर सकते हैं। सुरक्षा पोस्ट-ट्रेनिंग के बावजूद, ये सीमाएं तब भी मौजूद हो सकती हैं क्योंकि विभिन्न समूहों का प्रतिनिधित्व अलग-अलग होता है या प्रशिक्षण डेटा में नकारात्मक रूढ़ियों के उदाहरण वास्तविक दुनिया के पैटर्न और सामाजिक पूर्वाग्रहों को दर्शाते हैं।  
- **अनुचित या आपत्तिजनक सामग्री:** ये मॉडल्स अन्य प्रकार की अनुचित या आपत्तिजनक सामग्री उत्पन्न कर सकते हैं, जिससे संवेदनशील संदर्भों में इन्हें बिना अतिरिक्त उपयोग-विशिष्ट रोकथाम के लागू करना अनुचित हो सकता है।  
- **सूचना की विश्वसनीयता:** भाषा मॉडल्स बेतुकी सामग्री उत्पन्न कर सकते हैं या ऐसी सामग्री बना सकते हैं जो सुनने में तर्कसंगत लगे लेकिन असत्य या पुरानी हो।  
- **कोड के लिए सीमित दायरा:** Phi-3 के अधिकांश प्रशिक्षण डेटा Python पर आधारित हैं और सामान्य पैकेज जैसे "typing, math, random, collections, datetime, itertools" का उपयोग करते हैं। यदि मॉडल अन्य पैकेज या अन्य भाषाओं में स्क्रिप्ट उत्पन्न करता है, तो हम उपयोगकर्ताओं को सभी API उपयोगों की मैनुअल जांच करने की सख्त सलाह देते हैं।  

डेवलपर्स को जिम्मेदार AI सर्वोत्तम प्रथाओं को अपनाना चाहिए और यह सुनिश्चित करना चाहिए कि उनका विशिष्ट उपयोग मामला संबंधित कानूनों और नियमों (जैसे गोपनीयता, व्यापार आदि) का पालन करता हो।  

## जिम्मेदार AI विचार  

अन्य भाषा मॉडल्स की तरह, Phi श्रृंखला के मॉडल्स भी संभावित रूप से ऐसे व्यवहार कर सकते हैं जो अनुचित, अविश्वसनीय या आपत्तिजनक हों। कुछ सीमित व्यवहार जिनसे अवगत रहना चाहिए, वे हैं:  

**सेवा की गुणवत्ता:** Phi मॉडल्स मुख्य रूप से अंग्रेजी टेक्स्ट पर प्रशिक्षित हैं। अंग्रेजी के अलावा अन्य भाषाओं में प्रदर्शन खराब हो सकता है। प्रशिक्षण डेटा में कम प्रतिनिधित्व वाली अंग्रेजी की विभिन्न बोलियाँ मानक अमेरिकी अंग्रेजी की तुलना में खराब प्रदर्शन कर सकती हैं।  

**हानि का प्रतिनिधित्व और रूढ़ियों का निरंतरता:** ये मॉडल्स कुछ समूहों का अधिक या कम प्रतिनिधित्व कर सकते हैं, कुछ समूहों का प्रतिनिधित्व मिटा सकते हैं, या अपमानजनक या नकारात्मक रूढ़ियों को मजबूत कर सकते हैं। सुरक्षा पोस्ट-ट्रेनिंग के बावजूद, ये सीमाएं तब भी मौजूद हो सकती हैं क्योंकि विभिन्न समूहों का प्रतिनिधित्व अलग-अलग होता है या प्रशिक्षण डेटा में नकारात्मक रूढ़ियों के उदाहरण वास्तविक दुनिया के पैटर्न और सामाजिक पूर्वाग्रहों को दर्शाते हैं।  

**अनुचित या आपत्तिजनक सामग्री:** ये मॉडल्स अन्य प्रकार की अनुचित या आपत्तिजनक सामग्री उत्पन्न कर सकते हैं, जिससे संवेदनशील संदर्भों में इन्हें बिना अतिरिक्त उपयोग-विशिष्ट रोकथाम के लागू करना अनुचित हो सकता है।  
सूचना की विश्वसनीयता: भाषा मॉडल्स बेतुकी सामग्री उत्पन्न कर सकते हैं या ऐसी सामग्री बना सकते हैं जो सुनने में तर्कसंगत लगे लेकिन असत्य या पुरानी हो।  

**कोड के लिए सीमित दायरा:** Phi-3 के अधिकांश प्रशिक्षण डेटा Python पर आधारित हैं और सामान्य पैकेज जैसे "typing, math, random, collections, datetime, itertools" का उपयोग करते हैं। यदि मॉडल अन्य पैकेज या अन्य भाषाओं में स्क्रिप्ट उत्पन्न करता है, तो हम उपयोगकर्ताओं को सभी API उपयोगों की मैनुअल जांच करने की सख्त सलाह देते हैं।  

डेवलपर्स को जिम्मेदार AI सर्वोत्तम प्रथाओं को अपनाना चाहिए और यह सुनिश्चित करना चाहिए कि उनका विशिष्ट उपयोग मामला संबंधित कानूनों और नियमों (जैसे गोपनीयता, व्यापार आदि) का पालन करता हो। विचार करने के लिए महत्वपूर्ण क्षेत्र हैं:  

**आवंटन:** मॉडल्स उन परिदृश्यों के लिए उपयुक्त नहीं हो सकते जिनका कानूनी स्थिति या संसाधनों या जीवन के अवसरों (जैसे आवास, रोजगार, क्रेडिट आदि) के आवंटन पर महत्वपूर्ण प्रभाव हो सकता है, जब तक कि अतिरिक्त मूल्यांकन और पूर्वाग्रह शमन तकनीकें लागू न की जाएं।  

**उच्च जोखिम वाले परिदृश्य:** डेवलपर्स को उन उच्च जोखिम वाले परिदृश्यों में मॉडल के उपयोग की उपयुक्तता का आकलन करना चाहिए जहां अनुचित, अविश्वसनीय या आपत्तिजनक आउटपुट अत्यंत महंगा या हानिकारक हो सकता है। इसमें संवेदनशील या विशेषज्ञ क्षेत्रों में सलाह देना शामिल है जहां सटीकता और विश्वसनीयता महत्वपूर्ण है (जैसे कानूनी या स्वास्थ्य सलाह)। तैनाती संदर्भ के अनुसार एप्लिकेशन स्तर पर अतिरिक्त सुरक्षा उपाय लागू किए जाने चाहिए।  

**गलत सूचना:** मॉडल्स गलत जानकारी उत्पन्न कर सकते हैं। डेवलपर्स को पारदर्शिता सर्वोत्तम प्रथाओं का पालन करना चाहिए और अंतिम उपयोगकर्ताओं को सूचित करना चाहिए कि वे AI सिस्टम के साथ बातचीत कर रहे हैं। एप्लिकेशन स्तर पर, डेवलपर्स प्रतिक्रिया को उपयोग-मामला विशिष्ट, संदर्भित जानकारी पर आधारित बनाने के लिए फीडबैक तंत्र और पाइपलाइनों का निर्माण कर सकते हैं, जिसे Retrieval Augmented Generation (RAG) कहा जाता है।  

**हानिकारक सामग्री का उत्पादन:** डेवलपर्स को आउटपुट का संदर्भ के अनुसार आकलन करना चाहिए और उपलब्ध सुरक्षा वर्गीकरण या उपयोग-मामला उपयुक्त कस्टम समाधान का उपयोग करना चाहिए।  

**दुरुपयोग:** धोखाधड़ी, स्पैम, या मैलवेयर उत्पादन जैसे अन्य दुरुपयोग संभव हो सकते हैं, और डेवलपर्स को यह सुनिश्चित करना चाहिए कि उनके एप्लिकेशन लागू कानूनों और नियमों का उल्लंघन न करें।  

### फाइनट्यूनिंग और AI सामग्री सुरक्षा  

मॉडल को फाइनट्यून करने के बाद, हम अत्यधिक अनुशंसा करते हैं कि आप [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) उपायों का उपयोग करें ताकि मॉडल द्वारा उत्पन्न सामग्री की निगरानी की जा सके, संभावित जोखिमों, खतरों और गुणवत्ता समस्याओं की पहचान और अवरोधन किया जा सके।  

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c40507c5e8be556615b8377a63b8764865d057d4faac3757a478.hi.png)  

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) टेक्स्ट और इमेज दोनों प्रकार की सामग्री का समर्थन करता है। इसे क्लाउड, डिस्कनेक्टेड कंटेनर, और एज/एम्बेडेड डिवाइसेज पर तैनात किया जा सकता है।  

## Azure AI Content Safety का अवलोकन  

Azure AI Content Safety एक सार्वभौमिक समाधान नहीं है; इसे व्यवसायों की विशिष्ट नीतियों के अनुरूप अनुकूलित किया जा सकता है। इसके अलावा, इसके बहुभाषी मॉडल इसे एक साथ कई भाषाओं को समझने में सक्षम बनाते हैं।  

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a56cf708aff010a541799d002ae7ae84bb819b19ab8950591.hi.png)  

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5 वीडियो**  

Azure AI Content Safety सेवा एप्लिकेशन और सेवाओं में हानिकारक उपयोगकर्ता-जनित और AI-जनित सामग्री का पता लगाती है। इसमें टेक्स्ट और इमेज API शामिल हैं जो हानिकारक या अनुचित सामग्री का पता लगाने की अनुमति देते हैं।  

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ अपनी मूल भाषा में ही अधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सलाह दी जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।