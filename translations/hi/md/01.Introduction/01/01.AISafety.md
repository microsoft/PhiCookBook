<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-05-08T06:14:06+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "hi"
}
-->
# Phi मॉडल्स के लिए AI सुरक्षा  
Phi मॉडल परिवार का विकास [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) के अनुरूप किया गया है, जो कंपनी-व्यापी आवश्यकताओं का सेट है और निम्नलिखित छह सिद्धांतों पर आधारित है: जवाबदेही, पारदर्शिता, निष्पक्षता, विश्वसनीयता और सुरक्षा, गोपनीयता और सुरक्षा, तथा समावेशन, जो [Microsoft के Responsible AI सिद्धांतों](https://www.microsoft.com/ai/responsible-ai) का हिस्सा हैं।  

पिछले Phi मॉडलों की तरह, एक बहु-आयामी सुरक्षा मूल्यांकन और पोस्ट-ट्रेनिंग सुरक्षा दृष्टिकोण अपनाया गया है, जिसमें इस रिलीज की बहुभाषी क्षमताओं को ध्यान में रखते हुए अतिरिक्त उपाय शामिल हैं। हमारी सुरक्षा प्रशिक्षण और मूल्यांकन की प्रक्रिया, जिसमें कई भाषाओं और जोखिम श्रेणियों में परीक्षण शामिल है, [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) में विस्तार से बताई गई है। हालांकि Phi मॉडल इस दृष्टिकोण से लाभान्वित होते हैं, डेवलपर्स को जिम्मेदार AI सर्वोत्तम प्रथाओं को लागू करना चाहिए, जिसमें उनके विशिष्ट उपयोग मामले और सांस्कृतिक तथा भाषाई संदर्भ से जुड़े जोखिमों का मानचित्रण, मापन और शमन शामिल है।  

## सर्वोत्तम प्रथाएं  

अन्य मॉडलों की तरह, Phi मॉडल परिवार संभावित रूप से ऐसे व्यवहार कर सकता है जो अनुचित, अविश्वसनीय या आपत्तिजनक हो सकते हैं।  

SLM और LLM के कुछ सीमित व्यवहार जिनसे आपको अवगत होना चाहिए, वे हैं:  

- **सेवा की गुणवत्ता:** Phi मॉडल मुख्य रूप से अंग्रेजी पाठ पर प्रशिक्षित हैं। अंग्रेजी के अलावा अन्य भाषाओं में प्रदर्शन कम हो सकता है। प्रशिक्षण डेटा में कम प्रतिनिधित्व वाली अंग्रेजी भाषा विविधताएं मानक अमेरिकी अंग्रेजी की तुलना में खराब प्रदर्शन कर सकती हैं।  
- **हानि का प्रतिनिधित्व और रूढ़िवादिता का निरंतरता:** ये मॉडल कुछ समूहों का अधिक या कम प्रतिनिधित्व कर सकते हैं, कुछ समूहों का प्रतिनिधित्व मिटा सकते हैं, या अपमानजनक या नकारात्मक रूढ़ियों को बढ़ावा दे सकते हैं। सुरक्षा पोस्ट-ट्रेनिंग के बावजूद, ये सीमाएं अभी भी मौजूद हो सकती हैं क्योंकि विभिन्न समूहों का प्रतिनिधित्व अलग-अलग होता है या प्रशिक्षण डेटा में नकारात्मक रूढ़ियों के उदाहरण होते हैं जो वास्तविक दुनिया के पैटर्न और सामाजिक पूर्वाग्रहों को दर्शाते हैं।  
- **अनुचित या आपत्तिजनक सामग्री:** ये मॉडल अन्य प्रकार की अनुचित या आपत्तिजनक सामग्री उत्पन्न कर सकते हैं, जिसके कारण संवेदनशील संदर्भों में अतिरिक्त उपयोग-विशिष्ट शमन उपायों के बिना इन्हें लागू करना अनुचित हो सकता है।  
- **जानकारी की विश्वसनीयता:** भाषा मॉडल बेतुकी सामग्री उत्पन्न कर सकते हैं या ऐसी सामग्री बना सकते हैं जो सुनने में सही लगती है लेकिन असत्य या पुरानी हो सकती है।  
- **कोड के लिए सीमित दायरा:** Phi-3 प्रशिक्षण डेटा का अधिकांश हिस्सा Python पर आधारित है और "typing, math, random, collections, datetime, itertools" जैसे सामान्य पैकेजों का उपयोग करता है। यदि मॉडल अन्य पैकेजों या अन्य भाषाओं में स्क्रिप्ट उत्पन्न करता है, तो हम उपयोगकर्ताओं को सभी API उपयोगों को मैन्युअल रूप से सत्यापित करने की सलाह देते हैं।  

डेवलपर्स को जिम्मेदार AI सर्वोत्तम प्रथाओं को लागू करना चाहिए और यह सुनिश्चित करने के लिए जिम्मेदार होना चाहिए कि कोई विशिष्ट उपयोग मामला संबंधित कानूनों और नियमों (जैसे गोपनीयता, व्यापार, आदि) का पालन करता हो।  

## जिम्मेदार AI विचार  

अन्य भाषा मॉडलों की तरह, Phi श्रृंखला के मॉडल संभावित रूप से ऐसे व्यवहार कर सकते हैं जो अनुचित, अविश्वसनीय, या आपत्तिजनक हों। ध्यान देने योग्य कुछ सीमित व्यवहार हैं:  

**सेवा की गुणवत्ता:** Phi मॉडल मुख्य रूप से अंग्रेजी पाठ पर प्रशिक्षित हैं। अंग्रेजी के अलावा अन्य भाषाओं में प्रदर्शन कम हो सकता है। प्रशिक्षण डेटा में कम प्रतिनिधित्व वाली अंग्रेजी भाषा विविधताएं मानक अमेरिकी अंग्रेजी की तुलना में खराब प्रदर्शन कर सकती हैं।  

**हानि का प्रतिनिधित्व और रूढ़िवादिता का निरंतरता:** ये मॉडल कुछ समूहों का अधिक या कम प्रतिनिधित्व कर सकते हैं, कुछ समूहों का प्रतिनिधित्व मिटा सकते हैं, या अपमानजनक या नकारात्मक रूढ़ियों को बढ़ावा दे सकते हैं। सुरक्षा पोस्ट-ट्रेनिंग के बावजूद, ये सीमाएं अभी भी मौजूद हो सकती हैं क्योंकि विभिन्न समूहों का प्रतिनिधित्व अलग-अलग होता है या प्रशिक्षण डेटा में नकारात्मक रूढ़ियों के उदाहरण होते हैं जो वास्तविक दुनिया के पैटर्न और सामाजिक पूर्वाग्रहों को दर्शाते हैं।  

**अनुचित या आपत्तिजनक सामग्री:** ये मॉडल अन्य प्रकार की अनुचित या आपत्तिजनक सामग्री उत्पन्न कर सकते हैं, जिसके कारण संवेदनशील संदर्भों में अतिरिक्त उपयोग-विशिष्ट शमन उपायों के बिना इन्हें लागू करना अनुचित हो सकता है।  
जानकारी की विश्वसनीयता: भाषा मॉडल बेतुकी सामग्री उत्पन्न कर सकते हैं या ऐसी सामग्री बना सकते हैं जो सुनने में सही लगती है लेकिन असत्य या पुरानी हो सकती है।  

**कोड के लिए सीमित दायरा:** Phi-3 प्रशिक्षण डेटा का अधिकांश हिस्सा Python पर आधारित है और "typing, math, random, collections, datetime, itertools" जैसे सामान्य पैकेजों का उपयोग करता है। यदि मॉडल अन्य पैकेजों या अन्य भाषाओं में स्क्रिप्ट उत्पन्न करता है, तो हम उपयोगकर्ताओं को सभी API उपयोगों को मैन्युअल रूप से सत्यापित करने की सलाह देते हैं।  

डेवलपर्स को जिम्मेदार AI सर्वोत्तम प्रथाओं को लागू करना चाहिए और यह सुनिश्चित करने के लिए जिम्मेदार होना चाहिए कि कोई विशिष्ट उपयोग मामला संबंधित कानूनों और नियमों (जैसे गोपनीयता, व्यापार, आदि) का पालन करता हो। विचार के लिए महत्वपूर्ण क्षेत्र शामिल हैं:  

**आवंटन:** मॉडल उन परिदृश्यों के लिए उपयुक्त नहीं हो सकते जिनका कानूनी स्थिति या संसाधनों या जीवन के अवसरों (जैसे आवास, रोजगार, क्रेडिट, आदि) के आवंटन पर महत्वपूर्ण प्रभाव हो सकता है, जब तक कि आगे के मूल्यांकन और अतिरिक्त पूर्वाग्रह शमन तकनीकों को लागू न किया जाए।  

**उच्च जोखिम वाले परिदृश्य:** डेवलपर्स को उन उच्च जोखिम वाले परिदृश्यों में मॉडल के उपयोग की उपयुक्तता का आकलन करना चाहिए जहाँ अनुचित, अविश्वसनीय, या आपत्तिजनक आउटपुट अत्यंत महंगे या हानिकारक हो सकते हैं। इसमें संवेदनशील या विशेषज्ञ क्षेत्रों में सलाह देना शामिल है जहाँ सटीकता और विश्वसनीयता महत्वपूर्ण हैं (जैसे कानूनी या स्वास्थ्य सलाह)। अनुप्रयोग स्तर पर तैनाती के संदर्भ के अनुसार अतिरिक्त सुरक्षा उपाय लागू किए जाने चाहिए।  

**भ्रामक जानकारी:** मॉडल गलत जानकारी उत्पन्न कर सकते हैं। डेवलपर्स को पारदर्शिता की सर्वोत्तम प्रथाओं का पालन करना चाहिए और अंतिम उपयोगकर्ताओं को सूचित करना चाहिए कि वे AI सिस्टम के साथ बातचीत कर रहे हैं। अनुप्रयोग स्तर पर, डेवलपर्स प्रतिक्रिया तंत्र और पाइपलाइनों का निर्माण कर सकते हैं जो उपयोग-मामले विशेष, संदर्भित जानकारी पर आधारित हों, जिसे Retrieval Augmented Generation (RAG) के नाम से जाना जाता है।  

**हानिकारक सामग्री का उत्पादन:** डेवलपर्स को अपने आउटपुट को संदर्भ के अनुसार आकलन करना चाहिए और उपलब्ध सुरक्षा वर्गीकरण उपकरणों या उपयोग-मामले के लिए उपयुक्त कस्टम समाधानों का उपयोग करना चाहिए।  

**दुरुपयोग:** धोखाधड़ी, स्पैम, या मैलवेयर उत्पादन जैसे अन्य दुरुपयोग के रूप संभव हैं, और डेवलपर्स को सुनिश्चित करना चाहिए कि उनके अनुप्रयोग लागू कानूनों और नियमों का उल्लंघन न करें।  

### फाइनट्यूनिंग और AI सामग्री सुरक्षा  

मॉडल को फाइनट्यून करने के बाद, हम [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) उपायों का उपयोग करने की सिफारिश करते हैं ताकि मॉडल द्वारा उत्पन्न सामग्री की निगरानी की जा सके, संभावित जोखिमों, खतरों, और गुणवत्ता संबंधी मुद्दों की पहचान और अवरोधन किया जा सके।  

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c40507c5e8be556615b8377a63b8764865d057d4faac3757a478.hi.png)  

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) दोनों, टेक्स्ट और इमेज कंटेंट का समर्थन करता है। इसे क्लाउड, डिस्कनेक्टेड कंटेनर, और एज/एम्बेडेड डिवाइसेस पर तैनात किया जा सकता है।  

## Azure AI Content Safety का अवलोकन  

Azure AI Content Safety एक सार्वभौमिक समाधान नहीं है; इसे व्यवसायों की विशिष्ट नीतियों के अनुरूप अनुकूलित किया जा सकता है। इसके अलावा, इसके बहुभाषी मॉडल इसे एक साथ कई भाषाओं को समझने में सक्षम बनाते हैं।  

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a56cf708aff010a541799d002ae7ae84bb819b19ab8950591.hi.png)  

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5 वीडियो**  

Azure AI Content Safety सेवा एप्लिकेशन और सेवाओं में हानिकारक उपयोगकर्ता-जनित और AI-जनित सामग्री का पता लगाती है। इसमें टेक्स्ट और इमेज API शामिल हैं जो हानिकारक या अनुचित सामग्री का पता लगाने की अनुमति देते हैं।  

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या असंगतियाँ हो सकती हैं। मूल दस्तावेज़ को उसकी मूल भाषा में प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सलाह दी जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।