<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-07-16T19:34:49+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "hi"
}
-->
## NVIDIA NIM में Phi परिवार

NVIDIA NIM एक आसान उपयोग वाले माइक्रोसर्विसेज का सेट है, जो क्लाउड, डेटा सेंटर और वर्कस्टेशन में जनरेटिव AI मॉडल्स की तैनाती को तेज़ करता है। NIMs को मॉडल परिवार और प्रति मॉडल आधार पर वर्गीकृत किया गया है। उदाहरण के लिए, बड़े भाषा मॉडल (LLMs) के लिए NVIDIA NIM, अत्याधुनिक LLMs की शक्ति को एंटरप्राइज एप्लिकेशन में लाता है, जो बेजोड़ प्राकृतिक भाषा प्रसंस्करण और समझ क्षमताएं प्रदान करता है।

NIM IT और DevOps टीमों के लिए अपने प्रबंधित वातावरण में बड़े भाषा मॉडल (LLMs) को स्वयं होस्ट करना आसान बनाता है, साथ ही डेवलपर्स को उद्योग मानक API प्रदान करता है जो उन्हें शक्तिशाली copilots, चैटबॉट्स, और AI असिस्टेंट्स बनाने की अनुमति देते हैं जो उनके व्यवसाय को बदल सकते हैं। NVIDIA की अत्याधुनिक GPU त्वरक और स्केलेबल तैनाती का लाभ उठाते हुए, NIM बेजोड़ प्रदर्शन के साथ सबसे तेज़ इनफेरेंस पथ प्रदान करता है।

आप NVIDIA NIM का उपयोग Phi परिवार के मॉडल्स के इनफेरेंस के लिए कर सकते हैं

![nim](../../../../../translated_images/hi/Phi-NIM.09bebb743387ee4a.webp)

### **नमूने - NVIDIA NIM में Phi-3-Vision**

कल्पना करें कि आपके पास एक इमेज (`demo.png`) है और आप ऐसा Python कोड जनरेट करना चाहते हैं जो इस इमेज को प्रोसेस करे और इसका एक नया संस्करण (`phi-3-vision.jpg`) सेव करे।

ऊपर दिया गया कोड इस प्रक्रिया को स्वचालित करता है:

1. पर्यावरण और आवश्यक कॉन्फ़िगरेशन सेट करना।
2. एक प्रॉम्प्ट बनाना जो मॉडल को आवश्यक Python कोड जनरेट करने का निर्देश देता है।
3. प्रॉम्प्ट को मॉडल को भेजना और जनरेट किए गए कोड को इकट्ठा करना।
4. जनरेट किए गए कोड को निकालना और चलाना।
5. मूल और प्रोसेस की गई इमेज दिखाना।

यह तरीका AI की शक्ति का उपयोग करके इमेज प्रोसेसिंग कार्यों को स्वचालित करता है, जिससे आपके लक्ष्यों को हासिल करना आसान और तेज़ हो जाता है।

[Sample Code Solution](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

आइए पूरे कोड को चरण दर चरण समझते हैं:

1. **आवश्यक पैकेज इंस्टॉल करें**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```  
    यह कमांड `langchain_nvidia_ai_endpoints` पैकेज को इंस्टॉल करता है, यह सुनिश्चित करते हुए कि यह नवीनतम संस्करण हो।

2. **जरूरी मॉड्यूल इम्पोर्ट करें**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```  
    ये इम्पोर्ट्स NVIDIA AI एंडपॉइंट्स के साथ इंटरैक्ट करने, पासवर्ड सुरक्षित रूप से हैंडल करने, ऑपरेटिंग सिस्टम के साथ काम करने, और बेस64 फॉर्मेट में डेटा एन्कोड/डिकोड करने के लिए आवश्यक मॉड्यूल लाते हैं।

3. **API की सेट करें**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```  
    यह कोड जांचता है कि `NVIDIA_API_KEY` पर्यावरण चर सेट है या नहीं। यदि नहीं, तो यह उपयोगकर्ता से सुरक्षित रूप से API की दर्ज करने के लिए कहता है।

4. **मॉडल और इमेज पथ परिभाषित करें**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```  
    यह उपयोग किए जाने वाले मॉडल को सेट करता है, `ChatNVIDIA` का एक उदाहरण बनाता है, और इमेज फ़ाइल का पथ परिभाषित करता है।

5. **टेक्स्ट प्रॉम्प्ट बनाएं**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```  
    यह एक टेक्स्ट प्रॉम्प्ट परिभाषित करता है जो मॉडल को इमेज प्रोसेसिंग के लिए Python कोड जनरेट करने का निर्देश देता है।

6. **इमेज को बेस64 में एन्कोड करें**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```  
    यह कोड इमेज फ़ाइल को पढ़ता है, उसे बेस64 में एन्कोड करता है, और एन्कोडेड डेटा के साथ एक HTML इमेज टैग बनाता है।

7. **टेक्स्ट और इमेज को प्रॉम्प्ट में मिलाएं**:
    ```python
    prompt = f"{text} {image}"
    ```  
    यह टेक्स्ट प्रॉम्प्ट और HTML इमेज टैग को एक स्ट्रिंग में जोड़ता है।

8. **ChatNVIDIA का उपयोग करके कोड जनरेट करें**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```  
    यह कोड प्रॉम्प्ट को `ChatNVIDIA` मॉडल को भेजता है और जनरेट किए गए कोड को टुकड़ों में इकट्ठा करता है, प्रत्येक टुकड़ा प्रिंट करता है और `code` स्ट्रिंग में जोड़ता है।

9. **जनरेट किए गए कंटेंट से Python कोड निकालें**:
    ```python
    begin = code.index('```python') + 9  
    code = code[begin:]  
    end = code.index('```')
    code = code[:end]
    ```  
    यह मार्कडाउन फॉर्मेटिंग को हटाकर जनरेट किए गए कंटेंट से वास्तविक Python कोड निकालता है।

10. **जनरेट किए गए कोड को चलाएं**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```  
    यह निकाले गए Python कोड को एक सबप्रोसेस के रूप में चलाता है और इसका आउटपुट कैप्चर करता है।

11. **इमेज दिखाएं**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```  
    ये लाइनें `IPython.display` मॉड्यूल का उपयोग करके इमेज दिखाती हैं।

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ अपनी मूल भाषा में ही प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सलाह दी जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।