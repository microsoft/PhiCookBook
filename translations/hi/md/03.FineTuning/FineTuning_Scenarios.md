<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cb5648935f63edc17e95ce38f23adc32",
  "translation_date": "2025-07-17T08:24:29+00:00",
  "source_file": "md/03.FineTuning/FineTuning_Scenarios.md",
  "language_code": "hi"
}
-->
## फाइन ट्यूनिंग परिदृश्य

![FineTuning with MS Services](../../../../translated_images/FinetuningwithMS.3d0cec8ae693e094c38c72575e63f2c9bf1cf980ab90f1388e102709f9c979e5.hi.png)

**प्लेटफ़ॉर्म** इसमें Azure AI Foundry, Azure Machine Learning, AI Tools, Kaito, और ONNX Runtime जैसी विभिन्न तकनीकें शामिल हैं।

**इन्फ्रास्ट्रक्चर** इसमें CPU और FPGA शामिल हैं, जो फाइन-ट्यूनिंग प्रक्रिया के लिए आवश्यक हैं। मैं आपको इन तकनीकों के आइकन दिखाता हूँ।

**टूल्स और फ्रेमवर्क** इसमें ONNX Runtime शामिल है। मैं आपको इन तकनीकों के आइकन दिखाता हूँ।  
[ONNX Runtime के आइकन डालें]

Microsoft तकनीकों के साथ फाइन-ट्यूनिंग प्रक्रिया में विभिन्न घटक और टूल्स शामिल होते हैं। इन तकनीकों को समझकर और उपयोग करके, हम अपने एप्लिकेशन को प्रभावी ढंग से फाइन-ट्यून कर सकते हैं और बेहतर समाधान बना सकते हैं।

## मॉडल ऐज़ सर्विस

होस्टेड फाइन-ट्यूनिंग का उपयोग करके मॉडल को फाइन-ट्यून करें, बिना कंप्यूट बनाने और प्रबंधित करने की आवश्यकता के।

![MaaS Fine Tuning](../../../../translated_images/MaaSfinetune.3eee4630607aff0d0a137b16ab79ec5977ece923cd1fdd89557a2655c632669d.hi.png)

Phi-3-mini और Phi-3-medium मॉडल के लिए सर्वरलेस फाइन-ट्यूनिंग उपलब्ध है, जिससे डेवलपर्स क्लाउड और एज परिदृश्यों के लिए मॉडल को जल्दी और आसानी से कस्टमाइज़ कर सकते हैं, बिना कंप्यूट की व्यवस्था किए। हमने यह भी घोषणा की है कि Phi-3-small अब Models-as-a-Service ऑफरिंग के माध्यम से उपलब्ध है, ताकि डेवलपर्स बिना आधारभूत संरचना प्रबंधित किए AI विकास जल्दी और आसानी से शुरू कर सकें।

## मॉडल ऐज़ प्लेटफ़ॉर्म

उपयोगकर्ता अपने स्वयं के कंप्यूट का प्रबंधन करते हैं ताकि वे अपने मॉडल को फाइन-ट्यून कर सकें।

![Maap Fine Tuning](../../../../translated_images/MaaPFinetune.fd3829c1122f5d1c4a6a91593ebc348548410e162acda34f18034384e3b3816a.hi.png)

[Fine Tuning Sample](https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/system/finetune/chat-completion/chat-completion.ipynb)

## फाइन ट्यूनिंग परिदृश्य

| | | | | | | |
|-|-|-|-|-|-|-|
|परिदृश्य|LoRA|QLoRA|PEFT|DeepSpeed|ZeRO|DORA|
|पूर्व-प्रशिक्षित LLMs को विशिष्ट कार्यों या डोमेन के लिए अनुकूलित करना|हाँ|हाँ|हाँ|हाँ|हाँ|हाँ|
|टेक्स्ट वर्गीकरण, नामित इकाई मान्यता, और मशीन अनुवाद जैसे NLP कार्यों के लिए फाइन-ट्यूनिंग|हाँ|हाँ|हाँ|हाँ|हाँ|हाँ|
|QA कार्यों के लिए फाइन-ट्यूनिंग|हाँ|हाँ|हाँ|हाँ|हाँ|हाँ|
|चैटबॉट्स में मानव-समान प्रतिक्रियाएँ उत्पन्न करने के लिए फाइन-ट्यूनिंग|हाँ|हाँ|हाँ|हाँ|हाँ|हाँ|
|संगीत, कला, या अन्य रचनात्मक रूपों के लिए फाइन-ट्यूनिंग|हाँ|हाँ|हाँ|हाँ|हाँ|हाँ|
|संगणनात्मक और वित्तीय लागत को कम करना|हाँ|हाँ|नहीं|हाँ|हाँ|नहीं|
|मेमोरी उपयोग को कम करना|नहीं|हाँ|नहीं|हाँ|हाँ|हाँ|
|कुशल फाइन-ट्यूनिंग के लिए कम पैरामीटर का उपयोग|नहीं|हाँ|हाँ|नहीं|नहीं|हाँ|
|डेटा पैरेललिज़्म का मेमोरी-कुशल रूप जो सभी GPU उपकरणों की कुल GPU मेमोरी तक पहुंच प्रदान करता है|नहीं|नहीं|नहीं|हाँ|हाँ|हाँ|

## फाइन ट्यूनिंग प्रदर्शन उदाहरण

![Finetuning Performance](../../../../translated_images/Finetuningexamples.a9a41214f8f5afc186adb16a413b1c17e2f43a89933ba95feb5aee84b0b24add.hi.png)

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ अपनी मूल भाषा में ही अधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सलाह दी जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।