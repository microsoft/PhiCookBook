<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-07-16T19:41:36+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "es"
}
-->
## Comenzando con los Modelos Phi-Family en Foundry Local

### Introducci√≥n a Foundry Local

Foundry Local es una potente soluci√≥n de inferencia de IA en el dispositivo que lleva capacidades de IA de nivel empresarial directamente a tu hardware local. Este tutorial te guiar√° en la configuraci√≥n y uso de los modelos Phi-Family con Foundry Local, ofreci√©ndote control total sobre tus cargas de trabajo de IA, manteniendo la privacidad y reduciendo costos.

Foundry Local ofrece ventajas en rendimiento, privacidad, personalizaci√≥n y costos al ejecutar modelos de IA localmente en tu dispositivo. Se integra perfectamente en tus flujos de trabajo y aplicaciones existentes a trav√©s de una CLI intuitiva, SDK y API REST.


![arch](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7d68815ddb0153503587142ff32e6997041c7cf0c9df24b49.es.png)

### ¬øPor qu√© elegir Foundry Local?

Comprender los beneficios de Foundry Local te ayudar√° a tomar decisiones informadas sobre tu estrategia de despliegue de IA:

- **Inferencia en el dispositivo:** Ejecuta modelos localmente en tu propio hardware, reduciendo costos y manteniendo todos tus datos en tu dispositivo.

- **Personalizaci√≥n de modelos:** Elige entre modelos predefinidos o usa los tuyos propios para cumplir con requisitos y casos de uso espec√≠ficos.

- **Eficiencia en costos:** Elimina costos recurrentes de servicios en la nube usando tu hardware existente, haciendo la IA m√°s accesible.

- **Integraci√≥n sin complicaciones:** Con√©ctate con tus aplicaciones mediante un SDK, puntos finales API o la CLI, con f√°cil escalabilidad a Azure AI Foundry conforme crecen tus necesidades.

> **Nota para comenzar:** Este tutorial se centra en el uso de Foundry Local a trav√©s de las interfaces CLI y SDK. Aprender√°s ambos m√©todos para ayudarte a elegir el m√°s adecuado para tu caso.

## Parte 1: Configurando Foundry Local CLI

### Paso 1: Instalaci√≥n

La CLI de Foundry Local es tu puerta de entrada para gestionar y ejecutar modelos de IA localmente. Comencemos instal√°ndola en tu sistema.

**Plataformas soportadas:** Windows y macOS

Para instrucciones detalladas de instalaci√≥n, consulta la [documentaci√≥n oficial de Foundry Local](https://github.com/microsoft/Foundry-Local/blob/main/README.md).

### Paso 2: Explorando los Modelos Disponibles

Una vez que tengas instalada la CLI de Foundry Local, puedes descubrir qu√© modelos est√°n disponibles para tu caso de uso. Este comando te mostrar√° todos los modelos soportados:


```bash
foundry model list
```

### Paso 3: Entendiendo los Modelos Phi Family

La familia Phi ofrece una variedad de modelos optimizados para diferentes casos de uso y configuraciones de hardware. Aqu√≠ est√°n los modelos Phi disponibles en Foundry Local:

**Modelos Phi disponibles:** 

- **phi-3.5-mini** - Modelo compacto para tareas b√°sicas
- **phi-3-mini-128k** - Versi√≥n con contexto extendido para conversaciones m√°s largas
- **phi-3-mini-4k** - Modelo con contexto est√°ndar para uso general
- **phi-4** - Modelo avanzado con capacidades mejoradas
- **phi-4-mini** - Versi√≥n ligera de Phi-4
- **phi-4-mini-reasoning** - Especializado en tareas de razonamiento complejo

> **Compatibilidad de hardware:** Cada modelo puede configurarse para diferentes aceleraciones de hardware (CPU, GPU) seg√∫n las capacidades de tu sistema.

### Paso 4: Ejecutando tu Primer Modelo Phi

Comencemos con un ejemplo pr√°ctico. Ejecutaremos el modelo `phi-4-mini-reasoning`, que destaca en resolver problemas complejos paso a paso.


**Comando para ejecutar el modelo:**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **Configuraci√≥n inicial:** Al ejecutar un modelo por primera vez, Foundry Local lo descargar√° autom√°ticamente en tu dispositivo local. El tiempo de descarga var√≠a seg√∫n la velocidad de tu red, as√≠ que ten paciencia durante esta configuraci√≥n inicial.

### Paso 5: Probando el Modelo con un Problema Real

Ahora probemos nuestro modelo con un cl√°sico problema de l√≥gica para ver c√≥mo realiza el razonamiento paso a paso:

**Problema de ejemplo:**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**Comportamiento esperado:** El modelo deber√≠a desglosar este problema en pasos l√≥gicos, usando el hecho de que los faisanes tienen 2 patas y los conejos 4 para resolver el sistema de ecuaciones.

**Resultados:**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d916093866d4df99190150d4198fd33ab79e586f9d6f5403089.es.png)

## Parte 2: Construyendo Aplicaciones con Foundry Local SDK

### ¬øPor qu√© usar el SDK?

Mientras que la CLI es perfecta para pruebas e interacciones r√°pidas, el SDK te permite integrar Foundry Local en tus aplicaciones de forma program√°tica. Esto abre posibilidades para:

- Construir aplicaciones personalizadas impulsadas por IA
- Crear flujos de trabajo automatizados
- Integrar capacidades de IA en sistemas existentes
- Desarrollar chatbots y herramientas interactivas

### Lenguajes de Programaci√≥n Soportados

Foundry Local ofrece soporte SDK para varios lenguajes de programaci√≥n que se adaptan a tus preferencias de desarrollo:

**üì¶ SDKs disponibles:**

- **C# (.NET):** [Documentaci√≥n y ejemplos del SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)
- **Python:** [Documentaci√≥n y ejemplos del SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **JavaScript:** [Documentaci√≥n y ejemplos del SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)
- **Rust:** [Documentaci√≥n y ejemplos del SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### Pr√≥ximos pasos

1. **Elige el SDK que prefieras** seg√∫n tu entorno de desarrollo
2. **Sigue la documentaci√≥n espec√≠fica del SDK** para gu√≠as detalladas de implementaci√≥n
3. **Comienza con ejemplos simples** antes de construir aplicaciones complejas
4. **Explora el c√≥digo de ejemplo** proporcionado en cada repositorio del SDK

## Conclusi√≥n

Ahora has aprendido a:
- ‚úÖ Instalar y configurar Foundry Local CLI
- ‚úÖ Descubrir y ejecutar modelos Phi Family
- ‚úÖ Probar modelos con problemas del mundo real
- ‚úÖ Entender las opciones de SDK para desarrollo de aplicaciones

Foundry Local ofrece una base poderosa para llevar capacidades de IA directamente a tu entorno local, d√°ndote control sobre el rendimiento, la privacidad y los costos, mientras mantienes la flexibilidad para escalar a soluciones en la nube cuando sea necesario.

**Aviso legal**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional realizada por humanos. No nos hacemos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea derivada del uso de esta traducci√≥n.