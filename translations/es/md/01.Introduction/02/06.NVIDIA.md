<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-03-27T06:46:42+00:00",
  "source_file": "md\\01.Introduction\\02\\06.NVIDIA.md",
  "language_code": "es"
}
-->
## Familia Phi en NVIDIA NIM

NVIDIA NIM es un conjunto de microservicios fáciles de usar diseñados para acelerar la implementación de modelos de IA generativa en la nube, centros de datos y estaciones de trabajo. Los NIM se categorizan por familia de modelos y por modelo individual. Por ejemplo, NVIDIA NIM para modelos de lenguaje grande (LLMs) lleva el poder de los LLMs de última generación a las aplicaciones empresariales, ofreciendo capacidades incomparables de procesamiento y comprensión del lenguaje natural.

NIM facilita que los equipos de TI y DevOps alojen modelos de lenguaje grande (LLMs) en sus propios entornos gestionados, mientras que los desarrolladores tienen acceso a APIs estándar de la industria que les permiten crear copilotos, chatbots y asistentes de IA que pueden transformar sus negocios. Aprovechando la avanzada aceleración de GPU y el despliegue escalable de NVIDIA, NIM ofrece el camino más rápido hacia la inferencia con un rendimiento excepcional.

Puedes utilizar NVIDIA NIM para inferir modelos de la Familia Phi.

![nim](../../../../../translated_images/Phi-NIM.45af94d89220fbbbc85f8da0379150a29cc88c3dd8ec417b1d3b7237bbe1c58a.es.png)

### **Ejemplos - Phi-3-Vision en NVIDIA NIM**

Imagina que tienes una imagen (`demo.png`) y quieres generar código Python que procese esta imagen y guarde una nueva versión de ella (`phi-3-vision.jpg`).

El código anterior automatiza este proceso mediante:

1. Configurar el entorno y las configuraciones necesarias.
2. Crear un prompt que instruya al modelo a generar el código Python requerido.
3. Enviar el prompt al modelo y recoger el código generado.
4. Extraer y ejecutar el código generado.
5. Mostrar las imágenes original y procesada.

Este enfoque aprovecha el poder de la IA para automatizar tareas de procesamiento de imágenes, haciendo que sea más fácil y rápido alcanzar tus objetivos.

[Solución de Código de Ejemplo](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

Desglosamos lo que hace todo el código paso a paso:

1. **Instalar Paquete Requerido**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    Este comando instala el paquete `langchain_nvidia_ai_endpoints`, asegurándose de que sea la última versión.

2. **Importar Módulos Necesarios**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    Estas importaciones traen los módulos necesarios para interactuar con los endpoints de NVIDIA AI, manejar contraseñas de manera segura, interactuar con el sistema operativo y codificar/decodificar datos en formato base64.

3. **Configurar la Clave API**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    Este código verifica si la variable de entorno `NVIDIA_API_KEY` está configurada. Si no, solicita al usuario que ingrese su clave API de forma segura.

4. **Definir Modelo y Ruta de Imagen**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    Esto establece el modelo a usar, crea una instancia de `ChatNVIDIA` con el modelo especificado y define la ruta del archivo de imagen.

5. **Crear Prompt de Texto**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    Esto define un prompt de texto que instruye al modelo a generar código Python para procesar una imagen.

6. **Codificar Imagen en Base64**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    Este código lee el archivo de imagen, lo codifica en base64 y crea una etiqueta HTML de imagen con los datos codificados.

7. **Combinar Texto e Imagen en el Prompt**:
    ```python
    prompt = f"{text} {image}"
    ```
    Esto combina el prompt de texto y la etiqueta HTML de imagen en una sola cadena.

8. **Generar Código Usando ChatNVIDIA**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    Este código envía el prompt a `ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code` string.

9. **Extraer Código Python del Contenido Generado**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    Esto extrae el código Python real del contenido generado eliminando el formato markdown.

10. **Ejecutar el Código Generado**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    Esto ejecuta el código Python extraído como un subproceso y captura su salida.

11. **Mostrar Imágenes**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    Estas líneas muestran las imágenes utilizando el módulo `IPython.display`.

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisión, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables por malentendidos o interpretaciones erróneas que puedan surgir del uso de esta traducción.