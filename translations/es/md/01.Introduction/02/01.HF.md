<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-07T10:38:55+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "es"
}
-->
# **Usando Phi Family en Hugging Face**


[Hugging Face](https://huggingface.co/) es una comunidad de IA muy popular con abundantes datos y recursos de modelos de código abierto. Diferentes fabricantes lanzan modelos LLM y SLM de código abierto a través de Hugging Face, como Microsoft, Meta, Mistral, Apple, Google, etc.

La familia Microsoft Phi ya está disponible en Hugging Face. Los desarrolladores pueden descargar el modelo correspondiente de Phi Family según los escenarios y negocios. Además de desplegar modelos Phi Pytorch en Hugging Face, también lanzamos modelos cuantificados, usando formatos GGUF y ONNX para ofrecer a los usuarios finales más opciones.


## **Descargar modelos en Hugging Face**

Puedes descargar modelos de Phi Family con este enlace

[Microsoft Models en Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Puedes descargar el modelo de diferentes formas, como instalando el ***Hugging face CLI SDK*** o usando ***git clone***.

### **Usando Hugging face CLI para descargar el modelo Phi Family**

- Instalar Hugging face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Usar huggingface-cli para iniciar sesión

Inicia sesión en Hugging face con el [User Access Token](https://huggingface.co/docs/hub/security-tokens) desde tu [página de Configuración](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Descargar 


Puedes descargar el modelo y guardarlo en caché

```bash

huggingface-cli download microsoft/phi-4

```

Puedes establecer la ubicación en una ruta personalizada


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Usando git clone para descargar el modelo Phi Family**

También puedes usar ***git clone*** para descargar el modelo

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Ejemplos - Inferencia Microsoft Phi-4**

- **Instalando la librería transformers**

```bash

pip install transformers -U

```

- **Ejecutando este código en VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisión, tenga en cuenta que las traducciones automáticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para información crítica, se recomienda la traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que puedan surgir del uso de esta traducción.