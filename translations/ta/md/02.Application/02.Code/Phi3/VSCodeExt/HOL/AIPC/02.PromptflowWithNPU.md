# **லாப் 2 - AIPC-இல் Phi-3-mini உடன் Prompt flow இயக்குதல்**

## **Prompt flow என்றால் என்ன**

Prompt flow என்பது LLM அடிப்படையிலான AI பயன்பாடுகளின் முழுமையான மேம்பாட்டு சுழற்சியை (கருத்து உருவாக்கம், மாதிரி உருவாக்கம், சோதனை, மதிப்பீடு, உற்பத்தி பயன்பாடு மற்றும் கண்காணிப்பு) எளிமைப்படுத்த வடிவமைக்கப்பட்ட மேம்பாட்டு கருவிகளின் தொகுப்பாகும். இது prompt engineering-ஐ மிகவும் எளிதாக்குகிறது மற்றும் உற்பத்தி தரத்துடன் LLM பயன்பாடுகளை உருவாக்க உதவுகிறது.

Prompt flow மூலம், நீங்கள் செய்யக்கூடியவை:

- LLMகள், prompts, Python குறியீடு மற்றும் பிற கருவிகளை இணைக்கும் flows-ஐ உருவாக்கி செயல்படுத்தக்கூடிய workflow உருவாக்குதல்.

- LLMகளுடன் தொடர்புடைய flows-ஐ எளிதாக debug மற்றும் iterate செய்யுதல்.

- உங்கள் flows-ஐ மதிப்பீடு செய்து, பெரிய தரவுத்தொகுப்புகளுடன் தரம் மற்றும் செயல்திறன் அளவுகோள்களை கணக்கிடுதல்.

- உங்கள் CI/CD அமைப்பில் சோதனை மற்றும் மதிப்பீட்டை ஒருங்கிணைத்து flow-இன் தரத்தை உறுதிப்படுத்துதல்.

- உங்கள் flows-ஐ நீங்கள் தேர்ந்தெடுத்த சேவை தளத்தில் deploy செய்யுதல் அல்லது உங்கள் பயன்பாட்டின் code base-இல் எளிதாக ஒருங்கிணைத்தல்.

- (விருப்பமானது ஆனால் மிகவும் பரிந்துரைக்கப்படுகிறது) Azure AI-இல் Prompt flow-இன் cloud பதிப்பைப் பயன்படுத்தி உங்கள் குழுவுடன் இணைந்து பணியாற்றுதல்.

## **AIPC என்றால் என்ன**

AI PC-ல் CPU, GPU மற்றும் NPU ஆகியவை உள்ளன, ஒவ்வொன்றும் குறிப்பிட்ட AI வேகப்படுத்தும் திறன்களுடன். NPU, அல்லது neural processing unit, என்பது ஒரு சிறப்பு வேகப்படுத்தி ஆகும், இது cloud-க்கு தரவுகளை அனுப்பாமல் உங்கள் PC-யில் செயற்கை நுண்ணறிவு (AI) மற்றும் இயந்திர கற்றல் (ML) பணிகளைச் செய்கிறது. GPU மற்றும் CPU கூட இந்த பணிகளை செயல்படுத்த முடியும், ஆனால் NPU குறைந்த மின்சக்தி AI கணக்கீடுகளில் சிறப்பாக செயல்படுகிறது. AI PC எங்கள் கணினிகள் செயல்படும் முறையில் அடிப்படையான மாற்றத்தை பிரதிநிதித்துவப்படுத்துகிறது. இது முன்பே இல்லாத ஒரு பிரச்சினைக்கான தீர்வாக இல்லை. மாறாக, இது தினசரி PC பயன்பாடுகளுக்கு பெரிய முன்னேற்றமாக இருக்க வாய்ப்பு உள்ளது.

அது எப்படி செயல்படுகிறது? பொதுத் தரவின் மீது பயிற்சி பெறும் பெரிய LLMகள் மற்றும் உருவாக்கும் AI-யுடன் ஒப்பிடும்போது, உங்கள் PC-யில் நடைபெறும் AI அனைத்து நிலைகளிலும் மிகவும் அணுகக்கூடியதாக இருக்கும். இந்த கருத்து எளிதாக புரிந்துகொள்ளக்கூடியது, மேலும் cloud-ஐ அணுக தேவையில்லாமல் உங்கள் தரவின் மீது பயிற்சி பெறுவதால், பலருக்கும் உடனடியாக ஈர்க்கக்கூடிய நன்மைகள் கிடைக்கின்றன.

சமீபகாலத்தில், AI PC உலகம் உங்கள் PC-யில் நேரடியாக இயங்கும் தனிப்பட்ட உதவியாளர்கள் மற்றும் சிறிய AI மாதிரிகளை உள்ளடக்கியது, உங்கள் தரவைப் பயன்படுத்தி நீங்கள் தினசரி செய்யும் செயல்பாடுகளுக்கு தனிப்பட்ட, தனியார், மேலும் பாதுகாப்பான AI மேம்பாடுகளை வழங்குகிறது – கூட்டத்தின் குறிப்புகளை எடுப்பது, ஒரு கற்பனை கால்பந்து லீக்கை அமைப்பது, புகைப்பட மற்றும் வீடியோ திருத்தத்திற்கான தானியங்க மேம்பாடுகளைச் செயல் படுத்துவது, அல்லது குடும்ப மீளச்சேர்க்கைக்கான சரியான பயண திட்டத்தை அனைவரின் வருகை மற்றும் புறப்படும் நேரங்களின் அடிப்படையில் அமைப்பது போன்றவை.

## **AIPC-இல் generation code flows உருவாக்குதல்**

***குறிப்பு*** ：நீங்கள் சூழல் நிறுவலை முடிக்கவில்லை என்றால், [Lab 0 -Installations](./01.Installations.md) ஐ பார்வையிடவும்.

1. Visual Studio Code-இல் Prompt flow Extension-ஐ திறந்து ஒரு காலியான flow project உருவாக்கவும்.

![create](../../../../../../../../../imgs/02/vscodeext/pf_create.png)

2. Inputs மற்றும் Outputs அளவுருக்களை சேர்த்து Python Code-ஐ புதிய flow ஆக சேர்க்கவும்.

![flow](../../../../../../../../../imgs/02/vscodeext/pf_flow.png)

இந்த அமைப்பை (flow.dag.yaml) பயன்படுத்தி உங்கள் flow-ஐ அமைக்கலாம்.

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. ***Chat_With_Phi3.py***-இல் குறியீட்டை சேர்க்கவும்.

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Debug அல்லது Run மூலம் flow-ஐ சோதித்து generation code சரியாக இருக்கிறதா என்பதை சரிபார்க்கலாம்.

![RUN](../../../../../../../../../imgs/02/vscodeext/pf_run.png)

5. Terminal-இல் development API ஆக flow-ஐ இயக்கவும்.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Postman / Thunder Client-இல் இதை சோதிக்கலாம்.

### **குறிப்பு**

1. முதல் இயக்கம் அதிக நேரம் எடுக்கும். Hugging face CLI-இல் இருந்து phi-3 மாதிரியை பதிவிறக்க பரிந்துரைக்கப்படுகிறது.

2. Intel NPU-வின் வரையறுக்கப்பட்ட கணினி சக்தியை கருத்தில் கொண்டு, Phi-3-mini-4k-instruct-ஐ பயன்படுத்த பரிந்துரைக்கப்படுகிறது.

3. Intel NPU Acceleration-ஐ பயன்படுத்தி INT4 மாற்றத்தை quantize செய்கிறோம், ஆனால் நீங்கள் சேவையை மீண்டும் இயக்கினால், cache மற்றும் nc_workshop கோப்புறைகளை நீக்க வேண்டும்.

## **வளங்கள்**

1. Promptflow கற்றுக்கொள்ள [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Intel NPU Acceleration கற்றுக்கொள்ள [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. மாதிரி குறியீடு, [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC) பதிவிறக்கவும்.

---

**குறிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கின்றோம், ஆனால் தானியக்க மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறான தகவல்கள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளுங்கள். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.