<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "743d7e9cb9c4e8ea642d77bee657a7fa",
  "translation_date": "2025-10-11T11:45:19+00:00",
  "source_file": "md/03.FineTuning/LetPhi3gotoIndustriy.md",
  "language_code": "ta"
}
-->
# **Phi-3 மாடலை தொழில்துறை நிபுணராக மாற்றுங்கள்**

Phi-3 மாடலை ஒரு தொழில்துறையில் கொண்டு வர, தொழில்துறை வணிக தரவுகளை Phi-3 மாடலுடன் சேர்க்க வேண்டும். இதற்கு இரண்டு விதமான விருப்பங்கள் உள்ளன: முதலில் RAG (Retrieval Augmented Generation) மற்றும் இரண்டாவது Fine Tuning.

## **RAG மற்றும் Fine-Tuning**

### **Retrieval Augmented Generation**

RAG என்பது தரவுகளை மீட்டெடுக்கும் செயல்முறை + உரை உருவாக்கம். நிறுவனத்தின் கட்டமைக்கப்பட்ட மற்றும் கட்டமைக்கப்படாத தரவுகள் வெக்டர் தரவுத்தொகுப்பில் சேமிக்கப்படும். தொடர்புடைய உள்ளடக்கத்தைத் தேடும் போது, தொடர்புடைய சுருக்கம் மற்றும் உள்ளடக்கம் கண்டறியப்பட்டு ஒரு சூழலை உருவாக்க, LLM/SLM இன் உரை நிறைவு திறனுடன் இணைக்கப்பட்டு உள்ளடக்கம் உருவாக்கப்படும்.

### **Fine-tuning**

Fine-tuning என்பது ஒரு குறிப்பிட்ட மாடலை மேம்படுத்துவதில் அடிப்படையாகும். இது மாடல் அல்காரிதமிலிருந்து தொடங்க தேவையில்லை, ஆனால் தரவுகளை தொடர்ந்து சேகரிக்க வேண்டும். தொழில்துறை பயன்பாடுகளில் மேலும் துல்லியமான சொற்களையும் மொழி வெளிப்பாடுகளையும் விரும்பினால், Fine-tuning உங்களுக்கு சிறந்த தேர்வாக இருக்கும். ஆனால் உங்கள் தரவுகள் அடிக்கடி மாறினால், Fine-tuning சிக்கலாக மாறலாம்.

### **எதை தேர்வு செய்வது**

1. எங்கள் பதில் வெளிப்புற தரவுகளை அறிமுகப்படுத்த வேண்டும் என்றால், RAG சிறந்த தேர்வாக இருக்கும்.

2. நிலையான மற்றும் துல்லியமான தொழில்துறை அறிவை வெளியிட வேண்டும் என்றால், Fine-tuning நல்ல தேர்வாக இருக்கும். RAG முக்கியமாக தொடர்புடைய உள்ளடக்கத்தை பெற முன்னுரிமை அளிக்கிறது, ஆனால் எப்போதும் நுட்பமான விவரங்களை சரியாகப் பெற முடியாது.

3. Fine-tuning க்கு உயர்தரமான தரவுத்தொகுப்பு தேவை, மேலும் இது ஒரு சிறிய அளவிலான தரவாக இருந்தால், அது பெரிய மாற்றத்தை ஏற்படுத்தாது. RAG மிகவும் நெகிழ்வானது.

4. Fine-tuning என்பது ஒரு கருப்பு பெட்டி போன்றது, ஒரு மெய்யியல், மேலும் உள்நிலை செயல்முறையைப் புரிந்துகொள்வது கடினம். ஆனால் RAG தரவின் மூலத்தை எளிதாகக் கண்டறிய உதவுகிறது, இதன் மூலம் கற்பனை அல்லது உள்ளடக்கப் பிழைகளைச் சரிசெய்து சிறந்த வெளிப்படைத்தன்மையை வழங்குகிறது.

### **சூழ்நிலைகள்**

1. செங்குத்து தொழில்துறைகள் குறிப்பிட்ட தொழில்முறை சொற்களையும் வெளிப்பாடுகளையும் தேவைப்படுத்தும் போது, ***Fine-tuning*** சிறந்த தேர்வாக இருக்கும்.

2. கேள்வி-பதில் அமைப்பு, பல்வேறு அறிவு புள்ளிகளின் ஒருங்கிணைப்பை உள்ளடக்கியது, ***RAG*** சிறந்த தேர்வாக இருக்கும்.

3. தானியங்கி வணிக ஓட்டத்தின் இணைப்பு ***RAG + Fine-tuning*** சிறந்த தேர்வாக இருக்கும்.

## **RAG ஐ எப்படி பயன்படுத்துவது**

![rag](../../../../imgs/03/intro/rag.png)

வெக்டர் தரவுத்தொகுப்பு என்பது கணித வடிவத்தில் சேமிக்கப்பட்ட தரவுகளின் தொகுப்பாகும். வெக்டர் தரவுத்தொகுப்புகள் இயந்திர கற்றல் மாடல்களுக்கு முந்தைய உள்ளீடுகளை நினைவில் கொள்ள எளிதாக்குகின்றன, தேடல், பரிந்துரை மற்றும் உரை உருவாக்கம் போன்ற பயன்பாடுகளை ஆதரிக்க இயந்திர கற்றலைப் பயன்படுத்த அனுமதிக்கின்றன. தரவின் சூழ்நிலையை கணினி மாடல்கள் புரிந்துகொள்ள அனுமதிக்க, சரியான பொருத்தங்களை விட ஒத்திசைவு அளவீடுகளின் அடிப்படையில் தரவுகளை அடையாளம் காண முடியும்.

வெக்டர் தரவுத்தொகுப்பு என்பது RAG ஐ உணருவதற்கான முக்கிய அம்சமாகும். text-embedding-3, jina-ai-embedding போன்ற வெக்டர் மாடல்களின் மூலம் தரவுகளை வெக்டர் சேமிப்பாக மாற்ற முடியும்.

RAG பயன்பாட்டை உருவாக்குவது பற்றி மேலும் அறிய [https://github.com/microsoft/Phi-3CookBook](https://github.com/microsoft/Phi-3CookBook?WT.mc_id=aiml-138114-kinfeylo) 

## **Fine-tuning ஐ எப்படி பயன்படுத்துவது**

Fine-tuning இல் பொதுவாக பயன்படுத்தப்படும் அல்காரிதம்கள் Lora மற்றும் QLora ஆகும். எதைத் தேர்வு செய்வது?
- [இந்த மாதிரி நோட்புக் மூலம் மேலும் அறிக](../../../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python FineTuning மாதிரி உதாரணம்](../../../../code/04.Finetuning/FineTrainingScript.py)

### **Lora மற்றும் QLora**

![lora](../../../../imgs/03/intro/qlora.png)

LoRA (Low-Rank Adaptation) மற்றும் QLoRA (Quantized Low-Rank Adaptation) இரண்டும் Parameter Efficient Fine Tuning (PEFT) பயன்படுத்தி பெரிய மொழி மாடல்களை (LLMs) Fine-tune செய்ய பயன்படுத்தப்படும் தொழில்நுட்பங்கள். PEFT தொழில்நுட்பங்கள் பாரம்பரிய முறைகளைவிட மாடல்களை திறமையாக பயிற்சி பெற வடிவமைக்கப்பட்டவை.  
LoRA என்பது தனித்துவமான Fine-tuning தொழில்நுட்பமாகும், இது எடை புதுப்பிப்பு மாறிலியின் குறைந்த தரவரிசை அணுகுமுறையைப் பயன்படுத்தி நினைவகப் பயன்பாட்டை குறைக்கிறது. இது வேகமான பயிற்சி நேரத்தையும், பாரம்பரிய Fine-tuning முறைகளுக்கு நெருக்கமான செயல்திறனையும் வழங்குகிறது.  

QLoRA என்பது LoRA இன் விரிவாக்கப்பட்ட பதிப்பாகும், இது நினைவக பயன்பாட்டை மேலும் குறைக்க அளவீட்டு தொழில்நுட்பங்களை உள்ளடக்கியது. QLoRA, முன் பயிற்சி பெற்ற LLM இல் எடை அளவீட்டு அளவுகளை 4-பிட் துல்லியத்திற்கு அளவீடு செய்கிறது, இது LoRA விட நினைவக திறனில் அதிக திறமையானது. இருப்பினும், கூடுதல் அளவீடு மற்றும் அளவீடு நீக்குதல் செயல்முறைகளின் காரணமாக QLoRA பயிற்சி LoRA பயிற்சியை விட சுமார் 30% மெதுவாக இருக்கும்.  

QLoRA, அளவீட்டு பிழைகளை சரிசெய்ய LoRA ஐ துணைமுறையாகப் பயன்படுத்துகிறது. QLoRA, பில்லியன் அளவிலான அளவுருக்களுடன் கூடிய பெரிய மாடல்களை ஒப்பீட்டளவில் சிறிய, எளிதில் கிடைக்கும் GPUs இல் Fine-tune செய்ய அனுமதிக்கிறது. உதாரணமாக, QLoRA ஒரு 70B அளவுரு மாடலை, 36 GPUs தேவைப்படும் நிலையில், வெறும் 2 GPUs இல் Fine-tune செய்ய முடியும்.

---

**அறிவிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் சொந்த மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்களுக்கும் அல்லது தவறான விளக்கங்களுக்கும் நாங்கள் பொறுப்பல்ல.