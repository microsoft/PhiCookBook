<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-10-11T12:15:48+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ta"
}
-->
# Phi மாடல்களுக்கான AI பாதுகாப்பு
Phi மாடல்களின் குடும்பம் [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) அடிப்படையில் உருவாக்கப்பட்டது, இது முழு நிறுவனத்திற்கான தேவைகளின் தொகுப்பாகும். இது கீழ்க்கண்ட ஆறு கொள்கைகளின் அடிப்படையில் அமைக்கப்பட்டுள்ளது: பொறுப்புத்தன்மை, வெளிப்படைத்தன்மை, நியாயம், நம்பகத்தன்மை மற்றும் பாதுகாப்பு, தனியுரிமை மற்றும் பாதுகாப்பு, மற்றும் உள்ளடக்கத்தன்மை, இவை [Microsoft’s Responsible AI principles](https://www.microsoft.com/ai/responsible-ai) ஆகும்.

முந்தைய Phi மாடல்களைப் போலவே, பல்வேறு பாதுகாப்பு மதிப்பீடு மற்றும் பாதுகாப்பு பிந்தைய பயிற்சி அணுகுமுறை பின்பற்றப்பட்டது, மேலும் இந்த வெளியீட்டின் பன்மொழி திறன்களை கருத்தில் கொண்டு கூடுதல் நடவடிக்கைகள் எடுக்கப்பட்டன. பல மொழிகள் மற்றும் அபாய வகைகள் முழுவதும் சோதனை செய்யும் பாதுகாப்பு பயிற்சி மற்றும் மதிப்பீட்டு அணுகுமுறை [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) இல் விளக்கப்பட்டுள்ளது. Phi மாடல்கள் இந்த அணுகுமுறையால் பயனடைகின்றன, ஆனால் டெவலப்பர்கள் பொறுப்பான AI சிறந்த நடைமுறைகளைப் பயன்படுத்த வேண்டும், குறிப்பாக தங்கள் தனிப்பட்ட பயன்பாட்டின் அபாயங்கள் மற்றும் கலாச்சார, மொழி சூழல்களை வரைபடம், அளவிடுதல் மற்றும் குறைக்க வேண்டும்.

## சிறந்த நடைமுறைகள்

மற்ற மாடல்களைப் போலவே, Phi மாடல்களின் குடும்பம் நியாயமற்ற, நம்பகமற்ற அல்லது ஆபத்தான முறையில் செயல்பட வாய்ப்பு உள்ளது.

SLM மற்றும் LLM மாடல்களின் சில வரையறுக்கப்பட்ட நடத்தை பற்றிய விழிப்புணர்வு முக்கியம்:

- **சேவை தரம்:** Phi மாடல்கள் முதன்மையாக ஆங்கில உரை மீது பயிற்சி பெறுகின்றன. ஆங்கிலத்தைத் தவிர்ந்த மொழிகள் குறைவான செயல்திறனை அனுபவிக்கலாம். பயிற்சித் தரவுகளில் குறைவான பிரதிநிதித்துவம் கொண்ட ஆங்கில மொழி வகைகள், அமெரிக்க ஆங்கிலத்துடன் ஒப்பிடும்போது குறைவான செயல்திறனை அனுபவிக்கலாம்.
- **தீமைகள் மற்றும் கற்பனைகளின் நிலை:** இந்த மாடல்கள் மக்கள் குழுக்களை அதிகமாக அல்லது குறைவாக பிரதிநிதித்துவம் செய்யலாம், சில குழுக்களின் பிரதிநிதித்துவத்தை அழிக்கலாம் அல்லது அவமானகரமான அல்லது எதிர்மறையான கற்பனைகளை வலுப்படுத்தலாம். பாதுகாப்பு பிந்தைய பயிற்சிக்கு பிறகும், இந்த வரையறைகள் இன்னும் இருக்கக்கூடும், இது பல்வேறு குழுக்களின் பிரதிநிதித்துவ நிலைகள் அல்லது பயிற்சித் தரவுகளில் உள்ள எதிர்மறை கற்பனைகளின் பரவலின் காரணமாக இருக்கலாம்.
- **தகுதியற்ற அல்லது ஆபத்தான உள்ளடக்கம்:** இந்த மாடல்கள் மற்ற வகையான தகுதியற்ற அல்லது ஆபத்தான உள்ளடக்கத்தை உருவாக்கக்கூடும், இது குறிப்பிட்ட பயன்பாட்டிற்கான கூடுதல் தடுப்புகளை இல்லாமல் நெகிழ்வான சூழல்களில் பயன்படுத்துவதற்கு தகுதியற்றதாக இருக்கக்கூடும்.
- **தகவல் நம்பகத்தன்மை:** மொழி மாடல்கள் அர்த்தமற்ற உள்ளடக்கத்தை உருவாக்கலாம் அல்லது நியாயமானதாக தோன்றும் ஆனால் தவறான அல்லது காலாவதியான தகவலை உருவாக்கலாம்.
- **குறுகிய கோடிங் வரம்பு:** பெரும்பாலான Phi-3 பயிற்சித் தரவுகள் Python மற்றும் "typing, math, random, collections, datetime, itertools" போன்ற பொதுவான தொகுப்புகளை அடிப்படையாகக் கொண்டவை. மாடல் Python ஸ்கிரிப்ட்களை உருவாக்கும்போது, ​​மற்ற தொகுப்புகளை அல்லது பிற மொழிகளில் ஸ்கிரிப்ட்களை பயன்படுத்தினால், அனைத்து API பயன்பாடுகளையும் கையால் சரிபார்க்க strongly பரிந்துரைக்கப்படுகிறது.

டெவலப்பர்கள் பொறுப்பான AI சிறந்த நடைமுறைகளைப் பயன்படுத்த வேண்டும் மற்றும் குறிப்பிட்ட பயன்பாடு தொடர்பான சட்டங்கள் மற்றும் விதிமுறைகளை (எ.கா. தனியுரிமை, வர்த்தகம், போன்றவை) பின்பற்றுவதை உறுதிப்படுத்த வேண்டும்.

## பொறுப்பான AI கருத்துக்கள்

மொழி மாடல்களைப் போலவே, Phi மாடல்களின் தொடர் நியாயமற்ற, நம்பகமற்ற அல்லது ஆபத்தான முறையில் செயல்பட வாய்ப்பு உள்ளது. கவனிக்க வேண்டிய சில வரையறுக்கப்பட்ட நடத்தை:

**சேவை தரம்:** Phi மாடல்கள் முதன்மையாக ஆங்கில உரை மீது பயிற்சி பெறுகின்றன. ஆங்கிலத்தைத் தவிர்ந்த மொழிகள் குறைவான செயல்திறனை அனுபவிக்கலாம். பயிற்சித் தரவுகளில் குறைவான பிரதிநிதித்துவம் கொண்ட ஆங்கில மொழி வகைகள், அமெரிக்க ஆங்கிலத்துடன் ஒப்பிடும்போது குறைவான செயல்திறனை அனுபவிக்கலாம்.

**தீமைகள் மற்றும் கற்பனைகளின் நிலை:** இந்த மாடல்கள் மக்கள் குழுக்களை அதிகமாக அல்லது குறைவாக பிரதிநிதித்துவம் செய்யலாம், சில குழுக்களின் பிரதிநிதித்துவத்தை அழிக்கலாம் அல்லது அவமானகரமான அல்லது எதிர்மறையான கற்பனைகளை வலுப்படுத்தலாம். பாதுகாப்பு பிந்தைய பயிற்சிக்கு பிறகும், இந்த வரையறைகள் இன்னும் இருக்கக்கூடும், இது பல்வேறு குழுக்களின் பிரதிநிதித்துவ நிலைகள் அல்லது பயிற்சித் தரவுகளில் உள்ள எதிர்மறை கற்பனைகளின் பரவலின் காரணமாக இருக்கலாம்.

**தகுதியற்ற அல்லது ஆபத்தான உள்ளடக்கம்:** இந்த மாடல்கள் மற்ற வகையான தகுதியற்ற அல்லது ஆபத்தான உள்ளடக்கத்தை உருவாக்கக்கூடும், இது குறிப்பிட்ட பயன்பாட்டிற்கான கூடுதல் தடுப்புகளை இல்லாமல் நெகிழ்வான சூழல்களில் பயன்படுத்துவதற்கு தகுதியற்றதாக இருக்கக்கூடும்.
**தகவல் நம்பகத்தன்மை:** மொழி மாடல்கள் அர்த்தமற்ற உள்ளடக்கத்தை உருவாக்கலாம் அல்லது நியாயமானதாக தோன்றும் ஆனால் தவறான அல்லது காலாவதியான தகவலை உருவாக்கலாம்.

**குறுகிய கோடிங் வரம்பு:** பெரும்பாலான Phi-3 பயிற்சித் தரவுகள் Python மற்றும் "typing, math, random, collections, datetime, itertools" போன்ற பொதுவான தொகுப்புகளை அடிப்படையாகக் கொண்டவை. மாடல் Python ஸ்கிரிப்ட்களை உருவாக்கும்போது, ​​மற்ற தொகுப்புகளை அல்லது பிற மொழிகளில் ஸ்கிரிப்ட்களை பயன்படுத்தினால், அனைத்து API பயன்பாடுகளையும் கையால் சரிபார்க்க strongly பரிந்துரைக்கப்படுகிறது.

டெவலப்பர்கள் பொறுப்பான AI சிறந்த நடைமுறைகளைப் பயன்படுத்த வேண்டும் மற்றும் குறிப்பிட்ட பயன்பாடு தொடர்பான சட்டங்கள் மற்றும் விதிமுறைகளை (எ.கா. தனியுரிமை, வர்த்தகம், போன்றவை) பின்பற்றுவதை உறுதிப்படுத்த வேண்டும். முக்கியமான கருத்துக்கள்:

**ஒதுக்கீடு:** மாடல்கள் சட்ட நிலை அல்லது வளங்கள் அல்லது வாழ்க்கை வாய்ப்புகளின் ஒதுக்கீடு (எ.கா. வீடு, வேலை, கடன், போன்றவை) போன்ற முக்கியமான விளைவுகளை ஏற்படுத்தக்கூடிய சூழல்களுக்கு பொருத்தமாக இருக்கக்கூடாது. இது கூடுதல் மதிப்பீடுகள் மற்றும் பாகுபாடு குறைக்கும் தொழில்நுட்பங்களை தேவைப்படுத்தும்.

**அதிக அபாய சூழல்கள்:** நியாயமற்ற, நம்பகமற்ற அல்லது ஆபத்தான வெளியீடுகள் மிகவும் செலவாகவோ அல்லது தீமையை ஏற்படுத்தக்கூடிய அதிக அபாய சூழல்களில் மாடல்களைப் பயன்படுத்துவதற்கான பொருத்தத்தை டெவலப்பர்கள் மதிப்பீடு செய்ய வேண்டும். இது துல்லியத்தன்மை மற்றும் நம்பகத்தன்மை முக்கியமானது (எ.கா. சட்ட அல்லது சுகாதார ஆலோசனை) போன்ற நிபுணத்துவ துறைகளில் ஆலோசனை வழங்குவதை உள்ளடக்குகிறது. பயன்பாட்டு சூழலுக்கு ஏற்ப பயன்பாட்டு மட்டத்தில் கூடுதல் பாதுகாப்புகளை செயல்படுத்த வேண்டும்.

**தவறான தகவல்:** மாடல்கள் தவறான தகவலை உருவாக்கக்கூடும். டெவலப்பர்கள் வெளிப்படைத்தன்மை சிறந்த நடைமுறைகளை பின்பற்ற வேண்டும் மற்றும் இறுதி பயனர்களுக்கு அவர்கள் AI அமைப்புடன் தொடர்பு கொள்ளுகிறார்கள் என்பதைத் தெரிவிக்க வேண்டும். பயன்பாட்டு மட்டத்தில், டெவலப்பர்கள் Retrieval Augmented Generation (RAG) எனப்படும் தொழில்நுட்பத்தைப் பயன்படுத்தி, பயன்பாட்டு குறிப்பிட்ட, சூழலியல் தகவல்களில் பதில்களை நிலைப்படுத்துவதற்கான கருத்து முறைமைகள் மற்றும் குழாய்களை உருவாக்கலாம்.

**தீமையான உள்ளடக்கத்தை உருவாக்குதல்:** டெவலப்பர்கள் வெளியீடுகளை மதிப்பீடு செய்ய வேண்டும் மற்றும் தங்கள் பயன்பாட்டிற்கு பொருத்தமான பாதுகாப்பு வகைப்பாட்டாளர்கள் அல்லது தனிப்பயன் தீர்வுகளைப் பயன்படுத்த வேண்டும்.

**தவறான பயன்பாடு:** மோசடி, ஸ்பாம் அல்லது மால்வேர் தயாரிப்பு போன்ற பிற தவறான பயன்பாடுகள் சாத்தியமாக இருக்கலாம், மேலும் டெவலப்பர்கள் தங்கள் பயன்பாடுகள் பொருந்தக்கூடிய சட்டங்கள் மற்றும் விதிமுறைகளை மீறாததை உறுதிப்படுத்த வேண்டும்.

### Fine-tuning மற்றும் AI உள்ளடக்க பாதுகாப்பு

ஒரு மாடலை Fine-tuning செய்த பிறகு, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) நடவடிக்கைகளைப் பயன்படுத்தி, மாடல்களால் உருவாக்கப்படும் உள்ளடக்கத்தை கண்காணிக்க, சாத்தியமான அபாயங்கள், அச்சுறுத்தல்கள் மற்றும் தரம் தொடர்பான பிரச்சினைகளை அடையாளம் காணவும் மற்றும் தடுக்கவும் பரிந்துரைக்கப்படுகிறது.

![Phi3AISafety](../../../../../imgs/01/01/01.phi3aisafety.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) உரை மற்றும் பட உள்ளடக்கத்தை ஆதரிக்கிறது. இது மேகத்தில், துண்டிக்கப்பட்ட கன்டெய்னர்களில், மற்றும் எட்ஜ்/எம்பெடெட் சாதனங்களில் பயன்படுத்தப்படலாம்.

## Azure AI Content Safety இன் மேற்பார்வை

Azure AI Content Safety ஒரு ஒரே மாதிரியான தீர்வு அல்ல; இது வணிகங்களின் குறிப்பிட்ட கொள்கைகளுக்கு ஏற்ப தனிப்பயனாக்கப்படலாம். மேலும், அதன் பன்மொழி மாடல்கள் பல மொழிகளை ஒரே நேரத்தில் புரிந்துகொள்ள உதவுகின்றன.

![AIContentSafety](../../../../../imgs/01/01/01.AIcontentsafety.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 வீடியோக்கள்**

Azure AI Content Safety சேவை பயன்பாடுகள் மற்றும் சேவைகளில் பயனர் உருவாக்கிய மற்றும் AI உருவாக்கிய தீமையான உள்ளடக்கத்தை கண்டறிகிறது. இது தீமையான அல்லது தகுதியற்ற பொருட்களை கண்டறிய உரை மற்றும் பட APIகளை உள்ளடக்கியது.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

**அறிவிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சித்தாலும், தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது துல்லியக்குறைபாடுகள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் சொந்த மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்களுக்கும் அல்லது தவறான விளக்கங்களுக்கும் நாங்கள் பொறுப்பல்ல.