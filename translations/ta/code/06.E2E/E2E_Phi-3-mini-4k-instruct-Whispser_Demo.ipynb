{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## தொடர்பு செய்யக்கூடிய Phi 3 Mini 4K Instruct Chatbot with Whisper\n",
    "\n",
    "### அறிமுகம்:\n",
    "தொடர்பு செய்யக்கூடிய Phi 3 Mini 4K Instruct Chatbot என்பது பயனர்களுக்கு உரை அல்லது ஒலி உள்ளீடு மூலம் Microsoft Phi 3 Mini 4K instruct demo உடன் தொடர்பு கொள்ள அனுமதிக்கும் ஒரு கருவியாகும். இந்த சாட்போட்டை மொழிபெயர்ப்பு, காலநிலை தகவல்கள், மற்றும் பொது தகவல் சேகரிப்பு போன்ற பல்வேறு பணிகளுக்கு பயன்படுத்தலாம்.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "[உங்கள் Huggingface அணுகல் டோக்கனை உருவாக்கவும்](https://huggingface.co/settings/tokens)\n",
    "\n",
    "புதிய டோக்கனை உருவாக்கவும் \n",
    "புதிய பெயரை வழங்கவும் \n",
    "எழுதும் அனுமதிகளை தேர்வு செய்யவும்\n",
    "டோக்கனை நகலெடுத்து பாதுகாப்பான இடத்தில் சேமிக்கவும்\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "பின்வரும் Python குறியீடு இரண்டு முக்கிய பணிகளை செய்வதற்காக உள்ளது: `os` மாடியூலை இறக்குமதி செய்தல் மற்றும் ஒரு சுற்றுச்சூழல் மாறியை அமைத்தல்.\n",
    "\n",
    "1. Importing the `os` module:\n",
    "   - Python இல் உள்ள `os` மாடியூல் இயக்க முறைமையுடன் தொடர்பு கொள்ள ஒரு வழியை வழங்குகிறது. இது சுற்றுச்சூழல் மாறிகளை அணுகுதல், கோப்புகள் மற்றும் அடைவுகள் உடைய பணிகள் போன்ற பல இயக்க முறைமை சார்ந்த பணிகளை செய்ய அனுமதிக்கிறது.\n",
    "   - இந்த குறியீட்டில், `os` மாடியூல் `import` பிரகடனத்தைப் பயன்படுத்தி இறக்குமதி செய்யப்படுகிறது. இந்த பிரகடனம் `os` மாடியூலின் செயல்பாடுகளை தற்போதைய Python ஸ்கிரிப்டில் பயன்படுத்தக்கூடியதாகக் செய்கிறது.\n",
    "\n",
    "2. Setting an environment variable:\n",
    "   - ஒரு சுற்றுச்சூழல் மாறி என்பது இயக்க முறைமையில் இயங்கும் நிரல்களால் அணுகக்கூடிய ஒரு மதிப்பாகும். இது பல நிரல்களால் பயன்படுத்தக்கூடிய கட்டமைப்பு அமைப்புகள் அல்லது பிற தகவல்களை சேமிப்பதற்கான ஒரு வழியாகும்.\n",
    "   - இந்த குறியீட்டில், புதிய ஒரு சுற்றுச்சூழல் மாறி `os.environ` அகராதியைப் பயன்படுத்தி அமைக்கப்படுகிறது. அ அகராதியின் விசை `'HF_TOKEN'` ஆகும், மற்றும் அதன் மதிப்பு `HUGGINGFACE_TOKEN` மாறியிலிருந்து ஒதுக்கப்படுகிறது.\n",
    "   - `HUGGINGFACE_TOKEN` மாறி இந்த குறியீட்டு துணுக்குக்கு justo மேலே வரையறுக்கப்பட்டுள்ளது, மற்றும் அது `#@param` சொற்றொடரைப் பயன்படுத்தி `\"hf_**************\"` என்ற ஸ்ட்ரிங் மதிப்பாக ஒதுக்கப்பட்டுள்ளது. இந்த `#@param` சொற்றொடர் Jupyter நோட்புக்குகளில் பயனர் உள்ளீடு மற்றும் பராமேட்டர் கட்டமைப்பை நேரடியாக நோட்புக் இடைமுகத்தில் அனுமதிக்க பயன்படுத்தப்படுகிறது.\n",
    "   - `'HF_TOKEN'` சுற்றுச்சூழல் மாறியை அமைப்பதன் மூலம், அது நிரலின் பிற பகுதிகள் அல்லது அதே இயக்க முறைமையில் இயங்கும் பிற நிரல்களின் மூலம் அணுகப்படக்கூடியதாக இருக்கும்.\n",
    "\n",
    "Overall, this code imports the `os` module and sets an environment variable named `'HF_TOKEN'` with the value provided in the `HUGGINGFACE_TOKEN` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "இந்தக் குறியீட்டு துண்டு clear_output என்ற ஒரு செயல்பாட்டை வரையறுக்குகிறது, இது Jupyter Notebook அல்லது IPython இல் தற்போதைய செல்லின் வெளியீட்டை நீக்க பயன்படுத்தப்படுகிறது. கோடத்தை உடைத்து அதன் செயல்பாட்டை புரிந்துகொள்வோம்:\n",
    "\n",
    "clear_output செயல்பாடு wait எனப்படும் ஒரு அளவுருவை (parameter) பெறுகிறது, இது ஒரு boolean மதிப்பு. இயல்பாக, wait False ஆக அமைக்கப்பட்டுள்ளது. இந்த அளவுரு செயல்பாடு தற்போதைய வெளியீட்டை அழிப்பதற்கு முன்னர் அதை மாற்ற புதிய வெளியீடு கிடைக்கும் வரை காத்திருக்க வேண்டுமா என்பதை தீர்மானிக்கிறது.\n",
    "\n",
    "இந்த செயல்பாடு தான் தற்போதைய செல்லின் வெளியீட்டை அழிக்க பயன்படுத்தப்படுகிறது. Jupyter Notebook அல்லது IPython இல், ஒரு செல்லு பிரிண்ட் செய்த உரை அல்லது வரைபடங்கள் போன்ற வெளியீடை உருவாக்கும் போது, அந்த வெளியீடு செல்லின் கீழ் காண்பிக்கப்படும். clear_output செயல்பாடு அந்த வெளியீட்டை நீக்க உதவுகிறது.\n",
    "\n",
    "செயல்பாட்டின் அமல்படுத்தல் இந்த குறியீட்டு துண்டில் கொடுக்கப்படவில்லை, அதைப் (...) குறிப்பிடுகிறது. (...) என்பது வெளியீட்டை நீக்கும் செயலுக்கான உண்மையான குறியீட்டிற்கு ஒரு இடமாற்று (placeholder) என்பதை குறிக்கிறது. செயல்பாட்டின் அமல்படுத்தல் செல்லில் இருந்து உள்ளுள்ள வெளியீட்டை நீக்க Jupyter Notebook அல்லது IPython API உடன் தொடர்பு கொள்வதை உள்ளடக்கலாம்.\n",
    "\n",
    "மொத்தத்தில், இந்த செயல்பாடு Jupyter Notebook அல்லது IPython இல் தற்போதைய செல்லின் வெளியீட்டை அழிக்க ஒரு வசதியான வழியை வழங்குகிறது, இதனால் இடைமுகமான (interactive) நிரலாக்க அமர்வுகளில் காண்பிக்கப்பட்ட வெளியீட்டை நிர்வகிப்பதும் புதுப்பிப்பதும் எளிதாகிறது.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge TTS சேவையைப் பயன்படுத்தி உரையைக் குரலாக்க (TTS) செயற்படுத்தவும். சம்பந்தப்பட்ட செயல்பாடுகள் ஒன்றுக்கொன்று பார்க்கலாம்:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: இந்த செயல்பாடு ஒரு உள்ளீட்டு மதிப்பை எடுத்துக் கொண்டு TTS குரலுக்கு rate string ஐ கணக்கிடும். உள்ளீட்டு மதிப்பு பேச்சின் விரைவைக் குறிப்பதாகும், இதில் 1 என்பது சாதாரண வேகம். செயல்பாடு rate string ஐ கணக்கிடுவதற்காக உள்ளீட்டு மதிப்பில் இருந்து 1 ஐ கழித்து, அதை 100 மூலம் பெருக்கி, பின்னர் உள்ளீட்டு மதிப்பு 1 க்கு சமம் அல்லது அதற்கு மேல் என்ற அடிப்படையில் சின்னத்தை (sign) நிர்ணயிக்கின்றது. செயல்பாடு \"{sign}{rate}\" என்ற வடிவில் rate string ஐ திரும்ப அளிக்கின்றது.\n",
    "\n",
    "2.`make_chunks(input_text, language)`: இந்த செயல்பாடு ஒரு உள்ளீட்டு உரையையும் ஒரு மொழியையும் அளவுருக்களாக ஏற்றுக் கொள்கிறது. இது மொழி-சார்ந்த சட்டங்களின் அடிப்படையில் உள்ளீட்டு உரையை துண்டுகளாகப் பிரிக்கும். இந்த импிளிமென்டேஷனில், மொழி \"English\" என்றால், செயல்பாடு உரையை ஒவ்வொரு பீரியடிலும் (\".\") பிரித்து முனைய மற்றும் பின்னைய வெற்றிடங்களை நீக்குகிறது. பின்னர் ஒவ்வொரு துண்டுக்கும் ஒரு பீரியட் சேர்த்து வடிகட்டப்பட்ட துண்டுகளின் பட்டியலைத் திரும்ப அளிக்கிறது.\n",
    "\n",
    "3. `tts_file_name(text)`: இந்த செயல்பாடு TTS ஒலி கோப்பிற்கான கோப்பு பெயரை உள்ளீட்டு உரையின் அடிப்படையில் உருவாக்குகிறது. இது உரையில் பல மாற்றங்களைச் செய்கிறது: முடிவில் இருக்கும் பீரியடை (இருப்பின்) நீக்குதல், உரையை சிற்றெழுத்தாக மாற்றுதல், முனைய மற்றும் பின்னைய வெற்றிடங்களை அகற்றுதல், மற்றும் வெற்றிடங்களை underscores (_) மூலம் மாற்றுதல். பின்னர் உரையை அதிகபட்சம் 25 எழுத்துகளாக குறைத்தல் (நீளமானால்) அல்லது அது காலியானால் முழு உரையைப் பயன்படுத்துதல் நடைபெறுகிறது. கடைசியாக, இது [`uuid`] மொட்யூலைப் பயன்படுத்தி ஒரு சீரற்ற சரத்தை உருவாக்கி அதனை குறிக்கப்பட்ட உரையுடன் இணைத்து கோப்பு பெயரை \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\" என்ற வடிவில் உருவாக்குகிறது.\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: இந்த செயல்பாடு பல ஒலி கோப்புகளை ஒரே ஒலி கோப்பாக ஒன்றிணைக்கிறது. இது ஒலி கோப்பு பாதைகளின் பட்டியலை மற்றும் ஒரு output path ஐ அளவுருக்களாகக் கொள்கிறது. செயல்பாடு ஒரு காலியாக இருக்கும் `AudioSegment` பொருளை [`merged_audio`] என்ற பெயரில் ஆரம்பிக்கிறது. பின்னர் அது ஒவ்வொரு ஒலி கோப்பு பாதையிலும் வழியே சென்று, `pydub` நூலகத்தின் `AudioSegment.from_file()` முறையைப் பயன்படுத்தி ஒலி கோப்பைப் பதிவேற்றுகிறது மற்றும் தற்போதைய ஒலியை [`merged_audio`] இல் இணைக்கிறது. கடைசியாக, ஒன்றிணைக்கப்பட்ட ஒலியை குறிப்பிடப்பட்ட output path இல் MP3 வடிவில் ஏற்றுகிறது.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path): This function performs the TTS operation using the Edge TTS service. It takes a list of text chunks, the speed of the speech, the voice name, and the save path as parameters. If the number of chunks is greater than 1, the function creates a directory for storing the individual chunk audio files. It then iterates through each chunk, constructs an Edge TTS command using the `calculate_rate_string()' function, the voice name, and the chunk text, and executes the command using the `os.system()` function. If the command execution is successful, it appends the path of the generated audio file to a list. After processing all the chunks, it merges the individual audio files using the `merge_audio_files()` function and saves the merged audio to the specified save path. If there is only one chunk, it directly generates the Edge TTS command and saves the audio to the save path. Finally, it returns the save path of the generated audio file.\n",
    "\n",
    "6. `random_audio_name_generate()`: இந்த செயல்பாடு [`uuid`] மொட்யூலைப் பயன்படுத்தி ஒரு சீரற்ற ஒலி கோப்பு பெயரை உருவாக்குகிறது. இது ஒரு சீரற்ற UUID ஐ உருவாக்கி அதை string ஆக மாற்றி முதல் 8 எழுத்துகளை எடுத்து, \".mp3\" நீட்டிப்பைச் சேர்த்து அந்த சீரற்ற ஒலி கோப்பு பெயரைத் திரும்ப அளிக்கிறது.\n",
    "\n",
    "7. `talk(input_text)`: இந்த செயல்பாடு TTS செயல்பாட்டை நடாத்துவதற்கான முதன்மை நுழைவு புள்ளி ஆகும். இது ஒரு உள்ளீட்டு உரையை அளவுருவாகக் கொள்கிறது. முதலில், அது உள்ளீட்டு உரையின் நீளத்தை சோதித்து அது நீண்ட வாக்கியம் (600 எழுத்துகளுக்கு சமம் அல்லது அதற்கு மேல்) என உள்ளதா என்பதை தீர்மானிக்கிறது. நீளம் மற்றும் `translate_text_flag` மாறியின் மதிப்பின் அடிப்படையில், அது மொழியை தீர்மானித்து `make_chunks()` செயல்பாட்டைப் பயன்படுத்தி உரை துண்டுகளின் பட்டியலை உருவாக்கும். பின்னர் அது ஒலி கோப்புக்கான சேமிப்பு பாதையை `random_audio_name_generate()` மூலம் உருவாக்கும். கடைசியாக, அது `edge_free_tts()` ஐ அழைத்து TTS செயல்பாட்டை நடைமுறைப்படுத்தி உருவான ஒலி கோப்பின் சேமிப்பு பாதையை திரும்ப அளிக்கிறது.\n",
    "\n",
    "மொத்தமாக, இந்த செயல்பாடுகள் இணைந்து உள்ளீட்டு உரையை துண்டுகளாகப் பிரித்து, ஒலி கோப்பிற்கான கோப்பு பெயரை உருவாக்கி, Edge TTS சேவையைப் பயன்படுத்தி TTS செயல்பாட்டைச் செய்து, தனித்துண்டு ஒலி கோப்புகளை ஒரே ஒலி கோப்பாக இணைக்கின்றன.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "இரு செயல்பாடுகள் convert_to_text மற்றும் run_text_prompt இன் செயலாக்கமும், மற்றும் இரண்டு வகுப்புகள் str மற்றும் Audio இன் அறிவிப்பும்.\n",
    "\n",
    "convert_to_text செயல்பாடு audio_path-ஐ உள்ளீடாக பெற்று, whisper_model என்ற மாடலை பயன்படுத்தி ஆடியோவை உரையாக மாற்றுகிறது. செயல்பாடு முதலில் gpu கொெடியின் மதிப்பு True ஆக அமைக்கப்பட்டிருக்கிறதா என சரிபார்க்கிறது. அது இருந்தால், whisper_model word_timestamps=True, fp16=True, language='English', மற்றும் task='translate' போன்ற குறிப்புகள் கொண்டு பயன்படுத்தப்படுகிறது. gpu கொெடியின் மதிப்பு False என்றால், whisper_model fp16=False உடன் பயன்படுத்தப்படுகிறது. பெறப்பட்ட உரைப்படை 'scan.txt' என்ற கோப்பாக சேமித்து உரையாக திருப்பி வழங்கப்படுகின்றது.\n",
    "\n",
    "run_text_prompt செயல்பாடு message மற்றும் chat_history-ஐ உள்ளீடாக எடுக்கிறது. இது phi_demo செயல்பாட்டை பயன்படுத்தி உள்ளீடு message அடிப்படையில் ஒரு chatbot பதிலை உருவாக்குகிறது. உருவாக்கப்பட்ட பதில் பின்னர் talk செயல்பாட்டிற்கு கடத்தப்படுகின்றது, அது பதிலை ஒரு ஆடியோ கோப்பாக மாற்றி அதின் கோப்பு பாதையை திருப்பி வழங்குகிறது. Audio வகுப்பு அந்த ஆடியோ கோப்பை காட்சி படுத்தவும் மற்றும் வாசிக்கவும் பயன்படுகிறது. ஆடியோ IPython.display மொட்யூலில் உள்ள display செயல்பாட்டைப் பயன்படுத்தி காட்சி படுத்தப்படுகிறது, மற்றும் Audio பொருள் autoplay=True என்ற பரிமாணத்துடன் உருவாக்கப்படுகிறது, அதனால் ஆடியோ தானாகவே பாட தொடங்குகிறது. chat_history உள்ளீட்டு message மற்றும் உருவாக்கப்பட்ட பதிலுடன் புதுப்பிக்கப்படுகிறது, மற்றும் ஒரு வெற்று string மற்றும் புதுப்பிக்கப்பட்ட chat_history திருப்பி வழங்கப்படுகின்றன.\n",
    "\n",
    "str வகுப்பு Python-இல் உருவ்படுத்தப்பட்ட (built-in) வகுப்பாகும், இது எழுத்துகளின் தொடரை பிரதிநிதித்துவப்படுத்துகிறது. இது எழுத்துத்தொடர்களை மாற்றுதல் மற்றும் கையாள்வதற்கான பல்வேறு மெத்தடுகளை வழங்குகிறது, உதாரணமாக capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill, மற்றும் பல. இம்மெத்தடுகள் மூலம் தேடுதல், மாற்றுதல், வடிவமைத்தல் மற்றும் எழுத்துத்தொடர்களை கையாளுதல் போன்ற செயல்பாடுகளை செய்ய முடியும்.\n",
    "\n",
    "Audio வகுப்பு ஒரு தனிப்பயன் வகுப்பாகும், இது ஒரு ஆடியோ பொருளை பிரதிநிதித்துவப்படுத்துகிறது. இது Jupyter Notebook சூழலில் ஒரு ஆடியோ பிளேயரை உருவாக்க பயன்படுத்தப்படுகிறது. வகுப்பு data, filename, url, embed, rate, autoplay, மற்றும் normalize போன்ற பல்வேறு அளவுருக்களை ஏற்கிறது. data அளவுரு ஒரு numpy array, மாதிரிகளின் பட்டியல், filename அல்லது URL-ஐ பிரதிநிதித்துவப்படுத்தும் ஒரு string, அல்லது raw PCM தரவாக இருக்கலாம். filename அளவுரு உள்ளூர் கோப்பில் இருந்து ஆடியோ தரவை ஏற்ற குறிப்பிட பயன்படுத்தப்படுகிறது, மற்றும் url அளவுரு ஆடியோ தரவை பதிவிறக்கம் செய்ய ஒரு URL-ஐ குறிப்பிட பயன்படுகிறது. embed அளவுரு audio தரவை data URI-யைப் பயன்படுத்தி ஒட்ட வேண்டுமா அல்லது கொதிய மூலத்திலிருந்து குறிப்பிட்டு பயன்படுத்த வேண்டுமா என்பதைக் குறிக்கிறது. rate அளவுரு ஆடியோ தரவின் sampling rate-ஐ குறிப்பிடுகிறது. autoplay அளவுரு ஆடியோ தானாகவே துவங்க வேண்டுமா என்பதை தீர்மானிக்கிறது. normalize அளவுரு ஆடியோ தரவை அதிகபட்சமான இயல 가능한 வரம்பிற்கு மீள்மவுச்செய்ய (rescale) வேண்டுமா என்பதை குறிப்பிடுகிறது. Audio வகுப்பு reload போன்ற மீண்டும் ஏற்றும் மெத்தட்களை வழங்குவதுடன், src_attr, autoplay_attr, மற்றும் element_id_attr போன்ற பண்புருக்கள் HTML இல் ஆடியோ எலெமென்டுக்கான தொடர்புடைய பண்புகளை பெற உதவுகின்றன.\n",
    "\n",
    "மொத்தமாக, இவற்றைப் போன்ற செயல்பாடுகள் மற்றும் வகுப்புகள் ஆடியோவை உரையாக மாற்ற, chatbot-இலிருந்து ஆடியோப் பதில்களை உருவாக்க, மற்றும் Jupyter Notebook சூழலில் ஆடியோவை காட்சி படுத்தி வாசிக்க பயன்படுத்தப்படுகின்றன.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\nமறுப்பு:\nஇந்த ஆவணம் AI மொழிபெயர்ப்பு சேவையான Co-op Translator (https://github.com/Azure/co-op-translator) மூலம் மொழிபெயர்க்கப்பட்டது. நாங்கள் துல்லியத்திற்காக முயற்சித்தாலும், தானாக செய்யப்பட்ட மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனியுங்கள். மூல ஆவணத்தை அதன் தாய்மொழியில் அதிகாரபூர்வ ஆதாரமாக கருதவேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனுஷ்ய பெயர்ப்பை (human translation) பரிந்துரைக்கப்படுகிறோம். இந்த மொழிபெயர்ப்பின் பயன்பாட்டினால் ஏற்படும் எந்தவொரு தவறான புரிதல்களுக்கோ அல்லது தவறான விளக்கங்களுக்கோ நாங்கள் பொறுப்பேற்கமாட்டோம்.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-12-22T04:55:36+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "ta"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}