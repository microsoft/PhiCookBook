<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d658062de70b131ef4c0bff69b5fc70e",
  "translation_date": "2025-07-16T21:44:24+00:00",
  "source_file": "md/01.Introduction/04/QuantifyingPhi.md",
  "language_code": "mr"
}
-->
# **Phi कुटुंबाचे प्रमाणितीकरण**

मॉडेल प्रमाणितीकरण म्हणजे न्यूरल नेटवर्क मॉडेलमधील पॅरामीटर्स (जसे की वजन आणि सक्रियता मूल्ये) मोठ्या मूल्य श्रेणीतून (सामान्यतः सलग मूल्य श्रेणी) लहान निश्चित मूल्य श्रेणीमध्ये रूपांतरित करण्याची प्रक्रिया. ही तंत्रज्ञान मॉडेलचा आकार आणि गणनात्मक गुंतागुंत कमी करू शकते आणि मोबाइल उपकरणे किंवा एम्बेडेड सिस्टमसारख्या संसाधन-सीमित वातावरणात मॉडेलची कार्यक्षमता सुधारू शकते. मॉडेल प्रमाणितीकरण पॅरामीटर्सची अचूकता कमी करून संकुचन साध्य करते, पण त्याचबरोबर काही प्रमाणात अचूकतेचा तोटा देखील होतो. त्यामुळे प्रमाणितीकरण प्रक्रियेत मॉडेलचा आकार, गणनात्मक गुंतागुंत आणि अचूकता यांचा समतोल राखणे आवश्यक असते. सामान्य प्रमाणितीकरण पद्धतींमध्ये फिक्स्ड-पॉइंट प्रमाणितीकरण, फ्लोटिंग-पॉइंट प्रमाणितीकरण इत्यादींचा समावेश होतो. तुम्ही विशिष्ट परिस्थिती आणि गरजेनुसार योग्य प्रमाणितीकरण धोरण निवडू शकता.

आम्हाला GenAI मॉडेल एज डिव्हाइसेसवर तैनात करायचे आहे आणि अधिक उपकरणांना GenAI परिस्थितीत आणायचे आहे, जसे की मोबाइल उपकरणे, AI PC/Copilot+PC, आणि पारंपरिक IoT उपकरणे. प्रमाणितीकरण मॉडेलच्या माध्यमातून, आम्ही वेगवेगळ्या उपकरणांवर आधारित वेगवेगळ्या एज डिव्हाइसेसवर तैनात करू शकतो. हार्डवेअर उत्पादकांनी दिलेल्या मॉडेल वेगवान फ्रेमवर्क आणि प्रमाणितीकरण मॉडेलसह, आम्ही चांगल्या SLM अनुप्रयोग परिस्थिती तयार करू शकतो.

प्रमाणितीकरण परिस्थितीत, आमच्याकडे वेगवेगळ्या अचूकता पातळ्या (INT4, INT8, FP16, FP32) आहेत. खाली सामान्यतः वापरल्या जाणाऱ्या प्रमाणितीकरण अचूकता पातळ्यांचे स्पष्टीकरण दिले आहे.

### **INT4**

INT4 प्रमाणितीकरण ही एक अत्यंत कडक प्रमाणितीकरण पद्धत आहे जी मॉडेलच्या वजन आणि सक्रियता मूल्यांना 4-बिट पूर्णांकांमध्ये रूपांतरित करते. INT4 प्रमाणितीकरणामुळे कमी प्रतिनिधित्व श्रेणी आणि कमी अचूकतेमुळे अचूकतेचा मोठा तोटा होऊ शकतो. मात्र, INT8 प्रमाणितीकरणाच्या तुलनेत, INT4 प्रमाणितीकरण मॉडेलच्या संचयन गरजा आणि गणनात्मक गुंतागुंत आणखी कमी करू शकते. लक्षात घ्या की, व्यावहारिक वापरात INT4 प्रमाणितीकरण तुलनेने कमी वापरले जाते, कारण खूप कमी अचूकता मॉडेलच्या कार्यक्षमतेत लक्षणीय घट करू शकते. शिवाय, सर्व हार्डवेअर INT4 ऑपरेशन्सना समर्थन देत नाही, त्यामुळे प्रमाणितीकरण पद्धत निवडताना हार्डवेअर सुसंगतता विचारात घ्यावी लागते.

### **INT8**

INT8 प्रमाणितीकरण म्हणजे मॉडेलच्या वजन आणि सक्रियता फ्लोटिंग पॉइंट संख्यांमधून 8-बिट पूर्णांकांमध्ये रूपांतरित करण्याची प्रक्रिया. INT8 पूर्णांकांनी दर्शवलेली संख्यात्मक श्रेणी कमी आणि कमी अचूक असली तरी, हे संचयन आणि गणना गरजा लक्षणीयरीत्या कमी करू शकते. INT8 प्रमाणितीकरणात, मॉडेलच्या वजन आणि सक्रियता मूल्यांवर प्रमाणितीकरण प्रक्रिया केली जाते, ज्यात स्केलिंग आणि ऑफसेटचा समावेश असतो, ज्यामुळे मूळ फ्लोटिंग पॉइंट माहिती शक्य तितकी जपली जाते. अनुमान करताना, हे प्रमाणित मूल्य पुन्हा फ्लोटिंग पॉइंट संख्यांमध्ये रूपांतरित केले जाते आणि नंतर पुढील टप्प्यासाठी पुन्हा INT8 मध्ये रूपांतरित केले जाते. ही पद्धत बहुतेक अनुप्रयोगांमध्ये पुरेशी अचूकता देऊ शकते आणि उच्च गणनात्मक कार्यक्षमता राखते.

### **FP16**

FP16 फॉरमॅट म्हणजे 16-बिट फ्लोटिंग पॉइंट संख्या (float16), जी 32-बिट फ्लोटिंग पॉइंट संख्या (float32) च्या तुलनेत स्मृती वापर अर्धा करते, ज्यामुळे मोठ्या प्रमाणात डीप लर्निंग अनुप्रयोगांमध्ये महत्त्वाचे फायदे होतात. FP16 फॉरमॅटमुळे समान GPU स्मृती मर्यादेत मोठे मॉडेल लोड करणे किंवा अधिक डेटा प्रक्रिया करणे शक्य होते. आधुनिक GPU हार्डवेअर FP16 ऑपरेशन्सना समर्थन देत असल्यामुळे, FP16 फॉरमॅट वापरल्यास गणनात्मक गतीतही सुधारणा होऊ शकते. मात्र, FP16 फॉरमॅटची inherent कमतरता म्हणजे कमी अचूकता, ज्यामुळे काही वेळा संख्यात्मक अस्थिरता किंवा अचूकतेचा तोटा होऊ शकतो.

### **FP32**

FP32 फॉरमॅट उच्च अचूकता प्रदान करतो आणि विस्तृत मूल्य श्रेणी अचूकपणे दर्शवू शकतो. ज्या परिस्थितीत जटिल गणितीय ऑपरेशन्स कराव्या लागतात किंवा उच्च अचूकतेचे निकाल आवश्यक असतात, तिथे FP32 फॉरमॅट प्राधान्याने वापरला जातो. मात्र, उच्च अचूकता म्हणजे अधिक स्मृती वापर आणि जास्त गणना वेळ. मोठ्या प्रमाणात डीप लर्निंग मॉडेल्ससाठी, विशेषतः जेथे बरेच मॉडेल पॅरामीटर्स आणि प्रचंड डेटा असतो, FP32 फॉरमॅटमुळे GPU स्मृती अपुरी पडू शकते किंवा अनुमान गती कमी होऊ शकते.

मोबाइल उपकरणे किंवा IoT उपकरणांवर, आम्ही Phi-3.x मॉडेल्सना INT4 मध्ये रूपांतरित करू शकतो, तर AI PC / Copilot PC वर उच्च अचूकता जसे की INT8, FP16, FP32 वापरू शकतो.

सध्या, वेगवेगळ्या हार्डवेअर उत्पादकांकडे जनरेटिव्ह मॉडेल्सना समर्थन देण्यासाठी वेगवेगळे फ्रेमवर्क आहेत, जसे Intel चे OpenVINO, Qualcomm चे QNN, Apple चे MLX, आणि Nvidia चे CUDA, इत्यादी, जे मॉडेल प्रमाणितीकरणासह स्थानिक तैनाती पूर्ण करतात.

तंत्रज्ञानाच्या दृष्टीने, प्रमाणितीकरणानंतर आमच्याकडे वेगवेगळ्या फॉरमॅट समर्थन आहे, जसे PyTorch / Tensorflow फॉरमॅट, GGUF, आणि ONNX. मी GGUF आणि ONNX यांच्यात फॉरमॅट तुलना आणि अनुप्रयोग परिस्थिती केली आहे. येथे मी ONNX प्रमाणितीकरण फॉरमॅटची शिफारस करतो, ज्याला मॉडेल फ्रेमवर्कपासून हार्डवेअरपर्यंत चांगले समर्थन आहे. या प्रकरणात, आम्ही GenAI साठी ONNX Runtime, OpenVINO, आणि Apple MLX वापरून मॉडेल प्रमाणितीकरणावर लक्ष केंद्रित करू (जर तुमच्याकडे चांगला मार्ग असेल तर तुम्ही PR सबमिट करून आम्हाला देऊ शकता).

**या प्रकरणात समाविष्ट आहे**

1. [llama.cpp वापरून Phi-3.5 / 4 चे प्रमाणितीकरण](./UsingLlamacppQuantifyingPhi.md)

2. [onnxruntime साठी Generative AI विस्तार वापरून Phi-3.5 / 4 चे प्रमाणितीकरण](./UsingORTGenAIQuantifyingPhi.md)

3. [Intel OpenVINO वापरून Phi-3.5 / 4 चे प्रमाणितीकरण](./UsingIntelOpenVINOQuantifyingPhi.md)

4. [Apple MLX Framework वापरून Phi-3.5 / 4 चे प्रमाणितीकरण](./UsingAppleMLXQuantifyingPhi.md)

**अस्वीकरण**:  
हा दस्तऐवज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून अनुवादित केला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये चुका किंवा अचूकतेची कमतरता असू शकते. मूळ दस्तऐवज त्याच्या स्थानिक भाषेत अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी अनुवाद करण्याची शिफारस केली जाते. या अनुवादाच्या वापरामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थलागी आम्ही जबाबदार नाही.