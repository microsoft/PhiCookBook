<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T16:46:27+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "mr"
}
-->
# Phi मॉडेलसाठी AI सुरक्षितता
Phi मॉडेल कुटुंबाची निर्मिती [Microsoft Responsible AI Standard](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard) नुसार केली गेली होती, जो एक कंपनी-व्यापी सेट आहे ज्यामध्ये खालील सहा तत्त्वे समाविष्ट आहेत: जबाबदारी, पारदर्शकता, न्याय, विश्वासार्हता आणि सुरक्षितता, गोपनीयता आणि सुरक्षा, आणि सर्वसमावेशकता, जे [Microsoft चे Responsible AI तत्त्वे](https://www.microsoft.com/ai/responsible-ai) बनवतात.

पूर्वीच्या Phi मॉडेल्सप्रमाणेच, एक बहुआयामी सुरक्षितता मूल्यमापन आणि सुरक्षितता प्रशिक्षणानंतरची पद्धत स्वीकारली गेली होती, तसेच या आवृत्तीत बहुभाषिक क्षमतांचा विचार घेण्यासाठी अतिरिक्त उपाययोजना केल्या गेल्या. बहुभाषिक आणि धोका वर्गांमध्ये चाचणीसहित आमच्या सुरक्षितता प्रशिक्षण आणि मूल्यमापनाच्या पद्धतींचे विवरण [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) मध्ये आहे. जर आपण Phi मॉडेल्सचा फायदा घेत असाल, तर विकासकांनी त्यांच्या विशिष्ट वापर घटक आणि सांस्कृतिक व भाषिक संदर्भानुसार संबधित धोके मोजणे, नकाशा तयार करणे आणि कमी करण्यासाठी जबाबदार AI सर्वोत्तम पद्धती वापराव्यात.

## सर्वोत्तम पद्धती

इतर मॉडेल्सप्रमाणेच, Phi मॉडेल कुटुंब संभाव्यतः असे वर्तन करू शकते जे अन्यायकारक, अविश्वसनीय किंवा अपमानास्पद असू शकते.

SLM आणि LLM ची काही मर्यादित वर्तनं ज्यांची तुम्हाला जाणीव असावी, त्यात समाविष्ट आहेत:

- **सेवा गुणवत्ता:** Phi मॉडेल्स मुख्यत्वे इंग्रजी मजकूरावर प्रशिक्षण दिले गेले आहेत. इंग्रजी व्यतिरिक्त भाषा वापरताना कमी कार्यक्षमता अनुभवली जाऊ शकते. प्रशिक्षण डेटामध्ये कमी प्रतिनिधित्व असलेल्या इंग्रजी भाषा विविधता मानक अमेरिकन इंग्रजीच्या तुलनेत वाईट कार्यक्षमता दर्शवू शकतात.
- **हानिकारक प्रतिनिधित्व व पूर्वग्रह टिकविणे:** हे मॉडेल लोकांच्या गटांचे जास्त किंवा कमी प्रतिनिधित्व करू शकतात, काही गटांचे प्रतिनिधित्व मिटवू शकतात, किंवा नीच किंवा नकारात्मक पूर्वग्रह अधिकाधिक मजबूत करू शकतात. सुरक्षितता प्रशिक्षणानंतरही, विविध गटांच्या प्रतिनिधित्वातील फरक किंवा प्रशिक्षण डेटामध्ये नकारात्मक पूर्वग्रहांचे उदाहरणे असणे यामुळे ही मर्यादा अद्याप असू शकते, जी वास्तविक जगातील नमुने आणि सामाजिक पूर्वग्रह दर्शवते.
- **अशोभनीय किंवा अपमानास्पद सामग्री:** हे मॉडेल इतर प्रकारची अशोभनीय किंवा अपमानास्पद सामग्री तयार करू शकतात, ज्यामुळे संवेदनशील प्रसंगासाठी वापरल्यास अतिरिक्त उपाय न करता तिला पुढील केले जाणं योग्य नाही.
माहितीची विश्वासार्हता: भाषा मॉडेल्स गैरसमजूत किंवा खोटी माहिती तयार करू शकतात जी योग्य वाटू शकते पण चुकीची किंवा जुनाट असू शकते.
- **कोडसाठी मर्यादित व्याप्ती:** Phi-3 च्या प्रशिक्षण डेटाचा बहुसंख्य भाग Python आधारित असून त्यात "typing, math, random, collections, datetime, itertools" सारख्या लोकप्रिय पॅकेजचा वापर होतो. जर मॉडेल इतर पॅकेजेस किंवा इतर भाषांमध्ये स्क्रिप्टस् तयार करत असेल, तर वापरकर्त्यांनी सर्व API वापर यथायोग्य तपासणे कठोरपणे शिफारस केली जाते.

विकासकांनी जबाबदार AI सर्वोत्तम पद्धती वापराव्यात आणि विशिष्ट वापर घटक संबंधित कायदे व नियमांचे पालन करतो याची खात्री करणे त्यांची जबाबदारी आहे (उदा. गोपनीयता, व्यापार इत्यादी).

## जबाबदार AI विचार

इतर भाषा मॉडेल्सप्रमाणे, Phi सिरीज मॉडेल्स संभाव्यतः असे वर्तन करू शकतात जे अन्यायकारक, अविश्वसनीय, किंवा अपमानास्पद ठरू शकतात. काही मर्यादित वर्तनांमध्ये लक्ष द्यावे लागते:

**सेवा गुणवत्ता:** Phi मॉडेल्स मुख्यत्वे इंग्रजी मजकूरावर प्रशिक्षण दिलेले आहेत. इंग्रजी व्यतिरिक्त भाषा वापरताना कमी कार्यक्षमता अनुभवता येईल. प्रशिक्षण डेटामध्ये कमी प्रतिनिधित्व असलेल्या इंग्रजी भाषांयसाठी मानक अमेरिकन इंग्रजीइतकी कार्यक्षमता अपेक्षेइतकी नसेल.

**हानिकारक प्रतिनिधित्व व पूर्वग्रह टिकविणे:** हे मॉडेल लोकांच्या गटांचे जास्त किंवा कमी प्रतिनिधित्व करू शकतात, काही गटांचे प्रतिनिधित्व मिटवू शकतात, किंवा नीच किंवा नकारात्मक पूर्वग्रह अधिकाधिक मजबूत करू शकतात. सुरक्षितता प्रशिक्षणानंतरही या मर्यादा असू शकतात, कारण विविध गटांच्या प्रतिनिधित्वाची पातळी वेगळी आहे किंवा प्रशिक्षण डेटामध्ये प्रतिकूल पूर्वग्रहांचे उदाहरणे असतात जी वास्तव जगातील सामाजिक पूर्वग्रह प्रतिबिंबित करतात.

**अशोभनीय किंवा अपमानास्पद सामग्री:** हे मॉडेल इतर प्रकारची अशोभनीय किंवा अपमानास्पद सामग्री तयार करू शकतात, जी वापरलेल्यासाठी अस्वीकार्य ठरू शकते, विशेषतः संवेदनशील वापरासाठी अतिरिक्त उपाय न करता. माहितीची विश्वासार्हता: भाषा मॉडेल्स बोधगम्य नसलेली सामग्री तयार करू शकतात किंवा कालबाह्य, खोटी माहिती देऊ शकतात.

**कोडसाठी मर्यादित व्याप्ती:** Phi-3 च्या बहुसंख्य प्रशिक्षण डेटाचा भाग Python आधारित आणि सामान्य पॅकेजेस वापरतो, जसे "typing, math, random, collections, datetime, itertools". जर मॉडेल Python स्क्रिप्ट्स तयार करत असेल, जे इतर पॅकेजेस किंवा इतर भाषांमध्ये स्क्रिप्ट वापरतात, तर वापरकर्त्यांनी सर्व API वापर यथार्थपणे तपासणे आवश्यक आहे.

विकासकांनी जबाबदार AI सर्वोत्तम पद्धती वापराव्यात आणि विशिष्ट वापर घटक संबंधित नियम व कायदे (उदा. गोपनीयता, व्यापार इत्यादी) पाळले जात आहेत याची खात्री करणे त्यांची जबाबदारी आहे. विचार करण्याचे महत्त्वाचे क्षेत्रे खालीलप्रमाणे आहेत:

**वाटप:** मॉडेल काही परिस्थितींमध्ये जेथे कायदेशीर स्थिती किंवा संसाधने किंवा जीवन संधींचे वाटप प्रभावित होते (उदा. घरपणा, नोकरी, कर्ज इ.) अशा परिस्थितीसाठी योग्य नसू शकतात, विशेषतः अतिरिक्त मूल्यांकन आणि पूर्वग्रह कमी करण्याच्या तंत्रांशिवाय.

**उच्च-धोका परिस्थिती:** विकासकांनी मॉडेलचा वापर अशा उच्च-धोका परिस्थितींमध्ये करायचा आहे का हे तपासले पाहिजे जेथे अन्यायकारक, अविश्वसनीय किंवा अपमानास्पद निकाल फार महागात पडू शकतात किंवा हानी पोहोचू शकते. यामध्ये संवेदनशील किंवा तज्ञ क्षेत्रांमध्ये जसे कायदेशीर किंवा आरोग्य सल्ला देणे, जेथे अचूकता व विश्वासार्हता अत्यावश्यक आहे, यात विविध संरक्षणे लागू करणे आवश्यक आहे.

**अचूकता नसलेली माहिती:** मॉडेल चुकीची माहिती देऊ शकतात. विकासकांनी पारदर्शकता सर्वोत्तम पद्धती पाळून शेवटच्या वापरकर्त्यांना हे समजावून सांगावे की ते AI प्रणालीसह संवाद साधत आहेत. अ‍ॅप्लिकेशन स्तरावर, विकासक पुनरावलोकन यंत्रणा आणि वापर-केस-विशिष्ट माहितीवर आधारित प्रतिसाद देण्यासाठी पद्धती तयार करू शकतात, ज्याला Retrieval Augmented Generation (RAG) म्हणतात.

**हानिकारक सामग्री तयार करणे:** विकासकांनी उत्पादने त्यांच्या संदर्भात तपासावी आणि उपलब्ध सुरक्षितता वर्गीकरण करणारे उपकरणे किंवा विशिष्ट वापरासाठी सानुकूल उपाय वापरावेत.

**गलत वापर:** फसवणूक, स्पॅम, किंवा मालवेयर निर्माण यांसारखा इतर गैरवापर शक्य आहे, आणि विकासकांनी त्यांच्या अ‍ॅप्लिकेशन्सने लागू कायदे व नियमांचे उल्लंघन होणार नाही याची काळजी घ्यावी.

### फाइनट्यूनिंग आणि AI सामग्री सुरक्षितता

एखादे मॉडेल फाइनट्यून केल्यानंतर, आम्ही [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) उपाय योजना वापरण्याची जोरदार शिफारस करतो, ज्याद्वारे मॉडेलने तयार केल्या जाणाऱ्या सामग्रीवर लक्ष ठेवता येते, संभाव्य धोके, धोक्यांचे आणि गुणवत्तेच्या समस्या ओळखता आणि ब्लॉक करता येतात.

![Phi3AISafety](../../../../../translated_images/mr/01.phi3aisafety.c0d7fc42f5a5c405.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) ही मजकूर आणि प्रतिमा सामग्री दोन्हीत समर्थन करते. ती क्लाउड, डिस्कनेक्टेड कंटेनर्स, आणि एज/एंबेडेड डिव्हाइसेसवर आढळवता येते.

## Azure AI Content Safety चे विहंगावलोकन

Azure AI Content Safety हा सर्वांसाठी एकसमान उपाय नाही; तो व्यवसायांच्या विशिष्ट धोरणांशी जुळवून घेण्यासाठी सानुकूल केला जाऊ शकतो. तसेच, त्याचे बहुभाषिक मॉडेल्स एकाच वेळी अनेक भाषा समजण्यास सक्षम आहेत.

![AIContentSafety](../../../../../translated_images/mr/01.AIcontentsafety.a288819b8ce8da1a.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 व्हिडिओ**

Azure AI Content Safety सेवा अनुप्रयोगांमध्ये आणि सेवांमध्ये हानिकारक वापरकर्ता निर्मित आणि AI निर्मित सामग्री ओळखते. यात मजकूर आणि प्रतिमा API आहेत, जे तुम्हाला हानिकारक किंवा अशोभनीय सामग्री शोधण्यासाठी मदत करतात.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**अस्वीकरण**:  
हा दस्तऐवज AI अनुवाद सेव्हिस [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून अनुवादित केला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये चुका किंवा अचूकतेत कमतरता असू शकतात. मूळ दस्तऐवज त्याच्या स्थानिक भाषेत अधिकृत स्रोत मानला जावा. महत्वाच्या माहितीसाठी व्यावसायिक मानवी अनुवादाची शिफारस केली जाते. या अनुवादाच्या वापरामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थ लावणीबद्दल आम्ही जबाबदार नाही.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->