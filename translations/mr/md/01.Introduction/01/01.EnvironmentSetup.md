<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:08:33+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "mr"
}
-->
# Phi-3 सह स्थानिकपणे सुरू करा

हा मार्गदर्शक तुम्हाला Ollama वापरून Phi-3 मॉडेल चालवण्यासाठी तुमचे स्थानिक वातावरण सेटअप करण्यात मदत करेल. तुम्ही मॉडेल GitHub Codespaces, VS Code Dev Containers किंवा तुमच्या स्थानिक वातावरणात चालवू शकता.

## वातावरण सेटअप

### GitHub Codespaces

तुम्ही GitHub Codespaces वापरून हा टेम्प्लेट आभासीपणे चालवू शकता. हा बटण तुमच्या ब्राउझरमध्ये वेब-आधारित VS Code उदाहरण उघडेल:

1. टेम्प्लेट उघडा (यासाठी काही मिनिटे लागू शकतात):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. टर्मिनल विंडो उघडा

### VS Code Dev Containers

⚠️ हा पर्याय फक्त तेव्हाच काम करेल जेव्हा तुमच्या Docker Desktop ला किमान 16 GB RAM दिलेले असेल. जर तुमच्याकडे 16 GB पेक्षा कमी RAM असेल, तर तुम्ही [GitHub Codespaces पर्याय](../../../../../md/01.Introduction/01) वापरू शकता किंवा [स्थानिकपणे सेटअप](../../../../../md/01.Introduction/01) करू शकता.

संबंधित पर्याय म्हणजे VS Code Dev Containers, जे प्रोजेक्ट तुमच्या स्थानिक VS Code मध्ये [Dev Containers विस्तार](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) वापरून उघडेल:

1. Docker Desktop सुरू करा (जर आधी नसेल तर इंस्टॉल करा)
2. प्रोजेक्ट उघडा:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. उघडलेल्या VS Code विंडोमध्ये, जेव्हा प्रोजेक्ट फाइल्स दिसतील (यासाठी काही मिनिटे लागू शकतात), तेव्हा टर्मिनल विंडो उघडा.
4. [डिप्लॉयमेंट स्टेप्स](../../../../../md/01.Introduction/01) सह पुढे जा

### स्थानिक वातावरण

1. खालील टूल्स इंस्टॉल असल्याची खात्री करा:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## मॉडेलची चाचणी करा

1. Ollama ला phi3:mini मॉडेल डाउनलोड आणि चालवण्यास सांगा:

    ```shell
    ollama run phi3:mini
    ```

    मॉडेल डाउनलोड होण्यासाठी काही मिनिटे लागू शकतात.

2. जेव्हा आउटपुटमध्ये "success" दिसेल, तेव्हा तुम्ही त्या मॉडेलला प्रॉम्प्टवरून संदेश पाठवू शकता.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. काही सेकंदांनी, तुम्हाला मॉडेलकडून प्रतिसादाचा प्रवाह दिसेल.

4. भाषा मॉडेल्ससह वापरल्या जाणाऱ्या विविध तंत्रांबद्दल जाणून घेण्यासाठी, Python नोटबुक [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) उघडा आणि प्रत्येक सेल चालवा. जर तुम्ही 'phi3:mini' व्यतिरिक्त दुसरे मॉडेल वापरले असेल, तर पहिल्या सेलमधील `MODEL_NAME` बदला.

5. Python मधून phi3:mini मॉडेलशी संवाद साधण्यासाठी, Python फाइल [chat.py](../../../../../code/01.Introduce/chat.py) उघडा आणि चालवा. आवश्यकतेनुसार फाइलच्या वरच्या भागातील `MODEL_NAME` बदलू शकता, तसेच सिस्टम मेसेज किंवा काही उदाहरणे (few-shot examples) देखील बदलू शकता.

**अस्वीकरण**:  
हा दस्तऐवज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून अनुवादित केला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये चुका किंवा अचूकतेची कमतरता असू शकते. मूळ दस्तऐवज त्याच्या स्थानिक भाषेत अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी अनुवाद करण्याची शिफारस केली जाते. या अनुवादाच्या वापरामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थलागी आम्ही जबाबदार नाही.