<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:03:25+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "mr"
}
-->
# Phi-3 सह स्थानिकरित्या सुरू करा

हा मार्गदर्शक तुम्हाला Ollama वापरून Phi-3 मॉडेल चालवण्यासाठी स्थानिक वातावरण सेटअप करण्यात मदत करेल. तुम्ही हा मॉडेल GitHub Codespaces, VS Code Dev Containers किंवा तुमच्या स्थानिक वातावरणातून चालवू शकता.

## वातावरण सेटअप

### GitHub Codespaces

तुम्ही GitHub Codespaces वापरून हा टेम्पलेट आभासीपणे चालवू शकता. खालील बटण तुमच्या ब्राउझरमध्ये वेब-आधारित VS Code उघडेल:

1. टेम्पलेट उघडा (यासाठी काही मिनिटे लागू शकतात):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. टर्मिनल विंडो उघडा

### VS Code Dev Containers

⚠️ हा पर्याय फक्त तेव्हाच कार्य करेल जेव्हा तुमच्या Docker Desktop साठी किमान 16 GB RAM राखीव असेल. जर तुमच्याकडे 16 GB पेक्षा कमी RAM असेल, तर तुम्ही [GitHub Codespaces पर्याय](../../../../../md/01.Introduction/01) वापरू शकता किंवा [स्थानिकरित्या सेटअप करू शकता](../../../../../md/01.Introduction/01).

संबंधित पर्याय म्हणजे VS Code Dev Containers, जो प्रकल्प तुमच्या स्थानिक VS Code मध्ये [Dev Containers विस्तार](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) वापरून उघडेल:

1. Docker Desktop सुरू करा (जर आधी नसेल तर इन्स्टॉल करा)
2. प्रकल्प उघडा:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. जेव्हा VS Code विंडो उघडेल आणि प्रकल्प फाइल्स दिसतील (यासाठी काही मिनिटे लागू शकतात), तेव्हा टर्मिनल विंडो उघडा.
4. [deployment steps](../../../../../md/01.Introduction/01) सोबत पुढे जा

### स्थानिक वातावरण

1. खालील साधने इन्स्टॉल आहेत याची खात्री करा:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## मॉडेल चाचणी करा

1. Ollama ला phi3:mini मॉडेल डाउनलोड आणि चालवण्यास सांगा:

    ```shell
    ollama run phi3:mini
    ```

    मॉडेल डाउनलोड होण्यासाठी काही मिनिटे लागतील.

2. आउटपुटमध्ये "success" दिसल्यावर, तुम्ही त्या मॉडेलला प्रॉम्प्टवरून मेसेज पाठवू शकता.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. काही सेकंदांनी, तुम्हाला मॉडेलकडून प्रतिसाद प्रवाह दिसेल.

4. भाषा मॉडेल्ससह वापरल्या जाणाऱ्या विविध तंत्रांबद्दल जाणून घेण्यासाठी, Python नोटबुक [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) उघडा आणि प्रत्येक सेल चालवा. जर तुम्ही 'phi3:mini' शिवाय दुसरे मॉडेल वापरले असेल, तर फाईलच्या शीर्षभागी `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` आवश्यकतेनुसार बदला, तसेच तुम्ही सिस्टम मेसेज बदलू शकता किंवा आवश्यक असल्यास few-shot उदाहरणे देखील जोडू शकता.

**अस्वीकरण**:  
हा दस्तऐवज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून अनुवादित केला आहे. आम्ही अचूकतेसाठी प्रयत्नशील आहोत, तरी कृपया लक्षात ठेवा की स्वयंचलित अनुवादांमध्ये चुका किंवा अचूकतेच्या त्रुटी असू शकतात. मूळ दस्तऐवज त्याच्या मूळ भाषेतच अधिकारप्राप्त स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी अनुवादाची शिफारस केली जाते. या अनुवादाच्या वापरामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थलागी आम्ही जबाबदार नाही.