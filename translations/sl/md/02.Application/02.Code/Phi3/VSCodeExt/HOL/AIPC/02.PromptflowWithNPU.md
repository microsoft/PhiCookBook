<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-05-09T19:27:01+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "sl"
}
-->
# **Lab 2 -  Run Prompt flow with Phi-3-mini in AIPC**

## **Kaj je Prompt flow**

Prompt flow je niz razvojnih orodij, zasnovanih za poenostavitev celotnega razvojnega cikla AI aplikacij na osnovi LLM, od ideje, prototipiranja, testiranja, ocenjevanja do produkcijske namestitve in spremljanja. Omogoča lažje oblikovanje promptov in vam omogoča gradnjo LLM aplikacij s produkcijsko kakovostjo.

S Prompt flow boste lahko:

- Ustvarjali tokove, ki povezujejo LLM-je, prompte, Python kodo in druga orodja v izvršljiv potek dela.

- Enostavno odpravljali napake in iterirali svoje tokove, še posebej interakcijo z LLM-ji.

- Ocenjevali tokove, izračunavali metrike kakovosti in zmogljivosti na večjih podatkovnih nizih.

- Integrirali testiranje in ocenjevanje v vaš CI/CD sistem za zagotavljanje kakovosti toka.

- Enostavno namestili tokove na izbrano strežniško platformo ali jih vključili v kodo vaše aplikacije.

- (Neobvezno, a zelo priporočljivo) Sodelovali s svojo ekipo z uporabo oblačne različice Prompt flow v Azure AI.

## **Kaj je AIPC**

AI PC ima CPU, GPU in NPU, vsak s specifičnimi zmogljivostmi za pospeševanje AI. NPU ali nevronska procesna enota je specializiran pospeševalnik, ki izvaja naloge umetne inteligence (AI) in strojnega učenja (ML) neposredno na vašem računalniku, namesto da bi podatke pošiljal v oblak. GPU in CPU lahko prav tako obdelujeta te naloge, a NPU je posebej učinkovit pri nizkoenergijskih AI izračunih. AI PC predstavlja temeljno spremembo v delovanju naših računalnikov. Ni rešitev za problem, ki prej ni obstajal, ampak obljublja velik napredek pri vsakdanji uporabi računalnikov.

Kako deluje? V primerjavi z generativno AI in ogromnimi velikimi jezikovnimi modeli (LLM), treniranimi na množici javnih podatkov, je AI, ki teče na vašem računalniku, dostopnejša na skoraj vseh ravneh. Koncept je lažje razumljiv, ker je treniran na vaših podatkih in ne zahteva dostopa do oblaka, so koristi takoj bolj privlačne širšemu krogu uporabnikov.

V bližnji prihodnosti AI PC pomeni osebne asistente in manjše AI modele, ki tečejo neposredno na vašem računalniku, uporabljajo vaše podatke in nudijo osebne, zasebne in bolj varne AI izboljšave za vsakdanje naloge – zapisovanje zapisnikov sestankov, organizacijo fantazijske nogometne lige, avtomatizacijo izboljšav za urejanje fotografij in videov ali načrtovanje popolnega itinerarja za družinsko srečanje glede na čase prihoda in odhoda vseh.

## **Gradnja generacijskih kodnih tokov na AIPC**

***Note*** ：Če še niste dokončali namestitve okolja, obiščite [Lab 0 -Installations](./01.Installations.md)

1. Odprite Prompt flow razširitev v Visual Studio Code in ustvarite prazen projekt toka

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.sl.png)

2. Dodajte vhodne in izhodne parametre ter dodajte Python kodo kot nov tok

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.sl.png)

Lahko se sklicujete na to strukturo (flow.dag.yaml) za gradnjo vašega toka

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Dodajte kodo v ***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Tok lahko preizkusite preko Debug ali Run, da preverite, ali generiranje kode deluje pravilno

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.sl.png)

5. Zaženite tok kot razvojni API v terminalu

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Lahko ga preizkusite v Postman / Thunder Client

### **Note**

1. Prvi zagon traja dlje. Priporočamo, da model phi-3 prenesete preko Hugging face CLI.

2. Glede na omejeno računsko moč Intel NPU je priporočljivo uporabljati Phi-3-mini-4k-instruct.

3. Uporabljamo Intel NPU pospeševanje za kvantizacijo INT4, vendar če znova zaženete storitev, morate izbrisati mape cache in nc_workshop.

## **Viri**

1. Naučite se Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Naučite se Intel NPU pospeševanja [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Primer kode, prenesite [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo AI prevajalske storitve [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Ne odgovarjamo za morebitne nesporazume ali napačne interpretacije, ki izhajajo iz uporabe tega prevoda.