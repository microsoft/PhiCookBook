{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktivni Phi 3 Mini 4K Instruct Chatbot z Whisper\n",
    "\n",
    "### Uvod:\n",
    "Interaktivni Phi 3 Mini 4K Instruct Chatbot je orodje, ki uporabnikom omogoča interakcijo z Microsoft Phi 3 Mini 4K Instruct demo prek besedilnega ali zvočnega vnosa. Chatbot se lahko uporablja za različne naloge, kot so prevajanje, posodobitve vremena in zbiranje splošnih informacij.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "Ustvarite svoj Huggingface dostopni žeton\n",
    "\n",
    "Ustvarite nov žeton  \n",
    "Dajte mu novo ime  \n",
    "Izberite dovoljenja za pisanje  \n",
    "Kopirajte žeton in ga shranite na varno mesto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naslednja Python koda izvaja dve glavni nalogi: uvoz modula `os` in nastavitev okoljske spremenljivke.\n",
    "\n",
    "1. Uvoz modula `os`:\n",
    "   - Modul `os` v Pythonu omogoča interakcijo z operacijskim sistemom. Omogoča izvajanje različnih nalog, povezanih z operacijskim sistemom, kot so dostop do okoljskih spremenljivk, delo z datotekami in imeniki itd.\n",
    "   - V tej kodi je modul `os` uvožen z uporabo ukaza `import`. Ta ukaz omogoča uporabo funkcionalnosti modula `os` v trenutnem Python skriptu.\n",
    "\n",
    "2. Nastavitev okoljske spremenljivke:\n",
    "   - Okoljska spremenljivka je vrednost, do katere lahko dostopajo programi, ki se izvajajo na operacijskem sistemu. Gre za način shranjevanja nastavitev konfiguracije ali drugih informacij, ki jih lahko uporabljajo različni programi.\n",
    "   - V tej kodi se nova okoljska spremenljivka nastavi z uporabo slovarja `os.environ`. Ključ slovarja je `'HF_TOKEN'`, vrednost pa je dodeljena iz spremenljivke `HUGGINGFACE_TOKEN`.\n",
    "   - Spremenljivka `HUGGINGFACE_TOKEN` je definirana tik nad tem delom kode in ji je dodeljena nizovna vrednost `\"hf_**************\"` z uporabo sintakse `#@param`. Ta sintaksa se pogosto uporablja v Jupyter zvezkih za omogočanje vnosa uporabnika in konfiguracijo parametrov neposredno v vmesniku zvezka.\n",
    "   - Z nastavitvijo okoljske spremenljivke `'HF_TOKEN'` lahko do nje dostopajo drugi deli programa ali drugi programi, ki se izvajajo na istem operacijskem sistemu.\n",
    "\n",
    "Na splošno ta koda uvozi modul `os` in nastavi okoljsko spremenljivko z imenom `'HF_TOKEN'` z vrednostjo, ki je podana v spremenljivki `HUGGINGFACE_TOKEN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta del kode definira funkcijo z imenom clear_output, ki se uporablja za brisanje izpisa trenutne celice v Jupyter Notebooku ali IPythonu. Poglejmo si podrobnosti kode in razumimo njeno funkcionalnost:\n",
    "\n",
    "Funkcija clear_output sprejme en parameter, imenovan wait, ki je logična vrednost (boolean). Privzeto je wait nastavljen na False. Ta parameter določa, ali naj funkcija počaka, da je na voljo nov izpis za zamenjavo obstoječega izpisa, preden ga izbriše.\n",
    "\n",
    "Sama funkcija se uporablja za brisanje izpisa trenutne celice. V Jupyter Notebooku ali IPythonu, ko celica ustvari izpis, kot je natisnjeno besedilo ali grafični prikazi, se ta izpis prikaže pod celico. Funkcija clear_output omogoča, da ta izpis izbrišete.\n",
    "\n",
    "Implementacija funkcije ni podana v tem delčku kode, kar je označeno z elipso (...). Elipsa predstavlja mesto za dejansko kodo, ki izvaja brisanje izpisa. Implementacija funkcije lahko vključuje interakcijo z API-jem Jupyter Notebooka ali IPythona za odstranitev obstoječega izpisa iz celice.\n",
    "\n",
    "Na splošno ta funkcija ponuja priročen način za brisanje izpisa trenutne celice v Jupyter Notebooku ali IPythonu, kar olajša upravljanje in posodabljanje prikazanega izpisa med interaktivnimi programskimi sejami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izvedite pretvorbo besedila v govor (TTS) z uporabo storitve Edge TTS. Poglejmo si ustrezne implementacije funkcij eno za drugo:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: Ta funkcija sprejme vhodno vrednost in izračuna niz hitrosti za glas TTS. Vhodna vrednost predstavlja želeno hitrost govora, kjer vrednost 1 predstavlja normalno hitrost. Funkcija izračuna niz hitrosti tako, da od vhodne vrednosti odšteje 1, jo pomnoži s 100 in nato določi predznak glede na to, ali je vhodna vrednost večja ali enaka 1. Funkcija vrne niz hitrosti v formatu \"{sign}{rate}\".\n",
    "\n",
    "2. `make_chunks(input_text, language)`: Ta funkcija sprejme vhodno besedilo in jezik kot parametra. Besedilo razdeli na dele glede na jezikovno specifična pravila. V tej implementaciji, če je jezik \"English\", funkcija razdeli besedilo na vsaki piki (\".\") in odstrani morebitne začetne ali končne presledke. Nato vsakemu delu doda piko in vrne filtriran seznam delov.\n",
    "\n",
    "3. `tts_file_name(text)`: Ta funkcija ustvari ime datoteke za zvočno datoteko TTS na podlagi vhodnega besedila. Izvede več transformacij na besedilu: odstrani končno piko (če je prisotna), pretvori besedilo v male črke, odstrani začetne in končne presledke ter zamenja presledke z podčrtaji. Nato besedilo skrajša na največ 25 znakov (če je daljše) ali uporabi celotno besedilo, če je prazno. Na koncu ustvari naključni niz z uporabo modula [`uuid`] in ga združi s skrajšanim besedilom, da ustvari ime datoteke v formatu \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\".\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: Ta funkcija združi več zvočnih datotek v eno zvočno datoteko. Sprejme seznam poti zvočnih datotek in izhodno pot kot parametra. Funkcija inicializira prazen objekt `AudioSegment`, imenovan [`merged_audio`]. Nato iterira skozi vsako pot zvočne datoteke, naloži zvočno datoteko z metodo `AudioSegment.from_file()` iz knjižnice `pydub` in doda trenutno zvočno datoteko objektu [`merged_audio`]. Na koncu izvozi združeno zvočno datoteko na določeno izhodno pot v formatu MP3.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: Ta funkcija izvede operacijo TTS z uporabo storitve Edge TTS. Sprejme seznam delov besedila, hitrost govora, ime glasu in pot shranjevanja kot parametre. Če je število delov večje od 1, funkcija ustvari imenik za shranjevanje posameznih zvočnih datotek delov. Nato iterira skozi vsak del, sestavi ukaz Edge TTS z uporabo funkcije `calculate_rate_string()`, imena glasu in besedila dela ter izvede ukaz z uporabo funkcije `os.system()`. Če je izvedba ukaza uspešna, doda pot ustvarjene zvočne datoteke v seznam. Po obdelavi vseh delov združi posamezne zvočne datoteke z uporabo funkcije `merge_audio_files()` in shrani združeno zvočno datoteko na določeno pot shranjevanja. Če je samo en del, neposredno ustvari ukaz Edge TTS in shrani zvočno datoteko na pot shranjevanja. Na koncu vrne pot shranjene zvočne datoteke.\n",
    "\n",
    "6. `random_audio_name_generate()`: Ta funkcija ustvari naključno ime zvočne datoteke z uporabo modula [`uuid`]. Ustvari naključni UUID, ga pretvori v niz, vzame prvih 8 znakov, doda pripono \".mp3\" in vrne naključno ime zvočne datoteke.\n",
    "\n",
    "7. `talk(input_text)`: Ta funkcija je glavni vstopni točki za izvedbo operacije TTS. Sprejme vhodno besedilo kot parameter. Najprej preveri dolžino vhodnega besedila, da določi, ali gre za dolg stavek (večji ali enak 600 znakov). Na podlagi dolžine in vrednosti spremenljivke `translate_text_flag` določi jezik in ustvari seznam delov besedila z uporabo funkcije `make_chunks()`. Nato ustvari pot shranjevanja za zvočno datoteko z uporabo funkcije `random_audio_name_generate()`. Na koncu pokliče funkcijo `edge_free_tts()` za izvedbo operacije TTS in vrne pot shranjene zvočne datoteke.\n",
    "\n",
    "Skupno te funkcije delujejo skupaj, da razdelijo vhodno besedilo na dele, ustvarijo ime datoteke za zvočno datoteko, izvedejo operacijo TTS z uporabo storitve Edge TTS in združijo posamezne zvočne datoteke v eno zvočno datoteko.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacija dveh funkcij: convert_to_text in run_text_prompt, ter deklaracija dveh razredov: str in Audio.\n",
    "\n",
    "Funkcija convert_to_text sprejme parameter audio_path in prepiše zvok v besedilo z uporabo modela whisper_model. Funkcija najprej preveri, ali je zastavica gpu nastavljena na True. Če je, se whisper_model uporabi z določenimi parametri, kot so word_timestamps=True, fp16=True, language='English' in task='translate'. Če je gpu nastavljena na False, se whisper_model uporabi z nastavitvijo fp16=False. Nastali prepis se nato shrani v datoteko z imenom 'scan.txt' in vrne kot besedilo.\n",
    "\n",
    "Funkcija run_text_prompt sprejme sporočilo in zgodovino klepeta kot vhodne parametre. Uporabi funkcijo phi_demo za generiranje odgovora klepetalnega robota na podlagi vhodnega sporočila. Generirani odgovor se nato posreduje funkciji talk, ki pretvori odgovor v zvočno datoteko in vrne pot do datoteke. Razred Audio se uporablja za prikaz in predvajanje zvočne datoteke. Zvok se prikaže z uporabo funkcije display iz modula IPython.display, objekt Audio pa se ustvari s parametrom autoplay=True, tako da se zvok začne predvajati samodejno. Zgodovina klepeta se posodobi z vhodnim sporočilom in generiranim odgovorom, nato pa se vrnejo prazna vrstica in posodobljena zgodovina klepeta.\n",
    "\n",
    "Razred str je vgrajen razred v Pythonu, ki predstavlja zaporedje znakov. Ponuja različne metode za manipulacijo in delo z nizi, kot so capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill in še več. Te metode omogočajo izvajanje operacij, kot so iskanje, zamenjava, formatiranje in manipulacija nizov.\n",
    "\n",
    "Razred Audio je prilagojen razred, ki predstavlja zvočni objekt. Uporablja se za ustvarjanje zvočnega predvajalnika v okolju Jupyter Notebook. Razred sprejme različne parametre, kot so data, filename, url, embed, rate, autoplay in normalize. Parameter data je lahko numpy array, seznam vzorcev, niz, ki predstavlja ime datoteke ali URL, ali surovi PCM podatki. Parameter filename se uporablja za določanje lokalne datoteke, iz katere se naložijo zvočni podatki, parameter url pa za določanje URL-ja, s katerega se prenesejo zvočni podatki. Parameter embed določa, ali naj bodo zvočni podatki vdelani z uporabo URI podatkov ali referencirani iz izvirnega vira. Parameter rate določa vzorčno frekvenco zvočnih podatkov. Parameter autoplay določa, ali naj se zvok začne predvajati samodejno. Parameter normalize določa, ali naj se zvočni podatki normalizirajo (prilagodijo) na največji možni razpon. Razred Audio ponuja tudi metode, kot je reload za ponovno nalaganje zvočnih podatkov iz datoteke ali URL-ja, ter atribute, kot so src_attr, autoplay_attr in element_id_attr za pridobivanje ustreznih atributov za zvočni element v HTML-ju.\n",
    "\n",
    "Na splošno se te funkcije in razredi uporabljajo za prepis zvoka v besedilo, generiranje zvočnih odgovorov klepetalnega robota ter prikaz in predvajanje zvoka v okolju Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Omejitev odgovornosti**:  \nTa dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-13T07:04:40+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "sl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}