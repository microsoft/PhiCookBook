<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b028cdc5b33b99efb0f061bcff71023",
  "translation_date": "2025-04-04T11:57:05+00:00",
  "source_file": "md\\01.Introduction\\02\\06.NVIDIA.md",
  "language_code": "ja"
}
-->
## NVIDIA NIMにおけるPhiファミリー

NVIDIA NIMは、クラウド、データセンター、ワークステーションにおける生成AIモデルの展開を加速するために設計された使いやすいマイクロサービス群です。NIMはモデルファミリーごと、またはモデルごとに分類されます。例えば、大規模言語モデル（LLM）向けのNVIDIA NIMは、最先端のLLMの力を企業アプリケーションにもたらし、卓越した自然言語処理と理解能力を提供します。

NIMを利用することで、ITやDevOpsチームは自分たちの管理環境内で大規模言語モデル（LLM）をセルフホストしつつ、開発者には業界標準のAPIを提供できます。これにより、強力なコパイロット、チャットボット、AIアシスタントを構築し、ビジネスを変革することが可能です。NVIDIAの最先端GPUアクセラレーションとスケーラブルな展開を活用することで、NIMは比類のない性能で推論を行う最速の手段を提供します。

NIVIDIA NIMを使用してPhiファミリーモデルを推論することができます。

![nim](../../../../../translated_images/Phi-NIM.45af94d89220fbbbc85f8da0379150a29cc88c3dd8ec417b1d3b7237bbe1c58a.ja.png)

### **サンプル - NVIDIA NIMでのPhi-3-Vision**

例えば、画像 (`demo.png`) を持っていて、その画像を処理して新しいバージョンを保存するPythonコードを生成したいとします (`phi-3-vision.jpg`)。

上記のコードは以下のプロセスを自動化します：

1. 環境と必要な設定を整える。
2. モデルに必要なPythonコードを生成するよう指示するプロンプトを作成する。
3. プロンプトをモデルに送信し、生成されたコードを収集する。
4. 生成されたコードを抽出して実行する。
5. 元の画像と処理後の画像を表示する。

このアプローチは、AIの力を活用して画像処理タスクを自動化し、目標を達成するのをより簡単かつ迅速にします。

[サンプルコードソリューション](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

コード全体の処理をステップごとに分解してみましょう：

1. **必要なパッケージをインストール**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    このコマンドは`langchain_nvidia_ai_endpoints`パッケージをインストールし、最新バージョンであることを確認します。

2. **必要なモジュールをインポート**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    これらのインポートは、NVIDIA AIエンドポイントとのやり取り、パスワードの安全な取り扱い、OSとのやり取り、データのBase64形式でのエンコード/デコードを可能にします。

3. **APIキーを設定**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    このコードは`NVIDIA_API_KEY`環境変数が設定されているか確認します。設定されていない場合は、ユーザーにAPIキーを安全に入力するよう求めます。

4. **モデルと画像パスを定義**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    使用するモデルを設定し、指定されたモデルで`ChatNVIDIA`インスタンスを作成し、画像ファイルのパスを定義します。

5. **テキストプロンプトを作成**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    画像を処理するPythonコードを生成するようモデルに指示するテキストプロンプトを定義します。

6. **画像をBase64形式でエンコード**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    このコードは画像ファイルを読み込み、Base64形式でエンコードし、エンコードされたデータを含むHTML画像タグを作成します。

7. **テキストと画像をプロンプトに結合**:
    ```python
    prompt = f"{text} {image}"
    ```
    テキストプロンプトとHTML画像タグを一つの文字列に結合します。

8. **ChatNVIDIAを使用してコードを生成**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    このコードはプロンプトを`ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code`文字列に送信します。

9. **生成されたコンテンツからPythonコードを抽出**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    このコードはマークダウン形式を削除して、生成されたコンテンツから実際のPythonコードを抽出します。

10. **生成されたコードを実行**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    このコードは抽出されたPythonコードをサブプロセスとして実行し、その出力をキャプチャします。

11. **画像を表示**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    これらの行は`IPython.display`モジュールを使用して画像を表示します。

**免責事項**:  
この文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求していますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書が正式な情報源として考慮されるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当社は責任を負いません。