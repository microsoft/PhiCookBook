<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-07-16T17:44:20+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ja"
}
-->
# PhiモデルのAI安全性  
Phiシリーズのモデルは、[Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl)に基づいて開発されました。これは、説明責任、透明性、公平性、信頼性と安全性、プライバシーとセキュリティ、包括性という6つの原則に基づく、企業全体の要件セットであり、[Microsoftの責任あるAI原則](https://www.microsoft.com/ai/responsible-ai)を形成しています。

以前のPhiモデルと同様に、多面的な安全性評価と安全性ポストトレーニングのアプローチが採用されており、本リリースの多言語対応能力を考慮した追加の対策も講じられています。安全性トレーニングと評価のアプローチは、複数言語やリスクカテゴリにわたるテストを含み、[Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833)に詳述されています。Phiモデルはこのアプローチの恩恵を受けていますが、開発者は特定のユースケースや文化的・言語的文脈に関連するリスクのマッピング、測定、軽減を含む責任あるAIのベストプラクティスを適用すべきです。

## ベストプラクティス  

他のモデルと同様に、Phiシリーズのモデルも不公平、不信頼、または不快な振る舞いをする可能性があります。

SLMやLLMの制限的な挙動として注意すべき点は以下の通りです：

- **サービス品質:** Phiモデルは主に英語テキストで訓練されています。英語以外の言語では性能が低下する可能性があります。訓練データでの表現が少ない英語の方言は、標準的なアメリカ英語よりも性能が劣ることがあります。  
- **害の表現とステレオタイプの固定化:** これらのモデルは、特定の人々のグループを過剰または過小に表現したり、あるグループの表現を消したり、侮辱的または否定的なステレオタイプを強化したりすることがあります。安全性ポストトレーニングを行っても、異なるグループの表現レベルの違いや、訓練データに含まれる現実世界のパターンや社会的偏見を反映した否定的なステレオタイプの例の存在により、これらの制限は依然として残る可能性があります。  
- **不適切または攻撃的なコンテンツ:** これらのモデルは他の種類の不適切または攻撃的なコンテンツを生成することがあり、ユースケースに特化した追加の緩和策なしに、センシティブな文脈での展開は不適切な場合があります。  
- **情報の信頼性:** 言語モデルは意味不明な内容や、一見もっともらしいが不正確または古い情報を生成することがあります。  
- **コードの適用範囲の制限:** Phi-3の訓練データの大部分はPythonに基づいており、「typing, math, random, collections, datetime, itertools」などの一般的なパッケージを使用しています。モデルが他のパッケージを使ったPythonスクリプトや他言語のスクリプトを生成した場合は、すべてのAPI使用を手動で検証することを強く推奨します。

開発者は責任あるAIのベストプラクティスを適用し、特定のユースケースが関連する法律や規制（例：プライバシー、貿易など）に準拠していることを保証する責任があります。

## 責任あるAIに関する考慮事項  

他の言語モデルと同様に、Phiシリーズのモデルも不公平、不信頼、または不快な振る舞いをする可能性があります。注意すべき制限的な挙動は以下の通りです：

**サービス品質:** Phiモデルは主に英語テキストで訓練されています。英語以外の言語では性能が低下します。訓練データでの表現が少ない英語の方言は、標準的なアメリカ英語よりも性能が劣ることがあります。

**害の表現とステレオタイプの固定化:** これらのモデルは、特定の人々のグループを過剰または過小に表現したり、あるグループの表現を消したり、侮辱的または否定的なステレオタイプを強化したりすることがあります。安全性ポストトレーニングを行っても、異なるグループの表現レベルの違いや、訓練データに含まれる現実世界のパターンや社会的偏見を反映した否定的なステレオタイプの例の存在により、これらの制限は依然として残る可能性があります。

**不適切または攻撃的なコンテンツ:** これらのモデルは他の種類の不適切または攻撃的なコンテンツを生成することがあり、ユースケースに特化した追加の緩和策なしに、センシティブな文脈での展開は不適切な場合があります。  
情報の信頼性: 言語モデルは意味不明な内容や、一見もっともらしいが不正確または古い情報を生成することがあります。

**コードの適用範囲の制限:** Phi-3の訓練データの大部分はPythonに基づいており、「typing, math, random, collections, datetime, itertools」などの一般的なパッケージを使用しています。モデルが他のパッケージを使ったPythonスクリプトや他言語のスクリプトを生成した場合は、すべてのAPI使用を手動で検証することを強く推奨します。

開発者は責任あるAIのベストプラクティスを適用し、特定のユースケースが関連する法律や規制（例：プライバシー、貿易など）に準拠していることを保証する責任があります。重要な考慮点は以下の通りです：

**割り当て:** モデルは、法的地位や資源、生活機会の割り当てに重大な影響を与える可能性のあるシナリオ（例：住宅、雇用、信用など）には、さらなる評価や追加のバイアス除去技術なしでは適さない場合があります。

**高リスクシナリオ:** 開発者は、不公平、不信頼、または攻撃的な出力が非常に高いコストや害をもたらす可能性のある高リスクシナリオでのモデル使用の適合性を評価すべきです。これには、正確性と信頼性が重要なセンシティブまたは専門的な分野（例：法律相談や健康相談）での助言提供が含まれます。展開環境に応じて、アプリケーションレベルで追加の安全対策を実装する必要があります。

**誤情報:** モデルは不正確な情報を生成することがあります。開発者は透明性のベストプラクティスに従い、エンドユーザーにAIシステムと対話していることを知らせるべきです。アプリケーションレベルでは、ユースケース固有の文脈情報に基づく応答を実現するためのフィードバックメカニズムやパイプライン（Retrieval Augmented Generation（RAG）と呼ばれる技術）を構築できます。

**有害コンテンツの生成:** 開発者は出力の文脈を評価し、利用可能な安全性分類器やユースケースに適したカスタムソリューションを活用すべきです。

**悪用:** 詐欺、スパム、マルウェア生成などの悪用の可能性もあり、開発者は自分のアプリケーションが適用される法律や規制に違反しないようにする責任があります。

### ファインチューニングとAIコンテンツ安全性  

モデルのファインチューニング後は、[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)の機能を活用し、モデルが生成するコンテンツを監視し、潜在的なリスクや脅威、品質問題を特定・ブロックすることを強く推奨します。

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c40507c5e8be556615b8377a63b8764865d057d4faac3757a478.ja.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)はテキストと画像の両方のコンテンツに対応しており、クラウド、切断されたコンテナ、エッジ/組み込みデバイスで展開可能です。

## Azure AI Content Safetyの概要  

Azure AI Content Safetyは万能のソリューションではなく、企業の特定のポリシーに合わせてカスタマイズ可能です。さらに、多言語モデルにより複数の言語を同時に理解できます。

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a56cf708aff010a541799d002ae7ae84bb819b19ab8950591.ja.png)

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5本の動画**

Azure AI Content Safetyサービスは、アプリケーションやサービス内の有害なユーザー生成コンテンツおよびAI生成コンテンツを検出します。テキストと画像のAPIが含まれており、有害または不適切な素材を検出できます。

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**免責事項**：  
本書類はAI翻訳サービス「[Co-op Translator](https://github.com/Azure/co-op-translator)」を使用して翻訳されました。正確性を期しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。原文の言語による文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じた誤解や誤訳について、当方は一切の責任を負いかねます。