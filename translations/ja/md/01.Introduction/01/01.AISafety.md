<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T01:17:07+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ja"
}
-->
# PhiモデルのAI安全性
Phiファミリーのモデルは[Microsoft Responsible AI Standard](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard)に従って開発されました。これは、説明責任、透明性、公平性、信頼性と安全性、プライバシーとセキュリティ、包摂性という6つの原則に基づく全社的な要件群であり、これらは[Microsoft’s Responsible AI principles](https://www.microsoft.com/ai/responsible-ai)を形成します。 

前のPhiモデルと同様に、多面的な安全性評価とポストトレーニングによる安全対策が採用されており、本リリースの多言語対応能力を考慮した追加措置も講じられています。複数言語およびリスクカテゴリにわたるテストを含む当社の安全性トレーニングおよび評価のアプローチは、[Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833)に概説されています。Phiモデルはこのアプローチによる恩恵を受けますが、開発者は特定のユースケースや文化的・言語的文脈に関連するリスクをマッピング、測定、軽減するなど、責任あるAIのベストプラクティスを適用する必要があります。

## ベストプラクティス

他のモデルと同様に、Phiファミリーのモデルは不公平、不信頼、または攻撃的な振る舞いをする可能性があります。

SLMおよびLLMの留意すべき制限的な挙動の一部には次のものが含まれます:

- **Quality of Service:** Phiモデルは主に英語テキストで訓練されています。英語以外の言語は性能が低下する可能性があります。トレーニングデータでの表現が少ない英語のバリエーションは、標準的な米国英語よりも性能が悪くなる可能性があります。
- **Representation of Harms & Perpetuation of Stereotypes:** これらのモデルは、特定の人々のグループを過度にまたは過小に表現したり、あるグループの表現を消してしまったり、侮蔑的または否定的なステレオタイプを強化したりする可能性があります。安全性ポストトレーニングを行っていても、異なるグループの表現度合いや、トレーニングデータに存在する否定的ステレオタイプの例の多さが現実世界のパターンや社会的バイアスを反映しているため、これらの制限は依然として存在するかもしれません。
- **Inappropriate or Offensive Content:** これらのモデルは他の種類の不適切または攻撃的なコンテンツを生成する可能性があり、ユースケース固有の追加的な緩和策がない場合、センシティブな文脈での展開が不適切となることがあります。
情報の信頼性: 言語モデルは意味のないコンテンツや、一見もっともらしく聞こえるが不正確または古い情報を捏造することがあります。
- **Limited Scope for Code:** Majority of Phi-3 training data is based in Python and uses common packages such as "typing, math, random, collections, datetime, itertools". If the model generates Python scripts that utilize other packages or scripts in other languages, we strongly recommend users manually verify all API uses.

開発者は責任あるAIのベストプラクティスを適用するべきであり、特定のユースケースが関連法規（例：プライバシー、貿易など）に準拠していることを確保する責任があります。 

## 責任あるAIに関する考慮事項

他の言語モデルと同様に、Phiシリーズのモデルは不公平、不信頼、または攻撃的な振る舞いをする可能性があります。留意すべき制限的な挙動のいくつかは次のとおりです:

**Quality of Service:** Phiモデルは主に英語テキストで訓練されています。英語以外の言語は性能が低下する可能性があります。トレーニングデータでの表現が少ない英語のバリエーションは、標準的な米国英語よりも性能が悪くなる可能性があります。

**Representation of Harms & Perpetuation of Stereotypes:** これらのモデルは、特定の人々のグループを過度にまたは過小に表現したり、あるグループの表現を消してしまったり、侮蔑的または否定的なステレオタイプを強化したりする可能性があります。安全性ポストトレーニングを行っていても、異なるグループの表現度合いや、トレーニングデータに存在する否定的ステレオタイプの例の多さが現実世界のパターンや社会的バイアスを反映しているため、これらの制限は依然として存在するかもしれません。

**Inappropriate or Offensive Content:** これらのモデルは他の種類の不適切または攻撃的なコンテンツを生成する可能性があり、ユースケース固有の追加的な緩和策がない場合、センシティブな文脈での展開が不適切となることがあります。
情報の信頼性: 言語モデルは意味のないコンテンツや、一見もっともらしく聞こえるが不正確または古い情報を捏造することがあります。

**Limited Scope for Code:** Majority of Phi-3 training data is based in Python and use common packages such as "typing, math, random, collections, datetime, itertools". If the model generates Python scripts that utilize other packages or scripts in other languages, we strongly recommend users manually verify all API uses.

開発者は責任あるAIのベストプラクティスを適用するべきであり、特定のユースケースが関連法規（例：プライバシー、貿易など）に準拠していることを確保する責任があります。考慮すべき重要な領域には以下が含まれます:

**Allocation:** モデルは、法的地位や資源・人生の機会の配分に重要な影響を及ぼす可能性のあるシナリオ（例：住宅、雇用、与信など）には、さらなる評価や追加のデバイアス技術がない限り不適切である可能性があります。

**High-Risk Scenarios:** 開発者は、不公平、不信頼、または攻撃的な出力が非常に高いコストを招いたり害をもたらしたりする可能性のあるハイリスクなシナリオでのモデル使用の適合性を評価する必要があります。これには、正確性と信頼性が極めて重要な専門的な領域（例：法律相談や医療アドバイス）での助言の提供が含まれます。展開文脈に応じてアプリケーションレベルで追加的な安全措置を実装するべきです。

**Misinformation:** モデルは不正確な情報を生成することがあります。開発者は透明性のベストプラクティスに従い、最終ユーザーに対してAIシステムと対話していることを通知するべきです。アプリケーションレベルでは、フィードバック機構やユースケース固有の文脈情報に応答を根ざすためのパイプライン（Retrieval Augmented Generation（RAG）として知られる手法）を構築できます。

**Generation of Harmful Content:** 出力を文脈に応じて評価し、利用可能な安全性分類器やユースケースに適したカスタムソリューションを使って対処するべきです。

**Misuse:** 不正行為、スパム、マルウェア作成などの他の悪用形態が可能であるため、開発者は自分たちのアプリケーションが適用法規に違反していないことを確認する必要があります。

### ファインチューニングとAIコンテンツの安全性

モデルをファインチューニングした後は、生成されたコンテンツを監視し、潜在的なリスク、脅威、および品質問題を特定・ブロックするために、[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)の機能を活用することを強く推奨します。

![Phi3AIセーフティ](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c405.ja.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)はテキストと画像の両方のコンテンツに対応しています。クラウド、切断されたコンテナ、およびエッジ/組み込みデバイスにデプロイできます。

## Azure AI Content Safetyの概要

Azure AI Content Safetyは万能のソリューションではなく、企業の特定のポリシーに合わせてカスタマイズできます。さらに、多言語モデルにより複数の言語を同時に理解することが可能です。

![AIコンテンツセーフティ](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a.ja.png)

- **Azure AI コンテンツセーフティ**
- **Microsoft Developer**
- **5本の動画**

Azure AI Content Safetyサービスは、アプリケーションやサービス内の有害なユーザー生成コンテンツおよびAI生成コンテンツを検出します。これには、有害または不適切な素材を検出するためのテキストおよび画像APIが含まれます。

[AIコンテンツセーフティ プレイリスト](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
免責事項：この文書はAI翻訳サービス「Co-op Translator」（https://github.com/Azure/co-op-translator）を用いて翻訳されました。正確性には努めていますが、自動翻訳には誤りや不正確な箇所が含まれる可能性があります。原文（原言語の文書）を正式な情報源としてご確認ください。重要な内容については、専門の人間による翻訳をお勧めします。本翻訳の使用に起因するいかなる誤解や誤訳についても、当社は責任を負いません。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->