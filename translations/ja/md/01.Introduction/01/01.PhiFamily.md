<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5d936ffe4dfbab2244f6eb21b11f3b3",
  "translation_date": "2025-07-16T18:30:42+00:00",
  "source_file": "md/01.Introduction/01/01.PhiFamily.md",
  "language_code": "ja"
}
-->
# MicrosoftのPhiファミリー

Phiモデルは、同じサイズや一つ上のサイズのモデルを上回る性能を持つ、最も高性能かつコスト効率の良い小型言語モデル（SLM）です。言語、推論、コーディング、音声、視覚、数学の各ベンチマークで優れた結果を示しています。このリリースにより、高品質なモデルの選択肢が拡充され、生成AIアプリケーションの作成や構築により実用的な選択肢を提供します。

Phiファミリーは、Pythonコード生成向けのPhi-1から始まり、テキストおよびチャット補完に基づくPhi-1.5 / 2、Phi-3-mini/small/medium-instruct、Phi-3.5/4-mini-instructへと進化し、視覚向けのPhi-3/3.5-vision、強力な推論に基づくPhi-4、MoE向けのPhi-3.5-MoE、そして現在はフルモーダルモデルのPhi-4-multimodalへと発展しています。高品質なデータセットを通じて、より大きなトレーニングパラメータを持つモデルに匹敵する性能を実現しています。

## Phiファミリーモデル

<div style="font-size:8px">

| Model Card |パラメータ数|コーディング|テキスト/チャット補完|高度な推論|視覚|音声|MoE
| - | -  | - | - |- |- |- |- |
|[Phi-1](https://huggingface.co/microsoft/phi-1)|1.3B| はい| いいえ | いいえ |いいえ |いいえ |いいえ |
|[Phi-1.5](https://huggingface.co/microsoft/phi-1_5)|1.3B| はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-2](https://huggingface.co/microsoft/phi-1_5)|2.7B| はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)<br/>[Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)|3.8B| はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-3-small-8k-instruct](https://huggingface.co/microsoft/Phi-3-small-8k-instruct)<br/>[Phi-3-small-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct)<br/>|7B| はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-3-mediumn-4k-instruct](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)<br>[Phi-3-mediumn-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)|14B|はい|いいえ| いいえ |いいえ |いいえ |いいえ |
|[Phi-3-vision-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)|4.2B|はい|はい|いいえ |いいえ |いいえ |いいえ |
|[Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)|3.8B|はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct)|42B|はい|はい| いいえ |いいえ |いいえ |はい |
|[Phi-3.5-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3.5-vision-instruct)|4.2B|はい|はい| いいえ |はい |いいえ |いいえ |
|[Phi-4](https://huggingface.co/microsoft/phi-4)|14B|はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-4-mini](https://huggingface.co/microsoft/Phi-4-mini-instruct)|3.8B|はい|はい| いいえ |いいえ |いいえ |いいえ |
|[Phi-4-multimodal](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)|5.6B|はい|はい| いいえ |はい |はい |いいえ |
|[Phi-4-reasoning](../../../../../md/01.Introduction/01)|3.8B|はい|はい| はい |いいえ |いいえ |いいえ |
|[Phi-4-mini-reasoning](../../../../../md/01.Introduction/01)|3.8B|はい|はい| はい |いいえ |いいえ |いいえ |

</div>

## **さまざまなモデルプラットフォームでのPhiモデル一覧**

- [Azure AI Foundry Model catalog](https://ai.azure.com/explore/models?selectedCollection=phi)
- [GitHub Models](https://github.com/marketplace?query=Phi&type=models)
- Hugging Face
  - [Phi-1 /1.5](https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572)
  - [Phi-2](https://huggingface.co/microsoft/phi-2)
  - [Phi-3](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)
  - [Phi-4](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4) 
- [NVIDIA NIM](https://build.nvidia.com/search?q=Phi)

## モデル選択の例

| | | | |
|-|-|-|-|
|顧客のニーズ|タスク|おすすめモデル|詳細|
|メッセージのスレッドを簡単に要約したい|会話の要約|Phi-3 / 3.5 テキストモデル|顧客の言語タスクが明確で単純な場合に適しています|
|子ども向けの無料数学チューターアプリ|数学と推論|Phi-3 / 3.5 / 4 テキストモデル|無料アプリのため、継続的なコストがかからないソリューションが求められます|
|自動巡回車のカメラ|視覚解析|Phi-3 /3.5 -Vision または Phi-4-multimodal|インターネットなしでエッジ上で動作する必要があります|
|AIベースの旅行予約エージェントを構築したい|複雑な計画、関数呼び出し、オーケストレーションが必要|GPTモデル|計画立案、API呼び出し、実行が可能である必要があります|
|従業員向けのコパイロットを作りたい|RAG、複数ドメイン、複雑かつオープンエンド|GPTモデル + Phiファミリー|オープンエンドのシナリオで幅広い知識が必要なため、大きなモデルが適しています。知識のチャンク化が必要で、SLMが適している場合もあります|

**免責事項**：  
本書類はAI翻訳サービス「[Co-op Translator](https://github.com/Azure/co-op-translator)」を使用して翻訳されました。正確性の向上に努めておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。原文の言語によるオリジナル文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は責任を負いかねます。