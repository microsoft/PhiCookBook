<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-08T06:16:47+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "ja"
}
-->
# Phi-3をローカルで始める

このガイドでは、Ollamaを使ってPhi-3モデルをローカル環境で実行するための設定方法を説明します。GitHub Codespaces、VS Code Dev Containers、またはローカル環境でモデルを実行するいくつかの方法があります。

## 環境設定

### GitHub Codespaces

GitHub Codespacesを使うことで、このテンプレートをブラウザ上のVS Codeインスタンスで仮想的に実行できます。以下のボタンをクリックすると開きます：

1. テンプレートを開く（数分かかることがあります）：

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. ターミナルウィンドウを開く

### VS Code Dev Containers

⚠️ この方法はDocker Desktopに少なくとも16GBのRAMが割り当てられている場合のみ有効です。16GB未満の場合は、[GitHub Codespacesの方法](../../../../../md/01.Introduction/01)か[ローカル環境の設定](../../../../../md/01.Introduction/01)を試してください。

関連する方法として、VS Code Dev Containersがあります。これは[Dev Containers拡張機能](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)を使ってローカルのVS Codeでプロジェクトを開きます：

1. Docker Desktopを起動（未インストールの場合はインストールしてください）
2. プロジェクトを開く：

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. 開いたVS Codeのウィンドウで、プロジェクトファイルが表示されるまで待つ（数分かかることがあります）、その後ターミナルウィンドウを開く
4. [デプロイ手順](../../../../../md/01.Introduction/01)に進む

### ローカル環境

1. 以下のツールがインストールされていることを確認してください：

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## モデルのテスト

1. Ollamaにphi3:miniモデルのダウンロードと実行を依頼します：

    ```shell
    ollama run phi3:mini
    ```

    モデルのダウンロードには数分かかります。

2. 出力に「success」が表示されたら、そのモデルにプロンプトからメッセージを送信できます。

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. 数秒後、モデルからの応答ストリームが表示されるはずです。

4. 言語モデルで使われるさまざまな技術について学ぶには、Pythonノートブック[ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb)を開き、各セルを実行してください。もし'phi3:mini'以外のモデルを使った場合は、ファイルの先頭にある`MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME`を適宜変更し、システムメッセージの修正やfew-shot例の追加も可能です。

**免責事項**:  
本書類はAI翻訳サービス「Co-op Translator」（https://github.com/Azure/co-op-translator）を使用して翻訳されています。正確性の向上に努めておりますが、自動翻訳には誤りや不正確な表現が含まれる可能性があります。原文の言語による原本が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の使用により生じた誤解や誤訳について、当方は一切の責任を負いかねます。