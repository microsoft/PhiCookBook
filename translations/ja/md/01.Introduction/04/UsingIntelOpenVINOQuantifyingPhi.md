# **Intel OpenVINOã‚’ä½¿ã£ãŸPhi-3.5ã®é‡å­åŒ–**

Intelã¯æœ€ã‚‚ä¼çµ±çš„ãªCPUãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã€å¤šãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒã£ã¦ã„ã¾ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã‚„æ·±å±¤å­¦ç¿’ã®å°é ­ã«ä¼´ã„ã€Intelã‚‚AIã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç«¶äº‰ã«å‚å…¥ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«æ¨è«–ã«ãŠã„ã¦ã€Intelã¯GPUã‚„CPUã ã‘ã§ãªãã€NPUã‚‚æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚

ç§ãŸã¡ã¯Phi-3.xãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’ã‚¨ãƒƒã‚¸å´ã«å±•é–‹ã—ã€AI PCã‚„Copilot PCã®æœ€é‡è¦éƒ¨åˆ†ã«ãªã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚ã‚¨ãƒƒã‚¸å´ã§ã®ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¯ã€ã•ã¾ã–ã¾ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å”åŠ›ã«ä¾å­˜ã—ã¦ã„ã¾ã™ã€‚æœ¬ç« ã§ã¯ä¸»ã«Intel OpenVINOã‚’ç”¨ã„ãŸé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®é©ç”¨ã‚·ãƒŠãƒªã‚ªã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚

## **OpenVINOã¨ã¯**

OpenVINOã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰ã‚¨ãƒƒã‚¸ã¾ã§ã®æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–ã¨å±•é–‹ã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã§ã™ã€‚PyTorchã€TensorFlowã€ONNXãªã©ã®äººæ°—ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã€ç”ŸæˆAIã€å‹•ç”»ã€éŸ³å£°ã€è¨€èªãªã©å¤šæ§˜ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§æ·±å±¤å­¦ç¿’æ¨è«–ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›ã¨æœ€é©åŒ–ã‚’è¡Œã„ã€IntelÂ®ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚„ç’°å¢ƒã®çµ„ã¿åˆã‚ã›ã§ã€ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ã‚„ãƒ‡ãƒã‚¤ã‚¹ä¸Šã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚„ã‚¯ãƒ©ã‚¦ãƒ‰ã§å±•é–‹å¯èƒ½ã§ã™ã€‚

OpenVINOã‚’ä½¿ãˆã°ã€Intelãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ä¸Šã§GenAIãƒ¢ãƒ‡ãƒ«ã‚’ç´ æ—©ãé‡å­åŒ–ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ–ãŒå¯èƒ½ã§ã™ã€‚

ç¾åœ¨ã€OpenVINOã¯Phi-3.5-Visionã¨Phi-3.5 Instructã®é‡å­åŒ–å¤‰æ›ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

### **ç’°å¢ƒæ§‹ç¯‰**

ä»¥ä¸‹ã®ç’°å¢ƒä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯requirement.txtã§ã™ã€‚

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **OpenVINOã‚’ä½¿ã£ãŸPhi-3.5-Instructã®é‡å­åŒ–**

ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **OpenVINOã‚’ä½¿ã£ãŸPhi-3.5-Visionã®é‡å­åŒ–**

Pythonã¾ãŸã¯Jupyter labã§ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ğŸ¤– Intel OpenVINOå¯¾å¿œPhi-3.5ã®ã‚µãƒ³ãƒ—ãƒ«**

| ãƒ©ãƒœ    | èª¬æ˜ | ç§»å‹• |
| -------- | ------- |  ------- |
| ğŸš€ Lab-Introduce Phi-3.5 Instruct  | AI PCã§Phi-3.5 Instructã®ä½¿ã„æ–¹ã‚’å­¦ã¶    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| ğŸš€ Lab-Introduce Phi-3.5 Vision (ç”»åƒ) | AI PCã§Phi-3.5 Visionã‚’ä½¿ã£ã¦ç”»åƒè§£æã‚’å­¦ã¶      |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| ğŸš€ Lab-Introduce Phi-3.5 Vision (å‹•ç”»)   | AI PCã§Phi-3.5 Visionã‚’ä½¿ã£ã¦å‹•ç”»è§£æã‚’å­¦ã¶    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |



## **å‚è€ƒè³‡æ–™**

1. Intel OpenVINOã«ã¤ã„ã¦è©³ã—ãã¯ã“ã¡ã‚‰ [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHubãƒªãƒã‚¸ãƒˆãƒª [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**å…è²¬äº‹é …**ï¼š  
æœ¬æ›¸é¡ã¯AIç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹ã€Œ[Co-op Translator](https://github.com/Azure/co-op-translator)ã€ã‚’ä½¿ç”¨ã—ã¦ç¿»è¨³ã•ã‚Œã¾ã—ãŸã€‚æ­£ç¢ºæ€§ã‚’æœŸã—ã¦ãŠã‚Šã¾ã™ãŒã€è‡ªå‹•ç¿»è¨³ã«ã¯èª¤ã‚Šã‚„ä¸æ­£ç¢ºãªéƒ¨åˆ†ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚åŸæ–‡ã®è¨€èªã«ã‚ˆã‚‹ã‚ªãƒªã‚¸ãƒŠãƒ«æ–‡æ›¸ãŒæ­£å¼ãªæƒ…å ±æºã¨ã¿ãªã•ã‚Œã‚‹ã¹ãã§ã™ã€‚é‡è¦ãªæƒ…å ±ã«ã¤ã„ã¦ã¯ã€å°‚é–€ã®äººé–“ã«ã‚ˆã‚‹ç¿»è¨³ã‚’æ¨å¥¨ã—ã¾ã™ã€‚æœ¬ç¿»è¨³ã®åˆ©ç”¨ã«ã‚ˆã‚Šç”Ÿã˜ãŸã„ã‹ãªã‚‹èª¤è§£ã‚„èª¤è¨³ã«ã¤ã„ã¦ã‚‚ã€å½“æ–¹ã¯è²¬ä»»ã‚’è² ã„ã‹ã­ã¾ã™ã€‚