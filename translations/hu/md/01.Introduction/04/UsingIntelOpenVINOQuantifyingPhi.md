<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3139a6a82f357a9f90f1fe51c4caf65a",
  "translation_date": "2025-05-09T14:01:39+00:00",
  "source_file": "md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "hu"
}
-->
# **Phi-3.5 kvant√°l√°sa Intel OpenVINO haszn√°lat√°val**

Az Intel a legismertebb CPU gy√°rt√≥, sok felhaszn√°l√≥val. A g√©pi tanul√°s √©s a m√©lytanul√°s t√©rnyer√©s√©vel az Intel is bekapcsol√≥dott az AI gyors√≠t√°s verseny√©be. A modell inferencia sor√°n az Intel nem csak GPU-kat √©s CPU-kat haszn√°l, hanem NPU-kat is.

C√©lunk, hogy a Phi-3.x csal√°dot az √©l≈ë oldalon telep√≠ts√ºk, √©s ez√°ltal az AI PC √©s Copilot PC legfontosabb r√©sz√©v√© v√°ljunk. A modell bet√∂lt√©se az √©l≈ë oldalon k√ºl√∂nb√∂z≈ë hardvergy√°rt√≥k egy√ºttm≈±k√∂d√©s√©t≈ël f√ºgg. Ez a fejezet els≈ësorban az Intel OpenVINO kvant√°lt modell alkalmaz√°si eset√©re f√≥kusz√°l.

## **Mi az OpenVINO**

Az OpenVINO egy ny√≠lt forr√°sk√≥d√∫ eszk√∂zk√©szlet, amely a m√©lytanul√°si modellek optimaliz√°l√°s√°t √©s telep√≠t√©s√©t teszi lehet≈ëv√© a felh≈ët≈ël az √©l≈ë eszk√∂z√∂kig. Gyors√≠tja a m√©lytanul√°si inferenci√°t k√ºl√∂nb√∂z≈ë felhaszn√°l√°si ter√ºleteken, mint p√©ld√°ul generat√≠v AI, vide√≥, hang √©s nyelv, n√©pszer≈± keretrendszerekb≈ël sz√°rmaz√≥ modellekkel, mint a PyTorch, TensorFlow, ONNX √©s m√°sok. Lehet≈ëv√© teszi a modellek √°talak√≠t√°s√°t √©s optimaliz√°l√°s√°t, valamint telep√≠t√©s√©t Intel¬Æ hardvereken √©s k√ºl√∂nb√∂z≈ë k√∂rnyezetekben, helyben vagy eszk√∂z√∂n, b√∂ng√©sz≈ëben vagy felh≈ëben.

Most az OpenVINO seg√≠ts√©g√©vel gyorsan kvant√°lhatod a GenAI modellt Intel hardveren, √©s felgyors√≠thatod a modell referenci√°t.

Jelenleg az OpenVINO t√°mogatja a Phi-3.5-Vision √©s Phi-3.5 Instruct kvant√°l√°si √°talak√≠t√°s√°t.

### **K√∂rnyezeti be√°ll√≠t√°s**

K√©rj√ºk, gy≈ëz≈ëdj meg r√≥la, hogy az al√°bbi k√∂rnyezeti f√ºgg≈ës√©gek telep√≠tve vannak, ez a requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Phi-3.5-Instruct kvant√°l√°sa OpenVINO-val**

Termin√°lban futtasd ezt a szkriptet

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Phi-3.5-Vision kvant√°l√°sa OpenVINO-val**

Futtasd ezt a szkriptet Pythonban vagy Jupyter labban

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ü§ñ Phi-3.5 mint√°k Intel OpenVINO-val**

| Laborok | Bemutat√°s | Ind√≠t√°s |
| -------- | ------- | ------- |
| üöÄ Lab-Introduce Phi-3.5 Instruct  | Tanuld meg, hogyan haszn√°ld a Phi-3.5 Instructot az AI PC-den    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| üöÄ Lab-Introduce Phi-3.5 Vision (k√©p) | Tanuld meg, hogyan elemezheted a k√©peket Phi-3.5 Vision seg√≠ts√©g√©vel az AI PC-den      |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| üöÄ Lab-Introduce Phi-3.5 Vision (vide√≥)   | Tanuld meg, hogyan elemezheted a vide√≥kat Phi-3.5 Vision seg√≠ts√©g√©vel az AI PC-den    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |


## **Forr√°sok**

1. Tudj meg t√∂bbet az Intel OpenVINO-r√≥l [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub Repo [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Jogi nyilatkozat**:  
Ezt a dokumentumot az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel ford√≠tottuk. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n javasolt szakmai, emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get az ebb≈ël a ford√≠t√°sb√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.