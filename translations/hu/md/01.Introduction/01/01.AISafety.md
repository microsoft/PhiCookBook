<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T09:28:12+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "hu"
}
-->
# AI biztonság a Phi modellekhez
A Phi modellek családja a [Microsoft Felelős AI Szabvány](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard) szerint lett fejlesztve, amely egy vállalati szintű követelményrendszer a következő hat alapelv alapján: elszámoltathatóság, átláthatóság, méltányosság, megbízhatóság és biztonság, adatvédelem és biztonság, valamint befogadás, amelyek a [Microsoft Felelős AI alapelveit](https://www.microsoft.com/ai/responsible-ai) alkotják.

A korábbi Phi modellekhez hasonlóan egy többoldalú biztonsági értékelést és biztonsági utóképzési megközelítést alkalmaztunk, további intézkedésekkel a kiadás többnyelvű képességeinek figyelembevételére. Biztonsági képzésünket és értékeléseinket, beleértve a több nyelven és kockázati kategóriákon átívelő teszteket, a [Phi Biztonsági utóképzési dokumentumban](https://arxiv.org/abs/2407.13833) foglaltuk össze. Bár a Phi modellek előnyt élveznek ebből a megközelítésből, a fejlesztőknek a felelős AI legjobb gyakorlatait kell alkalmazniuk, beleértve a kockázatok feltérképezését, mérését és csökkentését az adott felhasználási esetük és kulturális, nyelvi kontextusuk szerint.

## Legjobb gyakorlatok

Más modellekhez hasonlóan a Phi modellek családja potenciálisan méltánytalan, megbízhatatlan vagy sértő módokon viselkedhet.

Néhány korlátozó viselkedés, amire ügyelni kell az SLM és LLM esetében:

- **Szolgáltatás minősége:** A Phi modelleket elsősorban angol szövegeken képezték. Az angoltól eltérő nyelveken rosszabb teljesítmény érhető el. Az olyan angol nyelvváltozatok, amelyek kevesebb képviselettel bírnak a képzési adatokban, rosszabb teljesítményt nyújthatnak, mint a szabványos amerikai angol.
- **Ártalmak megjelenítése és sztereotípiák fenntartása:** Ezek a modellek túl- vagy alulreprezentálhatnak csoportokat, eltörölhetnek bizonyos csoportok képviseletét, vagy megerősíthetnek lealacsonyító vagy negatív sztereotípiákat. A biztonsági utóképzés ellenére ezek a korlátok még mindig jelen lehetnek a csoportok eltérő képviselete vagy a képzési adatokban előforduló negatív sztereotípiák példáinak előfordulási gyakorisága miatt, amelyek a valós mintákat és társadalmi előítéleteket tükrözik.
- **Nem megfelelő vagy sértő tartalom:** Ezek a modellek más típusú nem megfelelő vagy sértő tartalmakat is előállíthatnak, ami miatt érzékeny kontextusban történő alkalmazásuk nem megfelelő lehet további, az adott felhasználási esetre szabott enyhítő intézkedések nélkül.
Információ megbízhatósága: A nyelvi modellek értelmetlen tartalmat vagy olyan tartalmat generálhatnak, amely ésszerűnek hangzik, de pontatlan vagy elavult.
- **Kód korlátozott hatóköre:** A Phi-3 képzési adatainak többsége Python alapú, és általános csomagokat használ, mint például "typing, math, random, collections, datetime, itertools". Ha a modell más csomagokat vagy más nyelveken írt szkripteket generál, erősen javasoljuk, hogy a felhasználók minden API-használatot manuálisan ellenőrizzenek.

A fejlesztőknek a felelős AI legjobb gyakorlatait kell alkalmazniuk, és felelősek azért, hogy az adott felhasználási eset megfeleljen a vonatkozó törvényeknek és szabályozásoknak (pl. adatvédelem, kereskedelem stb.).

## Felelős AI megfontolások

Más nyelvi modellekhez hasonlóan, a Phi sorozat modellek potenciálisan méltánytalan, megbízhatatlan vagy sértő módon viselkedhetnek. Néhány figyelembe veendő korlátozó viselkedés:

**Szolgáltatás minősége:** A Phi modelleket elsősorban angol szövegen képezték. Az angoltól eltérő nyelveken rosszabb teljesítmény várható. Az angol nyelvjárások, amelyek kevesebb képviselettel rendelkeznek a képzési adatban, rosszabb teljesítményt mutathatnak, mint a szabványos amerikai angol.

**Ártalmak megjelenítése és sztereotípiák fenntartása:** Ezek a modellek túl- vagy alulreprezentálhatnak csoportokat, megszüntethetik bizonyos csoportok képviseletét, vagy megerősíthetnek megalázó vagy negatív sztereotípiákat. A biztonsági utóképzés ellenére ezek a korlátok még jelen lehetnek a csoportok eltérő képviselete vagy a képzési adatokban szereplő negatív sztereotípiák előfordulása miatt, amelyek a valós mintákat és társadalmi előítéleteket tükrözik.

**Nem megfelelő vagy sértő tartalom:** Ezek a modellek más típusú nem megfelelő vagy sértő tartalmakat is előállíthatnak, ami miatt érzékeny kontextusra nem megfelelőek további, az adott felhasználási esetre szabott enyhítő intézkedések nélkül.
Információ megbízhatósága: A nyelvi modellek értelmetlen vagy szokatlan tartalmakat generálhatnak, amelyek ésszerűnek hangzanak, de pontatlanok vagy elavultak.

**Kód korlátozott hatóköre:** A Phi-3 tréning adatainak többsége Python alapú, és olyan közös csomagokat használ, mint "typing, math, random, collections, datetime, itertools". Ha a modell más csomagokat vagy más nyelveken írt szkripteket generál, erősen ajánlott, hogy a felhasználók manuálisan ellenőrizzék az összes API-hívást.

A fejlesztőknek a felelős AI legjobb gyakorlatait kell alkalmazniuk, és felelősek az adott felhasználási eset jogszabályi és szabályozási megfelelőségéért (pl. adatvédelem, kereskedelem stb.). Fontos szempontok:

**Erőforrás-elosztás:** A modellek nem biztos, hogy alkalmasak olyan helyzetekben, amelyek jogi státuszra vagy erőforrások vagy életlehetőségek (pl. lakhatás, foglalkoztatás, hitel stb.) elosztására gyakorolhatnak következményes hatást, további értékelések és plusz torzításcsökkentő technikák nélkül.

**Nagy kockázatú helyzetek:** A fejlesztőknek értékelniük kell a modellek alkalmasságát nagy kockázatú helyzetekben, ahol a méltánytalan, megbízhatatlan vagy sértő kimenetek rendkívül költségesek lehetnek vagy károkat okozhatnak. Ez magában foglalja az érzékeny vagy szakértői területeken adott tanácsadást, ahol a pontosság és megbízhatóság kritikus (pl. jogi vagy egészségügyi tanácsadás). További védelmeket kell alkalmazni az alkalmazás szintjén a telepítési kontextus szerint.

**Hamis információk:** A modellek pontatlan információkat állíthatnak elő. A fejlesztőknek követniük kell az átláthatóság legjobb gyakorlatait, és tájékoztatniuk kell a végfelhasználókat arról, hogy AI rendszerrel kommunikálnak. Az alkalmazás szintjén a fejlesztők visszacsatolási mechanizmusokat és adatfolyamokat építhetnek ki, hogy az válaszok az adott használati esethez és kontextushoz igazodjanak, amit Retrieval Augmented Generation (RAG) technikának neveznek.

**Ártalmas tartalom generálása:** A fejlesztőknek értékelniük kell a kimeneteket a kontextusukban, és használniuk kell a rendelkezésre álló biztonsági osztályozókat vagy az adott felhasználási esethez alkalmazkodó egyedi megoldásokat.

**Visszaélés:** Más visszaélések, mint például csalás, spam vagy rosszindulatú szoftver előállítása is előfordulhat, és a fejlesztőknek biztosítani kell, hogy alkalmazásaik ne sértsék a vonatkozó törvényeket és szabályozásokat.

### Finomhangolás és AI tartalombiztonság

Egy modell finomhangolása után erősen ajánljuk az [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) intézkedések használatát a modellek által generált tartalom megfigyelésére, a potenciális kockázatok, fenyegetések és minőségi problémák azonosítására és blokkolására.

![Phi3AISafety](../../../../../translated_images/hu/01.phi3aisafety.c0d7fc42f5a5c405.png)

Az [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) támogatja mind a szöveges, mind a képi tartalmakat. Felhőben, leválasztott konténerekben, illetve élő/ beágyazott eszközökön is telepíthető.

## Az Azure AI Content Safety áttekintése

Az Azure AI Content Safety nem egy mindenre jó megoldás; testre szabható, hogy igazodjon az üzleti specifikus irányelvekhez. Többnyelvű modelljeinek köszönhetően egyszerre több nyelvet is megért.

![AIContentSafety](../../../../../translated_images/hu/01.AIcontentsafety.a288819b8ce8da1a.png)

- **Azure AI Content Safety**
- **Microsoft fejlesztő**
- **5 videó**

Az Azure AI Content Safety szolgáltatás érzékeli a káros, felhasználó által generált és AI által előállított tartalmakat alkalmazásokban és szolgáltatásokban. Szöveg- és képi API-kat tartalmaz, amelyek lehetővé teszik káros vagy nem megfelelő anyagok felismerését.

[AI Content Safety lejátszási lista](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Jogi nyilatkozat**:
Ezt a dokumentumot az AI fordító szolgáltatás [Co-op Translator](https://github.com/Azure/co-op-translator) használatával fordítottuk. Bár a pontosságra törekszünk, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. A dokumentum eredeti, anyanyelvi változatát tekintse a hiteles forrásnak. Fontos információk esetén javasolt szakember által végzett emberi fordítás igénybevétele. Nem vállalunk felelősséget semmilyen félreértésért vagy téves értelmezésért, amely e fordítás használatából ered.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->