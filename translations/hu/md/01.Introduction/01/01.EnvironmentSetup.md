<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:16:18+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "hu"
}
-->
# Kezdj el dolgozni a Phi-3-mal helyben

Ez az útmutató segít beállítani a helyi környezetedet a Phi-3 modell futtatásához Ollama használatával. Többféleképpen is futtathatod a modellt, például GitHub Codespaces, VS Code Dev Containers vagy a helyi környezeted segítségével.

## Környezet beállítása

### GitHub Codespaces

Virtuálisan is futtathatod ezt a sablont a GitHub Codespaces használatával. A gomb megnyit egy böngészőalapú VS Code példányt:

1. Nyisd meg a sablont (ez néhány percet igénybe vehet):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Nyiss egy terminálablakot

### VS Code Dev Containers

⚠️ Ez az opció csak akkor működik, ha a Docker Desktop legalább 16 GB RAM-ot kapott. Ha kevesebb mint 16 GB RAM áll rendelkezésedre, próbáld meg a [GitHub Codespaces opciót](../../../../../md/01.Introduction/01) vagy [állítsd be helyben](../../../../../md/01.Introduction/01).

Egy kapcsolódó lehetőség a VS Code Dev Containers, amely megnyitja a projektet a helyi VS Code-ban a [Dev Containers bővítmény](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) segítségével:

1. Indítsd el a Docker Desktopot (telepítsd, ha még nincs)
2. Nyisd meg a projektet:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. A megnyíló VS Code ablakban, miután megjelentek a projekt fájljai (ez néhány percet igénybe vehet), nyiss egy terminálablakot.
4. Folytasd a [telepítési lépésekkel](../../../../../md/01.Introduction/01)

### Helyi környezet

1. Győződj meg róla, hogy a következő eszközök telepítve vannak:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## A modell tesztelése

1. Kérd meg Ollamát, hogy töltse le és futtassa a phi3:mini modellt:

    ```shell
    ollama run phi3:mini
    ```

    A modell letöltése pár percet vesz igénybe.

2. Amikor a kimenetben megjelenik a "success", küldhetsz üzenetet a modellnek a promptból.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Néhány másodperc múlva látnod kell a modell válaszfolyamát.

4. Ha szeretnél többet megtudni a nyelvi modellekkel kapcsolatos különféle technikákról, nyisd meg a Python jegyzetfüzetet [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb), és futtass minden cellát. Ha nem a 'phi3:mini' modellt használtad, a fájl tetején szükség szerint módosítsd a `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` értékét, továbbá megváltoztathatod a rendszerüzenetet vagy hozzáadhatsz néhány példát is, ha szeretnéd.

**Jogi nyilatkozat**:  
Ez a dokumentum az AI fordító szolgáltatás [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével készült. Bár igyekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum anyanyelvén tekintendő hiteles forrásnak. Fontos információk esetén javasolt professzionális, emberi fordítást igénybe venni. Nem vállalunk felelősséget az ebből eredő félreértésekért vagy téves értelmezésekért.