<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:11:55+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "hu"
}
-->
# Kezdj el dolgozni a Phi-3-mal helyben

Ez az útmutató segít beállítani a helyi környezetedet, hogy futtathasd a Phi-3 modellt Ollama segítségével. Többféleképpen is futtathatod a modellt, például GitHub Codespaces, VS Code Dev Containers vagy a helyi környezeted használatával.

## Környezet beállítása

### GitHub Codespaces

Virtuálisan is futtathatod ezt a sablont a GitHub Codespaces használatával. A gomb megnyit egy böngészőben futó webes VS Code példányt:

1. Nyisd meg a sablont (ez néhány percet igénybe vehet):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Nyiss egy terminálablakot

### VS Code Dev Containers

⚠️ Ez az opció csak akkor működik, ha a Docker Desktop legalább 16 GB RAM-ot kapott. Ha kevesebb, mint 16 GB RAM áll rendelkezésedre, próbáld meg a [GitHub Codespaces opciót](../../../../../md/01.Introduction/01) vagy [állítsd be helyben](../../../../../md/01.Introduction/01).

Egy kapcsolódó lehetőség a VS Code Dev Containers, amely megnyitja a projektet a helyi VS Code-ban a [Dev Containers bővítmény](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) segítségével:

1. Indítsd el a Docker Desktopot (ha még nincs telepítve, telepítsd)
2. Nyisd meg a projektet:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. A megnyíló VS Code ablakban, amikor megjelennek a projekt fájljai (ez néhány percet vehet igénybe), nyiss egy terminálablakot.
4. Folytasd a [telepítési lépésekkel](../../../../../md/01.Introduction/01)

### Helyi környezet

1. Győződj meg róla, hogy a következő eszközök telepítve vannak:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## A modell tesztelése

1. Kérd meg Ollamát, hogy töltse le és futtassa a phi3:mini modellt:

    ```shell
    ollama run phi3:mini
    ```

    A modell letöltése néhány percet vesz igénybe.

2. Amikor a kimenetben megjelenik a "success", küldhetsz üzenetet a modellnek a promptból.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Néhány másodperc múlva meg kell jelennie a modell válaszfolyamának.

4. Ha meg szeretnéd ismerni a nyelvi modellekkel kapcsolatos különböző technikákat, nyisd meg a Python jegyzetfüzetet [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) és futtass minden cellát. Ha nem a 'phi3:mini' modellt használtad, módosítsd a `MODEL_NAME` értékét az első cellában.

5. Ha szeretnél beszélgetni a phi3:mini modellel Pythonból, nyisd meg a [chat.py](../../../../../code/01.Introduce/chat.py) Python fájlt és futtasd. A fájl tetején szükség szerint módosíthatod a `MODEL_NAME` értékét, valamint a rendszerüzenetet vagy hozzáadhatsz néhány példát (few-shot) is, ha szeretnéd.

**Jogi nyilatkozat**:  
Ez a dokumentum az AI fordító szolgáltatás, a [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével készült. Bár a pontosságra törekszünk, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az anyanyelvén tekintendő hiteles forrásnak. Fontos információk esetén szakmai, emberi fordítást javaslunk. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy téves értelmezésekért.