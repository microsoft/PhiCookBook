<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-07-17T04:28:19+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/Apple/02.PromptflowWithMLX.md",
  "language_code": "hu"
}
-->
# **2. labor - Prompt flow futtatása Phi-3-mini modellel az AIPC-ben**

## **Mi az a Prompt flow**

A Prompt flow egy fejlesztői eszközkészlet, amely az LLM-alapú AI alkalmazások teljes fejlesztési ciklusát egyszerűsíti, az ötleteléstől, prototípus készítésen, tesztelésen, értékelésen át a termelési bevezetésig és monitorozásig. Megkönnyíti a prompt mérnöki munkát, és lehetővé teszi, hogy professzionális minőségű LLM alkalmazásokat építs.

A Prompt flow segítségével képes leszel:

- Olyan folyamatokat létrehozni, amelyek összekapcsolják az LLM-eket, promptokat, Python kódot és egyéb eszközöket egy futtatható munkafolyamatba.

- Könnyedén hibakeresni és iterálni a folyamataidat, különösen az LLM-ekkel való interakciókat.

- Értékelni a folyamataidat, minőségi és teljesítmény mutatókat számolni nagyobb adathalmazokon.

- Integrálni a tesztelést és értékelést a CI/CD rendszeredbe a folyamat minőségének biztosítása érdekében.

- Kiválasztott kiszolgáló platformra telepíteni a folyamataidat, vagy egyszerűen beépíteni az alkalmazásod kódjába.

- (Opcionális, de erősen ajánlott) Csapatoddal együttműködni a Prompt flow Azure AI felhő verziójának használatával.



## **Generációs kódfolyamatok építése Apple Siliconon**

***Megjegyzés***: Ha még nem végezted el a környezet telepítését, kérjük, látogass el a [Lab 0 - Telepítések](./01.Installations.md) oldalra.

1. Nyisd meg a Prompt flow bővítményt a Visual Studio Code-ban, és hozz létre egy üres flow projektet

![create](../../../../../../../../../translated_images/pf_create.bde888dc83502eba082a058175bbf1eee6791219795393a386b06fd3043ec54d.hu.png)

2. Adj hozzá bemeneti és kimeneti paramétereket, majd adj hozzá Python kódot új flow-ként

![flow](../../../../../../../../../translated_images/pf_flow.520824c0969f2a94f17e947f86bdc4b4c6c88a2efa394fe3bcfb58c0dbc578a7.hu.png)


A flow felépítéséhez hivatkozhatsz erre a struktúrára (flow.dag.yaml)

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. Kvantáld a phi-3-mini modellt

Célunk, hogy az SLM-et helyi eszközökön jobban futtassuk. Általában a modellt kvantáljuk (INT4, FP16, FP32)


```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Megjegyzés:** az alapértelmezett mappa a mlx_model

4. Adj hozzá kódot a ***Chat_With_Phi3.py*** fájlba


```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. A flow-t tesztelheted Debug vagy Run módban, hogy ellenőrizd, megfelelően generál-e kódot

![RUN](../../../../../../../../../translated_images/pf_run.4239e8a0b420a58284edf6ee1471c1697c345670313c8e7beac0edaee15b9a9d.hu.png)

5. Futtasd a flow-t fejlesztői API-ként a terminálban

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Tesztelheted Postman-ben vagy Thunder Client-ben


### **Megjegyzés**

1. Az első futtatás hosszabb ideig tart. Ajánlott a phi-3 modellt a Hugging face CLI segítségével letölteni.

2. Az Intel NPU korlátozott számítási kapacitása miatt ajánlott a Phi-3-mini-4k-instruct használata.

3. Az INT4 konverzió kvantálásához Intel NPU gyorsítást használunk, de ha újraindítod a szolgáltatást, törölnöd kell a cache és nc_workshop mappákat.



## **Források**

1. Ismerd meg a Promptflow-t [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Ismerd meg az Intel NPU gyorsítást [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Minta kód, letöltés [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**Jogi nyilatkozat**:  
Ez a dokumentum az AI fordító szolgáltatás, a [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével készült. Bár a pontosságra törekszünk, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az anyanyelvén tekintendő hiteles forrásnak. Fontos információk esetén szakmai, emberi fordítást javaslunk. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy téves értelmezésekért.