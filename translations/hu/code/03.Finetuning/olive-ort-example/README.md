<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:33:51+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "hu"
}
-->
# Phi3 finomhangol√°sa Olive-dal

Ebben a p√©ld√°ban az Olive seg√≠ts√©g√©vel:

1. Finomhangolunk egy LoRA adaptert, hogy a kifejez√©seket Sad, Joy, Fear, Surprise kateg√≥ri√°kba sorolja.
1. Egyes√≠tj√ºk az adapter s√∫lyait az alapmodellbe.
1. Optimaliz√°ljuk √©s kvant√°ljuk a modellt `int4` form√°tumba.

Megmutatjuk azt is, hogyan lehet az ONNX Runtime (ORT) Generate API seg√≠ts√©g√©vel lek√©rdezni a finomhangolt modellt.

> **‚ö†Ô∏è Finomhangol√°shoz megfelel≈ë GPU sz√ºks√©ges, p√©ld√°ul A10, V100, A100.**

## üíæ Telep√≠t√©s

Hozz l√©tre egy √∫j Python virtu√°lis k√∂rnyezetet (p√©ld√°ul `conda` haszn√°lat√°val):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ezut√°n telep√≠tsd az Olive-t √©s a finomhangol√°shoz sz√ºks√©ges f√ºgg≈ës√©geket:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Phi3 finomhangol√°sa Olive-dal
Az [Olive konfigur√°ci√≥s f√°jl](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) egy *workflow*-t tartalmaz a k√∂vetkez≈ë *l√©p√©sekkel*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

Magyar√°n a folyamat:

1. Finomhangolja a Phi3-at (150 l√©p√©sig, amit m√≥dos√≠thatsz) a [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) adatok alapj√°n.
1. Egyes√≠ti a LoRA adapter s√∫lyait az alapmodellbe, √≠gy egyetlen ONNX form√°tum√∫ modell j√∂n l√©tre.
1. A Model Builder optimaliz√°lja a modellt az ONNX runtime-hoz *√©s* kvant√°lja `int4` form√°tumba.

A workflow futtat√°s√°hoz haszn√°ld:

```bash
olive run --config phrase-classification.json
```

Amikor az Olive befejezte, az optimaliz√°lt `int4` finomhangolt Phi3 modell el√©rhet≈ë itt: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Finomhangolt Phi3 integr√°l√°sa az alkalmaz√°sodba

Az alkalmaz√°s futtat√°s√°hoz:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

A v√°lasznak egyetlen sz√≥ szerinti oszt√°lyoz√°snak kell lennie a kifejez√©sre (Sad/Joy/Fear/Surprise).

**Felel≈ëss√©gkiz√°r√°s**:  
Ezt a dokumentumot az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel ford√≠tottuk le. B√°r az pontoss√°gra t√∂reksz√ºnk, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok tartalmazhatnak hib√°kat vagy pontatlans√°gokat. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hivatalos forr√°snak. Kritikus inform√°ci√≥k eset√©n szakmai, emberi ford√≠t√°st javasolunk. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy f√©lre√©rtelmez√©sek√©rt.