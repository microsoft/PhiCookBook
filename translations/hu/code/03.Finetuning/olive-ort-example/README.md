<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-07-16T16:05:25+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "hu"
}
-->
# Phi3 finomhangol√°sa Olive seg√≠ts√©g√©vel

Ebben a p√©ld√°ban az Olive-t fogod haszn√°lni, hogy:

1. Finomhangolj egy LoRA adaptert, amely a kifejez√©seket Sad, Joy, Fear, Surprise kateg√≥ri√°kba sorolja.
1. Egyes√≠tsd az adapter s√∫lyait az alapmodellbe.
1. Optimaliz√°ld √©s kvant√°ld a modellt `int4` form√°tumba.

Megmutatjuk azt is, hogyan lehet a finomhangolt modellt az ONNX Runtime (ORT) Generate API seg√≠ts√©g√©vel haszn√°lni.

> **‚ö†Ô∏è A finomhangol√°shoz megfelel≈ë GPU sz√ºks√©ges ‚Äì p√©ld√°ul A10, V100, A100.**

## üíæ Telep√≠t√©s

Hozz l√©tre egy √∫j Python virtu√°lis k√∂rnyezetet (p√©ld√°ul `conda` haszn√°lat√°val):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ezut√°n telep√≠tsd az Olive-t √©s a finomhangol√°shoz sz√ºks√©ges f√ºgg≈ës√©geket:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Phi3 finomhangol√°sa Olive seg√≠ts√©g√©vel
Az [Olive konfigur√°ci√≥s f√°jl](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) egy *workflow*-t tartalmaz a k√∂vetkez≈ë *l√©p√©sekkel*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

Magas szinten ez a folyamat a k√∂vetkez≈ëket v√©gzi el:

1. Finomhangolja a Phi3-at (150 l√©p√©sig, amit m√≥dos√≠thatsz) a [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) adatok alapj√°n.
1. Egyes√≠ti a LoRA adapter s√∫lyait az alapmodellbe. √çgy egyetlen ONNX form√°tum√∫ modell √°ll majd rendelkez√©sre.
1. A Model Builder optimaliz√°lja a modellt az ONNX runtime-hoz *√©s* kvant√°lja `int4` form√°tumba.

A workflow futtat√°s√°hoz haszn√°ld a k√∂vetkez≈ët:

```bash
olive run --config phrase-classification.json
```

Amikor az Olive befejezte, az optimaliz√°lt, `int4` finomhangolt Phi3 modell el√©rhet≈ë itt: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª A finomhangolt Phi3 integr√°l√°sa az alkalmaz√°sodba

Az alkalmaz√°s futtat√°s√°hoz:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

A v√°lasznak egyetlen sz√≥ szerinti oszt√°lyoz√°snak kell lennie a kifejez√©sre (Sad/Joy/Fear/Surprise).

**Jogi nyilatkozat**:  
Ez a dokumentum az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel k√©sz√ºlt. B√°r a pontoss√°gra t√∂reksz√ºnk, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n szakmai, emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get az ebb≈ël a ford√≠t√°sb√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.