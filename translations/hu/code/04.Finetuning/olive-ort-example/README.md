<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:46:48+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "hu"
}
-->
# Fine-tune Phi3 Olive haszn√°lat√°val

Ebben a p√©ld√°ban az Olive seg√≠ts√©g√©vel:

1. Finomhangolunk egy LoRA adaptert, hogy a kifejez√©seket Sad, Joy, Fear, Surprise kateg√≥ri√°kba sorolja.
1. Egyes√≠tj√ºk az adapter s√∫lyait az alapmodellbe.
1. Optimaliz√°ljuk √©s kvant√°ljuk a modellt `int4` form√°tumba.

Megmutatjuk azt is, hogyan lehet az ONNX Runtime (ORT) Generate API seg√≠ts√©g√©vel lek√©rdezni a finomhangolt modellt.

> **‚ö†Ô∏è Finomhangol√°shoz megfelel≈ë GPU sz√ºks√©ges ‚Äì p√©ld√°ul A10, V100, A100.**

## üíæ Telep√≠t√©s

Hozz l√©tre egy √∫j Python virtu√°lis k√∂rnyezetet (p√©ld√°ul `conda` haszn√°lat√°val):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ezut√°n telep√≠tsd az Olive-t √©s a finomhangol√°shoz sz√ºks√©ges f√ºgg≈ës√©geket:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Phi3 finomhangol√°sa Olive seg√≠ts√©g√©vel
Az [Olive konfigur√°ci√≥s f√°jl](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) egy *workflow*-t tartalmaz a k√∂vetkez≈ë *l√©p√©sekkel*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

R√∂viden, ez a workflow a k√∂vetkez≈ëket v√©gzi el:

1. Finomhangolja a Phi3 modellt (150 l√©p√©sben, amit m√≥dos√≠thatsz) a [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json) adatok felhaszn√°l√°s√°val.
1. Egyes√≠ti a LoRA adapter s√∫lyait az alapmodellbe, √≠gy egyetlen ONNX form√°tum√∫ modell √°ll rendelkez√©sre.
1. A Model Builder optimaliz√°lja a modellt az ONNX runtime-hoz, *√©s* kvant√°lja `int4` form√°tumba.

A workflow futtat√°s√°hoz haszn√°ld:

```bash
olive run --config phrase-classification.json
```

Amikor az Olive befejezte, az optimaliz√°lt `int4` form√°tum√∫ finomhangolt Phi3 modell el√©rhet≈ë a k√∂vetkez≈ë helyen: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Finomhangolt Phi3 integr√°l√°sa az alkalmaz√°sodba

Az alkalmaz√°s futtat√°s√°hoz:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

A v√°lasznak egyetlen sz√≥b√≥l √°ll√≥ oszt√°lyoz√°snak kell lennie a kifejez√©sre (Sad/Joy/Fear/Surprise).

**Felel≈ëss√©gkiz√°r√°s**:  
Ez a dokumentum az AI ford√≠t√≥ szolg√°ltat√°s [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel k√©sz√ºlt. B√°r igyeksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum a saj√°t nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n professzion√°lis, emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy f√©lre√©rtelmez√©sek√©rt.