{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ad8c65",
   "metadata": {},
   "source": [
    "# Phi-4 Mini ONNX Parallel Function Calling Tutorial\n",
    "\n",
    "This notebook demonstrates how to use Phi-4 Mini with ONNX Runtime GenAI for parallel function calling. Function calling allows the model to intelligently invoke external tools and APIs based on user requests.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, you'll learn how to:\n",
    "- Set up Phi-4 Mini with ONNX Runtime GenAI\n",
    "- Define function schemas for booking flights and hotels\n",
    "- Use guided generation with Lark grammar for structured output\n",
    "- Execute parallel function calls for complex travel booking scenarios\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "- Downloaded the Phi-4 Mini ONNX model\n",
    "- Installed `onnxruntime-genai` package\n",
    "- Basic understanding of function calling concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2551b",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "First, we'll import the necessary libraries for our function calling implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7368a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e806340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime_genai as og"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55f0ab",
   "metadata": {},
   "source": [
    "## Step 2: Model Setup and Configuration\n",
    "\n",
    "Now we'll configure the Phi-4 Mini ONNX model. Make sure to replace the path with your actual model directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8edfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with your actual Phi-4 Mini ONNX model path\n",
    "# Download from: https://huggingface.co/microsoft/Phi-4-mini-onnx\n",
    "path = 'Your phi-4-mini-onnx path'  # Update this path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80f5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = og.Config(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e9a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = og.Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ce23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = og.Tokenizer(model)\n",
    "tokenizer_stream = tokenizer.create_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac6d4a",
   "metadata": {},
   "source": [
    "## Step 3: Configure Generation Parameters\n",
    "\n",
    "Set up the generation parameters to control the model's output behavior. These settings ensure deterministic and focused responses for function calling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af01f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure generation parameters for deterministic function calling\n",
    "search_options = {}\n",
    "search_options['max_length'] = 4096      # Maximum tokens to generate\n",
    "search_options['temperature'] = 0.00001  # Very low temperature for deterministic output\n",
    "search_options['top_p'] = 1.0            # Nucleus sampling parameter\n",
    "search_options['do_sample'] = False       # Disable sampling for consistent results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2808a51",
   "metadata": {},
   "source": [
    "## Step 4: Define Available Functions\n",
    "\n",
    "Here we define the functions that our AI assistant can call. In this example, we have two travel-related functions:\n",
    "1. **booking_flight_tickets**: For booking flights between airports\n",
    "2. **booking_hotels**: For booking hotel accommodations\n",
    "\n",
    "The function definitions follow OpenAI's function calling schema format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc53b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = '[{\"name\": \"booking_flight_tickets\", \"description\": \"booking flights\", \"parameters\": {\"origin_airport_code\": {\"description\": \"The name of Departure airport code\", \"type\": \"string\"}, \"destination_airport_code\": {\"description\": \"The name of Destination airport code\", \"type\": \"string\"}, \"departure_date\": {\"description\": \"The date of outbound flight\", \"type\": \"string\"}, \"return_date\": {\"description\": \"The date of return flight\", \"type\": \"string\"}}}, {\"name\": \"booking_hotels\", \"description\": \"booking hotel\", \"parameters\": {\"destination\": {\"description\": \"The name of the city\", \"type\": \"string\"}, \"check_in_date\": {\"description\": \"The date of check in\", \"type\": \"string\"}, \"checkout_date\": {\"description\": \"The date of check out\", \"type\": \"string\"}}}]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb4048",
   "metadata": {},
   "source": [
    "## Step 5: Grammar Generation Helper Functions\n",
    "\n",
    "These helper functions convert our function definitions into Lark grammar format, which is used by ONNX Runtime GenAI for guided generation. This ensures the model outputs valid function calls in the correct JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f86e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lark_grammar(input_tools):\n",
    "    tools_list = get_tools_list(input_tools)\n",
    "    prompt_tool_input = create_prompt_tool_input(tools_list)\n",
    "    if len(tools_list) == 1:\n",
    "        # output = (\"start: TEXT | fun_call\\n\" \"TEXT: /[^{](.|\\\\n)*/\\n\" \" fun_call: <|tool_call|> %json \" + json.dumps(tools_list[0]))\n",
    "        output = (\"start: TEXT | fun_call\\n\" \"TEXT: /[^{](.|\\\\n)*/\\n\" \" fun_call: <|tool_call|> %json \" + json.dumps(convert_tool_to_grammar_input(tools_list[0])))\n",
    "        return prompt_tool_input, output\n",
    "    else:\n",
    "        return prompt_tool_input, \"start: TEXT | fun_call \\n TEXT: /[^{](.|\\n)*/ \\n fun_call: <|tool_call|> %json {\\\"anyOf\\\": [\" + ','.join([json.dumps(tool) for tool in tools_list]) + \"]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f2da98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools_list(input_tools):\n",
    "    # input_tools format: '[{\"name\": \"fn1\", \"description\": \"fn details\", \"parameters\": {\"p1\": {\"description\": \"details\", \"type\": \"string\"}}},\n",
    "    # {\"fn2\": 2},{\"fn3\": 3}]'\n",
    "    tools_list = []\n",
    "    try:\n",
    "        tools_list = json.loads(input_tools)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\"Invalid JSON format for tools list, expected format: '[{\\\"name\\\": \\\"fn1\\\"},{\\\"name\\\": \\\"fn2\\\"}]'\")\n",
    "    if len(tools_list) == 0:\n",
    "        raise ValueError(\"Tools list cannot be empty\")\n",
    "    return tools_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b1c2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_tool_input(tools_list):\n",
    "    tool_input = str(tools_list[0])\n",
    "    for tool in tools_list[1:]:\n",
    "        tool_input += ',' + str(tool)\n",
    "    return tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa82c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tool_to_grammar_input(tool):\n",
    "    param_props = {}\n",
    "    required_params = []\n",
    "    for param_name, param_info in tool.get(\"parameters\", {}).items():\n",
    "        param_props[param_name] = {\n",
    "            \"type\": param_info.get(\"type\", \"string\"),\n",
    "            \"description\": param_info.get(\"description\", \"\")\n",
    "        }\n",
    "        required_params.append(param_name)\n",
    "    output_schema = {\n",
    "        \"description\": tool.get('description', ''),\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\"name\", \"parameters\"],\n",
    "        \"additionalProperties\": False,\n",
    "        \"properties\": {\n",
    "            \"name\": { \"const\": tool[\"name\"] },\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": param_props,\n",
    "                \"required\": required_params,\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if len(param_props) == 0:\n",
    "        output_schema[\"required\"] = [\"name\"]\n",
    "    return output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284c9474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"{'name': 'booking_flight_tickets', 'description': 'booking flights', 'parameters': {'origin_airport_code': {'description': 'The name of Departure airport code', 'type': 'string'}, 'destination_airport_code': {'description': 'The name of Destination airport code', 'type': 'string'}, 'departure_date': {'description': 'The date of outbound flight', 'type': 'string'}, 'return_date': {'description': 'The date of return flight', 'type': 'string'}}},{'name': 'booking_hotels', 'description': 'booking hotel', 'parameters': {'destination': {'description': 'The name of the city', 'type': 'string'}, 'check_in_date': {'description': 'The date of check in', 'type': 'string'}, 'checkout_date': {'description': 'The date of check out', 'type': 'string'}}}\",\n",
       " 'start: TEXT | fun_call \\n TEXT: /[^{](.|\\n)*/ \\n fun_call: <|tool_call|> %json {\"anyOf\": [{\"name\": \"booking_flight_tickets\", \"description\": \"booking flights\", \"parameters\": {\"origin_airport_code\": {\"description\": \"The name of Departure airport code\", \"type\": \"string\"}, \"destination_airport_code\": {\"description\": \"The name of Destination airport code\", \"type\": \"string\"}, \"departure_date\": {\"description\": \"The date of outbound flight\", \"type\": \"string\"}, \"return_date\": {\"description\": \"The date of return flight\", \"type\": \"string\"}}},{\"name\": \"booking_hotels\", \"description\": \"booking hotel\", \"parameters\": {\"destination\": {\"description\": \"The name of the city\", \"type\": \"string\"}, \"check_in_date\": {\"description\": \"The date of check in\", \"type\": \"string\"}, \"checkout_date\": {\"description\": \"The date of check out\", \"type\": \"string\"}}}]}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lark_grammar(tool_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534ff02",
   "metadata": {},
   "source": [
    "## Step 6: Test Grammar Generation\n",
    "\n",
    "Let's test our grammar generation functions to see how they convert our tool definitions into the proper format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a730b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tool_input, guidance_input = get_lark_grammar(tool_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca5aa8",
   "metadata": {},
   "source": [
    "## Step 7: Prepare System Prompt and Generator\n",
    "\n",
    "Now we'll create the system prompt that tells the model about available tools and set up the generator with guided generation parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8474cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt that introduces the assistant and its capabilities\n",
    "system_prompt = \"You are a helpful assistant with these tools.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c4c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the system message with tools information\n",
    "messages = f\"\"\"[{{\"role\": \"system\", \"content\": \"{system_prompt}\", \"tools\": \"{prompt_tool_input}\"}}]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaabbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply chat template to format the system prompt properly\n",
    "tokenizer_input_system_prompt = tokenizer.apply_chat_template(messages=messages, add_generation_prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f0da4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|system|>You are a helpful assistant with these tools.<|tool|>{'name': 'booking_flight_tickets', 'description': 'booking flights', 'parameters': {'origin_airport_code': {'description': 'The name of Departure airport code', 'type': 'string'}, 'destination_airport_code': {'description': 'The name of Destination airport code', 'type': 'string'}, 'departure_date': {'description': 'The date of outbound flight', 'type': 'string'}, 'return_date': {'description': 'The date of return flight', 'type': 'string'}}},{'name': 'booking_hotels', 'description': 'booking hotel', 'parameters': {'destination': {'description': 'The name of the city', 'type': 'string'}, 'check_in_date': {'description': 'The date of check in', 'type': 'string'}, 'checkout_date': {'description': 'The date of check out', 'type': 'string'}}}<|/tool|><|end|><|endoftext|>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_input_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10605b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.encode(tokenizer_input_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6de50e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = input_tokens[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c17a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_length = len(input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5f242",
   "metadata": {},
   "source": [
    "## Step 8: Initialize Generator with Guided Generation\n",
    "\n",
    "Now we'll create the generator with our configured parameters and apply the Lark grammar for guided generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54180c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator parameters and apply search options\n",
    "params = og.GeneratorParams(model)\n",
    "params.set_search_options(**search_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eec56940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Lark grammar for guided generation to ensure valid function call format\n",
    "params.set_guidance(\"lark_grammar\", guidance_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92207c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "690112f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = og.Generator(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "789d5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.append_tokens(input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c9c2e",
   "metadata": {},
   "source": [
    "## Step 9: Test Parallel Function Calling\n",
    "\n",
    "Now let's test our setup with a complex travel booking scenario that requires calling multiple functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ac5ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex travel booking request that requires both flight and hotel booking\n",
    "text = \"book flight ticket from Beijing to Paris(using airport code) in 2025-12-04 to 2025-12-10 , then book hotel from 2025-12-04 to 2025-12-10 in Paris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36386526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format user message and apply chat template\n",
    "messages = f\"\"\"[{{\"role\": \"user\", \"content\": \"{text}\"}}]\"\"\"\n",
    "\n",
    "# Apply Chat Template for user input\n",
    "user_prompt = tokenizer.apply_chat_template(messages=messages, add_generation_prompt=True)\n",
    "input_tokens = tokenizer.encode(user_prompt)\n",
    "generator.append_tokens(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f85f5caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|user|>book flight ticket from Beijing to Paris(using airport code) in 2025-12-04 to 2025-12-10 , then book hotel from 2025-12-04 to 2025-12-10 in Paris<|end|><|assistant|>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c90f9",
   "metadata": {},
   "source": [
    "### View the formatted user prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65331735",
   "metadata": {},
   "source": [
    "### Generate Function Calls\n",
    "\n",
    "The model will now generate structured function calls based on our user request. Thanks to guided generation, the output will be in valid JSON format that can be directly executed.\n",
    "\n",
    "**Expected Output**: The model should generate function calls for:\n",
    "1. `booking_flight_tickets` with Beijing (PEK) to Paris (CDG) details\n",
    "2. `booking_hotels` with Paris accommodation details\n",
    "\n",
    "Run the cell below to see the live generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64a703a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"name\": \"booking_flight_tickets\", \"arguments\": {\"origin_airport_code\": \"PEKK\", \"destination_airport_code\": \"CDG\", \"departure_date\": \"2025-12-04\", \"return_date\": \"2025-12-10\"}}, {\"name\": \"booking_hotels\", \"arguments\": {\"destination\": \"Paris\", \"check_in_date\": \"2025-12-04\", \"checkout_date\": \"2025-12-10\"}}]"
     ]
    }
   ],
   "source": [
    "# Generate tokens one by one and stream the output\n",
    "while not generator.is_done():\n",
    "    generator.generate_next_token()\n",
    "    new_token = generator.get_next_tokens()[0]\n",
    "    print(tokenizer_stream.decode(new_token), end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db4123",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "ðŸŽ‰ **Congratulations!** You've successfully implemented parallel function calling with Phi-4 Mini using ONNX Runtime GenAI.\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. **Model Setup**: How to configure Phi-4 Mini with ONNX Runtime GenAI\n",
    "2. **Function Definition**: How to define function schemas for AI function calling\n",
    "3. **Guided Generation**: How to use Lark grammar for structured output generation\n",
    "4. **Parallel Function Calls**: How to handle complex requests requiring multiple function calls\n",
    "\n",
    "### Key Benefits:\n",
    "\n",
    "- âœ… **Structured Output**: Guided generation ensures valid JSON function calls\n",
    "- âœ… **Parallel Processing**: Handle multiple function calls in a single request\n",
    "- âœ… **High Performance**: ONNX Runtime provides optimized inference\n",
    "- âœ… **Flexible Schema**: Easy to add or modify function definitions\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [Phi-4 Mini Documentation](https://huggingface.co/microsoft/Phi-4-mini-onnx)\n",
    "- [ONNX Runtime GenAI Documentation](https://onnxruntime.ai/docs/genai/)\n",
    "- [Function Calling Best Practices](https://platform.openai.com/docs/guides/function-calling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\nDisclaimer:\nThis document has been translated using AI translation service Co-op Translator (https://github.com/Azure/co-op-translator). While we strive for accuracy, please be aware that automated translations may contain errors or inaccuracies. The original document in its native language should be considered the authoritative source. For critical information, professional human translation is recommended. We are not liable for any misunderstandings or misinterpretations arising from the use of this translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "8b61c907614fd2780d526c45c388d285",
   "translation_date": "2025-12-22T09:06:39+00:00",
   "source_file": "md/02.Application/07.FunctionCalling/Phi4/ONNX/onnx_parallel_functioncalling.ipynb",
   "language_code": "en"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}