<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-07-16T18:49:26+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "en"
}
-->
# **Using Phi Family in Hugging Face**


[Hugging Face](https://huggingface.co/) is a very popular AI community with abundant data and open-source model resources. Various manufacturers release open-source LLM and SLM models through Hugging Face, including Microsoft, Meta, Mistral, Apple, Google, and others.

Microsoft Phi Family has been released on Hugging Face. Developers can download the appropriate Phi Family model based on their scenarios and business needs. Besides deploying Phi PyTorch models on Hugging Face, we also offer quantized models in GGUF and ONNX formats to provide end users with more options.


## **Download Models on Hugging Face**

You can download Phi family models using this link

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

You can download the models in different ways, such as by installing the ***Hugging Face CLI SDK*** or using ***git clone***.

### **Using Hugging Face CLI to Download Phi Family Models**

- Install Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Use huggingface-cli to log in

Log in to Hugging Face with your [User Access Token](https://huggingface.co/docs/hub/security-tokens) from your [Settings page](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Download 


You can download the model and save it to cache 

```bash

huggingface-cli download microsoft/phi-4

```

You can specify a custom location


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Using git clone to Download Phi Family Models**

You can also use ***git clone*** to download the models

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Samples - Inference with Microsoft Phi-4**

- **Installing the transformers library**

```bash

pip install transformers -U

```

- **Running this code in VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Disclaimer**:  
This document has been translated using the AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). While we strive for accuracy, please be aware that automated translations may contain errors or inaccuracies. The original document in its native language should be considered the authoritative source. For critical information, professional human translation is recommended. We are not liable for any misunderstandings or misinterpretations arising from the use of this translation.