<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5d936ffe4dfbab2244f6eb21b11f3b3",
  "translation_date": "2025-07-16T18:27:56+00:00",
  "source_file": "md/01.Introduction/01/01.PhiFamily.md",
  "language_code": "en"
}
-->
# Microsoft's Phi family

The Phi models are the most capable and cost-effective Small Language Models (SLMs) available, outperforming models of the same size and even the next size up across a variety of language, reasoning, coding, audio, vision, and math benchmarks. This release broadens the range of high-quality models for customers, providing more practical options for creating and building generative AI applications.

The Phi Family began with Phi-1 for Python code generation, then progressed to Phi-1.5 / 2 based on text and chat completion, followed by Phi-3-mini/small/medium-instruct and Phi-3.5/4-mini-instruct. It further evolved into Phi-3/3.5-vision for vision tasks, Phi-4 focused on strong reasoning, Phi-3.5-MoE for Mixture of Experts (MoE), and now the full-modal model Phi-4-multimodal. Thanks to high-quality datasets, these benchmarks can be trained to perform comparably to models with larger parameter counts.

## Phi Family models 

<div style="font-size:8px">

| Model Card | Parameters | Coding | Text/Chat Completion | Advanced Reasoning | Vision | Audio | MoE |
| - | - | - | - | - | - | - | - |
|[Phi-1](https://huggingface.co/microsoft/phi-1)|1.3B| YES| NO | NO | NO | NO | NO |
|[Phi-1.5](https://huggingface.co/microsoft/phi-1_5)|1.3B| YES| YES | NO | NO | NO | NO |
|[Phi-2](https://huggingface.co/microsoft/phi-1_5)|2.7B| YES| YES | NO | NO | NO | NO |
|[Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)<br/>[Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)|3.8B| YES| YES | NO | NO | NO | NO |
|[Phi-3-small-8k-instruct](https://huggingface.co/microsoft/Phi-3-small-8k-instruct)<br/>[Phi-3-small-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct)|7B| YES| YES | NO | NO | NO | NO |
|[Phi-3-medium-4k-instruct](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)<br/>[Phi-3-medium-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)|14B| YES| NO | NO | NO | NO | NO |
|[Phi-3-vision-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)|4.2B| YES| YES | NO | NO | NO | NO |
|[Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)|3.8B| YES| YES | NO | NO | NO | NO |
|[Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct)|42B| YES| YES | NO | NO | NO | YES |
|[Phi-3.5-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3.5-vision-instruct)|4.2B| YES| YES | NO | YES | NO | NO |
|[Phi-4](https://huggingface.co/microsoft/phi-4)|14B| YES| YES | NO | NO | NO | NO |
|[Phi-4-mini](https://huggingface.co/microsoft/Phi-4-mini-instruct)|3.8B| YES| YES | NO | NO | NO | NO |
|[Phi-4-multimodal](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)|5.6B| YES| YES | NO | YES | YES | NO |
|[Phi-4-reasoning](../../../../../md/01.Introduction/01)|3.8B| YES| YES | YES | NO | NO | NO |
|[Phi-4-mini-reasoning](../../../../../md/01.Introduction/01)|3.8B| YES| YES | YES | NO | NO | NO |

</div>

## **Find all Phi models on different model platforms**

- [Azure AI Foundry Model catalog](https://ai.azure.com/explore/models?selectedCollection=phi)
- [GitHub Models](https://github.com/marketplace?query=Phi&type=models)
- Hugging Face
  - [Phi-1 /1.5](https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572)
  - [Phi-2](https://huggingface.co/microsoft/phi-2)
  - [Phi-3](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)
  - [Phi-4](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4) 
- [NVIDIA NIM](https://build.nvidia.com/search?q=Phi)

## Example of Model Selection

| | | | |
|-|-|-|-|
|Customer Need|Task|Start with|More Details|
|Need a model that simply summarizes a thread of messages|Conversation Summarization|Phi-3 / 3.5 text model|The key factor here is that the customer has a clearly defined and straightforward language task|
|A free math tutor app for kids|Math and Reasoning|Phi-3 / 3.5 / 4 text models|Since the app is free, customers want a solution that doesnâ€™t incur ongoing costs|
|Self Patrol Car Camera|Vision analysis|Phi-3 / 3.5-Vision or Phi-4-multimodal|Requires a solution that can run on edge devices without internet connectivity|
|Wants to build an AI-based travel booking agent|Needs complex planning, function calling, and orchestration|GPT models|Requires the ability to plan, call APIs to gather information, and execute tasks|
|Wants to build a copilot for their employees|RAG, multiple domains, complex and open-ended|GPT models + Phi Family|Open-ended scenario needing broad world knowledge, so a larger model is more suitable. You may need to chunk knowledge content; SLMs might be a good fit|

**Disclaimer**:  
This document has been translated using the AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). While we strive for accuracy, please be aware that automated translations may contain errors or inaccuracies. The original document in its native language should be considered the authoritative source. For critical information, professional human translation is recommended. We are not liable for any misunderstandings or misinterpretations arising from the use of this translation.