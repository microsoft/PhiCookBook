{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keyframes(video_path, output_folder):\n",
    "    videoCapture = cv2.VideoCapture(video_path)\n",
    "    success, frame = videoCapture.read()\n",
    "    i = 0\n",
    "    while success:\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        hist = cv2.calcHist([gray_frame], [0], None, [256], [0, 256])\n",
    "        \n",
    "        success, next_frame = videoCapture.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        next_gray_frame = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        next_hist = cv2.calcHist([next_gray_frame], [0], None, [256], [0, 256])\n",
    "        \n",
    "        similarity = cv2.compareHist(hist, next_hist, cv2.HISTCMP_CORREL)\n",
    "        \n",
    "        if similarity < 0.9:\n",
    "            i += 1\n",
    "            cv2.imwrite(f\"{output_folder}/keyframe_{i}.jpg\", frame)\n",
    "            print(f\"Saved keyframe {i}\")\n",
    "        \n",
    "        frame = next_frame\n",
    "\n",
    "    videoCapture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keyframes('../examples/video/car.mp4', './output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests, base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [] \n",
    "placeholder = \"\" \n",
    "for i in range(1,4): \n",
    "    with open(\"../examples/output/keyframe_\"+str(i)+\".jpg\", \"rb\") as f:\n",
    "\n",
    "        images.append(Image.open(\"../examples/output/keyframe_\"+str(i)+\".jpg\"))\n",
    "        placeholder += f\"<|image_{i}|>\\n\"\n",
    "        # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import device_widget\n",
    "\n",
    "device = device_widget(default=\"GPU\", exclude=[\"NPU\"])\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ov_phi3_vision import OvPhi3Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../model/phi-3.5-vision-128k-instruct-ov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OvPhi3Vision(out_dir, device.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, TextStreamer\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":  placeholder+\"Summarize the video.\"},\n",
    "]\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(out_dir, trust_remote_code=True)\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, images, return_tensors=\"pt\")\n",
    "\n",
    "generation_args = {\"max_new_tokens\": 500, \"do_sample\": False, \"streamer\": TextStreamer(processor.tokenizer, skip_prompt=True, skip_special_tokens=True)}\n",
    "\n",
    "print(\"Summary:\")\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責聲明**：  \n本文件已使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始語言的文件應被視為權威來源。對於重要信息，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋概不負責。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvinodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "56cf1c05848d752df163a2bf29cefba4",
   "translation_date": "2025-09-12T15:51:58+00:00",
   "source_file": "code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb",
   "language_code": "hk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}