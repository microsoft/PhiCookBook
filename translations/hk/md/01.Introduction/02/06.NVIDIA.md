<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-07-16T19:34:07+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "hk"
}
-->
## Phi 家族於 NVIDIA NIM

NVIDIA NIM 是一組易於使用的微服務，旨在加速生成式 AI 模型在雲端、數據中心及工作站的部署。NIM 根據模型家族及單一模型進行分類。例如，針對大型語言模型（LLMs）的 NVIDIA NIM，將最先進的 LLM 能力帶入企業應用，提供無與倫比的自然語言處理與理解功能。

NIM 讓 IT 和 DevOps 團隊能輕鬆在自家管理的環境中自我托管大型語言模型（LLMs），同時為開發者提供業界標準的 API，讓他們能打造強大的輔助工具、聊天機器人及 AI 助理，徹底改變業務運作。利用 NVIDIA 領先的 GPU 加速與可擴展部署，NIM 提供最快的推理路徑與無可比擬的效能。

你可以使用 NVIDIA NIM 來推理 Phi 家族模型

![nim](../../../../../translated_images/Phi-NIM.09bebb743387ee4a5028d7d4f8fed55e619711b26c8937526b43a2af980f7dcf.hk.png)

### **範例 - NVIDIA NIM 中的 Phi-3-Vision**

假設你有一張圖片（`demo.png`），想要生成 Python 程式碼來處理這張圖片，並儲存一個新的版本（`phi-3-vision.jpg`）。

上方的程式碼自動化了這個流程，包含：

1. 設定環境與必要的配置。
2. 建立提示詞，指示模型生成所需的 Python 程式碼。
3. 將提示詞傳送給模型並收集生成的程式碼。
4. 擷取並執行生成的程式碼。
5. 顯示原始與處理後的圖片。

這種方法利用 AI 的力量自動化影像處理任務，讓你更輕鬆且快速地達成目標。

[範例程式碼解決方案](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

讓我們逐步解析整段程式碼的功能：

1. **安裝所需套件**：
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    這個指令安裝 `langchain_nvidia_ai_endpoints` 套件，確保是最新版本。

2. **匯入必要模組**：
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    這些匯入包含與 NVIDIA AI 端點互動、密碼安全處理、作業系統操作及 base64 編碼/解碼所需的模組。

3. **設定 API 金鑰**：
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    這段程式碼會檢查 `NVIDIA_API_KEY` 環境變數是否已設定，若未設定，會安全地提示使用者輸入 API 金鑰。

4. **定義模型與圖片路徑**：
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    設定要使用的模型，建立指定模型的 `ChatNVIDIA` 實例，並定義圖片檔案路徑。

5. **建立文字提示詞**：
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    定義一段文字提示，指示模型生成用於處理圖片的 Python 程式碼。

6. **將圖片編碼為 Base64**：
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    讀取圖片檔案，將其編碼成 base64，並建立包含編碼資料的 HTML 圖片標籤。

7. **將文字與圖片結合成提示詞**：
    ```python
    prompt = f"{text} {image}"
    ```
    將文字提示與 HTML 圖片標籤合併成一個字串。

8. **使用 ChatNVIDIA 生成程式碼**：
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    將提示詞傳送給 `ChatNVIDIA` 模型，並分段收集生成的程式碼，同時印出並附加到 `code` 字串。

9. **從生成內容中擷取 Python 程式碼**：
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    透過移除 markdown 格式，擷取出實際的 Python 程式碼。

10. **執行生成的程式碼**：
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    以子程序方式執行擷取出的 Python 程式碼，並捕捉其輸出。

11. **顯示圖片**：
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    使用 `IPython.display` 模組顯示圖片。

**免責聲明**：  
本文件由 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於確保準確性，但請注意自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於重要資訊，建議採用專業人工翻譯。我們不對因使用本翻譯而引起的任何誤解或誤釋承擔責任。