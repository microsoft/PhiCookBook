<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-07-16T19:43:24+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "hk"
}
-->
## 在 Foundry Local 使用 Phi-Family 模型入門

### Foundry Local 簡介

Foundry Local 是一個強大的本地 AI 推理解決方案，將企業級 AI 能力直接帶到你的本地硬件。這個教學將引導你如何設定及使用 Phi-Family 模型搭配 Foundry Local，讓你完全掌控 AI 工作負載，同時保障隱私並降低成本。

Foundry Local 透過在本地設備上運行 AI 模型，提供效能、隱私、自訂化及成本上的優勢。它能透過直覺的 CLI、SDK 及 REST API 無縫整合到你現有的工作流程和應用程式中。

![arch](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7.hk.png)

### 為什麼選擇 Foundry Local？

了解 Foundry Local 的優點，有助你做出明智的 AI 部署策略決策：

- **本地推理：** 在你自己的硬件上本地運行模型，降低成本，同時所有資料都保留在你的設備上。

- **模型自訂：** 可選擇預設模型或使用自有模型，以符合特定需求和使用場景。

- **成本效益：** 利用現有硬件，免除持續的雲端服務費用，讓 AI 更加普及。

- **無縫整合：** 透過 SDK、API 端點或 CLI 與你的應用程式連接，並可隨需求擴展至 Azure AI Foundry。

> **入門提示：** 本教學重點介紹如何透過 CLI 和 SDK 介面使用 Foundry Local，讓你了解兩種方式，幫助你選擇最適合的使用方法。

## 第一部分：設定 Foundry Local CLI

### 步驟 1：安裝

Foundry Local CLI 是你管理及本地運行 AI 模型的入口。讓我們先在系統上安裝它。

**支援平台：** Windows 和 macOS

詳細安裝說明請參考 [官方 Foundry Local 文件](https://github.com/microsoft/Foundry-Local/blob/main/README.md)。

### 步驟 2：探索可用模型

安裝 Foundry Local CLI 後，你可以查看有哪些模型適合你的使用場景。以下指令會列出所有支援的模型：

```bash
foundry model list
```

### 步驟 3：認識 Phi Family 模型

Phi Family 提供多款針對不同使用需求及硬件配置優化的模型。以下是 Foundry Local 中可用的 Phi 模型：

**可用 Phi 模型：**

- **phi-3.5-mini** - 適合基本任務的輕量模型
- **phi-3-mini-128k** - 支援更長對話的擴展上下文版本
- **phi-3-mini-4k** - 一般用途的標準上下文模型
- **phi-4** - 具備更強能力的進階模型
- **phi-4-mini** - Phi-4 的輕量版本
- **phi-4-mini-reasoning** - 專為複雜推理任務設計

> **硬件相容性：** 每款模型可根據系統能力設定不同硬件加速（CPU、GPU）。

### 步驟 4：運行你的第一個 Phi 模型

讓我們從實作開始，運行 `phi-4-mini-reasoning` 模型，它擅長逐步解決複雜問題。

**運行模型指令：**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **首次設定說明：** 第一次運行模型時，Foundry Local 會自動下載模型到本地設備。下載時間視網絡速度而定，請耐心等待初次設定完成。

### 步驟 5：用實際問題測試模型

現在用一個經典邏輯問題測試模型，看看它如何逐步推理：

**範例問題：**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**預期行為：** 模型應該會將問題拆解成邏輯步驟，利用野雞有兩隻腳、兔子有四隻腳的事實，解出方程式。

**結果：**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d91.hk.png)

## 第二部分：使用 Foundry Local SDK 建立應用程式

### 為什麼使用 SDK？

CLI 適合測試和快速互動，而 SDK 則讓你能以程式化方式將 Foundry Local 整合到應用程式中。這帶來更多可能性：

- 建立自訂 AI 應用程式
- 創建自動化工作流程
- 將 AI 功能整合到現有系統
- 開發聊天機器人和互動工具

### 支援的程式語言

Foundry Local 提供多種程式語言的 SDK，符合你的開發偏好：

**📦 可用 SDK：**

- **C# (.NET)：** [SDK 文件與範例](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)
- **Python：** [SDK 文件與範例](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **JavaScript：** [SDK 文件與範例](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)
- **Rust：** [SDK 文件與範例](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### 下一步

1. **根據開發環境選擇合適的 SDK**
2. **參考 SDK 專屬文件，了解詳細實作指南**
3. **從簡單範例開始，逐步建立複雜應用**
4. **探索各 SDK 倉庫中的範例程式碼**

## 結語

你已學會如何：
- ✅ 安裝並設定 Foundry Local CLI
- ✅ 探索並運行 Phi Family 模型
- ✅ 用實際問題測試模型
- ✅ 了解 SDK 選項以開發應用程式

Foundry Local 為你提供強大基礎，將 AI 能力直接帶到本地環境，讓你掌控效能、隱私與成本，同時保有擴展至雲端解決方案的彈性。

**免責聲明**：  
本文件由 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於確保準確性，但請注意自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於重要資訊，建議採用專業人工翻譯。我們不對因使用本翻譯而引起的任何誤解或誤釋承擔責任。