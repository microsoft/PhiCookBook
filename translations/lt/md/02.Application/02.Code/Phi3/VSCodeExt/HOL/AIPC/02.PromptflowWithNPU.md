<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-09-12T14:28:08+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "lt"
}
-->
# **Laboratorinis darbas 2 - Paleiskite Prompt flow su Phi-3-mini AIPC**

## **Kas yra Prompt flow**

Prompt flow – tai įrankių rinkinys, skirtas supaprastinti visą LLM pagrįstų AI programų kūrimo ciklą: nuo idėjų generavimo, prototipų kūrimo, testavimo, vertinimo iki diegimo ir stebėjimo gamyboje. Jis palengvina prompt inžineriją ir leidžia kurti aukštos kokybės LLM programas.

Naudodami Prompt flow galėsite:

- Kurti srautus, kurie sujungia LLM, prompt'us, Python kodą ir kitus įrankius į vykdomą darbo eigą.

- Lengvai derinti ir tobulinti savo srautus, ypač sąveiką su LLM.

- Vertinti savo srautus, skaičiuoti kokybės ir našumo rodiklius naudojant didesnius duomenų rinkinius.

- Integruoti testavimą ir vertinimą į savo CI/CD sistemą, kad užtikrintumėte srauto kokybę.

- Lengvai diegti savo srautus pasirinktoje platformoje arba integruoti į savo programos kodą.

- (Pasirinktinai, bet labai rekomenduojama) Bendradarbiauti su komanda, naudojant Prompt flow debesų versiją Azure AI.

## **Kas yra AIPC**

AI kompiuteris (AIPC) turi CPU, GPU ir NPU, kiekvienas iš jų turi specifines AI spartinimo galimybes. NPU, arba neuronų apdorojimo vienetas, yra specializuotas spartintuvas, kuris vykdo dirbtinio intelekto (AI) ir mašininio mokymosi (ML) užduotis tiesiogiai jūsų kompiuteryje, o ne siunčia duomenis apdoroti debesyje. GPU ir CPU taip pat gali apdoroti šias užduotis, tačiau NPU ypač gerai tinka mažos galios AI skaičiavimams. AI kompiuteris žymi esminį pokytį, kaip veikia mūsų kompiuteriai. Tai nėra sprendimas problemai, kuri anksčiau neegzistavo, bet žada didelį patobulinimą kasdieniam kompiuterio naudojimui.

Kaip tai veikia? Palyginti su generatyviniu AI ir didžiuliais dideliais kalbos modeliais (LLM), kurie mokomi naudojant daugybę viešų duomenų, AI, vykdomas jūsų kompiuteryje, yra prieinamesnis beveik visais lygmenimis. Koncepcija yra lengviau suprantama, o kadangi ji mokoma naudojant jūsų duomenis, nereikalaujant prieigos prie debesies, privalumai tampa patrauklesni platesnei auditorijai.

Artimiausiu metu AI kompiuterio pasaulis apima asmeninius asistentus ir mažesnius AI modelius, kurie veikia tiesiogiai jūsų kompiuteryje, naudodami jūsų duomenis, kad pasiūlytų asmeninius, privačius ir saugesnius AI patobulinimus kasdienėms užduotims – susitikimų protokolų sudarymui, fantazijos futbolo lygos organizavimui, nuotraukų ir vaizdo įrašų redagavimo automatizavimui ar tobulo šeimos susitikimo maršruto sudarymui pagal visų atvykimo ir išvykimo laikus.

## **Kodo generavimo srautų kūrimas AIPC**

***Pastaba***: Jei dar nebaigėte aplinkos diegimo, apsilankykite [Lab 0 - Diegimas](./01.Installations.md)

1. Atidarykite Prompt flow plėtinį Visual Studio Code ir sukurkite tuščią srauto projektą.

![create](../../../../../../../../../imgs/02/vscodeext/pf_create.png)

2. Pridėkite įvesties ir išvesties parametrus bei Python kodą kaip naują srautą.

![flow](../../../../../../../../../imgs/02/vscodeext/pf_flow.png)

Galite remtis šia struktūra (flow.dag.yaml), kad sukurtumėte savo srautą.

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Pridėkite kodą į ***Chat_With_Phi3.py***.

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Galite išbandyti srautą naudodami Debug arba Run, kad patikrintumėte, ar kodo generavimas veikia tinkamai.

![RUN](../../../../../../../../../imgs/02/vscodeext/pf_run.png)

5. Paleiskite srautą kaip vystymo API terminale.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Galite jį išbandyti naudodami Postman / Thunder Client.

### **Pastabos**

1. Pirmasis paleidimas užtrunka ilgai. Rekomenduojama atsisiųsti phi-3 modelį naudojant Hugging face CLI.

2. Atsižvelgiant į ribotą Intel NPU skaičiavimo galią, rekomenduojama naudoti Phi-3-mini-4k-instruct.

3. Naudojame Intel NPU spartinimą INT4 konversijai kvantizuoti, tačiau jei paleisite paslaugą iš naujo, turite ištrinti talpyklą ir nc_workshop aplankus.

## **Ištekliai**

1. Sužinokite apie Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Sužinokite apie Intel NPU spartinimą [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Pavyzdinis kodas, atsisiųskite [Vietinio NPU agento pavyzdinį kodą](../../../../../../../../../code/07.Lab/01/AIPC)

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.