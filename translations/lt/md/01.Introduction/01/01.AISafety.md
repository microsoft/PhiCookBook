<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-09-12T14:48:24+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "lt"
}
-->
# AI saugumas Phi modeliams
Phi modelių šeima buvo sukurta laikantis [Microsoft atsakingo dirbtinio intelekto standarto](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl), kuris yra visos įmonės reikalavimų rinkinys, pagrįstas šiais šešiais principais: atskaitomybė, skaidrumas, sąžiningumas, patikimumas ir saugumas, privatumas ir saugumas bei įtrauktis, kurie sudaro [Microsoft atsakingo dirbtinio intelekto principus](https://www.microsoft.com/ai/responsible-ai).

Kaip ir ankstesni Phi modeliai, buvo taikomas daugiapakopis saugumo vertinimas ir saugumo po mokymo metodas, papildomai atsižvelgiant į šio leidimo daugiakalbį pajėgumą. Mūsų požiūris į saugumo mokymą ir vertinimą, įskaitant testavimą įvairiomis kalbomis ir rizikos kategorijomis, aprašytas [Phi saugumo po mokymo dokumente](https://arxiv.org/abs/2407.13833). Nors Phi modeliai gauna naudos iš šio metodo, kūrėjai turėtų taikyti geriausią atsakingo dirbtinio intelekto praktiką, įskaitant rizikų, susijusių su konkrečiu naudojimo atveju ir kultūriniu bei kalbiniu kontekstu, žemėlapio sudarymą, matavimą ir mažinimą.

## Geriausia praktika

Kaip ir kiti modeliai, Phi modelių šeima gali elgtis nesąžiningai, nepatikimai ar įžeidžiamai.

Kai kurie ribojantys SLM ir LLM elgesiai, kuriuos turėtumėte žinoti, yra šie:

- **Paslaugos kokybė:** Phi modeliai daugiausia mokomi anglų kalbos tekstais. Kalbos, kurios nėra anglų, turės prastesnį našumą. Anglų kalbos variantai, kurie mažiau atstovaujami mokymo duomenyse, gali turėti prastesnį našumą nei standartinė amerikiečių anglų kalba.
- **Žalos atstovavimas ir stereotipų stiprinimas:** Šie modeliai gali per daug arba per mažai atstovauti žmonių grupėms, ištrinti kai kurių grupių atstovavimą arba sustiprinti žeminančius ar neigiamus stereotipus. Nepaisant saugumo po mokymo, šie apribojimai vis dar gali būti dėl skirtingų grupių atstovavimo lygių arba neigiamų stereotipų pavyzdžių paplitimo mokymo duomenyse, kurie atspindi realaus pasaulio modelius ir visuomenės šališkumą.
- **Netinkamas ar įžeidžiantis turinys:** Šie modeliai gali generuoti kitų tipų netinkamą ar įžeidžiantį turinį, kuris gali būti netinkamas naudoti jautriuose kontekstuose be papildomų priemonių, pritaikytų konkrečiam naudojimo atvejui.
- **Informacijos patikimumas:** Kalbos modeliai gali generuoti nesąmoningą turinį arba sukurti turinį, kuris gali skambėti pagrįstai, bet yra netikslus arba pasenęs.
- **Ribotas kodavimo apimtis:** Dauguma Phi-3 mokymo duomenų yra pagrįsti Python ir naudoja įprastus paketus, tokius kaip "typing, math, random, collections, datetime, itertools". Jei modelis generuoja Python scenarijus, kurie naudoja kitus paketus arba scenarijus kitomis kalbomis, primygtinai rekomenduojame vartotojams rankiniu būdu patikrinti visus API naudojimus.

Kūrėjai turėtų taikyti geriausią atsakingo dirbtinio intelekto praktiką ir yra atsakingi už tai, kad konkretus naudojimo atvejis atitiktų galiojančius įstatymus ir reglamentus (pvz., privatumo, prekybos ir kt.).

## Atsakingo dirbtinio intelekto svarstymai

Kaip ir kiti kalbos modeliai, Phi serijos modeliai gali elgtis nesąžiningai, nepatikimai ar įžeidžiamai. Kai kurie ribojantys elgesiai, kuriuos reikia žinoti, yra šie:

**Paslaugos kokybė:** Phi modeliai daugiausia mokomi anglų kalbos tekstais. Kalbos, kurios nėra anglų, turės prastesnį našumą. Anglų kalbos variantai, kurie mažiau atstovaujami mokymo duomenyse, gali turėti prastesnį našumą nei standartinė amerikiečių anglų kalba.

**Žalos atstovavimas ir stereotipų stiprinimas:** Šie modeliai gali per daug arba per mažai atstovauti žmonių grupėms, ištrinti kai kurių grupių atstovavimą arba sustiprinti žeminančius ar neigiamus stereotipus. Nepaisant saugumo po mokymo, šie apribojimai vis dar gali būti dėl skirtingų grupių atstovavimo lygių arba neigiamų stereotipų pavyzdžių paplitimo mokymo duomenyse, kurie atspindi realaus pasaulio modelius ir visuomenės šališkumą.

**Netinkamas ar įžeidžiantis turinys:** Šie modeliai gali generuoti kitų tipų netinkamą ar įžeidžiantį turinį, kuris gali būti netinkamas naudoti jautriuose kontekstuose be papildomų priemonių, pritaikytų konkrečiam naudojimo atvejui.

**Informacijos patikimumas:** Kalbos modeliai gali generuoti nesąmoningą turinį arba sukurti turinį, kuris gali skambėti pagrįstai, bet yra netikslus arba pasenęs.

**Ribotas kodavimo apimtis:** Dauguma Phi-3 mokymo duomenų yra pagrįsti Python ir naudoja įprastus paketus, tokius kaip "typing, math, random, collections, datetime, itertools". Jei modelis generuoja Python scenarijus, kurie naudoja kitus paketus arba scenarijus kitomis kalbomis, primygtinai rekomenduojame vartotojams rankiniu būdu patikrinti visus API naudojimus.

Kūrėjai turėtų taikyti geriausią atsakingo dirbtinio intelekto praktiką ir yra atsakingi už tai, kad konkretus naudojimo atvejis atitiktų galiojančius įstatymus ir reglamentus (pvz., privatumo, prekybos ir kt.). Svarbios sritys, kurias reikia apsvarstyti, apima:

**Paskirstymas:** Modeliai gali būti netinkami scenarijams, kurie gali turėti reikšmingą poveikį teisiniam statusui arba išteklių ar gyvenimo galimybių paskirstymui (pvz., būstas, užimtumas, kreditas ir kt.) be papildomų vertinimų ir papildomų šališkumo mažinimo metodų.

**Didelės rizikos scenarijai:** Kūrėjai turėtų įvertinti modelių tinkamumą naudoti didelės rizikos scenarijuose, kur nesąžiningi, nepatikimi ar įžeidžiantys rezultatai gali būti labai brangūs arba sukelti žalą. Tai apima patarimų teikimą jautriose ar ekspertinėse srityse, kur tikslumas ir patikimumas yra labai svarbūs (pvz., teisiniai ar sveikatos patarimai). Papildomos apsaugos priemonės turėtų būti įgyvendintos programos lygiu pagal diegimo kontekstą.

**Dezinformacija:** Modeliai gali generuoti netikslią informaciją. Kūrėjai turėtų laikytis skaidrumo geriausios praktikos ir informuoti galutinius vartotojus, kad jie sąveikauja su dirbtinio intelekto sistema. Programos lygiu kūrėjai gali sukurti grįžtamojo ryšio mechanizmus ir procesus, kad atsakymai būtų pagrįsti konkrečiu naudojimo atveju ir kontekstine informacija, technika, vadinama informacijos paieškos papildyta generacija (RAG).

**Kenksmingo turinio generavimas:** Kūrėjai turėtų įvertinti rezultatus pagal jų kontekstą ir naudoti turimus saugumo klasifikatorius arba pritaikytus sprendimus, tinkamus jų naudojimo atvejui.

**Piktnaudžiavimas:** Kiti piktnaudžiavimo būdai, tokie kaip sukčiavimas, šlamštas ar kenkėjiškų programų kūrimas, gali būti įmanomi, ir kūrėjai turėtų užtikrinti, kad jų programos nepažeistų taikomų įstatymų ir reglamentų.

### Modelių pritaikymas ir AI turinio saugumas

Po modelio pritaikymo primygtinai rekomenduojame naudoti [Azure AI turinio saugumo](https://learn.microsoft.com/azure/ai-services/content-safety/overview) priemones, kad stebėtumėte modelių generuojamą turinį, identifikuotumėte ir blokuotumėte galimas rizikas, grėsmes ir kokybės problemas.

![Phi3AISafety](../../../../../imgs/01/01/01.phi3aisafety.png)

[Azure AI turinio saugumas](https://learn.microsoft.com/azure/ai-services/content-safety/overview) palaiko tiek teksto, tiek vaizdo turinį. Jis gali būti diegiamas debesyje, atjungtuose konteineriuose ir kraštiniuose/įterptuose įrenginiuose.

## Azure AI turinio saugumo apžvalga

Azure AI turinio saugumas nėra universalus sprendimas; jis gali būti pritaikytas pagal konkrečias verslo politikos nuostatas. Be to, jo daugiakalbiai modeliai leidžia suprasti kelias kalbas vienu metu.

![AIContentSafety](../../../../../imgs/01/01/01.AIcontentsafety.png)

- **Azure AI turinio saugumas**
- **Microsoft kūrėjas**
- **5 vaizdo įrašai**

Azure AI turinio saugumo paslauga aptinka kenksmingą vartotojų generuotą ir dirbtinio intelekto generuotą turinį programose ir paslaugose. Ji apima teksto ir vaizdo API, leidžiančias aptikti kenksmingą ar netinkamą medžiagą.

[AI turinio saugumo grojaraštis](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama profesionali žmogaus vertimo paslauga. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius naudojant šį vertimą.