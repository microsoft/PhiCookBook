<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T16:08:58+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "lt"
}
-->
# AI saugumas Phi modeliams
Phi modelių šeima buvo sukurta laikantis [Microsoft atsakingo AI standarto](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard), kuris yra įmonės mastu taikomas reikalavimų rinkinys, pagrįstas šiomis šešiomis pagrindinėmis taisyklėmis: atsakomybė, skaidrumas, sąžiningumas, patikimumas ir saugumas, privatumas ir saugumas bei įtrauktis, sudarančios [Microsoft atsakingo AI principus](https://www.microsoft.com/ai/responsible-ai).

Kaip ir ankstesniuose Phi modeliuose, buvo pritaikytas daugiapakopis saugumo vertinimas ir po treniruočių saugumo metodas, papildomai atsižvelgiant į šio leidimo daugialypes kalbines galimybes. Mūsų saugumo mokymo ir vertinimo metodai, įskaitant testavimą keliose kalbose ir rizikos kategorijose, yra aprašyti [Phi saugumo po treniruočių dokumente](https://arxiv.org/abs/2407.13833). Nors Phi modeliai naudoja šį metodą, kūrėjai turėtų taikyti atsakingo AI gerąsias praktikas, įskaitant rizikų, susijusių su jų konkrečiu naudojimo atveju ir kultūriniu bei kalbiniu kontekstu, žemėlapių sudarymą, matavimą ir mažinimą.

## Gerosios praktikos

Kaip ir kiti modeliai, Phi modelių šeima gali elgtis neteisingai, nepatikimai arba įžeidžiančiai.

Kai kurios SLM ir LLM ribojančios elgsenos, apie kurias verta žinoti, yra:

- **Paslaugos kokybė:** Phi modeliai daugiausia treniruojami anglų kalbos tekstais. Kitomis nei anglų kalbomis rezultatai gali būti prastesni; anglų kalbos variantai, kurie yra mažiau atstovaujami mokymo duomenyse, gali turėti blogesnį veikimą nei standartinė Amerikos anglų kalba.
- **Žalos atvaizdavimas ir stereotipų palaikymas:** Šie modeliai gali pernelyg arba nepakankamai atstovauti kai kurias žmonių grupes, ištrinti kai kurių grupių atstovavimą arba sustiprinti menkinančius ar neigiamus stereotipus. Nepaisant saugumo po treniruočių, šie apribojimai vis dar gali būti dėl skirtingų atstovavimo lygių įvairioms grupėms arba dėl neigiamų stereotipų pavyzdžių gausos mokymo duomenyse, kurie atspindi realaus pasaulio tendencijas ir visuomenės šališkumus.
- **Netinkamas ar įžeidžiantis turinys:** Šie modeliai gali generuoti kitų tipų netinkamą arba įžeidžiantį turinį, dėl kurio gali būti netinkama naudoti jautriuose kontekstuose be papildomų specifinių naudojimo atvejui taikomų priemonių.
Informacijos patikimumas: Kalbos modeliai gali generuoti nesąmoningą turinį arba sukurti turinį, kuris gali skambėti protingai, bet yra neteisingas arba pasenęs.
- **Apribotas kodų taikymo sritis:** Didžioji dalis Phi-3 mokymo duomenų pagrįsti Python ir naudoja įprastas paketas, tokias kaip „typing, math, random, collections, datetime, itertools“. Jei modelis generuoja Python skriptus, kurie naudoja kitus paketus ar kitų kalbų skriptus, rekomenduojame vartotojams rankiniu būdu patikrinti visus API naudojimus.

Kūrėjai turėtų taikyti atsakingo AI geriausias praktikas ir yra atsakingi už tai, kad konkretus naudojimo atvejis atitiktų taikomus įstatymus ir taisykles (pvz., privatumo, prekybos ir kt.).

## Atsakingo AI svarstymai

Kaip ir kiti kalbos modeliai, Phi serijos modeliai gali elgtis neteisingai, nepatikimai arba įžeidžiančiai. Kai kurios elgsenos apribojimai, apie kuriuos reikia žinoti, yra:

**Paslaugos kokybė:** Phi modeliai daugiausia treniruojami anglų kalbos tekstais. Kitomis nei anglų kalbomis rezultatai gali būti prastesni. Anglų kalbos variantai, kurių mokymo duomenyse yra mažiau, gali turėti blogesnį veikimą nei standartinė Amerikos anglų kalba.

**Žalos atvaizdavimas ir stereotipų palaikymas:** Šie modeliai gali pernelyg arba nepakankamai atstovauti kai kurias žmonių grupes, ištrinti kai kurių grupių atstovavimą arba sustiprinti menkinančius ar neigiamus stereotipus. Nepaisant saugumo po treniruočių, šie apribojimai vis dar gali būti dėl skirtingų atstovavimo lygių įvairioms grupėms arba dėl neigiamų stereotipų pavyzdžių gausos mokymo duomenyse, kurie atspindi realaus pasaulio tendencijas ir visuomenės šališkumus.

**Netinkamas ar įžeidžiantis turinys:** Šie modeliai gali generuoti kitų tipų netinkamą arba įžeidžiantį turinį, dėl kurio gali būti netinkama naudoti jautriuosiuose kontekstuose be papildomų specifinių naudojimo atvejui taikomų priemonių.
Informacijos patikimumas: Kalbos modeliai gali generuoti nesąmoningą turinį arba sukurti turinį, kuris gali skambėti protingai, bet yra neteisingas arba pasenęs.

**Apribotas kodų taikymo sritis:** Didžioji dalis Phi-3 mokymo duomenų pagrįsti Python ir naudoja įprastas paketus, tokias kaip „typing, math, random, collections, datetime, itertools“. Jei modelis generuoja Python skriptus, kurie naudoja kitus paketus ar kitų kalbų skriptus, rekomenduojame vartotojams rankiniu būdu patikrinti visus API naudojimus.

Kūrėjai turėtų taikyti atsakingo AI geriausias praktikas ir yra atsakingi už tai, kad konkretus naudojimo atvejis atitiktų taikomus įstatymus ir taisykles (pvz., privatumo, prekybos ir kt.). Svarbios svarstytinos sritys yra:

**Skyrimas:** Modeliai gali būti netinkami scenarijuose, kurie gali turėti reikšmingą poveikį teisinei padėčiai arba išteklių ar gyvenimo galimybių paskirstymui (pvz., būstas, darbas, kreditas ir kt.) be papildomų vertinimų ir šalinimo nuo šališkumo metodų.

**Didelės rizikos scenarijai:** Kūrėjai turėtų įvertinti modelių tinkamumą naudoti didelės rizikos scenarijuose, kur neteisingi, nepatikimi ar įžeidžiantys rezultatai gali būti ypač brangūs arba sukelti žalą. Tai apima patarimų teikimą jautriose ar ekspertinėse srityse, kur svarbus tikslumas ir patikimumas (pvz., teisė ar sveikata). Papildomos apsaugos priemonės turėtų būti įdiegtos programų lygyje pagal diegimo kontekstą.

**Dezinformacija:** Modeliai gali generuoti netikslią informaciją. Kūrėjai turėtų laikytis skaidrumo gerosios praktikos ir informuoti galutinius vartotojus, kad jie bendrauja su AI sistema. Programų lygyje kūrėjai gali kurti atsiliepimų mechanizmus ir vamzdynus, kad atsakymai būtų grindžiami konkrečiu naudotojo atveju ir kontekstine informacija, tai yra vadinama Retrieval Augmented Generation (RAG).

**Žalingo turinio generavimas:** Kūrėjai turėtų įvertinti rezultatus atsižvelgdami į kontekstą ir naudoti prieinamus saugumo klasifikatorius ar adaptyvius sprendimus, tinkamus jų naudojimo atvejui.

**Piktnaudžiavimas:** Kitos piktnaudžiavimo formos, tokios kaip sukčiavimas, šlamštas ar kenkėjiškų programų gamyba, gali būti įmanomos, ir kūrėjai turėtų užtikrinti, kad jų programos neprieštarautų taikomiems įstatymams ir taisyklėms.

### Modelio papildomas mokymas ir AI turinio saugumas

Po modelio papildomo mokymo labai rekomenduojame pasinaudoti [Azure AI turinio saugumu](https://learn.microsoft.com/azure/ai-services/content-safety/overview), kad būtų stebimas modelių sugeneruotas turinys, identifikuojamos ir blokuojamos galimos rizikos, grėsmės ir kokybės problemos.

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c405.lt.png)

[Azure AI turinio saugumas](https://learn.microsoft.com/azure/ai-services/content-safety/overview) palaiko tiek teksto, tiek vaizdų turinį. Jį galima diegti debesyje, atsijungusiuose konteineriuose ir periferinėse/įterptose įrenginiuose.

## Azure AI turinio saugumo apžvalga

Azure AI turinio saugumas nėra universali visiems tinkanti priemonė; ji gali būti pritaikoma pagal įmonių specifines politikos taisykles. Be to, jos daugialypiai kalbiniai modeliai leidžia vienu metu suprasti kelias kalbas.

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a.lt.png)

- **Azure AI turinio saugumas**
- **Microsoft Developer**
- **5 vaizdo įrašai**

Azure AI turinio saugumo paslauga aptinka kenksmingą vartotojų ir AI generuojamą turinį programose ir paslaugose. Ji apima teksto ir vaizdų API, leidžiančius aptikti žalingą ar netinkamą medžiagą.

[AI turinio saugumo grojaraštis](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Atsakomybės apribojimas**:
Šis dokumentas buvo išverstas naudojant dirbtinio intelekto vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors stengiamės užtikrinti tikslumą, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas gimtąja kalba laikomas autoritetingu šaltiniu. Svarbiai informacijai rekomenduojama kreiptis į profesionalius vertėjus. Mes neatsakome už jokius nesusipratimus ar neteisingus interpretavimus, kilusius dėl šio vertimo naudojimo.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->