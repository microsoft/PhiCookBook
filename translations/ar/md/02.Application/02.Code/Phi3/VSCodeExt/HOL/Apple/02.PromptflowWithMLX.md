<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-03-27T12:20:56+00:00",
  "source_file": "md\\02.Application\\02.Code\\Phi3\\VSCodeExt\\HOL\\Apple\\02.PromptflowWithMLX.md",
  "language_code": "ar"
}
-->
# **المختبر 2 - تشغيل Prompt flow مع Phi-3-mini في AIPC**

## **ما هو Prompt flow**

Prompt flow هو مجموعة من الأدوات التطويرية المصممة لتبسيط دورة التطوير الكاملة لتطبيقات الذكاء الاصطناعي المستندة إلى النماذج اللغوية الكبيرة (LLM)، بدءًا من الفكرة، النمذجة الأولية، الاختبار، التقييم، وصولاً إلى النشر في الإنتاج والمراقبة. يجعل هندسة التعليمات البرمجية أسهل بكثير ويساعدك على بناء تطبيقات LLM بجودة إنتاجية.

مع Prompt flow، ستتمكن من:

- إنشاء تدفقات تربط بين النماذج اللغوية، التعليمات البرمجية، أكواد Python وأدوات أخرى في سير عمل قابل للتنفيذ.

- تصحيح الأخطاء وتكرار تحسين تدفقاتك، خصوصًا التفاعل مع النماذج اللغوية، بسهولة.

- تقييم تدفقاتك، وحساب مقاييس الجودة والأداء باستخدام مجموعات بيانات أكبر.

- دمج الاختبار والتقييم في نظام CI/CD الخاص بك لضمان جودة التدفق.

- نشر التدفقات إلى منصة الخدمة التي تختارها أو دمجها بسهولة في قاعدة الأكواد الخاصة بتطبيقك.

- (اختياري ولكنه موصى به بشدة) التعاون مع فريقك من خلال الاستفادة من النسخة السحابية لـ Prompt flow في Azure AI.



## **بناء تدفقات أكواد التوليد على أجهزة Apple Silicon**

***ملاحظة***: إذا لم تكمل تثبيت البيئة بعد، يرجى زيارة [Lab 0 -Installations](./01.Installations.md)

1. افتح امتداد Prompt flow في Visual Studio Code وقم بإنشاء مشروع تدفق فارغ.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.ar.png)

2. أضف مدخلات ومخرجات كمعلمات وأضف كود Python كتدفق جديد.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.ar.png)

يمكنك الرجوع إلى هذا الهيكل (flow.dag.yaml) لإنشاء التدفق الخاص بك.

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. تحويل phi-3-mini

نهدف إلى تشغيل SLM بشكل أفضل على الأجهزة المحلية. بشكل عام، نقوم بتحويل النموذج (INT4, FP16, FP32).

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**ملاحظة:** المجلد الافتراضي هو mlx_model.

4. أضف الكود في ***Chat_With_Phi3.py***

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. يمكنك اختبار التدفق من خلال Debug أو Run للتحقق مما إذا كان كود التوليد يعمل بشكل صحيح.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.ar.png)

5. قم بتشغيل التدفق كواجهة برمجية للتطوير في الطرفية.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

يمكنك اختباره باستخدام Postman / Thunder Client.


### **ملاحظات**

1. التشغيل الأول يستغرق وقتًا طويلاً. يُوصى بتنزيل نموذج phi-3 من خلال Hugging face CLI.

2. نظرًا للقدرة الحوسبية المحدودة لوحدة معالجة الشبكات العصبية Intel NPU، يُوصى باستخدام Phi-3-mini-4k-instruct.

3. نستخدم تسريع Intel NPU لتحويل INT4، ولكن إذا قمت بإعادة تشغيل الخدمة، ستحتاج إلى حذف مجلدات cache وnc_workshop.



## **المصادر**

1. تعلم Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. تعلم تسريع Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. أكواد تجريبية، قم بتنزيل [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الرسمي. للحصول على معلومات حاسمة، يُوصى باستخدام ترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة ناتجة عن استخدام هذه الترجمة.