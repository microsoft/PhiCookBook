<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "006e8cf75211d3297f24e1b22e38955f",
  "translation_date": "2025-05-07T11:03:56+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "ar"
}
-->
# دردشة تعليمية تفاعلية Phi 3 Mini 4K مع Whisper

## نظرة عامة

تُعد دردشة Phi 3 Mini 4K التعليمية التفاعلية أداة تتيح للمستخدمين التفاعل مع عرض Microsoft Phi 3 Mini 4K التعليمي باستخدام إدخال نصي أو صوتي. يمكن استخدام الدردشة لمجموعة متنوعة من المهام، مثل الترجمة، تحديثات الطقس، وجمع المعلومات العامة.

### البدء

لاستخدام هذه الدردشة، اتبع التعليمات التالية ببساطة:

1. افتح [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb)
2. في النافذة الرئيسية للدفتر، سترى واجهة صندوق دردشة تحتوي على مربع إدخال نص وزر "إرسال".
3. لاستخدام الدردشة النصية، ببساطة اكتب رسالتك في مربع الإدخال ثم اضغط على زر "إرسال". سيرد الروبوت بملف صوتي يمكن تشغيله مباشرة من داخل الدفتر.

**ملاحظة**: تتطلب هذه الأداة وجود وحدة معالجة رسومات (GPU) والوصول إلى نماذج Microsoft Phi-3 وOpenAI Whisper، المستخدمة للتعرف على الكلام والترجمة.

### متطلبات وحدة معالجة الرسومات (GPU)

لتشغيل هذا العرض التجريبي، تحتاج إلى ذاكرة GPU بسعة 12 جيجابايت.

تعتمد متطلبات الذاكرة لتشغيل عرض **Microsoft-Phi-3-Mini-4K instruct** على GPU على عدة عوامل، مثل حجم بيانات الإدخال (صوت أو نص)، اللغة المستخدمة للترجمة، سرعة النموذج، والذاكرة المتاحة على وحدة معالجة الرسومات.

بشكل عام، تم تصميم نموذج Whisper للعمل على وحدات معالجة الرسومات. الحد الأدنى الموصى به لذاكرة GPU لتشغيل نموذج Whisper هو 8 جيجابايت، لكنه يمكن التعامل مع كميات أكبر من الذاكرة إذا لزم الأمر.

من المهم ملاحظة أن تشغيل كمية كبيرة من البيانات أو عدد كبير من الطلبات على النموذج قد يتطلب المزيد من ذاكرة GPU وقد يسبب مشاكل في الأداء. يُنصح باختبار حالتك مع تكوينات مختلفة ومراقبة استخدام الذاكرة لتحديد الإعدادات المثلى لاحتياجاتك الخاصة.

## عينة E2E لدردشة Phi 3 Mini 4K التعليمية التفاعلية مع Whisper

يعرض دفتر Jupyter المعنون [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) كيفية استخدام عرض Microsoft Phi 3 Mini 4K التعليمي لإنشاء نص من إدخال صوتي أو نصي مكتوب. يعرّف الدفتر عدة دوال:

1. `tts_file_name(text)`: هذه الدالة تولد اسم ملف بناءً على النص المدخل لحفظ ملف الصوت الناتج.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: تستخدم هذه الدالة واجهة برمجة تطبيقات Edge TTS لإنشاء ملف صوتي من قائمة من أجزاء النص المدخل. معلمات الإدخال هي قائمة الأجزاء، سرعة الكلام، اسم الصوت، ومسار الإخراج لحفظ ملف الصوت الناتج.
1. `talk(input_text)`: تولد هذه الدالة ملف صوتي باستخدام Edge TTS API وتحفظه باسم ملف عشوائي في مجلد /content/audio. معلمة الإدخال هي النص المراد تحويله إلى كلام.
1. `run_text_prompt(message, chat_history)`: تستخدم هذه الدالة عرض Microsoft Phi 3 Mini 4K التعليمي لإنشاء ملف صوتي من رسالة إدخال وتضيفه إلى سجل المحادثة.
1. `run_audio_prompt(audio, chat_history)`: تحول هذه الدالة ملف صوتي إلى نص باستخدام نموذج Whisper API وترسله إلى الدالة `run_text_prompt()`.
1. يشغل الكود تطبيق Gradio يسمح للمستخدمين بالتفاعل مع عرض Phi 3 Mini 4K التعليمي إما بكتابة الرسائل أو رفع ملفات صوتية. يتم عرض الإخراج كرسالة نصية داخل التطبيق.

## استكشاف الأخطاء وإصلاحها

تثبيت تعريفات Cuda GPU

1. تأكد من تحديث تطبيقات Linux الخاصة بك

    ```bash
    sudo apt update
    ```

1. تثبيت تعريفات Cuda

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. تسجيل موقع تعريف cuda

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. التحقق من حجم ذاكرة Nvidia GPU (مطلوب 12 جيجابايت من ذاكرة GPU)

    ```bash
    nvidia-smi
    ```

1. تفريغ الذاكرة المؤقتة: إذا كنت تستخدم PyTorch، يمكنك استدعاء torch.cuda.empty_cache() لتحرير كل الذاكرة المؤقتة غير المستخدمة حتى يمكن استخدامها من قبل تطبيقات GPU الأخرى

    ```python
    torch.cuda.empty_cache() 
    ```

1. التحقق من Nvidia Cuda

    ```bash
    nvcc --version
    ```

1. قم بالمهام التالية لإنشاء رمز توكن من Hugging Face.

    - انتقل إلى [صفحة إعدادات رمز توكن Hugging Face](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo).
    - اختر **New token**.
    - أدخل اسم المشروع الذي تريد استخدامه.
    - اختر **Type** إلى **Write**.

> **ملاحظة**
>
> إذا واجهت الخطأ التالي:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> لحل هذه المشكلة، اكتب الأمر التالي داخل الطرفية الخاصة بك.
>
> ```bash
> sudo ldconfig
> ```

**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الرسمي والمعتمد. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية محترفة. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ناتج عن استخدام هذه الترجمة.