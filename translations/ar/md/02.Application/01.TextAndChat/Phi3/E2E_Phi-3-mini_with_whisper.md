<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f72d7981ed3640865700f51ae407da4",
  "translation_date": "2026-01-14T15:02:57+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "ar"
}
-->
# برنامج الدردشة التفاعلي Phi 3 Mini 4K Instruct مع Whisper

## نظرة عامة

برنامج الدردشة التفاعلي Phi 3 Mini 4K Instruct هو أداة تسمح للمستخدمين بالتفاعل مع عرض Microsoft Phi 3 Mini 4K instruct باستخدام الإدخال النصي أو الصوتي. يمكن استخدام برنامج الدردشة لمجموعة متنوعة من المهام، مثل الترجمة، تحديثات الطقس، وجمع المعلومات العامة.

### البدء

لاستخدام هذا البرنامج، اتبع التعليمات التالية:

1. افتح ملف [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) جديد
2. في النافذة الرئيسية للمفكرة، سترى واجهة صندوق دردشة بها مربع إدخال نص وزر "إرسال".
3. لاستخدام برنامج الدردشة النصي، فقط اكتب رسالتك في مربع الإدخال النصي واضغط على زر "إرسال". سيرد برنامج الدردشة بملف صوتي يمكن تشغيله مباشرة من داخل المفكرة.

**ملاحظة**: تتطلب هذه الأداة وجود وحدة معالجة رسومات (GPU) والوصول إلى نماذج Microsoft Phi-3 وOpenAI Whisper، التي تُستخدم للتعرف على الكلام والترجمة.

### متطلبات وحدة معالجة الرسومات (GPU)

لتشغيل هذا العرض، تحتاج إلى 12 جيجابايت من ذاكرة وحدة معالجة الرسومات.

تعتمد متطلبات الذاكرة لتشغيل عرض **Microsoft-Phi-3-Mini-4K instruct** على وحدة معالجة الرسومات على عدة عوامل، مثل حجم بيانات الإدخال (صوت أو نص)، اللغة المستخدمة للترجمة، سرعة النموذج، والذاكرة المتاحة على وحدة معالجة الرسومات.

بشكل عام، تم تصميم نموذج Whisper ليعمل على وحدات معالجة الرسومات. الحد الأدنى الموصى به لذاكرة وحدة معالجة الرسومات لتشغيل نموذج Whisper هو 8 جيجابايت، لكنه يمكن أن يتعامل مع حجم ذاكرة أكبر إذا لزم الأمر.

من المهم ملاحظة أن تشغيل كمية كبيرة من البيانات أو حجم مرتفع من الطلبات على النموذج قد يتطلب المزيد من ذاكرة وحدة معالجة الرسومات و/أو قد يسبب مشكلات في الأداء. يُنصح باختبار حالة الاستخدام الخاصة بك مع تكوينات مختلفة ومراقبة استخدام الذاكرة لتحديد الإعدادات المثلى لاحتياجاتك الخاصة.

## نموذج E2E لبرنامج الدردشة التفاعلي Phi 3 Mini 4K Instruct مع Whisper

توضح دفترة الـ Jupyter المعنونة [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) كيفية استخدام عرض Microsoft Phi 3 Mini 4K instruct لتوليد نص من إدخال صوتي أو نصي مكتوب. تحدد الدفتر عدة دوال:

1. `tts_file_name(text)`: تقوم هذه الوظيفة بإنشاء اسم ملف بناءً على النص الإدخالي لحفظ الملف الصوتي المولد.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: تستخدم هذه الوظيفة واجهة برمجة التطبيقات Edge TTS لتوليد ملف صوتي من قائمة أجزاء نص الإدخال. المعطيات الإدخالية هي قائمة الأجزاء، سرعة الكلام، اسم الصوت، ومسار الإخراج لحفظ الملف الصوتي المولد.
1. `talk(input_text)`: تولد هذه الوظيفة ملفًا صوتيًا باستخدام واجهة برمجة التطبيقات Edge TTS وحفظه باسم عشوائي في دليل /content/audio. المعطى الإدخالي هو النص الذي يُراد تحويله إلى كلام.
1. `run_text_prompt(message, chat_history)`: تستخدم هذه الوظيفة عرض Microsoft Phi 3 Mini 4K instruct لتوليد ملف صوتي من رسالة إدخالية وتضيفه إلى محفوظات الدردشة.
1. `run_audio_prompt(audio, chat_history)`: تحول هذه الوظيفة ملفًا صوتيًا إلى نص باستخدام واجهة نموذج Whisper API وتمريره إلى وظيفة `run_text_prompt()`.
1. يشغل الكود تطبيق Gradio يسمح للمستخدمين بالتفاعل مع عرض Phi 3 Mini 4K instruct إما بكتابة الرسائل أو تحميل الملفات الصوتية. يتم عرض الإخراج كرسالة نصية داخل التطبيق.

## استكشاف الأخطاء وإصلاحها

تثبيت برامج تشغيل Cuda GPU

1. تأكد من أن تطبيقات Linux لديك محدثة

    ```bash
    sudo apt update
    ```

1. تثبيت برامج تشغيل Cuda

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. تسجيل موقع برنامج تشغيل cuda

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. التحقق من حجم ذاكرة Nvidia GPU (مطلوب 12 جيجابايت من ذاكرة GPU)

    ```bash
    nvidia-smi
    ```

1. تفريغ الذاكرة المؤقتة: إذا كنت تستخدم PyTorch، يمكنك استدعاء torch.cuda.empty_cache() لتحرير كل الذاكرة المؤقتة غير المستخدمة حتى تتمكن تطبيقات GPU الأخرى من استخدامها

    ```python
    torch.cuda.empty_cache() 
    ```

1. التحقق من Nvidia Cuda

    ```bash
    nvcc --version
    ```

1. نفذ المهام التالية لإنشاء رمز Hugging Face.

    - انتقل إلى [صفحة إعدادات رمز Hugging Face](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo).
    - اختر **رمز جديد**.
    - أدخل **اسم** المشروع الذي تريد استخدامه.
    - اختر **النوع** إلى **كتابة**.

> [!NOTE]
>
> إذا واجهت الخطأ التالي:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> لحل هذه المشكلة، اكتب الأمر التالي داخل الطرفية الخاصة بك.
>
> ```bash
> sudo ldconfig
> ```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو لُبس في المعنى. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق به. للمعلومات الهامة، يُنصح بالاعتماد على الترجمة البشرية المهنية. نحن غير مسؤولين عن أي سوء فهم أو تفسير ناتج عن استخدام هذه الترجمة.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->