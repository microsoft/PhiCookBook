<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-07-16T18:57:09+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "ar"
}
-->
## عائلة Phi في نماذج GitHub

مرحبًا بك في [نماذج GitHub](https://github.com/marketplace/models)! لقد جهزنا كل شيء لتستكشف نماذج الذكاء الاصطناعي المستضافة على Azure AI.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.aa43c51c36454747ca1cc1ffa799db02cc66b4fb7e8495311701adb072442df8.ar.png)

لمزيد من المعلومات حول النماذج المتاحة على نماذج GitHub، اطلع على [سوق نماذج GitHub](https://github.com/marketplace/models)

## النماذج المتاحة

كل نموذج له مساحة مخصصة للتجربة مع كود أمثلة

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.cf6a9f1106e048535478f17ed0078551c3959884e4083eb62a895bb089dd831c.ar.png)

### عائلة Phi في كتالوج نماذج GitHub

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## البدء

هناك بعض الأمثلة الأساسية الجاهزة للتشغيل. يمكنك العثور عليها في مجلد العينات. إذا أردت الانتقال مباشرة إلى لغتك المفضلة، يمكنك إيجاد الأمثلة في اللغات التالية:

- Python  
- JavaScript  
- C#  
- Java  
- cURL  

يوجد أيضًا بيئة Codespaces مخصصة لتشغيل العينات والنماذج.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.150220a802da6fb67944ad93c1a4c7b8a9811e43d77879a149ecf54c02928c6b.ar.png)

## كود العينة

فيما يلي مقتطفات كود لأمثلة استخدام مختلفة. لمزيد من المعلومات حول Azure AI Inference SDK، راجع الوثائق الكاملة والعينات.

## الإعداد

1. أنشئ رمز وصول شخصي  
لا تحتاج إلى منح أي أذونات للرمز. لاحظ أن الرمز سيتم إرساله إلى خدمة مايكروسوفت.

لاستخدام مقتطفات الكود أدناه، أنشئ متغير بيئة لتعيين الرمز الخاص بك كمفتاح لكود العميل.

إذا كنت تستخدم bash:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
إذا كنت تستخدم powershell:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

إذا كنت تستخدم موجه أوامر ويندوز:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## عينة Python

### تثبيت التبعيات  
ثبت Azure AI Inference SDK باستخدام pip (يتطلب: Python >=3.8):

```
pip install azure-ai-inference
```  
### تشغيل مثال كود أساسي

يعرض هذا المثال استدعاءً بسيطًا لواجهة برمجة تطبيقات إكمال الدردشة. يستخدم نقطة نهاية استدلال نموذج الذكاء الاصطناعي على GitHub ورمز GitHub الخاص بك. الاستدعاء متزامن.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### إجراء محادثة متعددة الأدوار

يعرض هذا المثال محادثة متعددة الأدوار مع واجهة برمجة تطبيقات إكمال الدردشة. عند استخدام النموذج لتطبيق دردشة، ستحتاج إلى إدارة سجل المحادثة وإرسال أحدث الرسائل إلى النموذج.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### بث المخرجات

لتحسين تجربة المستخدم، ستحتاج إلى بث استجابة النموذج بحيث يظهر أول رمز مبكرًا وتتجنب الانتظار الطويل للردود.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## الاستخدام المجاني وحدود المعدل لنماذج GitHub

![Model Catalog](../../../../../translated_images/GitHub_Model.ca6c125cb3117d0ea7c2e204b066ee4619858d28e7b1a419c262443c5e9a2d5b.ar.png)

[حدود المعدل لمساحة التجربة والاستخدام المجاني لواجهة برمجة التطبيقات](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) تهدف إلى مساعدتك في تجربة النماذج وتصميم تطبيقات الذكاء الاصطناعي الخاصة بك. لاستخدام يتجاوز هذه الحدود، ولتوسيع تطبيقك، يجب أن توفر موارد من حساب Azure، وتوثق من هناك بدلاً من رمز الوصول الشخصي لـ GitHub. لا تحتاج إلى تغيير أي شيء آخر في كودك. استخدم هذا الرابط لاكتشاف كيفية تجاوز حدود الطبقة المجانية في Azure AI.

### إخلاء المسؤولية

تذكر عند التفاعل مع نموذج أنك تجرب الذكاء الاصطناعي، لذا قد تحدث أخطاء في المحتوى.

الميزة تخضع لقيود مختلفة (بما في ذلك الطلبات في الدقيقة، الطلبات في اليوم، الرموز في الطلب، والطلبات المتزامنة) وليست مصممة للاستخدام في بيئات الإنتاج.

نماذج GitHub تستخدم Azure AI Content Safety. لا يمكن تعطيل هذه الفلاتر كجزء من تجربة نماذج GitHub. إذا قررت استخدام النماذج عبر خدمة مدفوعة، يرجى ضبط فلاتر المحتوى لتلبية متطلباتك.

هذه الخدمة تخضع لشروط الإصدار المسبق الخاصة بـ GitHub.

**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق به. للمعلومات الهامة، يُنصح بالاعتماد على الترجمة البشرية المهنية. نحن غير مسؤولين عن أي سوء فهم أو تفسير ناتج عن استخدام هذه الترجمة.