<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "805b96b20152936d8f4c587d90d6e06e",
  "translation_date": "2025-07-16T22:47:32+00:00",
  "source_file": "md/01.Introduction/05/ResponsibleAI.md",
  "language_code": "ar"
}
-->
# **تقديم الذكاء الاصطناعي المسؤول**

[Microsoft Responsible AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=aiml-138114-kinfeylo) هي مبادرة تهدف إلى مساعدة المطورين والمؤسسات في بناء أنظمة ذكاء اصطناعي تكون شفافة، موثوقة، ومسؤولة. توفر المبادرة إرشادات وموارد لتطوير حلول ذكاء اصطناعي مسؤولة تتماشى مع المبادئ الأخلاقية مثل الخصوصية، العدالة، والشفافية. سنستعرض أيضًا بعض التحديات وأفضل الممارسات المرتبطة ببناء أنظمة ذكاء اصطناعي مسؤولة.

## نظرة عامة على Microsoft Responsible AI

![RAIPrinciples](../../../../../translated_images/ar/RAIPrinciples.bf9c9bc6ca160d33.png)

**المبادئ الأخلاقية**

تسترشد Microsoft Responsible AI بمجموعة من المبادئ الأخلاقية مثل الخصوصية، العدالة، الشفافية، المساءلة، والسلامة. تم تصميم هذه المبادئ لضمان تطوير أنظمة الذكاء الاصطناعي بطريقة أخلاقية ومسؤولة.

**الذكاء الاصطناعي الشفاف**

تؤكد Microsoft Responsible AI على أهمية الشفافية في أنظمة الذكاء الاصطناعي. يشمل ذلك تقديم تفسيرات واضحة لكيفية عمل نماذج الذكاء الاصطناعي، بالإضافة إلى ضمان توفر مصادر البيانات والخوارزميات للجمهور.

**الذكاء الاصطناعي المسؤول**

[Microsoft Responsible AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=aiml-138114-kinfeylo) تشجع على تطوير أنظمة ذكاء اصطناعي مسؤولة، يمكنها تقديم رؤى حول كيفية اتخاذ نماذج الذكاء الاصطناعي للقرارات. هذا يساعد المستخدمين على فهم وثقة مخرجات أنظمة الذكاء الاصطناعي.

**الشمولية**

يجب تصميم أنظمة الذكاء الاصطناعي لتفيد الجميع. تهدف Microsoft إلى إنشاء ذكاء اصطناعي شامل يأخذ في الاعتبار وجهات نظر متنوعة ويتجنب التحيز أو التمييز.

**الموثوقية والسلامة**

ضمان أن تكون أنظمة الذكاء الاصطناعي موثوقة وآمنة أمر بالغ الأهمية. تركز Microsoft على بناء نماذج قوية تؤدي أداءً ثابتًا وتتجنب النتائج الضارة.

**العدالة في الذكاء الاصطناعي**

تعترف Microsoft Responsible AI بأن أنظمة الذكاء الاصطناعي قد تعزز التحيزات إذا تم تدريبها على بيانات أو خوارزميات متحيزة. توفر المبادرة إرشادات لتطوير أنظمة ذكاء اصطناعي عادلة لا تميز بناءً على عوامل مثل العرق، الجنس، أو العمر.

**الخصوصية والأمان**

تؤكد Microsoft Responsible AI على أهمية حماية خصوصية المستخدم وأمن البيانات في أنظمة الذكاء الاصطناعي. يشمل ذلك تنفيذ تشفير قوي للبيانات وضوابط وصول، بالإضافة إلى تدقيق منتظم للأنظمة للكشف عن الثغرات.

**المساءلة والمسؤولية**

تشجع Microsoft Responsible AI على المساءلة والمسؤولية في تطوير ونشر الذكاء الاصطناعي. يشمل ذلك ضمان وعي المطورين والمؤسسات بالمخاطر المحتملة المرتبطة بأنظمة الذكاء الاصطناعي واتخاذ خطوات لتقليل تلك المخاطر.

## أفضل الممارسات لبناء أنظمة ذكاء اصطناعي مسؤولة

**تطوير نماذج ذكاء اصطناعي باستخدام مجموعات بيانات متنوعة**

لتجنب التحيز في أنظمة الذكاء الاصطناعي، من المهم استخدام مجموعات بيانات متنوعة تمثل مجموعة واسعة من وجهات النظر والتجارب.

**استخدام تقنيات الذكاء الاصطناعي القابلة للتفسير**

يمكن لتقنيات الذكاء الاصطناعي القابلة للتفسير مساعدة المستخدمين على فهم كيفية اتخاذ نماذج الذكاء الاصطناعي للقرارات، مما يزيد من الثقة في النظام.

**تدقيق أنظمة الذكاء الاصطناعي بانتظام للكشف عن الثغرات**

يمكن أن تساعد عمليات التدقيق المنتظمة لأنظمة الذكاء الاصطناعي في تحديد المخاطر والثغرات المحتملة التي يجب معالجتها.

**تنفيذ تشفير قوي للبيانات وضوابط وصول**

يساعد تشفير البيانات وضوابط الوصول في حماية خصوصية وأمان المستخدمين في أنظمة الذكاء الاصطناعي.

**اتباع المبادئ الأخلاقية في تطوير الذكاء الاصطناعي**

اتباع المبادئ الأخلاقية مثل العدالة، الشفافية، والمساءلة يمكن أن يساعد في بناء ثقة في أنظمة الذكاء الاصطناعي وضمان تطويرها بطريقة مسؤولة.

## استخدام AI Foundry للذكاء الاصطناعي المسؤول

[Azure AI Foundry](https://ai.azure.com?WT.mc_id=aiml-138114-kinfeylo) هو منصة قوية تتيح للمطورين والمؤسسات إنشاء تطبيقات ذكية ومتطورة وجاهزة للسوق وبمسؤولية بسرعة. فيما يلي بعض الميزات والقدرات الرئيسية لـ Azure AI Foundry:

**واجهات برمجة التطبيقات والنماذج الجاهزة**

يوفر Azure AI Foundry واجهات برمجة تطبيقات ونماذج جاهزة وقابلة للتخصيص. تغطي هذه مجموعة واسعة من مهام الذكاء الاصطناعي، بما في ذلك الذكاء الاصطناعي التوليدي، معالجة اللغة الطبيعية للمحادثات، البحث، المراقبة، الترجمة، الصوت، الرؤية، واتخاذ القرار.

**Prompt Flow**

تمكنك ميزة Prompt Flow في Azure AI Foundry من إنشاء تجارب ذكاء اصطناعي محادثية. تتيح لك تصميم وإدارة تدفقات المحادثات، مما يسهل بناء روبوتات الدردشة، المساعدين الافتراضيين، وتطبيقات تفاعلية أخرى.

**التوليد المعزز بالاسترجاع (RAG)**

RAG هي تقنية تجمع بين النهج القائم على الاسترجاع والنهج التوليدي. تعزز جودة الردود المولدة من خلال الاستفادة من المعرفة الموجودة مسبقًا (الاسترجاع) والإبداع في التوليد (التوليد).

**مقاييس التقييم والمراقبة للذكاء الاصطناعي التوليدي**

يوفر Azure AI Foundry أدوات لتقييم ومراقبة نماذج الذكاء الاصطناعي التوليدي. يمكنك تقييم أدائها، عدالتها، وغيرها من المقاييس المهمة لضمان النشر المسؤول. بالإضافة إلى ذلك، إذا قمت بإنشاء لوحة تحكم، يمكنك استخدام واجهة المستخدم بدون كود في Azure Machine Learning Studio لتخصيص وإنشاء لوحة تحكم للذكاء الاصطناعي المسؤول وبطاقة تقييم مرتبطة بناءً على مكتبات [Repsonsible AI Toolbox](https://responsibleaitoolbox.ai/?WT.mc_id=aiml-138114-kinfeylo) الخاصة بـ Python. تساعدك بطاقة التقييم هذه على مشاركة الرؤى الرئيسية المتعلقة بالعدالة، أهمية الميزات، واعتبارات النشر المسؤول مع أصحاب المصلحة الفنيين وغير الفنيين.

لاستخدام AI Foundry مع الذكاء الاصطناعي المسؤول، يمكنك اتباع أفضل الممارسات التالية:

**تحديد المشكلة وأهداف نظام الذكاء الاصطناعي**

قبل بدء عملية التطوير، من المهم تحديد المشكلة أو الهدف الذي يهدف نظام الذكاء الاصطناعي إلى حله بوضوح. سيساعدك ذلك في تحديد البيانات، الخوارزميات، والموارد اللازمة لبناء نموذج فعال.

**جمع البيانات ذات الصلة ومعالجتها مسبقًا**

جودة وكمية البيانات المستخدمة في تدريب نظام الذكاء الاصطناعي يمكن أن تؤثر بشكل كبير على أدائه. لذلك، من المهم جمع بيانات ذات صلة، تنظيفها، معالجتها مسبقًا، والتأكد من تمثيلها للسكان أو المشكلة التي تحاول حلها.

**اختيار التقييم المناسب**

تتوفر خوارزميات تقييم مختلفة. من المهم اختيار الخوارزمية الأنسب بناءً على بياناتك ومشكلتك.

**تقييم النموذج وتفسيره**

بمجرد بناء نموذج ذكاء اصطناعي، من المهم تقييم أدائه باستخدام المقاييس المناسبة وتفسير النتائج بطريقة شفافة. سيساعدك ذلك في تحديد أي تحيزات أو قيود في النموذج وإجراء التحسينات اللازمة.

**ضمان الشفافية وقابلية التفسير**

يجب أن تكون أنظمة الذكاء الاصطناعي شفافة وقابلة للتفسير حتى يتمكن المستخدمون من فهم كيفية عملها وكيفية اتخاذ القرارات. هذا مهم بشكل خاص للتطبيقات التي تؤثر بشكل كبير على حياة البشر، مثل الرعاية الصحية، المالية، والأنظمة القانونية.

**مراقبة النموذج وتحديثه**

يجب مراقبة أنظمة الذكاء الاصطناعي باستمرار وتحديثها لضمان بقائها دقيقة وفعالة مع مرور الوقت. يتطلب ذلك صيانة مستمرة، اختبار، وإعادة تدريب للنموذج.

في الختام، تعد Microsoft Responsible AI مبادرة تهدف إلى مساعدة المطورين والمؤسسات في بناء أنظمة ذكاء اصطناعي شفافة، موثوقة، ومسؤولة. تذكر أن تنفيذ الذكاء الاصطناعي المسؤول أمر حيوي، وتهدف Azure AI Foundry إلى جعله عمليًا للمؤسسات. من خلال اتباع المبادئ الأخلاقية وأفضل الممارسات، يمكننا ضمان تطوير ونشر أنظمة الذكاء الاصطناعي بطريقة مسؤولة تفيد المجتمع ككل.

**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق به. للمعلومات الهامة، يُنصح بالترجمة البشرية المهنية. نحن غير مسؤولين عن أي سوء فهم أو تفسير ناتج عن استخدام هذه الترجمة.