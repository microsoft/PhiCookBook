{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# المختبر-1-تعريف Phi-3.5 Instruct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تحويل نموذج Phi-3-mini-4k-instruct إلى INT4 باستخدام optimum-cli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "llm_model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "llm_model_path = \"../model/phi-3.5-mini-instruct-ov\"\n",
    "\n",
    "if not Path(llm_model_path).exists():\n",
    "    !optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from optimum.intel.openvino import OVModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_config = {\"PERFORMANCE_HINT\": \"LATENCY\", \"NUM_STREAMS\": \"1\", \"CACHE_DIR\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_model = OVModelForCausalLM.from_pretrained(\n",
    "    llm_model_path,\n",
    "    device='GPU',\n",
    "    ov_config=ov_config,\n",
    "    config=AutoConfig.from_pretrained(llm_model_path, trust_remote_code=True),\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(llm_model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs =  {\"add_special_tokens\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<|user|>\\n你了解 .NET 吗?\\n<|end|><|assistant|>\\n\"\n",
    "input_tokens = tok(prompt, return_tensors=\"pt\", **tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ov_model.generate(**input_tokens, max_new_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.batch_decode(answer, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvinodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "92140c3d4ec4c67c1232c5d30f1d2b84",
   "translation_date": "2025-09-12T19:13:44+00:00",
   "source_file": "code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}