<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-07-16T18:55:01+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "ro"
}
-->
# **Folosirea familiei Phi în Hugging Face**

[Hugging Face](https://huggingface.co/) este o comunitate AI foarte populară, cu resurse bogate de date și modele open source. Diferite companii lansează modele LLM și SLM open source prin Hugging Face, cum ar fi Microsoft, Meta, Mistral, Apple, Google și altele.

Familia Microsoft Phi a fost lansată pe Hugging Face. Dezvoltatorii pot descărca modelele corespunzătoare familiei Phi în funcție de scenarii și domenii de activitate. Pe lângă implementarea modelelor Phi Pytorch pe Hugging Face, am lansat și modele cuantificate, folosind formatele GGUF și ONNX pentru a oferi utilizatorilor finali mai multe opțiuni.

## **Descărcarea modelelor pe Hugging Face**

Poți descărca modelele din familia Phi folosind acest link

[Modele Microsoft pe Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Poți descărca modelele în mai multe moduri, cum ar fi instalarea ***Hugging face CLI SDK*** sau folosind ***git clone***.

### **Folosirea Hugging face CLI pentru a descărca modelele din familia Phi**

- Instalează Hugging face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Folosirea huggingface-cli pentru autentificare

Autentifică-te pe Hugging face cu [User Access Token](https://huggingface.co/docs/hub/security-tokens) de pe pagina ta de [Setări](https://huggingface.co/settings/tokens)

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Descărcare

Poți descărca modelul și îl poți salva în cache

```bash

huggingface-cli download microsoft/phi-4

```

Poți seta locația într-un folder special

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **Folosirea git clone pentru a descărca modelele din familia Phi**

Poți folosi și ***git clone*** pentru a descărca modelele

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Exemple - Inferență Microsoft Phi-4**

- **Instalarea bibliotecii transformers**

```bash

pip install transformers -U

```

- **Rularea acestui cod în VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa nativă trebuie considerat sursa autorizată. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm răspunderea pentru eventualele neînțelegeri sau interpretări greșite rezultate din utilizarea acestei traduceri.