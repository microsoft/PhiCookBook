<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-05-09T08:59:29+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "ro"
}
-->
## Familia Phi în GitHub Models

Bine ați venit la [GitHub Models](https://github.com/marketplace/models)! Avem totul pregătit pentru ca tu să explorezi modelele AI găzduite pe Azure AI.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.4fc858ab26afe64c43f5e423ad0c5c733878bb536fdb027a5bcf1f80c41b0633.ro.png)

Pentru mai multe informații despre modelele disponibile pe GitHub Models, consultă [GitHub Model Marketplace](https://github.com/marketplace/models)

## Modele Disponibile

Fiecare model are un spațiu dedicat de testare și cod exemplu

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.998e294f6ee69c3ca174c880b32af9feec4221d0d787de899ad9bb2da3b58981.ro.png)

### Familia Phi în Catalogul GitHub Models

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## Începutul utilizării

Există câteva exemple de bază gata să fie rulate. Le poți găsi în directorul samples. Dacă vrei să treci direct la limbajul tău preferat, poți găsi exemplele în următoarele limbaje:

- Python
- JavaScript
- C#
- Java
- cURL

Există, de asemenea, un mediu dedicat Codespaces pentru rularea exemplelor și a modelelor.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.b4b839a081583da39bc976c2f0d8ac4603d3b8c23194b16cc9e0a1014f5611d0.ro.png)

## Cod Exemplu

Mai jos sunt fragmente de cod exemplu pentru câteva cazuri de utilizare. Pentru informații suplimentare despre Azure AI Inference SDK, consultă documentația completă și exemplele.

## Configurare

1. Creează un token de acces personal  
Nu trebuie să oferi niciun fel de permisiuni token-ului. Reține că token-ul va fi trimis către un serviciu Microsoft.

Pentru a folosi fragmentele de cod de mai jos, creează o variabilă de mediu pentru a seta token-ul tău ca și cheie pentru codul client.

Dacă folosești bash:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
Dacă folosești powershell:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

Dacă folosești Windows command prompt:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## Exemplu Python

### Instalarea dependențelor  
Instalează Azure AI Inference SDK folosind pip (Necesită: Python >=3.8):

```
pip install azure-ai-inference
```  
### Rulează un exemplu simplu de cod

Acest exemplu demonstrează un apel de bază la API-ul de chat completion. Folosește endpoint-ul de inferență al modelului AI GitHub și token-ul tău GitHub. Apelul este sincron.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### Rulează o conversație multi-turn

Acest exemplu arată o conversație multi-turn cu API-ul de chat completion. Când folosești modelul pentru o aplicație de chat, trebuie să gestionezi istoricul conversației și să trimiți ultimele mesaje către model.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### Redirecționarea răspunsului în timp real

Pentru o experiență mai bună a utilizatorului, vei dori să redirecționezi răspunsul modelului astfel încât primul token să apară rapid și să eviți să aștepți răspunsuri lungi.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## Utilizare GRATUITĂ și limite de rată pentru GitHub Models

![Model Catalog](../../../../../translated_images/GitHub_Model.0c2abb992151c5407046e2b763af51505ff709f04c0950785e0300fdc8c55a0c.ro.png)

[Limitele de rată pentru playground și utilizarea gratuită a API-ului](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) sunt concepute pentru a te ajuta să experimentezi cu modelele și să prototipezi aplicația ta AI. Pentru utilizarea dincolo de aceste limite și pentru a-ți scala aplicația, trebuie să aloci resurse dintr-un cont Azure și să te autentifici de acolo în loc de token-ul tău personal GitHub. Nu trebuie să schimbi nimic altceva în codul tău. Folosește acest link pentru a afla cum să depășești limitele gratuite în Azure AI.

### Declarații

Ține minte că atunci când interacționezi cu un model, experimentezi cu AI, deci pot apărea erori de conținut.

Funcționalitatea este supusă unor limite variate (inclusiv cereri pe minut, cereri pe zi, tokeni per cerere și cereri concurente) și nu este destinată pentru cazuri de utilizare în producție.

GitHub Models folosește Azure AI Content Safety. Aceste filtre nu pot fi dezactivate în cadrul experienței GitHub Models. Dacă decizi să folosești modele printr-un serviciu plătit, te rugăm să configurezi filtrele de conținut conform cerințelor tale.

Acest serviciu este supus Termenilor Pre-release GitHub.

**Declinare a responsabilității**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa nativă, trebuie considerat sursa autorizată. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm răspunderea pentru eventualele neînțelegeri sau interpretări greșite rezultate din utilizarea acestei traduceri.