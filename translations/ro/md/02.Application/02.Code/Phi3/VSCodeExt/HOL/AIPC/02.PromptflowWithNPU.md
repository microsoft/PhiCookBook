<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-05-09T19:26:19+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "ro"
}
-->
# **Lab 2 - Rulează Prompt flow cu Phi-3-mini în AIPC**

## **Ce este Prompt flow**

Prompt flow este un set de instrumente de dezvoltare conceput pentru a simplifica ciclul complet de dezvoltare a aplicațiilor AI bazate pe LLM, de la idee, prototipare, testare, evaluare până la implementare în producție și monitorizare. Face ingineria prompturilor mult mai ușoară și îți permite să construiești aplicații LLM de calitate pentru producție.

Cu prompt flow, vei putea:

- Să creezi fluxuri care leagă LLM-uri, prompturi, cod Python și alte unelte într-un flux de lucru executabil.

- Să depanezi și să iterezi fluxurile tale, în special interacțiunea cu LLM-urile, cu ușurință.

- Să evaluezi fluxurile, să calculezi metrici de calitate și performanță cu seturi de date mai mari.

- Să integrezi testarea și evaluarea în sistemul tău CI/CD pentru a asigura calitatea fluxului.

- Să implementezi fluxurile pe platforma de servire aleasă sau să le integrezi ușor în baza de cod a aplicației tale.

- (Opțional, dar foarte recomandat) Să colaborezi cu echipa ta folosind versiunea cloud a Prompt flow în Azure AI.

## **Ce este AIPC**

Un AI PC are un CPU, un GPU și un NPU, fiecare cu capacități specifice de accelerare AI. Un NPU, sau unitate de procesare neurală, este un accelerator specializat care gestionează sarcinile de inteligență artificială (AI) și învățare automată (ML) direct pe PC-ul tău, în loc să trimită datele pentru procesare în cloud. GPU-ul și CPU-ul pot procesa, de asemenea, aceste sarcini, dar NPU-ul este deosebit de eficient la calculele AI cu consum redus de energie. AI PC reprezintă o schimbare fundamentală în modul în care funcționează computerele noastre. Nu este o soluție pentru o problemă care nu exista înainte, ci promite o îmbunătățire majoră pentru utilizările zilnice ale PC-ului.

Cum funcționează? Comparativ cu AI generativ și modelele mari de limbaj (LLM) antrenate pe volume uriașe de date publice, AI-ul care rulează pe PC-ul tău este mai accesibil practic la toate nivelurile. Conceptul este mai ușor de înțeles, iar pentru că este antrenat pe datele tale, fără a fi nevoie să acceseze cloud-ul, beneficiile sunt imediat mai atractive pentru un public mai larg.

Pe termen scurt, lumea AI PC implică asistenți personali și modele AI mai mici care rulează direct pe PC-ul tău, folosind datele tale pentru a oferi îmbunătățiri AI personale, private și mai sigure pentru activitățile pe care le faci zilnic – luarea notițelor în ședințe, organizarea unei ligi de fantasy football, automatizarea îmbunătățirilor pentru editarea foto și video sau planificarea itinerariului perfect pentru o reuniune de familie în funcție de orele de sosire și plecare ale tuturor.

## **Construirea fluxurilor de generare de cod pe AIPC**

***Note*** ：Dacă nu ai finalizat instalarea mediului, te rugăm să vizitezi [Lab 0 - Installations](./01.Installations.md)

1. Deschide extensia Prompt flow în Visual Studio Code și creează un proiect de flux gol

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.ro.png)

2. Adaugă parametrii Inputs și Outputs și adaugă cod Python ca un nou flux

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.ro.png)

Poți consulta această structură (flow.dag.yaml) pentru a-ți construi fluxul

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Adaugă cod în ***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Poți testa fluxul din Debug sau Run pentru a verifica dacă generarea codului funcționează corect

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.ro.png)

5. Rulează fluxul ca API de dezvoltare în terminal

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Poți testa în Postman / Thunder Client

### **Note**

1. Prima rulare durează mult. Se recomandă să descarci modelul phi-3 folosind Hugging face CLI.

2. Având în vedere puterea de calcul limitată a Intel NPU, se recomandă utilizarea Phi-3-mini-4k-instruct.

3. Folosim Intel NPU Acceleration pentru conversia în cuantizare INT4, dar dacă reiei serviciul, trebuie să ștergi folderele cache și nc_workshop.

## **Resurse**

1. Învață Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Învață Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Cod exemplu, descarcă [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Declinare a responsabilității**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa nativă trebuie considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite rezultate din utilizarea acestei traduceri.