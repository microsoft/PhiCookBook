<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c4fe7f589d179be96a5577b0b8cba6aa",
  "translation_date": "2025-07-17T02:55:07+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md",
  "language_code": "ro"
}
-->
# **Folosirea Microsoft Phi-3.5 tflite pentru a crea o aplicaÈ›ie Android**

Acesta este un exemplu Android care utilizeazÄƒ modelele Microsoft Phi-3.5 tflite.

## **ğŸ“š CunoÈ™tinÈ›e**

Android LLM Inference API Ã®È›i permite sÄƒ rulezi modele mari de limbaj (LLM-uri) complet pe dispozitiv pentru aplicaÈ›iile Android, pe care le poÈ›i folosi pentru o gamÄƒ largÄƒ de sarcini, cum ar fi generarea de text, extragerea informaÈ›iilor Ã®n formÄƒ naturalÄƒ È™i rezumarea documentelor. AceastÄƒ funcÈ›ie oferÄƒ suport integrat pentru mai multe modele mari de limbaj text-la-text, astfel Ã®ncÃ¢t sÄƒ poÈ›i aplica cele mai noi modele generative AI pe dispozitiv Ã®n aplicaÈ›iile tale Android.

Googld AI Edge Torch este o bibliotecÄƒ Python care suportÄƒ conversia modelelor PyTorch Ã®n format .tflite, care pot fi apoi rulate cu TensorFlow Lite È™i MediaPipe. Aceasta permite aplicaÈ›ii pentru Android, iOS È™i IoT care pot rula modelele complet pe dispozitiv. AI Edge Torch oferÄƒ o acoperire largÄƒ pentru CPU, cu suport iniÈ›ial pentru GPU È™i NPU. AI Edge Torch urmÄƒreÈ™te o integrare strÃ¢nsÄƒ cu PyTorch, construind pe baza torch.export() È™i oferind o bunÄƒ acoperire a operatorilor Core ATen.

## **ğŸª¬ Ghid**

### **ğŸ”¥ Conversia Microsoft Phi-3.5 la suport tflite**

0. Acest exemplu este pentru Android 14+

1. InstaleazÄƒ Python 3.10.12

***Sugestie:*** foloseÈ™te conda pentru a-È›i instala mediul Python

2. Ubuntu 20.04 / 22.04 (te rugÄƒm sÄƒ te concentrezi pe [google ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch))

***Sugestie:*** FoloseÈ™te o maÈ™inÄƒ virtualÄƒ Azure Linux sau o maÈ™inÄƒ virtualÄƒ cloud de la terÈ›i pentru a-È›i crea mediul

3. Deschide terminalul Linux È™i instaleazÄƒ biblioteca Python

```bash

git clone https://github.com/google-ai-edge/ai-edge-torch.git

cd ai-edge-torch

pip install -r requirements.txt -U 

pip install tensorflow-cpu -U

pip install -e .

```

4. DescarcÄƒ Microsoft-3.5-Instruct de pe Hugging face

```bash

git lfs install

git clone  https://huggingface.co/microsoft/Phi-3.5-mini-instruct

```

5. ConverteÈ™te Microsoft Phi-3.5 Ã®n tflite

```bash

python ai-edge-torch/ai_edge_torch/generative/examples/phi/convert_phi3_to_tflite.py --checkpoint_path  Your Microsoft Phi-3.5-mini-instruct path --tflite_path Your Microsoft Phi-3.5-mini-instruct tflite path  --prefill_seq_len 1024 --kv_cache_max_len 1280 --quantize True

```

### **ğŸ”¥ Conversia Microsoft Phi-3.5 Ã®n pachet Android Mediapipe**

te rugÄƒm sÄƒ instalezi mai Ã®ntÃ¢i mediapipe

```bash

pip install mediapipe

```

ruleazÄƒ acest cod Ã®n [notebook-ul tÄƒu](../../../../../../code/09.UpdateSamples/Aug/Android/convert/convert_phi.ipynb)

```python

import mediapipe as mp
from mediapipe.tasks.python.genai import bundler

config = bundler.BundleConfig(
    tflite_model='Your Phi-3.5 tflite model path',
    tokenizer_model='Your Phi-3.5 tokenizer model path',
    start_token='start_token',
    stop_tokens=[STOP_TOKENS],
    output_filename='Your Phi-3.5 task model path',
    enable_bytes_to_unicode_mapping=True or Flase,
)
bundler.create_bundle(config)

```

### **ğŸ”¥ Folosirea adb push pentru a transfera modelul task pe calea dispozitivului tÄƒu Android**

```bash

adb shell rm -r /data/local/tmp/llm/ # Remove any previously loaded models

adb shell mkdir -p /data/local/tmp/llm/

adb push 'Your Phi-3.5 task model path' /data/local/tmp/llm/phi3.task

```

### **ğŸ”¥ Rularea codului tÄƒu Android**

![demo](../../../../../../translated_images/ro/demo.06d5a4246f057d1b.png)

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim pentru acurateÈ›e, vÄƒ rugÄƒm sÄƒ reÈ›ineÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa nativÄƒ trebuie considerat sursa autorizatÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm rÄƒspunderea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite rezultate din utilizarea acestei traduceri.