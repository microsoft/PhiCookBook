<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f4cbbe7bf3e764de52d64a96d97b3c35",
  "translation_date": "2026-01-05T15:08:36+00:00",
  "source_file": "md/01.Introduction/04/QuantifyingPhi.md",
  "language_code": "ml"
}
-->
# **ഫൈ കുടുംബത്തിന്റെ അളവ് നിർണ്ണയം**

മോഡൽ ക്വാണ്ടൈസേഷൻ란 അത് ഒരു ന്യൂറൽ നെറ്റ്‌വർക്ക് മോഡലിലുള്ള പരാമീറ്ററുകളെ (ഭാരം, ആക്ടിവേഷൻ മൂല്യങ്ങൾ പോലുള്ളവ) വലിയ മൂല്യപരിധി (സാധാരണയായി സ്ഥിരം മൂല്യപരിധി) నుండి ചെറിയ പരിമിതമായ മൂല്യപരിധിയിലേക്ക് മാപ്പ് ചെയ്യുന്നതിനെ സൂചിപ്പിക്കുന്നു. ഈ സാങ്കേതിക വിദ്യ മോഡലിന്റെ വലിപ്പവും കണക്കുകൂട്ടൽ താഴ്ചയും കുറയ്ക്കുകയും, മൊബൈൽ ഉപകരണങ്ങൾ അല്ലെങ്കിൽ എംബഡഡ് സിസ്റ്റങ്ങൾ പോലുള്ള വിഭവ പരിമിത സാഹചര്യങ്ങളിലും മോഡലിന്റെ പ്രവർത്തനക്ഷമത മെച്ചപ്പെടുത്തുകയും ചെയ്യുന്നു. മോഡൽ ക്വാണ്ടൈസേഷൻ, പരാമീറ്ററുകളുടെ അടിഷ്ടാനമായ കൃത്യത കുറച്ചുകൊണ്ട് സംഖ്യാനിക്ഷേപം നേടുന്നു, എന്നാൽ ഇത് ചില കൃത്യത നഷ്ടവും ഉണ്ടാക്കുന്നു. അതിനാൽ ക്വാണ്ടൈസേഷൻ പ്രക്രിയയിൽ മോഡലിന്റെ വലിപ്പം, കണക്കുകൂട്ടൽ സങ്കീർണ്ണത, കൃത്യത എന്നിവയ്ക്ക് സമതുലനം പാലിക്കേണ്ടതുണ്ട്. സാധാരണയായി ഉപയോഗിക്കുന്ന ക്വാണ്ടൈസേഷൻ മാർഗങ്ങൾക്കായി സ്ഥിരം പോയിന്റ് ക്വാണ്ടൈസേഷൻ, ഫ്ലോട്ടിങ് പോയിന്റ് ക്വാണ്ടൈസേഷൻ എന്നിവ ഉൾപ്പെടുന്നു. പ്രത്യേക സാഹചര്യങ്ങളെയും ആവശ്യങ്ങളെയും അനുസരിച്ച് അനുയോജ്യമായ ക്വാണ്ടൈസേഷൻ തന്ത്രം തിരഞ്ഞെടുക്കാവുന്നതാണ്.

GenAI മോഡലുകൾ എഡ്ജ് ഉപകരണങ്ങളിൽ വിന്യസിക്കുകയും, കൂടുതൽ ഉപകരണങ്ങൾ GenAI സാഹചര്യങ്ങളിൽ പ്രവേശിപ്പിക്കുകയും ചെയ്യാൻ ആഗ്രഹിക്കുന്നു, ഉദാഹരണത്തിന് മൊബൈൽ ഉപകരണങ്ങൾ, AI PC / Copilot+PC, പാരമ്പര്യ IoT ഉപകരണങ്ങൾ തുടങ്ങിയവ. ക്വാണ്ടൈസേഷൻ മോഡലിലൂടെ, വ്യത്യസ്ത ഉപകരണങ്ങളുടെ അടിസ്ഥാനത്തിൽ വിവിധ എഡ്ജ് ഉപകരണങ്ങളിൽ വിന്യസിക്കാം. ഹാർഡ്‌വെയർ നിർമ്മാതാക്കള կողմից നൽകിയ മോഡൽ ബൂസ്റ്റ് ഫ്രെയിംവർക്ക്, ക്വാണ്ടൈസേഷൻ മോഡലുകൾ എന്നിവയുടെ സംയോജനത്തിൽ മികച്ച SLM അപ്ലിക്കേഷൻ സാഹചര്യങ്ങൾ സൃഷ്ടിക്കാവുന്നതാണ്.

ക്വാണ്ടൈസേഷൻ സാഹചര്യങ്ങളിൽ, വിവിധ കൃത്യതയുണ്ട് (INT4, INT8, FP16, FP32). താഴെ സാധാരണ ഉപയോഗിക്കുന്ന ക്വാണ്ടൈസേഷൻ കൃത്യതകളുടെ വിവരണം നൽകിയിരിക്കുന്നു.

### **INT4**

INT4 ക്വാണ്ടൈസേഷൻ മോഡലിന്റെ ഭാരങ്ങളും ആക്ടിവേഷൻ മൂല്യങ്ങളും 4-ബിറ്റ് ഇന്റിജറായി ക്വאַנץ ചെയ്യുന്നതാണ്. ചെറിയ പ്രതിനിധാന പരിധിയും കുറഞ്ഞ കൃത്യതയും മൂലം INT4 ക്വാണ്ടൈസേഷൻ സാധാരണയായി വലിയ കൃത്യത നഷ്ടം ഉണ്ടാക്കുന്നു. എന്നിരുന്നാലും, INT8 ക്വാണ്ടൈസേഷനോടുള്ള താരതമ്യത്തിൽ, INT4 ക്വാണ്ടൈസേഷൻ മോഡലിന്റെ സ്റ്റോറേജ് ആവശ്യകതകളും കണക്കുകൂട്ടൽ സങ്കീർണ്ണതയും തുടർന്നും കുറയ്ക്കാൻ കഴിയും. പ്രായോഗിക ഉപയോഗങ്ങളിൽ INT4 ക്വാണ്ടൈസേഷൻ അപൂർവ്വമാണ്, കാരണം വളരെ കുറവ് കൃത്യത മോഡൽ പ്രവർത്തനക്ഷമതയിൽ വലിയ കുറവ് ഉണ്ടാക്കാം. കൂടാതെ, എല്ലാ ഹാർഡ്‌വെയറും INT4 പ്രവർത്തനങ്ങളെ പിന്തുണയ്ക്കുന്നില്ല, അതിനാൽ ക്വാണ്ടൈസേഷൻ മാർഗം തിരഞ്ഞെടുക്കുമ്പോൾ ഹാർഡ്‌വെയർ അനുസരണമുണ്ടോ എന്നത് പരിഗണിക്കേണ്ടതാണ്.

### **INT8**

INT8 ക്വാണ്ടൈസേഷൻ란 മോഡലിന്റെ ഭാരങ്ങളും ആക്ടിവേഷൻ മൂല്യങ്ങളും ഫ്ലോട്ടിങ് പോയിന്റ് നമ്പറുകളിൽ നിന്നും 8-ബിറ്റ് ഇന്റിജറുകളിലേക്ക് പരിവർത്തനം ചെയ്യുന്നതാണ്. INT8 ഇंटേജറുകൾ പ്രതിനിധാനം ചെയ്യുന്ന സംഖ്യ പരിധി വളരെ കുറവായതും കുറഞ്ഞ കൃത്യതയുള്ളതുമായിരിക്കാം, പക്ഷേ ഇത് സ്റ്റോറേജ് ആവശ്യകതകളും കണക്കുകൂട്ടൽ വേഗതകളും ഗണ്യമായി കുറയ്ക്കാം. INT8 ക്വാണ്ടൈസേഷനിൽ, മോഡലിന്റെ ഭാരങ്ങളും ആക്ടിവേഷൻ മൂല്യങ്ങളും സ്കെയിലിംഗും ഓഫ്‌സെറ്റും ഉൾപ്പെടുന്ന ക്വാണ്ടൈസേഷൻ പ്രക്രിയയിലൂടെ കടന്ന് യഥാർത്ഥ ഫ്ലോട്ടിങ് പോയിന്റ് വിവരങ്ങൾ പരമാവധി സംരക്ഷിക്കുകയും ചെയ്യുന്നു. ഇൻഫറൻസിന്റെ സമയത്ത്, ഇവ യഥാർത്ഥ ഫ്ലോട്ടിങ് പോയിന്റ് നമ്പറുകളിൽ തിരിച്ചുമാറ്റപ്പെട്ട് കണക്കു തീർക്കുന്നു, പിന്നെ അടുത്ത ഘട്ടത്തിനായി വീണ്ടും INT8 ആക്കുന്നു. ഈ രീതിയിൽ അധികം കൃത്യത ആവശ്യമായ അവസ്ഥകളിൽ മതി വിലയിരുത്തൽ പ്രദാനം ചെയ്യുന്നു, കൂടാതെ ഉയർന്ന കണക്കുകൂട്ടൽ കാര്യക്ഷമത നിലനിർത്തുന്നു.

### **FP16**

FP16 ഫോർമാറ്റ്, അതായത് 16-ബിറ്റ് ഫ്ലോട്ടിങ് പോയിന്റ് നമ്പറുകൾ (float16), 32-ബിറ്റ് ഫ്ലോട്ടിങ് പോയിന്റ് നമ്പറുകളുമായി താരതമ്യേന മെമ്മറി ഉപഭോഗം പകുതിയായി കുറയ്ക്കുന്നു, ഇത് വൻതോതിൽ ഡീപ്പ് ലേണിംഗ് അപ്ലിക്കേഷനുകളിൽ ഗണ്യമായ പ്രയോജനം നൽകുന്നു. FP16 ഫോർമാറ്റ് വലിയ മോഡലുകൾ ലോഡ് ചെയ്യാനും, ഒരേ GPU മെമ്മറി പരിധിയിലുള്ള കൂടുതൽ ഡാറ്റ പ്രക്രിയ ചെയ്യാനും സഹായിക്കുന്നു. ആധുനിക GPU ഹാർഡ്‌വെയർ FP16 പ്രവർത്തനങ്ങൾക്ക് പിന്തുണ നൽകുന്നതുകൊണ്ട്, FP16 ഫോർമാറ്റ് ഉപയോഗിക്കുന്നത് കണക്കുകൂട്ടൽ വേഗത മെച്ചപ്പെടുത്താനും സഹായിക്കും. എന്നാൽ FP16 ഫോർമാറ്റിന് ഉള്ള ഒരു അവലംബം, കുറഞ്ഞ കൃത്യത ആയതിനാൽ ചില സാഹചര്യങ്ങളിൽ സംഖ്യാശാസ്ത്ര的不സ്ഥിതിയോ കൃത്യതയുടെ നഷ്ടവോ ഉണ്ടാകാം.

### **FP32**

FP32 ഫോർമാറ്റ് ഉയർന്ന കൃത്യത നൽകുകയും വ്യാപകമായി മൂല്യങ്ങൾ കൃത്യമായി പ്രതിനിധാനം ചെയ്യുകയും ചെയ്യുന്നു. സങ്കീർണ്ണ ഗണിത പ്രവർത്തനങ്ങൾ നടക്കുമ്പോൾ അല്ലെങ്കിൽ ഉയർന്ന കൃത്യത ഫലം ആവശ്യമുള്ളപ്പോൾ FP32 ഫോർമാറ്റ് മുൻഗണന ലഭിക്കുന്നു. എന്നാൽ ഉയർന്ന കൃത്യതയെന്ന് അർത്ഥം കൂടുതൽ മെമ്മറി ഉപയോഗവും നീണ്ട കണക്കുകൂട്ടൽ സമയവുമാണ്. വൻതോതിലുള്ള ഡീപ്പ് ലേണിംഗ് മോഡലുകൾ, പ്രത്യേകിച്ചും നിരവധി മോഡൽ പരിച്ഛന്നങ്ങളും വൻതോതിലുള്ള ഡാറ്റയും ഉണ്ടായാൽ FP32 ഫോർമാറ്റ് GPU മെമ്മറി പരിമിതത്വം ഉണ്ടാക്കാവുന്നതാണ്, അല്ലെങ്കിൽ ഇൻഫറൻസിന്റെ വേഗത കുറയാവുന്നതാണ്.

മോബൈൽ ഉപകരണങ്ങളിലും IoT ഉപകരണങ്ങളിലും Phi-3.x മോഡലുകൾ INT4-ലേക്ക് പരിവർത്തനം ചെയ്യാവുന്നതാണ്, അതേസമയം AI PC / Copilot PC പോലുള്ളവയ്ക്ക് ഉയർന്ന കൃത്യതയായ INT8, FP16, FP32 എന്നിവ ഉപയോഗിക്കാം.

ഇപ്പോൾ വ്യത്യസ്ത ഹാർഡ്‌വെയർ നിർമ്മാതാക്കളുടെ വ്യത്യസ്ത ഫ്രെയിംവർക്കുകൾ നിർമ്മിതമുണ്ട് ജെനറേറ്റീവ് മോഡലുകൾക്ക് പിന്തുണയ്‌ക്കാൻ, ഉദാഹരണത്തിന് Intel OpenVINO, Qualcomm QNN, Apple MLX, Nvidia CUDA എന്നിവ, കൂടാതെ മോഡൽ ക്വാണ്ടൈസേഷനുമായി സംയോജിപ്പിച്ച് പ്രാദേശിക വിന്യാസം പൂർത്തിയാക്കുന്നു.

സാങ്കേതിക വിഷയങ്ങളിൽ, ക്വാണ്ടൈസേഷനു ശേഷം വ്യത്യസ്ത ഫോർമാറ്റ് പിന്തുണ ലഭ്യമാണ്, ഉദാഹരണത്തിന് PyTorch / TensorFlow ഫോർമാറ്റ്, GGUF, ONNX തുടങ്ങിയവ. GGUF-വും ONNX-വുമിടയിൽ ഫോർമാറ്റ് താരതമ്യവും ഉപയോഗ സാഹചര്യങ്ങളും ഞാൻ ചെയ്തു. ഇവിടെ മോഡൽ ഫ്രെയിംവർക്ക് മുതൽ ഹാർഡ്‌വെയർ വരെ മികച്ച പിന്തുണയുള്ള ONNX ക്വാണ്ടൈസേഷൻ ഫോർമാറ്റ് ഞാന് ശുപാർശ ചെയ്യുന്നു. ഈ അധ്യായത്തിൽ, GenAI-യ്‌ക്കുള്ള ONNX റൺടൈം, OpenVINO, Apple MLX ഉപയോഗിച്ച് മോഡൽ ക്വാണ്ടൈസേഷൻ നടത്തുന്നതിൽ ശ്രദ്ധ കേന്ദ്രീകരിക്കും (നിങ്ങൾക്ക് നല്ല മാർഗം ഉണ്ടായിരിക്കാം, അതുമായി ബന്ധപ്പെട്ട് PR സമർപ്പിക്കാം).

**ഈ അധ്യായത്തിൽ ഉൾപ്പെടുത്തിയിരിക്കുന്നത്**

1. [llama.cpp ഉപയോഗിച്ച് Phi-3.5 / 4 ക്വാണ്ടൈസേഷൻ](./UsingLlamacppQuantifyingPhi.md)

2. [onnxruntime യുടെ ജെനറേറ്റീവ് AI എക്‌സ്‌റ്റൻഷനുകൾ ഉപയോഗിച്ച് Phi-3.5 / 4 ക്വാണ്ടൈസേഷൻ](./UsingORTGenAIQuantifyingPhi.md)

3. [Intel OpenVINO ഉപയോഗിച്ച് Phi-3.5 / 4 ക്വാണ്ടൈസേഷൻ](./UsingIntelOpenVINOQuantifyingPhi.md)

4. [Apple MLX Framework ഉപയോഗിച്ച് Phi-3.5 / 4 ക്വാണ്ടൈസേഷൻ](./UsingAppleMLXQuantifyingPhi.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**അസ്വീകരണം**:  
ഈ പ്രമാണം AI വിവർത്തന സേവനമായ [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ചാണ് വിവർത്തനം ചെയ്തത്. നാം സാധാരണയായി സുതാര്യതയ്ക്കായി ശ്രമിക്കുന്നുവെങ്കിലും, സ്വയം ചെയ്ത വിവർത്തനങ്ങളിൽ പിശകുകൾ അല്ലെങ്കിൽ അശുദ്ധതകൾ ഉണ്ടാകാവുന്നതാണ്. അത്തരം പ്രമാണത്തിന്റെ സਥാനീയ ഭാഷയിലുള്ള അസ്റ്റ്‌പ്രമാണം മാത്രമേ പ്രാമാണിക ഉറവിടമായിരിക്കൂ. പ്രധാന വിവരങ്ങൾക്ക് için പ്രൊഫഷണൽ മാനവീയം വിവർത്തനം ശിപാർശ ചെയ്യുന്നു. ഈ വിവർത്തനം ഉപയോഗിക്കുന്നതിനാൽ ഉണ്ടാകുന്ന ഏതെങ്കിലും തെറ്റിദ്ധാരണകൾക്കും തെറ്റായ വ്യാഖ്യാനങ്ങൾക്കും ഞങ്ങൾ ഉത്തരവാദികളല്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->