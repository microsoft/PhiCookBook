<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-12-21T23:26:22+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ml"
}
-->
# Phi മോഡലുകൾക്കുള്ള എഐ സുരക്ഷ
Phi മോഡലുകളുടെ കുടുംബം വികസിപ്പിച്ചത് [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) അനുസരിച്ച് ആണ്, ഇത് കമ്പനിവ്യാപകമായി ഇനിപ്പറയുന്ന ആറ് സിദ്ധാന്തങ്ങളുള്ള ആവശ്യകതകളുടെ ഒരു സെറ്റ് ആണ്: ഉത്തരവാദിത്വം, വയദ്ധ്യത (transparency), നീതിത്വം, വിശ്വാസ്യതയും സുരക്ഷയും, സ്വകാര്യതയും സുരക്ഷയും, ഉൾക്കൊള്ളുന്ന സമീപനം — ഇവയാണ് [Microsoft’s Responsible AI principles](https://www.microsoft.com/ai/responsible-ai) ഉണ്ടായത്.

മുമ്പത്തെ Phi മോഡലുകൾ പോലെ, ബഹുമുഖ സുരക്ഷാ മൂല്യനിർണയവും പരിശീലനാനന്തര സുരക്ഷാ സമീപനവും സ്വീകരിച്ചു; ഈ റിലീസിന്റെ ബഹുഭാഷാ കഴിവുകൾ കൂടി പരിഗണിച്ച് അധിക നടപടികൾ എടുത്തു. നിരവധി ഭാഷകളിലും റിസ്ക് വിഭാഗങ്ങളിലും ടെസ്റ്റിംഗ് ഉൾപ്പെടുത്തിക്കൊണ്ടുള്ള നമ്മുടെ സുരക്ഷാ പരിശീലനവും മൂല്യനിർണയവും [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) ൽ വിശദമായി നൽകിയിരിക്കുന്നു. Phi മോഡലുകൾക്ക് ഈ സമീപനത്തിൽനിന്ന് ലാഭം ഉണ്ടെങ്കിൽ പോലും, ഡെവലപ്പർമാർ അവരുടെ പ്രത്യേക ഉപയോഗകേസിന്റെയും സാംസ്‌കാരിക-ഭാഷാശൈലിയുടെ കണ്ടക്ടിന്റെയും അനുയോജ്യമായി റിസ്കുകൾ മാപ്പിംഗ്, അളക്കൽ, കുറയ്ക്കൽ എന്നിവ ഉൾപ്പെടെയുള്ള ഉത്തരവാദിത്വമുള്ള എഐ മികച്ച രീതികൾ പ്രയോഗിക്കണം.

## മികച്ച പ്രവർത്തനരീതികൾ

മറ്റു മോഡലുകൾ പോലെ, Phi മോഡൽ കുടുംബം നീതിയിൽില്ലാത്തവയായോ വിശ്വസനീയമല്ലാത്തവയായോ അപമാനകരമായോ പെരുമാറ്റം കാണിക്കാൻ സാധ്യതയുണ്ട്.

SLM കൂടിയും LLM കൂടിയും നിങ്ങളുടെ ശ്രദ്ധയിൽവെക്കേണ്ട ചില പരിധിയുള്ള പെരുമാറ്റങ്ങൾ ഇത്തരമാണ്:

- **സേവന നിലവാരം:** Phi മോഡലുകൾ പ്രധാനമായും ഇംഗ്ലീഷ് ഉള്ളടക്കത്തിലെയാണ് പരിശീലിപ്പിച്ചിരിക്കുന്നത്. ഇംഗ്ലീഷിന് വ്യത്യസ്തമായ ഭാഷകൾ തുടക്കത്തിൽ കൂടുതല്‍ മോശം പ്രകടനം അനുഭവിക്കാം English language varieties with less representation in the training data might experience worse performance than standard American English.
- **ഹാനികളുടെ പ്രതിനിധാനം & ധാരണാപരമായ ചിത്രീകരണങ്ങൾക്ക് തുടർച്ച നൽകൽ:** ഈ മോഡലുകൾ ആളുകളുടെ ചില സാമുദായിക വിഭാഗങ്ങളെ過മാത്രം വളർത്തുകയോ കുറക്കുകയോ ചില ഗ്രൂപ്പുകളുടെ പ്രതിനിധാനം മായ്ച്ചടക്കം, നിരുപദേശമോ നെഗറ്റീവോ ആയ സ്റ്റീരിയോട്ടൈപ്പുകൾ ശക്തിപ്പെടുത്തുകയോ ചെയ്യാം. പരിശീലനാനന്തര സുരക്ഷ ഉണ്ടായിട്ടും, വിവിധ ഗ്രൂപ്പുകളുടെ പ്രതിനിധാനത്തിന്റെ വ്യത്യാസങ്ങളോ പരിശീലന ഡേറ്റയിൽ ഉണ്ടാകുന്ന നെഗറ്റീവ് സ്റ്റീരിയോട്ടൈപ്പ് ഉദാഹരണങ്ങളുടെ വ്യാപ്തിയോ കാരണം ഈ പരിധികൾ ഇപ്പോഴും ഉണ്ടാവാം, അവ യഥാർത്ഥ ലോക മാതൃകകളും സമൂഹത്തെ ബാധിക്കുന്ന ഭേദഭാവങ്ങളും പ്രതിഫലിപ്പിക്കാം.
- **അസംബന്ധമായോ അപമാനകരമായോ ഉള്ള ഉള്ളടക്കം:** ഈ മോഡലുകൾ മറ്റ് തരത്തിലുള്ള അസംബന്ധമോ അപമാനകരമോ ഉള്ള ഉള്ളടക്കം ഉണ്ടാക്കാൻ സാധ്യതയുണ്ട്, അതിനാൽ പ്രത്യേക കണക്‌സ്റ്റുകൾക്ക് ഉപയോഗിക്കുമ്പോൾ കേഡ്ജുവായ ഇടപെടലുകൾ ഇല്ലാതെ ഉപയോഗിക്കുന്നത് അനുയോജ്യമാകാമെങ്കിലും അല്ലാതിരിക്കാൻ സാധ്യതയുണ്ട്.
Information Reliability: Language models can generate nonsensical content or fabricate content that might sound reasonable but is inaccurate or outdated.
- **കോഡിന്‌ ഉള്ള പരിധികൾ:** Phi-3 പരിശീലന ഡേറ്റയുടെ വലിയഭാഗം Python-ൽ മാത്രമേ അടിസ്ഥാനമായുള്ളൂ; സാധാരണ പാക്കേജുകൾ പോലുള്ള "typing, math, random, collections, datetime, itertools" ഉപയോഗിക്കുന്നു. മോഡൽ Python സ്ക്രിപ്ടുകൾ other packages ഉപയോഗിച്ച് അല്ലെങ്കിൽ മറ്റു ഭാഷകളിൽ സ്ക്രിപ്റ്റുകൾ നിർമ്മിക്കുന്നെങ്കിൽ, എല്ലാറ്റരം API ഉപയോഗങ്ങളും ഉപയോക്താക്കൾ മാനുവലായി പരിശോദിക്കുന്നതു സുപ്രധാനമാണ്.

ഡെവലപ്പർമാർ ഉത്തരവാദിത്വമുള്ള എഐ മികച്ച പ്രവർത്തനരീതികൾ പ്രയോഗിക്കണം, കൂടാതെ ഒരു പ്രത്യേക ഉപയോഗകേസ് ബന്ധപ്പെട്ട നിയമങ്ങളും നിബന്ധനകളും (ഉദാ. സ്വകാര്യത, വ്യാപാരം മുതലായവ) പാലിക്കുന്നുണ്ടെന്ന് ഉറപ്പാക്കേണ്ടത് അവര്ക്ക് ഉത്തരവാദിത്വമാണ്.

## ഉത്തരവാദി എഐ പരിഗണനകൾ

മറ്റു ഭാഷാ മോഡലുകളെല്ലാം പോലെ, Phi പരമ്പര മോഡലുകൾ നീതിയില്ലാത്തതും വിശ്വാസ്യതയില്ലാത്തതും അപമാനകരവുമായ രീതിയിൽ പ്രവർത്തിക്കാനുള്ള സാധ്യതയുണ്ട്. ശ്രദ്ധിക്കേണ്ട ചില പരിധിയുള്ള പെരുമാറ്റങ്ങൾ ഇവയാണ്:

**സേവന നിലവാരം:** Phi മോഡലുകൾ പ്രധാനമായും ഇംഗ്ലീഷ് ടെക്സ്റ്റിൽ പരിശീലിപ്പിച്ചിരിക്കുന്നു. ഇംഗ്ലീഷിന് പുറമെ ഉള്ള ഭാഷകൾക്ക് മോശപ്പെട്ട പ്രകടനം ഉണ്ടായേക്കാം. പരിശീലന ഡേറ്റയിൽ കുറവ് പ്രതിനിധാനമുള്ള ഇംഗ്ലീഷ് ഭാഷാചറിത്രങ്ങൾ സ്റ്റാൻഡേർഡ് അമേരിക്കൻ ഇംഗ്ലീഷിനെക്കാൾ മോശമായ പ്രകടനം കാണിച്ചേക്കാം.

**ഹാനികളുടെ പ്രതിനിധാനം & ധാരണാപരമായ ചിത്രീകരണങ്ങൾക്ക് തുടർച്ച നൽകൽ:** ഈ മോഡലുകൾ ചില ആളുകളുടെ ഗ്രൂപ്പുകൾ കൂടുതൽ kapena കുറച്ചു പ്രതിനിധാനം ചെയ്യാനോ, ചില ഗ്രൂപ്പുകളുടെ പ്രതിനിധാനം ഇല്ലാതാക്കാനോ, അപമാനകരമോ നെഗറ്റീവോ ആയ സ്റ്റീരിയോട്ടൈപ്പ് ശക്തിപ്പെടുത്താനോ കഴിയും. പരിശീലനാനന്തര സുരക്ഷ ഉണ്ടായിട്ടും, വ്യത്യസ്ത ഗ്രൂപ്പുകളുടെ പ്രതിനിധാനത്തിന്റെ തലങ്ങളിൽ ഉള്ള വ്യത്യാസങ്ങളോ പരിശീലന ഡേറ്റയിൽ ഉള്ള നെഗറ്റീവ് സ്റ്റീരിയോട്ടൈപ്പുകളുടെ വ്യാപ്തിയോ കാരണം ഈ പരിധികൾ ഇപ്പോഴും നിലനിൽക്കാവുന്നതാണ്, അത് യാഥാർത്ഥ്യ ലോക മാതൃകകളും സാമൂഹ്യ പൂർവ്വാഗ്രഹങ്ങളും പ്രതിഫലിപ്പിക്കാം.

**അസംബന്ധമായോ അപമാനകരമായോ ഉള്ള ഉള്ളടക്കം:** ഈ മോഡലുകൾ മറ്റു തരത്തിലുള്ള അസംബന്ധമോ അപമാനകരമോ ഉള്ളടക്കം ഉത്പാദിപ്പിക്കാം, അതിനാൽ വ്യക്തിഗത ഉപയോഗകേസിന് അനുയോജ്യമായ അധിക ഭദ്രതാ നടപടികൾ ഇല്ലാതെ സെൻസിറ്റീവ് ചെറുതായുള്ള സാഹചര്യങ്ങളിൽ വിന്യസിക്കാൻ ഇത് അനുയോജ്യമല്ല.
Information Reliability: Language models can generate nonsensical content or fabricate content that might sound reasonable but is inaccurate or outdated.

**കോഡിന്റെ പരിധി:** Phi-3 പരിശീലന ഡേറ്റയുടെ വലിയഭാഗം Python-ൽ അടിസ്ഥാനമാണ്, കൂടാതെ "typing, math, random, collections, datetime, itertools" പോലുള്ള സാധാരണ പാക്കേജുകൾ ഉപയോഗിക്കുന്നു. മോഡൽ Python സ്ക്രിപ്ടുകൾ other packages ഉപയോഗിച്ചോ അല്ലെങ്കിൽ മറ്റു ഭാഷകളിൽ സ്ക്രിപ്ടുകൾ സൃഷ്ടിച്ചോ ചെയ്യുമ്പോൾ, എല്ലാ API ഉപയോഗങ്ങളും ഉപയോക്താക്കൾ കയ്യോടെ പരിശോദിക്കണമെന്ന് ഞങ്ങൾ ശക്തമായി ശുപാർശ ചെയ്യുന്നു.

ഡെവലപ്പർമാർ ഉത്തരവാദിത്വമുള്ള എഐ മികച്ച രീതികൾ പ്രയോഗിക്കണം, കൂടാതെ ഒരു പ്രത്യേക ഉപയോഗകേസ് ബന്ധപ്പെട്ട നിയമങ്ങളും നിബന്ധനകളും (ഉദാ. സ്വകാര്യത, വ്യാപാരം മുതലായവ) പാലിക്കുന്നുണ്ടെന്ന് ഉറപ്പാക്കേണ്ടത് അവര്ക്ക് ഉത്തരവാദിത്വമാണ്. പരിഗണിക്കേണ്ട പ്രധാന മേഖലകൾ ഉൾപ്പെടുന്നു:

**വിന്യാസം (Allocation):** നിയമാത്മക നിലയോ ഉറവിടം അല്ലെങ്കിൽ ജീവിതാവസരങ്ങളുടെ വിന്യാസത്തിൻറെ (ഉദാ: നിവാസം, തൊഴിൽ, ക്രെഡിറ്റ് മുതലായവ) കാര്യങ്ങളിൽ വിലപ്പെട്ട സ്വാധീനം ഉണ്ടാകാവുന്ന സാഹചര്യങ്ങൾക്ക് മോഡലുകൾ അനുയോജ്യമാകാവുന്നത് കുറവായിരിക്കാം — കൂടുതൽ പരിശോധനകളും അധിക ഡീബയസിംഗ് സാങ്കേതികതകളും ആവശ്യമായിരിക്കും.

**ഉയർച്ചയായ-റിസ്‌ക് സംഭവങ്ങൾ:** ഡെവലപ്പർമാർ മോഡലുകൾ ഉപയോഗിക്കാൻ അനുയോജ്യമായതോ എന്നത് അവലോകനം ചെയ്യണം, പ്രത്യേകിച്ച് നീതിയില്ലാത്തതോ വിശ്വാസ്യതയില്ലാത്തതോ അപമാനകരമായ ഔട്ട്പുട്ടുകൾ വളരെ വിലമതിക്കുന്നതോ ഹാനി വരുത്താവുന്നതായ സാഹചര്യങ്ങളിൽ. ഇത് സങ്കീർണമായ വിദഗ്ധ മേഖലകളിൽ (ഉദാ: നിയമസേവനങ്ങൾ അല്ലെങ്കിൽ ആരോഗ്യ ഉപദേശം) സ്ഥിതിച്ചാൽ സ്‌പെഷ്യൽ‍ ആശങ്കകൾ ഉള്ളതാണ്. വിന്യസത്തിന്റെ കോൺടക്സ്റ്റ് അനുസരിച്ച് ആപ്ലിക്കേഷൻ തലത്തിൽ അധിക സുരക്ഷാമാർഗങ്ങൾ നടപ്പിലാക്കണം.

**തെറ്റായ വിവരങ്ങൾ:** മോഡലുകൾ തെറ്റായ വിവരങ്ങൾ ഉൽപ്പാദിപ്പിക്കാം. ഡെവലപ്പർമാർ പരദർശകതയുടെ മികച്ച രീതികൾ അനുയോജ്യമായി പിന്തുടർന്ന് ഉപഭോക്താക്കളോട് അവർ ഒരു എഐ സിസ്റ്റവുമായി ഇടപെടുകയാണെന്ന് അറിയിക്കണം. ആപ്ലിക്കേഷൻ തലത്തിൽ, ഡെവലപ്പർമാർ ഫീഡ്ബാക്ക് മെക്കാനിസങ്ങൾയും ഉപയോഗകേസ്-നിർദ്ദിഷ്ട, കോൺടെക്സ്ഷ്വൽ വിവരങ്ങളിൽ നിസ്സാരം നൽകുന്ന പൈപ്പ്ലൈനുകൾ വികസിപ്പിക്കാവുന്നതാണ്; ഇത് Retrieval Augmented Generation (RAG) എന്നറിയപ്പെടുന്ന ഒരു സാങ്കേതികതയാണ്.

**ഹാനികരമായ ഉള്ളടക്കത്തിന്റെ ഉത്പാദനം:** ഡെവലപ്പർമാർ അവരുടെ ഔട്ട്‌പുട്ടുകൾ കോൺടെക്‌സ്റ്റിന്റെ അടിസ്ഥാനത്തിൽ വിലയിരുത്തി ഉപയോഗകേസിനനുസരിച്ച് ലഭ്യമായ സുരക്ഷാ ക്ലാസിഫയർമാർ അല്ലെങ്കിൽ ആപ്ലിക്കേഷനു അനുയോജ്യമായ കസ്റ്റം പരിഹാരങ്ങൾ ഉപയോഗിക്കണം.

**ദുഷ്പ്രയോജനം:** തട്ടിപ്പ്, സ്‌പാം, മാൽവെയർ നിർമ്മാണം തുടങ്ങിയ മറ്റ് ദുഷ്പ്രയോജന രൂപങ്ങൾ ഉണ്ടായേക്കാവുന്നതാണ്, അതുകൊണ്ട് ഡെവലപ്പർമാർ അവരുടെ ആപ്ലിക്കേഷനുകൾ ബാധകമായ നിയമങ്ങളും നിബന്ധനകളും ലംഘിക്കാതെ എന്നതു ഉറപ്പാക്കേണ്ടതാണ്.

### ഫൈനറ്റ്യൂണിംഗ് மற்றும் എഐ ഉള്ളടക്ക സുരക്ഷ

ഒരു മോഡൽ ഫൈനറ്റ്യൂൺ ചെയ്തുകഴിഞ്ഞാൽ, മോഡലുകൾ ഉൽപ്പാദിപ്പിക്കുന്ന ഉള്ളടക്കം നിരീക്ഷിക്കാൻ, ചിലνοςാധ്യങ്ങളെയും ഭീഷണികളെയും ഗുണനിലവാര പ്രശ്നങ്ങളെയും തിരിച്ചറിഞ്ഞ് ബ്ലോക്ക് ചെയ്യാൻ [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) മാർഗ്ഗങ്ങൾ ഉപയോഗിക്കാൻ ഞങ്ങൾ ശക്തമായി ശുപാർശ ചെയ്യുന്നു.

![Phi3 എഐസുരക്ഷ](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c405.ml.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) ടെക്സ്റ്റ് ഉം ഇമേജ് ഉള്ളടക്കവും രണ്ടും പിന്തുണയ്ക്കുന്നു. ഇത് ക്ലൗഡിലും, ഡിസ്‌കണെക്ടഡ് കണ്ടെയ്‌നറുകളിലും, എജ്ജ്/എംബെഡഡ് ഉപകരണങ്ങളിലും വിന്യസിക്കാവുന്നതാണ്.

![എഐ ഉള്ളടക്കസുരക്ഷ](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a.ml.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 വീഡിയോകൾ**

Azure AI Content Safety സർവീസ് ആപ്പ്‌ളിക്കേഷനുകളിലും സേവനങ്ങളിലുമുള്ള ഉപയോക്താവ്-സൃഷ്ടിച്ചതുമായും എഐ-സൃഷ്ടിച്ചതുമായ ഹാനികരമായ ഉള്ളടക്കങ്ങളെ കണ്ടെത്തുന്നു. ഹാനികരമോ അസംബന്ധമോ ആയ സാമഗ്രികൾ കണ്ടെത്താൻ ഇത് ടെക്സ്റ്റ്, ഇമേജ് API കൾ ഉൾപ്പെടുത്തിയിരിക്കുന്നു.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
അറിയിപ്പ്:
ഈ രേഖ AI പരിഭാഷാ സേവനമായ [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. നാം കൃത്യതയ്ക്കായി പരിശ്രമിച്ചിട്ടും, യന്ത്രപരിഭാഷകളിൽ പിശകുകളും അശുദ്ധങ്ങളും ഉണ്ടായേക്കാമെന്നത് ദയവായി മനസിലാക്കുക. മൂലഭാഷയിലുള്ള ഓറിജിനൽ രേഖ അധികാരപരമായ ഉറവിടമായി പരിഗണിക്കണം. നിർണ്ണായകമായ വിവരങ്ങൾക്ക് പ്രൊഫഷണൽ മനുഷ്യപരിഭാഷ ശുപാർശ ചെയ്യപ്പെടുന്നു. ഈ പരിഭാഷ ഉപയോഗിച്ചതിലൂടെ ഉണ്ടാകുന്ന任何 തെറ്റിദ്ധാരണകൾക്കും വ്യാഖ്യാനക്കുറവുകൾക്കുമുള്ള ഉത്തരവാദിത്വം ഞങ്ങൾ ഏറ്റെടുക്കുന്നില്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->