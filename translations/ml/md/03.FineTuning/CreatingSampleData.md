<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3cd0b727945d57998f1096763df56a84",
  "translation_date": "2025-12-21T17:59:21+00:00",
  "source_file": "md/03.FineTuning/CreatingSampleData.md",
  "language_code": "ml"
}
-->
# Hugging Face-ൽ നിന്നുള്ള ഡാറ്റാസെറ്റ് ഒപ്പം ബന്ധപ്പെട്ട ചിത്രങ്ങൾ ഡൗൺലോഡ് ചെയ്ത് ഇമേജ് ഡാറ്റാസെറ്റ് സൃഷ്ടിക്കുക


### അവലോകനം

ഈ സ്ക്രിപ്റ്റ് ആവശ്യമായ ചിത്രങ്ങൾ ഡൗൺലോഡ് ചെയ്ത്, ചിത്രങ്ങൾ ഡൗൺലോഡ് ചെയ്യാൻ പരാജയപ്പെട്ട വരികൾ ഫിൽറ്റർ ചെയ്ത്, ഡാറ്റാസെറ്റ് ഒരു CSV ഫയലായി സേവ് ചെയ്യുകയായിരുന്നു മെഷീൻ ലേണിങ്ങിനായി ഡാറ്റാസെറ്റ് തയ്യാറാക്കുന്നത്.

### മുൻഅവശ്യങ്ങൾ

ഈ സ്ക്രിപ്റ്റ് 실행 ചെയ്യാൻ മുമ്പ്, താഴെ പറയുന്ന ലൈബ്രററികൾ ഇൻസ്റ്റാൾ ചെയ്തിട്ടുണ്ടെന്ന് ഉറപ്പാക്കുക: `Pandas`, `Datasets`, `requests`, `PIL`, and `io`. കൂടാതെ line 2-ൽ `'Insert_Your_Dataset'` എന്നത് Hugging Face-ൽ നിന്നുള്ള നിങ്ങളുടെ ഡാറ്റാസെറ്റ് നാമത്തിൽ മാറ്റേണ്ടതുണ്ടാകും.

ആവശ്യമായ ലൈബ്രറികൾ:

```python

import os
import pandas as pd
from datasets import load_dataset
import requests
from PIL import Image
from io import BytesIO
```

### പ്രവർത്തനം

സ്ക്രിപ്റ്റ് താഴെപ്പറയുന്ന ഘട്ടങ്ങൾ ചെയ്യുന്നു:

1. Hugging Face-ൽ നിന്നുള്ള ഡാറ്റാസെറ്റ് `load_dataset()` ഫംഗ്ഷൻ ഉപയോഗിച്ച് ഡൗൺലോഡ് ചെയ്യുന്നു.
2. എളുപ്പത്തിൽ കൈകാര്യം ചെയ്യാൻ Hugging Face ഡാറ്റാസെറ്റ് `to_pandas()` മെഥഡ് ഉപയോഗിച്ച് Pandas DataFrame ആയി മാറ്റുന്നു.
3. ഡാറ്റാസെറ്റും ചിത്രങ്ങളും സേവ് ചെയ്യാൻ ഡയറക്ടറികൾ സൃഷ്ടിക്കുന്നു.
4. DataFrame-ൽ ഓരോ റോവും ത്രavers്ച്ച ചെയ്യുന്നതിലൂടെ, കസ്റ്റം `download_image()` ഫംഗ്ഷൻ ഉപയോഗിച്ച് ചിത്രം ഡൗൺലോഡ് ചെയ്ത് ചിത്രഡൗൺലോഡ് പരാജയപ്പെടുന്ന വരികൾ ഒഴിവാക്കി ഫിൽറ്റർ ചെയ്ത വരിയെ `filtered_rows` എന്ന പുതിയ DataFrame-ലേക്ക് ചേർത്തുകൊണ്ടുള്ള ഫിൽറ്ററിംഗ്.
5. ഫിൽറ്റർ ചെയ്ത വരികളോടെ ഒരു പുതിയ DataFrame സൃഷ്ടിച്ച് അത് ഡിസ്കിൽ CSV ഫയലാക്കി സേവ് ചെയ്യുന്നു.
6. ഡാറ്റാസെറ്റ് എവിടെ കൂടി ചിത്രങ്ങൾ സേവ് ചെയ്തിരിക്കുന്നതെന്ന് സൂചിപ്പിക്കുന്ന ഒരു സന്ദേശം പ്രിന്റ് ചെയ്യുന്നു.

### കസ്റ്റം ഫങ്ഷൻ

`download_image()` ഫംഗ്ഷൻ ഒരു URL-ൽ നിന്നുള്ള ചിത്രം ഡൗൺലോഡ് ചെയ്യുകയും Pillow Image Library (PIL)യും `io` മൊഡ്യൂളും ഉപയോഗിച്ച് അതിനെ ലോക്കലായി സേവ് ചെയ്യുകയും ചെയ്യുന്നു. ചിത്രം വിജയകരമായി ഡൗൺലോഡ് ചെയ്താൽ ഇത് True റിട്ടേൺ ചെയ്യുന്നു, അല്ലാത്ത പക്ഷം False റിട്ടേൺ ചെയ്യുന്നു. അപേക്ഷ പരാജയപ്പെട്ടപ്പോൾ ഫംഗ്ഷൻ പിശകിനോടനുബന്ധിച്ച എക്സെപ്ഷൻ എടുത്തുചാട്ടുന്നതും ഉണ്ട്.

### ഇത് എങ്ങനെ പ്രവർത്തിക്കുന്നു

download_image ഫംഗ്ഷന് രണ്ട് പാരാമീറ്ററുകൾ ഉണ്ടാകുന്നു: image_url, ഡൗൺലോഡ് ചെയ്യേണ്ട ചിത്രത്തിന്റെ URL ആണ്, കൂടാതെ save_path, ഡൗൺലോഡ് ചെയ്ത ചിത്രം സേവ് ചെയ്യേണ്ട പാത്ത് ആണ്.

ഫംഗ്ഷൻ പ്രവർത്തിക്കുന്ന വിധം ചുവടെ ആണ്:

ഇത് requests.get മെതഡ് ഉപയോഗിച്ച് image_url-ൽ ഒരു GET അഭ്യർത്ഥന അയക്കുന്നതോടെ ആരംഭിക്കുന്നു. ഇതിലൂടെ URL-ല നിന്നും ചിത്രം സംബന്ധിച്ച ഡാറ്റ ലഭ്യമാണ്.

response.raise_for_status() ലൈനും അഭ്യർഥന വിജയിച്ചിട്ടുണ്ടോ എന്നത് പരിശോധിക്കുന്നു. അഭ്യർഥന സ്റ്റാറ്റസ് കോഡ് ഒരു പിശക് സൂചിപ്പിക്കുകയാണെങ്കിൽ (ഉദാഹരണത്തിന് 404 - Not Found), അത് ഒരു എക്സെപ്ഷൻ ഉയര്‍ത്തും. ഇത് അഭ്യർഥനം വിജയിച്ചിരുന്നപ്പോൾ മാത്രമേ നാം ചിത്രത്തിന്റെ ഡൗൺലോഡിലേക്ക് മുൻപോട്ട് പോവുകയുള്ളൂ എന്നതിനെ ഉറപ്പാക്കുന്നു.

അ ചിത്ര ഡാറ്റ പിന്നീട് PIL (Python Imaging Library) മൊഡ്യൂളിനുള്ളിൽനിന്നുള്ള Image.open മെതഡിലേക്ക് geçirilുന്നു. ഈ മെതഡ് ചിത്ര ഡാറ്റയിൽനിന്ന് ഒരു Image ഒബ്ജക്റ്റ് സൃഷ്ടിക്കുന്നു.

image.save(save_path) ലൈനും ചിത്രം നിശ്ചിത save_path-ലേക്ക് സേവ് ചെയ്യുന്നു. save_path-ൽ ആവശ്യമായ ഫയൽ നാമവും വിപുലീകരണവും ഉൾപ്പെടണം.

അവസാനത്തിൽ, ഫംഗ്ഷൻ ചിത്രം വിജയകരമായി ഡൗൺലോഡ് ചെയ്ത് സേവ് ചെയ്തതായി സൂചിപ്പിക്കാൻ True റിട്ടേൺ ചെയ്യുന്നു. പ്രക്രിയയുടെ ഇടയിൽ ഏതെങ്കിലും എക്സെപ്ഷൻ ഉണ്ടായാൽ അത് പിടിച്ചു പിശകിനെ കുറിച്ചുള്ളൊരു സന്ദേശം പ്രിന്റ് ചെയ്ത് False റിട്ടേൺ ചെയ്യും.

ഈ ഫംഗ്ഷൻ URL-കളിൽ നിന്നുള്ള ചിത്രങ്ങൾ ഡൗൺലോഡ് ചെയ്ത് ലോക്കലായി സേവ് ചെയ്യുന്നതിനായി ഉപകാരപ്രദമാണ്. ഡൗൺലോഡ് പ്രക്രിയയിൽ സാദ്ധ്യമായ പിശകുകൾ കൈകാര്യം ചെയ്യുകയും ഡൗൺലോഡ് വിജയിച്ചോ അല്ലയോ എന്നതിന്റെ ഫീഡ്ബാക്ക് നൽകുകയും ചെയ്യുന്നു.

കുറിച്ച് അറിയിക്കുക: HTTP അഭ്യർഥനകൾ നടത്താൻ requests ലൈബ്രറി ഉപയോഗിക്കുന്നു, ചിത്രങ്ങളുമായി പ്രവർത്തിക്കാൻ PIL ലൈബ്രറി ഉപയോഗിക്കുന്നു, 그리고 BytesIO class ചിത്ര ഡാറ്റ ഒരു ബൈറ്റ്സ് സ്ട്രീമായാണ് കൈകാര്യം ചെയ്യുന്നതെന്ന് ഉപയോഗിക്കുന്നു.

### നിഗമനം

ആവശ്യമായ ചിത്രങ്ങൾ ഡൗൺലോഡ് ചെയ്ത്, ചിത്ര ഡൗൺലോഡ് പരാജയപ്പെടുന്ന വരികൾ ഫിൽറ്റർ ചെയ്ത്, ഡാറ്റാസെറ്റ് ഒരു CSV ഫയലായി സേവ് ചെയ്യുന്നതിലൂടെ മെഷീൻ ലേണിങ്ങിനായി ഡാറ്റാസെറ്റ് തയ്യാറാക്കാനുള്ള ഒരു സൗകര്യപ്രദമായ മാർഗ്ഗം ഈ സ്ക്രിപ്റ്റ് നൽകുന്നു.

### സാമ്പിൾ സ്ക്രിപ്റ്റ്

```python
import os
import pandas as pd
from datasets import load_dataset
import requests
from PIL import Image
from io import BytesIO

def download_image(image_url, save_path):
    try:
        response = requests.get(image_url)
        response.raise_for_status()  # അഭ്യർഥനം വിജയകരമായിരുന്നോ എന്ന് പരിശോധിക്കുക
        image = Image.open(BytesIO(response.content))
        image.save(save_path)
        return True
    except Exception as e:
        print(f"Failed to download {image_url}: {e}")
        return False


# Hugging Face-ൽ നിന്ന് ഡാറ്റാസെറ്റ് ഡൗൺലോഡ് ചെയ്യുക
dataset = load_dataset('Insert_Your_Dataset')


# Hugging Face ഡാറ്റാസെറ്റിനെ Pandas DataFrame-ലേക്ക് മാറ്റുക
df = dataset['train'].to_pandas()


# ഡാറ്റാസെറ്റും ചിത്രങ്ങളും സേവ് ചെയ്യാൻ ഡയറക്ടറികൾ സൃഷ്ടിക്കുക
dataset_dir = './data/DataSetName'
images_dir = os.path.join(dataset_dir, 'images')
os.makedirs(images_dir, exist_ok=True)


# ചിത്രം ഡൗൺലോഡ് പരാജയപ്പെടുന്ന വരികളെ ഫിൽട്ടർ ചെയ്യുക
filtered_rows = []
for idx, row in df.iterrows():
    image_url = row['imageurl']
    image_name = f"{row['product_code']}.jpg"
    image_path = os.path.join(images_dir, image_name)
    if download_image(image_url, image_path):
        row['local_image_path'] = image_path
        filtered_rows.append(row)


# ഫിൽട്ടർ ചെയ്ത വരികളുള്ള പുതിയ DataFrame സൃഷ്ടിക്കുക
filtered_df = pd.DataFrame(filtered_rows)


# പുതുക്കിയ ഡാറ്റാസെറ്റ് ഡിസ്‌കിൽ സേവ് ചെയ്യുക
dataset_path = os.path.join(dataset_dir, 'Dataset.csv')
filtered_df.to_csv(dataset_path, index=False)


print(f"Dataset and images saved to {dataset_dir}")
```

### സാമ്പിൾ കോഡ് ഡൗൺലോഡ് 
[പുതിയ ഡാറ്റാസെറ്റ് സ്ക്രിപ്റ്റ് ഉണ്ടാക്കുക](../../../../code/04.Finetuning/generate_dataset.py)

### സാമ്പിൾ ഡാറ്റാസെറ്റ്
[LORA ഉപയോഗിച്ച ഫൈൻട്യൂണിങ്ങിൽ നിന്നുള്ള സാമ്പിൾ ഡാറ്റാസെറ്റ് ഉദാഹരണം](../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ഡിസ്ക്ലൈമർ:
ഈ രേഖ AI വിവർത്തന സേവനമായ [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. ഞങ്ങൾ കൃത്യതയ്ക്ക് ശ്രമിച്ചാൽപ്പോഴും, ഓട്ടോമേറ്റഡ് വിവർത്തനങ്ങളിൽ തെറ്റുകൾ അല്ലെങ്കിൽ നിഷ്‌ക്രിയതകൾ ഉണ്ടാകാവുന്നതാണ് എന്ന് ശ്രദ്ധിക്കുക. मूल രേഖ അതിന്റെ മാതൃഭാഷയിലുള്ള പതിപ്പാണ് ആധികാരിക ഉറവിടമെന്ന് കരുതേണ്ടത്. നിർണായകമായ വിവരങ്ങൾക്ക് പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ശുപാർശ ചെയ്യപ്പെടുന്നു. ഈ വിവർത്തനത്തിന്റെ ഉപയോഗത്തിൽ നിന്നു ഉണ്ടായേക്കാവുന്ന തെറ്റിദ്ധാരണങ്ങൾക്കോ വ്യാഖ്യാനപിഴവുകൾക്കോ ഞങ്ങൾ ഉത്തരവാദികളല്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->