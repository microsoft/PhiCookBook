<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "743d7e9cb9c4e8ea642d77bee657a7fa",
  "translation_date": "2025-12-21T17:25:06+00:00",
  "source_file": "md/03.FineTuning/LetPhi3gotoIndustriy.md",
  "language_code": "ml"
}
-->
# **Phi-3-നെ ഒരു വ്യവസായ വിദഗ്ധനാക്കി മാറ്റുക**

Phi-3 മോഡൽ ഒരു വ്യവസായത്തിൽ ഉപയോഗത്തിൽ കൊണ്ടുവരുന്നതിനായി, വ്യവസായ ബിസിനസ് ഡാറ്റ Phi-3 മോഡലിൽ ചേർക്കേണ്ടതാണ്. ഞങ്ങൾക്ക് രണ്ട് വ്യത്യസ്ത ഓപ്ഷനുകൾ ഉണ്ട് — ആദ്യത്തേത് RAG (Retrieval Augmented Generation) ആണ്, രണ്ടാംത് ഫൈൻ-ട്യൂണിംഗ് ആണ്.

## **RAG vs ഫൈൻ-ട്യൂണിംഗ്**

### **Retrieval Augmented Generation**

RAG ഡാറ്റ റിട്രീവൽ + ടെക്സ്റ്റ് ജനറേഷനാണ്. സംരംഭത്തിന്റെ ഘടനാപരമായ (structured)യും ഘടനയില്ലാത്ത (unstructured)വുമായ ഡാറ്റകൾ വെക്ടർ ഡാറ്റാബേസിൽ സംഭരിച്ചിരിക്കുന്നു. ബന്ധപ്പെട്ട ഉള്ളടക്കം അന്വേഷിക്കുമ്പോൾ, ബന്ധപ്പെട്ട സംക്ഷേപവും ഉള്ളടക്കവും കണ്ടെത്തി ഒരു_Context_ രൂപപ്പെടുത്തുന്നു, പിന്നെ LLM/SLM-യുടെ ടെക്സ്റ്റ് സെപ്ലീഷൻ ശേഷി കോംബൈൻ ചെയ്ത് ഉള്ളടക്കം ജനറേറ്റ് ചെയ്യുന്നു.

### **Fine-tuning**

ഫൈൻ-ട്യൂണിംഗ് ഒരു സ 특정 മോഡലിന്റെ മെച്ചപ്പെടുത്തലിനെ ആശ്രയിച്ചാണ്. ഇത് മോഡൽ അല്ഗോരിത്തമിൽ നിന്ന് ആരംഭിക്കേണ്ടതില്ല, പക്ഷേ ഡാറ്റ തുടർച്ചയായി ശേഖരിക്കപ്പെടണം. വ്യവസായപരമായ അപേക്ഷകളിൽ കൂടുതൽ നിഷ്‌കളങ്കമായ ടെർമിനോളജി ಮತ್ತು ഭാഷാ പ്രകടനം ആവശ്യമെങ്കിൽ, ഫൈൻ-ട്യൂണിംഗ് നിങ്ങളുടെ മികച്ച തിരഞ്ഞെടുപ്പായിരിക്കും. എന്നാൽ നിങ്ങളുടെ ഡാറ്റ.frequency ആയി മാറെങ്കിൽ, ഫൈൻ-ട്യൂണിംഗ് מורכമായതാകും.

### **എങ്ങനെ തിരഞ്ഞെടുക്കണം**

1. നമ്മുടെയോ ഉത്തരത്തിന് പുറമേ പുറത്തുള്ള ഡാറ്റയെ പരിചയപ്പെടുത്തേണ്ടതുണ്ടെങ്കിൽ, RAG ഏറ്റവും നല്ല തിരഞ്ഞെടുപ്പാണ്

2. നിങ്ങൾക്ക് സ്ഥിരവും കൃത്യവുമായ വ്യവസായ വിജ്ഞാനം output ചെയ്യേണ്ടതുണ്ടെങ്കിൽ, ഫൈൻ-ട്യൂണിംഗ് നല്ല ഒരു തിരഞ്ഞെടുപ്പാകും. RAG ബന്ധപ്പെട്ട ഉള്ളടക്കം പിടിച്ച് വരുന്നതിനുള്ള ആദ്യാംശം നൽകുന്നു, പക്ഷേ പ്രത്യേക വിദഗ്ധ ന്യുയാൻസുകൾ എല്ലായ്പ്പോഴും താറുമാറായിരിക്കില്ല.

3. ഫൈൻ-ട്യൂണിംഗിന് ഉയർന്ന നాణ്യമായ ഡാറ്റാസെറ്റ് ആവശ്യമുണ്ട്, ഒരു ചെറിയ പരിധിയിലെ ഡാറ്റ മാത്രമാണെങ്കിൽ അതിന്റെ വലിയ വ്യത്യാസം ഉണ്ടാകില്ല. RAG കൂടുതൽ ലളിതമാണ്

4. ഫൈൻ-ട്യൂണിംഗ് ഒരു ബ്ലാക്ക്ബോക്സാണ്, അതിന്റെ اندرങ്ങത്തെ മനസ്സിലാക്കാൻ ബുദ്ധിമുട്ടാണ്. എന്നാൽ RAG ഡാറ്റയുടെ ഉറവിടം കണ്ടെത്താൻ സഹായിക്കുന്നതിനാൽ ഹ്യാലൂസിനേഷനുകൾ അല്ലെങ്കിൽ ഉള്ളടക്കം തെറ്റുകൾ ഫലപ്രദമായി ശരിയാക്കാനും പരദർശിത്വം മെച്ചപ്പെടുത്താനും കഴിയും.

### **പ്രസ്ഥാനങ്ങൾ**

1. Verticle industries-കൾക്ക് പ്രത്യേക പ്രഫഷണൽ വാക്കുകളും പ്രകടനങ്ങളുമുണ്ടെങ്കിൽ, ***ഫൈൻ-ട്യൂണിംഗ്***最佳 തിരഞ്ഞെടുപ്പ് ആയിരിക്കും

2. QA സിസ്റ്റം, വ്യത്യസ്ത നോളജ് പോയിന്റുകൾ സംയോജിപ്പിക്കുന്നതായി, ***RAG*** ആണ് najbolji തിരഞ്ഞെടുപ്പ്

3. ഓട്ടോമേറ്റഡ് ബിസിനസ് ഫ്ലോയുടെ സംയോജനം എങ്കിൽ, ***RAG + ഫൈൻ-ട്യൂണിംഗ്*** ആണ് മികച്ചത്


## **RAG എങ്ങനെ ഉപയോഗിക്കാം**

![RAG](../../../../translated_images/rag.2014adc59e6f6007bafac13e800a6cbc3e297fbb9903efe20a93129bd13987e9.ml.png)


വെക്ടർ ഡാറ്റാബേസ് എന്ന് പറ്റുന്നത് ഡാറ്റ ഗണിത രൂപത്തിൽ സംഭരിച്ചുള്ള ഒരു ശേഖരമാണ്. വെക്ടർ ഡാറ്റാബേസുകൾ മെഷീൻ ലേണിംഗ് മോഡലുകൾക്ക് മുമ്പത്തെ ഇൻപുട്ടുകൾ ഓർത്ത് വെയ്ക്കുന്നത് എളുപ്പമാക്കുന്നു, ഇത് തിരയൽ, ശുപാർശകൾ, ടെക്സ്റ്റ് ജനറേഷൻ തുടങ്ങിയ ഉപയോഗകേസുകൾക്ക് പിന്തുണ നൽകാൻ മെഷീൻ ലേണിംഗ് ഉപയോഗിക്കാൻ സാധ്യമാക്കുന്നു. ഡാറ്റയെ കൃത്യ പൊരുത്തത്തിനെ ആശ്രയിച്ച് കാണinstead of exact matches similarity metrics ഉപയോഗിച്ച് തിരിച്ചറിഞ്ഞു, കമ്പ്യൂട്ടർ മോഡലുകൾക്ക് ഡാറ്റയുടെ കോൺടെക്‌സ്‌റ്റ് മനസ്സിലാക്കാൻ സാധിക്കും.

വെക്ടർ ഡാറ്റാബേസ് RAG യാഥാർഥ്യമാക്കാൻ പ്രധാന ഘടകമാണ്. നമ്മൾ text-embedding-3, jina-ai-embedding തുടങ്ങിയ വെക്ടർ മോഡലുകൾ വഴി ഡാറ്റയെ വെക്ടർ സംഭരണത്തിലേയ്ക്ക് മാറ്റിക്കൊടുക്കാം.

RAG ആപ്ലിക്കേഷൻ സൃഷ്ടിക്കാൻ കൂടുതൽ പഠിക്കുവാൻ [https://github.com/microsoft/Phi-3CookBook](https://github.com/microsoft/Phi-3CookBook?WT.mc_id=aiml-138114-kinfeylo) ഗോ

## **Fine-tuning എങ്ങനെ ഉപയോഗിക്കാം**

ഫൈൻ-ട്യൂണിങ്ങിൽ സാധാരണ ഉപയോഗിക്കുന്ന ആൽഗോരിത്തങ്ങൾ Lora மற்றும் QLora ആണ്. തിരഞ്ഞെടുക്കാൻ എന്തെങ്ങനെ?
- [ഈ സാമ്പിൾ നോട്ട്‌ബുക്കിന്റെ സഹായത്തോടെ കൂടുതൽ പഠിക്കുക](../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python FineTuning സാമ്പിളിന്റെ ഉദാഹരണം](../../../../code/04.Finetuning/FineTrainingScript.py)

### **Lora and QLora**

![lora](../../../../translated_images/qlora.e6446c988ee04ca08807488bb7d9e2c0ea7ef4af9d000fc6d13032b4ac2de18d.ml.png)


LoRA (Low-Rank Adaptation)യും QLoRA (Quantized Low-Rank Adaptation)യും Parameter Efficient Fine Tuning (PEFT) ഉപയോഗിച്ച് വലിയ ഭാഷാ മോഡൾ(LLM)കൾ ഫൈൻ-ട്യൂൺ ചെയ്യാൻ ഉപയോഗിക്കുന്ന സാങ്കേതിക വിദ്യകളാണ്. PEFT സാങ്കേതിക വിദ്യകൾ പരമ്പരാഗത രീതികളേക്കാൾ മോഡലുകൾ കൂടുതൽ കാര്യക്ഷമമായി ട്രെയിൻ ചെയ്യാൻ രൂപപ്പെടുത്തിയതാണ്. 
LoRA ഒരു സ്വതന്ത്ര ഫൈന്റ്യൂണിംഗ് സാങ്കേതിക വിദ്യയാണ്, ഭാരം അപ്ഡേറ്റ് മാട്രിക്സിൽ ലോ-റാങ്ക് ആപ്രോക്സിമേഷൻ പ്രയോഗിച്ച് മെമ്മറി ഫുട്പ്രിന്റ് കുറച്ചുകൊള്ളുന്നു. ഇത് വേഗത്തിലുള്ള ട്രെയിനിംഗ് സമയം നൽകുകയും പരമ്പരാഗത ഫൈൻ-ട്യൂണിംഗ് രീതികളോടു കണ്ടുതെരെ സാധാരണ പ്രകടനം നിലനിർത്തുകയും ചെയ്യുന്നു.

QLoRA LoRA-യുടെ വിപുലീകരിച്ച പതിപ്പാണ്, ഇത് മെമ്മറി ഉപയോഗം കുറക്കാൻ ക്വാന്തൈസേഷൻ സാങ്കേതിക വിദ്യകൾ ഉൾക്കൊള്ളിക്കുന്നു. QLoRA pretrained LLM-യിലെ ഭാര പാരാമീറ്ററുകളുടെ നിർണ്ണായകത 4-bit precision ആയാക്കി ക്വാന്തൈസ് ചെയ്യുന്നു, ഇത് LoRA-യേക്കാൾ മെമ്മറി കാര്യക്ഷമമാണ്. എന്നിരുന്നാലും, അധിക ക്വാന്തൈസേഷൻ-ഡിക്വാന്തൈസേഷൻ ഘട്ടങ്ങളാൽ QLoRA ട്രെയിനിംഗ് LoRA ട്രെയിനിംഗിനേക്കാൾ ഏകദേശം 30% മന്ദഗതിയിലാണ്.

QLoRA ക്വാന്തൈസേഷനിലൂടെ ഉള്‍പ്പെടുന്ന തെറ്റുകൾ ശരിയാക്കാൻ LoRA-യെ സഹായിയായി ഉപയോഗിക്കുന്നു. QLoRA വളരെ വലിയ പാരാമീറ്ററുകൾ ഉള്ള മോഡലുകൾ ചെറിയ, ലഭ്യമായ GPUs-ൽ ഫൈൻ-ട്യൂൺ ചെയ്യാൻ അനുവദിക്കുന്നു. ഉദാഹരണത്തിന്, QLoRA 70B പാരാമീറ്റർ മോഡൽ, 36 GPUs ആവശ്യമുള്ളതിനെ താരതമ്യത്തിൽ，仅仅 2

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ഡിസ്‌ക്ലെയിമർ:
ഈ രേഖ AI അടിസ്ഥാനമാക്കിയ വിവർത്തന സേവനമായ [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. ഞങ്ങൾ കൃത്യതയ്ക്കായി ശ്രമിച്ചെങ്കിലും, സ്വയം പ്രവർത്തിക്കുന്ന വിവർത്തനങ്ങളിൽ പിഴവുകൾ അല്ലെങ്കിൽ തെറ്റുകൾ ഉണ്ടായേക്കാമെന്ന് ദയവായി ശ്രദ്ധിക്കുക. അതിന്റെ മാതൃഭാഷയിലെ മൂലരൂപം പ്രാമാണികമായ സ്രോതസ്സായി കരുതണം. നിർണായകമായ വിവരങ്ങൾക്ക് പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ഉപയോഗിക്കാൻ ശിപാർശ ചെയ്യപ്പെടുന്നു. ഈ വിവർത്തനം ഉപയോഗിച്ചതിന്റെ ഫലം മൂലം ഉണ്ടാകുന്ന ഏതെങ്കിലും തെറ്റിദ്ധാരണങ്ങളോ തെറ്റായ വ്യാഖ്യാനങ്ങളോ നമുക്ക് ഉത്തരവാദിത്വം ഇല്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->