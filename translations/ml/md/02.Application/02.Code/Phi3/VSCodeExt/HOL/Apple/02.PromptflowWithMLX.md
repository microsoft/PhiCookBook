<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-12-21T20:02:42+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/Apple/02.PromptflowWithMLX.md",
  "language_code": "ml"
}
-->
# **Lab 2 -  AIPC-ൽ Phi-3-mini ഉപയോഗിച്ച് Prompt flow ഓടിക്കുക**

## **Prompt flow എന്താണ്**

Prompt flow LLM-അടിസ്ഥാനമായ AI ആപ്ലിക്കേഷനുകളുടെ ഐഡിയേഷൻ, പ്രോട്ടോട്ടൈപ്പിംഗ്, ടെസ്റ്റിംഗ്, മൂല്യനിർണയം മുതൽ പ്രൊഡക്ഷൻ ഡിപ്ലോയ്മെന്റും മോണിറ്ററിംഗും വരെ എന്റു-ടു-എന്റ് ഡവലപ്പ്മെന്റ് സൈകിള്‍ സുഗമമാക്കാൻ രൂപകൽപ്പന ചെയ്ത ഒരു ഡവലപ്പ്മെന്റ് ഉപകരണങ്ങളുടെ സ്വീട്ട് ആണ്. ഇത് പ്രോംപ്റ്റ് എഞ്ചിനീയറിങ്ങ് വളരെ എളുപ്പമാക്കുകയും പ്രൊഡക്ഷൻ ഗുണമേന്മയുള്ള LLM ആപ്പുകൾ നിർമ്മിക്കാൻ കഴിയുന്നതാക്കുകയും ചെയ്യുന്നു.

Prompt flow ഉപയോഗിച്ച്, നിങ്ങൾക്ക് സാധിക്കും:

- LLMകൾ, prompts, Python കോഡ് மற்றும் മറ്റ് ടൂളുകൾ തമ്മിൽ ബന്ധപ്പെട്ട് ഒരു എക്സിക്യൂട്ടബിൾ വര്‍ക്‌ഫ്ലോയിൽ ഫ്ലോകൾ സൃഷ്ടിക്കുക.

- നിങ്ങളുടെ ഫ്ലോകൾ ഡീബഗ് ചെയ്യുകയും ആവർത്തിക്കുകയും ചെയ്യുക, പ്രത്യേകിച്ച് LLMകളുമായി ഉണ്ടായുള്ള ഇന്ററാക്ഷനുകൾ എളുപ്പത്തിൽ പരിശോധിക്കുക.

- നിങ്ങളുടെ ഫ്ലോകളുടെ മൂല്യം നിർണ്ണയിക്കുക, മഹത്തരമായ ഡാറ്റാസെറ്റുകളുമായി ഗുണനിലവാരവും പ്രകടന മാനദണ്ഡങ്ങളും കണക്കാക്കുക.

- ടെസ്റ്റിംഗ്, മൂല്യനിർണയ പ്രവർത്തനങ്ങൾ നിങ്ങളുടെ CI/CD സംവിധാനത്തിലേക്ക് സംയോജിപ്പിച്ച് ഫ്ലോയുടെ ഗുണനിലവാരം ഉറപ്പാക്കുക.

- നിങ്ങളുടെ തിരഞ്ഞെടുക്കുന്ന സർവിംഗ് പ്ലാറ്റ്ഫോമിലേക്ക് ഫ്ലോകൾ ഡിപ്ലോയ് ചെയ്യുക അല്ലെങ്കിൽ നിങ്ങളുടെ ആപ്പ് കോഡ് ബേസിൽ എളുപ്പത്തിൽ സംയോജിപ്പിക്കുക.

- (ഐച്ഛികം പക്ഷേ ശക്തമായി ശുപാർശ ചെയ്യപ്പെടുന്നു) Azure AI-യിലെ Prompt flow ക്ലൗഡ് പതിപ്പ് ഉപയോഗിച്ച് നിങ്ങളുടെ ടീം ഒത്തു ചേർന്ന് പ്രവർത്തിക്കുക.



## **Apple Silicon-ൽ ജനറേഷൻ കോഡ് ഫ്ലോകൾ നിർമ്മിക്കൽ**

***കുറിപ്പ്*** ：പരിസ്ഥിതി ഇൻസ്റ്റലേഷൻ പൂർത്തിയാക്കിയിട്ടില്ലെങ്കിൽ , ദയവായി സന്ദർശിക്കുക [Lab 0 -Installations](./01.Installations.md)

1. Visual Studio Code-ൽ Prompt flow Extension തുറന്ന് ഒരു ശൂന്യ ഫ്ലോ പ്രോജക്ട് സൃഷ്ടിക്കുക

![സൃഷ്ടിക്കുക](../../../../../../../../../translated_images/pf_create.bde888dc83502eba082a058175bbf1eee6791219795393a386b06fd3043ec54d.ml.png)

2. Inputs and Outputs പാരാമീറ്ററുകൾ ചേർക്കുക, Python Code നെ പുതിയ ഫ്ലോ ആയി ചേർക്കുക

![ഫ്ലോ](../../../../../../../../../translated_images/pf_flow.520824c0969f2a94f17e947f86bdc4b4c6c88a2efa394fe3bcfb58c0dbc578a7.ml.png)


You can refer to this structure (flow.dag.yaml) to construct your flow

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. phi-3-mini ക്വാണ്ടൈസ് ചെയ്യുക

We hope to better run SLM on local devices. Generally, we quantify the model (INT4, FP16, FP32)


```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**കുറിപ്പ്:** ഡീഫോൾട്ട് ഫോൾഡർ mlx_model 

4. ***Chat_With_Phi3.py*** ൽ കോഡ് ചേർക്കുക


```python


from promptflow import tool

from mlx_lm import load, generate


# കോഡ് സേവ് ചെയ്തതിന് ശേഷം ടൂൾ ഫംഗ്ഷന്റെ ആർഗുമെന്റുകളുടെ അടിസ്ഥാനത്തിൽ ഇൻപുട്ടുകൾ വിഭാഗം മാറും
# ആർഗുമെന്റുകൾക്കും റിട്ടേൺ മൂല്യത്തിനും ടൈപ്പ് ചേർക്കുന്നത് സിസ്റ്റത്തിന് ടൈപ്പുകൾ ശരിയായി പ്രദർശിപ്പിക്കാൻ സഹായിക്കും
# ദയവായി ആവശ്യത്തിന് അനുസരിച്ച് ഫംഗ്ഷന്റെ പേര്/സിഗ്നേച്ചർ അപ്ഡേറ്റ് ചെയ്യുക
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nഫൈബണാചി പരമ്പരയ്ക്ക് വേണ്ടി പൈതൺ കോഡ് എഴുതുക. ദയവായി ഔട്ട്പുട്ടായി മാർക്ക്ഡൗൺ ഉപയോഗിക്കുക<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. നിങ്ങളുടെ ജനറേഷൻ കോഡ് ശരിയാണോ എന്നു പരിശോധിക്കാൻ നിങ്ങൾ Debug അല്ലെങ്കിൽ Run മുതൽ ഫ്ലോ ടെസ്റ്റ് ചെയ്യാം 

![റൺ](../../../../../../../../../translated_images/pf_run.4239e8a0b420a58284edf6ee1471c1697c345670313c8e7beac0edaee15b9a9d.ml.png)

5. ടെർമിനലിൽ ഫ്ലോയെ ഡവലപ്പ്മെന്റ് API ആയി ഓടിക്കുക

```

pf flow serve --source ./ --port 8080 --host localhost   

```

നിങ്ങൾ അത് Postman / Thunder Client-ൽ ടെസ്റ്റ് ചെയ്യാം


### **കുറിപ്പ്**

1. ആദ്യ റൺ കൂടുതൽ സമയം എടുക്കും. Hugging Face CLI-ൽ നിന്ന് phi-3 മോഡൽ ഡൗൺലോഡ് ചെയ്യുന്നത് ശുപാർശ ചെയ്യപ്പെടുന്നു.

2. Intel NPU-യുടെ പരിമിത കമ്പ്യൂട്ടിംഗ് ശേഷി പരിഗണിച്ച്, Phi-3-mini-4k-instruct ഉപയോഗിക്കാനുള്ള ശുപാർശ ചെയ്യാം

3. INT4 ക്വാണ്ടൈസേഷൻ നടത്താൻ നാം Intel NPU Acceleration ഉപയോഗിക്കുന്നു, പക്ഷേ നിങ്ങൾ സേവനം വീണ്ടും ഓടിക്കുന്ന പക്ഷം cache and nc_workshop ഫോൾഡറുകൾ മായ്ക്കേണ്ടതുണ്ട്.



## **റിസോഴ്‌സുകൾ**

1. Promptflow പഠിക്കുക [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Intel NPU Acceleration പഠിക്കുക [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. സാമ്പിൾ കോഡ്, ഡൗൺലോഡ് ചെയ്യാൻ [Local NPU ഏജന്റ് സാമ്പിൾ കോഡ്](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ഡിസ്ക്ലെയിമർ:
ഈ രേഖ AI തർജ്ജമാ സേവനം [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് തർജ്ജമ ചെയ്‌തതാണ്. നാം കൃത്യതയ്ക്കായി ശ്രമിച്ചിട്ടുണ്ടെങ്കിലും യന്ത്രത്തർജ്ജമയിൽ പിശകുകളോ തെറ്റിദ്ധാരണങ്ങളോ ഉണ്ടാകാവുന്നതാണെന്ന് ദയവായി ശ്രദ്ധിക്കുക. ഈ രേഖയുടെ യഥാർഥ ഭാഷയിലെ ഒറിജിനൽ ഡോക്യുമെന്റ് ആണ് അധികാരപരമായ ഉറവിടം എന്ന് കരുതേണ്ടത് ഉചിതമാണ്. നിർണായകമായ വിവരങ്ങൾക്ക് പ്രൊഫഷണൽ മാനവിക തർജ്ജമ ശുപാർശ ചെയ്യപ്പെടുന്നു. ഈ തർജ്ജമ ഉപയോഗിച്ചതിൽ നിന്നുണ്ടാകുന്ന ഏതെങ്കിലും തെറ്റിദ്ധാരണകളോ തെറ്റായ വ്യാഖ്യാനങ്ങളോ үшін ഞങ്ങൾ ഉത്തരവാദികളല്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->