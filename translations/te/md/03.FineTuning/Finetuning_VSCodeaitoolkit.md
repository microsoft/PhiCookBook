<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2bc0950f44919ac75a88c1a871680c2",
  "translation_date": "2025-12-21T18:15:46+00:00",
  "source_file": "md/03.FineTuning/Finetuning_VSCodeaitoolkit.md",
  "language_code": "te"
}
-->
## AI Toolkit for VS Code కి స్వాగతం

[AI Toolkit for VS Code](https://github.com/microsoft/vscode-ai-toolkit/tree/main) Azure AI Studio Catalog మరియు Hugging Face వంటి ఇతర క్యాటలాగ్‌ల నుండి వివిధ మోడళ్లను ఒకటిగా తీసుకువస్తుంది. ఈ టూల్‌కిట్ జనరేటివ్ AI టూల్స్ మరియు మోడళ్లతో AI యాప్స్ నిర్మాణం కోసం సాధారణ అభివృద్ధి పనులను సులభతరం చేస్తుంది:
- మోడల్ కనుగొనడం మరియు ప్లేగ్రౌండ్ ద్వారా ప్రారంభించండి.
- స్థానిక కంప్యూటింగ్ వనరులను ఉపయోగించి మోడల్ ఫైన్‑ట్యూనింగ్ మరియు ఇన్ఫరెన్స్.
- Azure వనరులను ఉపయోగించి రిమోట్ ఫైన్‑ట్యూనింగ్ మరియు ఇన్ఫరెన్స్

[VSCode కోసం AI Toolkit ఇన్‌స్టాల్ చేయండి](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

![AIToolkit ఫైన్‌ట్యూనింగ్](../../../../translated_images/Aitoolkit.7157953df04812dced01c8815a5a4d4b139e6640cc19b1c7adb4eea15b5403e6.te.png)


**[ప్రైవేట్ ప్రీవ్యూ]** క్లౌడ్‌లో మోడల్ ఫైన్‑ట్యూనింగ్ మరియు ఇన్ఫరెన్స్ నడిపే Azure Container Apps కోసం ఒక క్లిక్ ప్రావిజనింగ్.

ఇప్పుడు మీ AI యాప్ అభివృద్ధికి మొదలుపెడదాం:

- [AI Toolkit for VS Code కి స్వాగతం](../../../../md/03.FineTuning)
- [స్థానిక అభివృద్ధి](../../../../md/03.FineTuning)
  - [తయారీలు](../../../../md/03.FineTuning)
  - [Conda యాక్టివేట్ చేయండి](../../../../md/03.FineTuning)
  - [కేవలం బేస్ మోడల్ ఫైన్‑ట్యూనింగ్](../../../../md/03.FineTuning)
  - [మోడల్ ఫైన్‑ట్యూనింగ్ మరియు ఇన్ఫరెన్సింగ్](../../../../md/03.FineTuning)
  - [మోడల్ ఫైన్‑ట్యూనింగ్](../../../../md/03.FineTuning)
  - [Microsoft Olive](../../../../md/03.FineTuning)
  - [ఫైన్‑ట్యూనింగ్ నమూనాలు మరియు వనరులు](../../../../md/03.FineTuning)
- [**\[ప్రైవేట్ ప్రీవ్యూ\]** రిమోట్ అభివృద్ధి](../../../../md/03.FineTuning)
  - [ఆవశ్యకతలు](../../../../md/03.FineTuning)
  - [రిమోట్ అభివృద్ధి ప్రాజెక్ట్ సెట్టప్ చేయడం](../../../../md/03.FineTuning)
  - [Azure వనరులను ప్రావిజన్ చేయండి](../../../../md/03.FineTuning)
  - [\[ఐచ్చిక\] Huggingface టోకెన్‌ను Azure Container App Secret లో జోడించండి](../../../../md/03.FineTuning)
  - [ఫైన్‑ట్యూనింగ్ నడిపి](../../../../md/03.FineTuning)
  - [ఇన్ఫరెన్స్ എൻడ్‌పాయింట్ ప్రావిజన్ చేయండి](../../../../md/03.FineTuning)
  - [ఇన్ఫరెన్స్ ఎండ్‌పాయింట్ ను డిప్లాయ్ చేయండి](../../../../md/03.FineTuning)
  - [అడ్వాన్స్డ్ వినియోగం](../../../../md/03.FineTuning)

## స్థానిక అభివృద్ధి
### తయారీలు

1. హోస్ట్‌లో NVIDIA డ్రైవర్ ఇన్స్టాల్ అయ్యి ఉందని నిర్ధారించండి. 
2. మీరు HF ను dataset వినియోగానికి ఉపయోగిస్తుంటే `huggingface-cli login` ను నడపండి
3. మెమరీ వినియోగాన్ని మార్చే ఎటువంటి అంశాలకు సంబంధించిన `Olive` కీలక సెట్టింగ్ వివరణలు. 

### Conda యాక్టివేట్ చేయండి
మనం WSL పరిసరాన్ని ఉపయోగిస్తున్నాము మరియు అది షేర్ చేయబడుతుంది కాబట్టి మీరు conda పరిసరాన్ని మాన్యువల్‌గా యాక్టివేట్ చేయాలి. ఈ దశ తర్వాత మీరు ఫైన్‌ట్యూనింగ్ లేదా ఇన్ఫరెన్స్ నడుపగలడు.

```bash
conda activate [conda-env-name] 
```

### కేవలం బేస్ మోడల్ ఫైన్‑ట్యూనింగ్
Conda యాక్టివేట్ చేసిన తర్వాత కేవలం బేస్ మోడల్ ను పరీక్షించాలనుకుంటే ఈ కమాండ్‌ను నడపవచ్చు.

```bash
cd inference

# వెబ్ బ్రౌజర్ ఇంటర్‌ఫేస్ గరిష్ట కొత్త టోకెన్ పొడవు, టెంపరేచర్ వంటి కొన్ని పారామీటర్లను సర్దుబాటు చేయడానికి అనుమతిస్తుంది.
# gradio కనెక్షన్లు ప్రారంభించిన తర్వాత వినియోగదారుడు బ్రౌజర్‌లో లింక్ (ఉదా. http://0.0.0.0:7860) ను మాన్యువల్‌గా తెరవాలి.
python gradio_chat.py --baseonly
```

### మోడల్ ఫైన్‑ట్యూనింగ్ మరియు ఇన్ఫరెన్సింగ్

ఒకసారి వర్క్‌స్పేస్ డెవ్ కంటెయినర్‌లో తెరవబడిన తర్వాత, ఒక టర్మినల్‌ను (డిఫాల్ట్ పాత్ ప్రాజెక్ట్ రూట్) తెరవండి, తరువాత ఎంచుకున్న dataset పై LLM ను ఫైన్‑ట్యూన్ చేయడానికి దిగువ కమాండ్‌ను నడపండి.

```bash
python finetuning/invoke_olive.py 
```

Checkpointలు మరియు ఫైనల్ మోడల్ `models` ఫోల్డర్‌లో సేవ్ చేయబడతాయి.

తరువాత `console`, `web browser` లేదా `prompt flow` లో చాట్స్ ద్వారా ఫైన్‑ట్యూన్డ్ మోడల్‌తో ఇన్ఫరెన్సింగ్ నడపండి.

```bash
cd inference

# కన్సోల్ ఇంటర్‌ఫేస్.
python console_chat.py

# వెబ్ బ్రౌజర్ ఇంటర్‌ఫేస్ కొన్ని పరామితులను సవరించడానికి అనుమతిస్తుంది, ఉదాహరణకు గరిష్ఠ కొత్త టోకెన్ పొడవు, టెంపరేచర్ మొదలైనవి.
# వినియోగదారు gradio కనెక్షన్లు ప్రారంభించిన తర్వాత లింక్ (ఉదా. http://127.0.0.1:7860) బ్రౌజరులో మాన్యువల్‌గా తెరవాలి.
python gradio_chat.py
```

VS Codeలో `prompt flow` ను ఉపయోగించడానికి, దయచేసి ఈ [Quick Start](https://microsoft.github.io/promptflow/how-to-guides/quick-start.html) ను స్సంధించండి.

### మోడల్ ఫైన్‑ట్యూనింగ్

తరవాత, మీ డివైస్‌లో GPU లభ్యతను బట్టి క్రింది మోడల్‌ను డౌన్‌లోడ్ చేయండి.

QLoRA ఉపయోగించి స్థానిక ఫైన్‑ట్యూనింగ్ సెషన్ ను ప్రారంభించడానికి, మా క్యాటలాగ్ నుండి ఫైన్‑ట్యూన్ చేయదలిచిన మోడల్‌ను ఎంచుకోండి.
| ప్లాట్‌ఫారమ్(లు) | GPU లభ్యమా | మోడల్ పేరు | సైజ్ (GB) |
|---------|---------|--------|--------|
| Windows | అవును | Phi-3-mini-4k-**directml**-int4-awq-block-128-onnx | 2.13GB |
| Linux | అవును | Phi-3-mini-4k-**cuda**-int4-onnx | 2.30GB |
| Windows<br>Linux | లేదు | Phi-3-mini-4k-**cpu**-int4-rtn-block-32-acc-level-4-onnx | 2.72GB |

**_గమనిక_** మీరు మోడల్స్ డౌన్‌లోడ్ చేసుకోవడానికి Azure ఖాతా అవసరం లేదు

Phi3-mini (int4) మోడల్ సుమారు 2GB-3GB పరిమాణంలో ఉంటుంది. మీ నెట్‌వర్క్ వేగం ఆధారంగా, డౌన్‌లోడ్ చేయడానికి కొన్ని నిమిషాలు పడవచ్చు.

ప్రారంభించడానికి ప్రాజెక్ట్ పేరు మరియు స్థానాన్ని ఎంచుకుంటూ ప్రారంభించండి.
తరువాత, మోడల్ క్యాటలాగ్ నుండి ఒక మోడల్‌ను ఎంచుకోండి. ప్రాజెక్ట్ టెంప్లేట్ డౌన్‌లోడ్ చేయమని మీరు అడిగేరు. ఆపై వివిధ సెట్టింగ్స్‌ను సర్దుబాటు చేయడానికి మీరు "Configure Project" పై క్లిక్ చేయవచ్చు.

### Microsoft Olive 

మేము మా క్యాటలాగ్ నుండి PyTorch మోడల్ పై QLoRA ఫైన్‑ట్యూనింగ్ నిర్వహించడానికి [Olive](https://microsoft.github.io/Olive/why-olive.html) ను ఉపయోగిస్తాము. మెమొరీ పనితీరు మెరుగు పరచడానికి డిఫాల్ట్ విలువలతో అన్ని సెట్టింగ్‌లు ప్రీసెట్ చేయబడ్డాయి, కానీ మీ పరిస్థితికి అనుగుణంగా ఇవి సర్దుకోవచ్చు.

### ఫైన్‑ట్యూనింగ్ నమూనాలు మరియు వనరులు

- [ఫైన్‑ట్యూనింగ్ ప్రారంభ గైడ్](https://learn.microsoft.com/windows/ai/toolkit/toolkit-fine-tune)
- [HuggingFace Dataset తో ఫైన్‑ట్యూనింగ్](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/walkthrough-hf-dataset.md)
- [సింపుల్ Dataset తో ఫైన్‑ట్యూనింగ్](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/walkthrough-simple-dataset.md)

## **[ప్రైవేట్ ప్రీవ్యూ]** రిమోట్ అభివృద్ధి

### ఆవశ్యకతలు

1. మీ రిమోట్ Azure Container App పరిసరంలో మోడల్ ఫైన్‑ట్యూనింగ్ నడిపేందుకు, మీ సబ్‌స్క్రిప్షన్‌కు సరిపడిన GPU సామర్ధ్యం ఉందో లేదో నిర్ధారించండి. మీ అప్లికేషన్ కోసం కావలసిన సామర్ధ్యాన్ని అభ్యర్థించడానికి [support ticket](https://azure.microsoft.com/support/create-ticket/) అందించండి. [GPU సామర్ధ్యం గురించి మరింత సమాచారం పొందండి](https://learn.microsoft.com/azure/container-apps/workload-profiles-overview)
2. మీరు HuggingFace పై ప్రైవేట్ డేటాసెట్ ఉపయోగిస్తున్నారు అయితే, దయచేసి మీకు [HuggingFace ఖాతా](https://huggingface.co/?WT.mc_id=aiml-137032-kinfeylo) ఉన్నట్లు మరియు [ఒక యాక్సెస్ టోకెన్ తయారు చేసినట్లు](https://huggingface.co/docs/hub/security-tokens?WT.mc_id=aiml-137032-kinfeylo) నిర్ధారించండి
3. AI Toolkit for VS Code లో Remote Fine-tuning మరియు Inference ఫీచర్ ఫ్లాగ్‌ను ఎనేబుల్ చేయండి
   1. *File -> Preferences -> Settings* ఎంచుకుని VS Code సెట్టింగ్స్‌ను ఓపెన్ చేయండి.
   2. *Extensions* కి వెళ్లి *AI Toolkit* ను ఎంచుకోండి.
   3. *"Enable Remote Fine-tuning And Inference"* ఎంపికను ఎంచుకోండి.
   4. ప్రభావవంతం చేసేందుకు VS Code ను రీలోడ్ చేయండి.

- [Remote Fine tuning](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/remote-finetuning.md)

### రిమోట్ అభివృద్ధి ప్రాజెక్ట్ సెట్టప్ చేయడం
1. కమాండ్ ప్యాలెట్‌లో `AI Toolkit: Focus on Resource View` ను అమలు చేయండి.
2. మోడల్ ఫైన్‑ట్యూనింగ్ కి వెళ్లి మోడల్ క్యాటలాగ్‌కి యాక్సెస్ పొందండి. మీ ప్రాజెక్ట్‌కు ఒక పేరు ఇవ్వండి మరియు మీ మెషీన్‌లోని స్థానాన్ని ఎంచుకోండి. తరువాత *"Configure Project"* బటన్ నొక్కండి.
3. ప్రాజెక్ట్ కాన్ఫిగరేషన్
    1. *"Fine-tune locally"* ఆప్షన్‌ను ఎనేబుల్ చేయకుండా ఉండండి.
    2. Olive కాన్ఫిగరేషన్ సెట్టింగ్‌లు ప్రీ-సెట్ డిఫాల్్ట్ విలువలతో కనిపిస్తాయి. అవసరానికి అనుగుణంగా ఈ కాన్ఫిగరేషన్లను సర్దుమనుకోండి మరియు పూర్తి చేయండి.
    3. *Generate Project* కు కొనసాగండి. ఈ దశ WSL ను ఉపయోగిస్తుంది మరియు కొత్త Conda పరిసరాన్ని సెటప్ చేయడాన్ని ఇన్‌క్లూడ్ చేస్తుంది, భవిష్యత్తు అప్డేట్స్ Dev Containers ను ఉన్నత ప్రాధాన్యంగా తీసుకుంటాయి.
4. మీ రిమోట్ అభివృద్ధి ప్రాజెక్ట్‌ను ఓపెన్ చేయడానికి *"Relaunch Window In Workspace"* పై క్లిక్ చేయండి.

> **గమనిక:** ప్రాజెక్ట్ ప్రస్తుతం AI Toolkit for VS Code లో స్థానికంగా లేదా రిమోట్లలోనే పని చేస్తుంది. మీరు ప్రాజెక్ట్ సృష్టించే సమయంలో *"Fine-tune locally"* ను ఎంచుకుంటే, అది ప్రత్యేకంగా WSL లో రన్ అవుతుంది మరియు రిమోట్ అభివృద్ధి సామర్ధ్యాలు ఉండవు. మరొకవైపు, మీరు *"Fine-tune locally"* ని ఎనేబుల్ చేయకపోతే, ప్రాజెక్ట్ రిమోట్ Azure Container App పరిసరానికి పరిమితమవుతుంది.

### Azure వనరులను ప్రావిజన్ చేయండి
ప్రారంభించడానికి, రిమోట్ ఫైన్‑ట్యూనింగ్ కోసం Azure రిసోర్స్‌ను ప్రావిజన్ చేయాలి. కమాండ్ ప్యాలెట్ నుండి `AI Toolkit: Provision Azure Container Apps job for fine-tuning` ను నడిపి ఈ పనిని చేయండి.

ప్రావిజన్ ప్రగతిని అవుట్‌పుట్ ఛానెల్‌లో ప్రదర్శించిన లింక్ ద్వారా మానిటర్ చేయండి.

### [ఐచ్చిక] Huggingface టోకెన్‌ను Azure Container App Secret లో జోడించండి
మీరు ప్రైవేట్ HuggingFace dataset ఉపయోగిస్తున్నట్లయితే, HuggingFace హబ్‌లో మాన్యువల్ లాగిన్ అవసరం లేకుండా మీ HuggingFace టోకెన్‌ను వాతావరణ చరంతో సెట్ చేయండి.
ఇది చేయడానికి మీరు `AI Toolkit: Add Azure Container Apps Job secret for fine-tuning command` ను ఉపయోగించవచ్చు. ఈ కమాండ్‌తో మీరు సీక్రెట్ పేరును [`HF_TOKEN`](https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hftoken) గా సెట్ చేయవచ్చు మరియు మీ Hugging Face టోకెన్‌ను సీక్రెట్ విలువగా ఉపయోగించవచ్చు.

### ఫైన్‑ట్యూనింగ్ నడిపి
రిమోట్ ఫైన్‑ట్యూనింగ్ జాబ్‌ను ప్రారంభించడానికి `AI Toolkit: Run fine-tuning` కమాండ్‌ను అమలు చేయండి.

సిస్టమ్ మరియు కన్సోల్ లాగ్‌లను చూడటానికి, అవుట్‌పుట్ ప్యానెల్లో ఇచ్చిన లింక్ ద్వారా Azure పోర్టల్‌ను సందర్శించవచ్చు ([View and Query Logs on Azure](https://aka.ms/ai-toolkit/remote-provision#view-and-query-logs-on-azure) లో మరిన్ని దశలు). లేదా, `AI Toolkit: Show the running fine-tuning job streaming logs` కమాండ్‌ను నడిపి VSCode అవుట్‌పుట్ ప్యానెల్‌లోనే కన్సోల్ లాగ్‌లను నేరుగా చూడవచ్చు. 
> **గమనిక:** వనరుల లోపం కారణంగా జాబ్ క్యూ లో నిలవవచ్చు. లాగ్ ప్రదర్శించబడకపోతే, `AI Toolkit: Show the running fine-tuning job streaming logs` కమాండ్‌ను అమలుచేయండి, కొంతసేపు వేచి మళ్లీ కమాండ్‌ను అమలు చేసి స్ట్రీమింగ్ లాగ్‌కు మళ్లీ కనెక్ట్ అవ్వండి.

ఈ ప్రక్రియలో QLoRA ఫైన్‑ట్యూనింగ్ కోసం ఉపయోగిస్తారు మరియు ఇన్ఫరెన్స్ సమయంలో మోడల్ వినియోగించుకోవడానికి LoRA అడాప్టర్లు సృష్టిస్తుంది.
ఫైన్‑ట్యూనింగ్ ఫలితాలు Azure Files లో నిల్వ చేయబడతాయి.

### ఇన్ఫరెన్స్ ఎండ్‌పాయింట్ ప్రావిజన్ చేయండి
అడాప్టర్లు రిమోట్ పరిసరంలో ట్రెయిన్ అయ్యాక, మోడల్‌తో ఇంటరాక్ట్ చేయడానికి సింపుల్ Gradio అప్లికేషన్‌ను ఉపయోగించండి.
ఫైన్‑ట్యూనింగ్ ప్రక్రియ వంటినే, రిమోట్ ఇన్ఫరెన్స్ కోసం Azure వనరులను సెటప్ చేయడానికి కమాండ్ ప్యాలెట్ నుండి `AI Toolkit: Provision Azure Container Apps for inference` ను అమలు చేయండి.

డిఫాల్ట్‌గా, ఇన్ఫరెన్స్ కోసం ఉపయోగించే సబ్‌స్క్రిప్షన్ మరియు రిసోర్స్ గ్రూప్‌లు ఫైన్‑ట్యూనింగ్ సమయంలో ఉపయోగించబడిన వాటితో మ్యాచ్ అవ్వాలి. ఇన్ఫరెన్స్ అదే Azure Container App Environment ను ఉపయోగిస్తుంది మరియు ఫైన్‑ట్యూనింగ్ దశలో Azure Files లో నిల్వ చేయబడిన మోడల్ మరియు మోడల్ అడాప్టర్‌ను యాక్సెస్ చేస్తుంది. 


### ఇన్ఫరెన్స్ ఎండ్‌పాయింట్ ను డిప్లాయ్ చేయండి
మీరు ఇన్ఫరెన్స్ కోడ్‌ని సరిచేయాలనుకుంటే లేదా ఇన్ఫరెన్స్ మోడల్‌ను రీలోడ్ చేయాలనుకుంటే, `AI Toolkit: Deploy for inference` కమాండ్‌ను అమలు చేయండి. ఇది మీ తాజా కోడ్‌ను Azure Container App తో సమకాలీకరించి రిప్లికాను రీస్టార్ట్ చేస్తుంది।  

డిప్లాయ్ పూర్తి అయిన వెంటనే, మీరు VSCode నోటిఫికేషన్‌లో ప్రసాదించబడిన "*Go to Inference Endpoint*" బటన్‌పై క్లిక్ చేయడం ద్వారా ఇన్ఫరెన్స్ API ను యాక్సెస్ చేయవచ్చు. లేదా, వెబ్ API ఎండ్‌పాయింట్ `./infra/inference.config.json` లోని `ACA_APP_ENDPOINT` కింద మరియు అవుట్‌పుట్ ప్యానెల్లో కనిపిస్తుంది. ఈ ఎండ్‌పాయింట్‌ను ఉపయోగించి మీరు ఇప్పుడు మోడల్‌ను మూల్యాంకనం చేయడానికి సిద్ధంగా ఉన్నారు.

### అడ్వాన్స్డ్ వినియోగం
AI Toolkit తో రిమోట్ అభివృద్ధి గురించి మరింత సమాచారం కోసం, [Fine-Tuning models remotely](https://aka.ms/ai-toolkit/remote-provision) మరియు [Inferencing with the fine-tuned model](https://aka.ms/ai-toolkit/remote-inference) డాక్యుమెంటేషన్‌ను చూడండి.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
నిరాకరణ:

ఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ద్వారా అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో తప్పులు లేదా అస్పష్టతలు ఉండే అవకాశం ఉందని దయచేసి గమనించండి. మూల పత్రాన్ని దాని స్థానిక భాషలోని ప్రతిని అధికారం గల వనరుగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి వృత్తిపరమైన మానవ అనువాదాన్ని సిఫారసు చేస్తాము. ఈ అనువాదాన్ని ఉపయోగించడంవల్ల ఏర్పడిన ఏవైనా అపార్థాలు లేదా తప్పుగా అర్ధం చేసుకోవడాలపై మేము బాధ్యత వహించము.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->