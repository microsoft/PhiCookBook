<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f4cbbe7bf3e764de52d64a96d97b3c35",
  "translation_date": "2026-01-05T15:00:58+00:00",
  "source_file": "md/01.Introduction/04/QuantifyingPhi.md",
  "language_code": "te"
}
-->
# **ఫై ఫ్యామిలీని పరిమితిచేయడం**

మోడల్ పరిమితిచేయడం అనేది న్యూరల్ నెట్‌వర్క్ మోడల్‌లోని పరామితులు (వెయిట్లు మరియు యాక్టివేషన్ విలువలు వంటి) ఒక పెద్ద విలువ పరిధి (సాధారణంగా నిరంతర విలువ పరిధి) నుండి ఒక చిన్న పరిమిత సంఖ్య పరిధికి మ్యాపింగ్ చేసే ప్రక్రియ. ఈ సాంకేతికత మోడల్ పరిమాణం మరియు గణనాత్మక సంక్లిష్టతను తగ్గించి, మొబైల్ పరికరాలు లేదా ఎంబెడ్డెడ్ సిస్టమ్స్ వంటి వనరుల పరిమిత పరిసరాల్లో మోడల్ నడుం సామర్థ్యాన్ని మెరుగుపరచగలదు. మోడల్ పరిమితిచేయడం పరామితుల నేరం తగ్గించడం ద్వారా సంకెతీకరణ సాధించబడుతుంది, కాని ఇది కొంత న ఖాతరాస్యత నష్టాన్ని కూడా తెస్తుంది. కాబట్టి, పరిమితిచేయు ప్రక్రియలో మోడల్ పరిమాణం, గణన సంక్లిష్టత, మరియు ఖాతరాస్యత మధ్య సమతుల్యత అవసరం. సాధారణ పరిమితిచేయు పద్ధతులు ఫిక్స్డ్-పాయింట్ పరిమితిచేయు, ఫ్లోటింగ్-పాయింట్ పరిమితిచేయు మొదలైనవి. మీరు ప్రత్యేక పరిస్థితి మరియు అవసరాల ప్రకారం తగిన పరిమితి వ్యూహాన్ని ఎంచుకోవచ్చు.

మేము జెన్‌ఎఐ మోడల్‌ను ఎడ్జ్ పరికరాలకు నిల్వచేయాలని ఆశిస్తున్నాము మరియు మరిన్ని పరికరాలు జెన్‌ఎఐ పరిసరాల్లోకి ప్రవేశించడాన్ని అనుమతించాలని, ఉదాహరణకు మొబైల్ పరికరాలు, AI PC/Copilot+PC, మరియు సాంప్రదాయ IoT పరికరాలు. పరిమితి మోడల్ ద్వారా, మేము వివిధ పరికరాల ఆధారంగా వివిధ ఎడ్జ్ పరికరాలకు దీన్ని నిల్వ చేయవచ్చు. హార్డ్‌వేర్ తయారీదారులు ఇవ్వబడిన మోడల్ త్వ‌ర‌ను పెంపొందించే ఫ్రేమ్‌వర్క్ మరియు పరిమితి మోడల్‌తో కలిపి, మేము మెరుగైన SLM అప్లికేషన్ పరిసరాలను నిర్మించవచ్చు.

పరిమితి సందర్భంలో, మాకు వేర్వేరు ఖాతరాస్యాలు (INT4, INT8, FP16, FP32) ఉన్నాయి. క్రింద సాధారణంగా వాడే పరిమితి ఖాతరాస్యాల వివరణ ఉంది

### **INT4**

INT4 పరిమితిచేయు అనేది అత్యవసర పరిమితి పద్ధతి, ఇది మోడల్ యొక్క వెయిట్లు మరియు యాక్టివేషన్ విలువలను 4-బిట్ ಪೂర్ణాంకాల్లో పరిమితి చేస్తుంది. 4-బిట్ ప్రాతినిధ్యం పరిధి మరియు తక్కువ ఖాతరాస్యత కారణంగా, INT4 పరిమితి సాధారణంగా ఎక్కువ ఖాతరాస్యత నష్టం కలిగిస్తుంది. అయినప్పటికీ, INT8 పరిమితి తో పోలిస్తే, INT4 పరిమితి మరింత నిల్వ అవసరాలు మరియు గణన సంక్లిష్టత తగ్గిస్తుంది. గమనించవలసిన విషయం ఏమిటంటే, INT4 పరిమితి ప్రాయోగిక అనువర్తనాల్లో తక్కువగా కనిపిస్తుంది, ఎందుకంటే తక్కువ ఖాతరాస్యత మోడల్ పనితీరులో గణనీయమైన తగ్గింపుకు కారణమవచ్చు. అదనంగా, అన్ని హార్డ్‌వేర్ INT4 ఆపరేషన్లను మద్దతు ఇవ్వవు, కాబట్టి పరిమితి పద్ధతి ఎంచుకునేటప్పుడు హార్డ్‌వేర్ అనుకూలతని పరిగణలోకి తీసుకోవాలి.

### **INT8**

INT8 పరిమితిచేయు అనేది మోడల్ వెయిట్లు మరియు యాక్టివేషన్లను ఫ్లోటింగ్ పాయింట్ సంఖ్యల నుండి 8-బిట్ పూర్తి సంఖ్యలకు మార్చే ప్రక్రియ. INT8 పూర్తి సంఖ్యలు సూచించే సంఖ్య పరిధి చిన్నదే, ఖాతరాస్యత తక్కువ, కానీ ఇది నిల్వ మరియు గణన అవసరాలను గణనీయంగా తగ్గిస్తుంది. INT8 పరిమితి లో, మోడల్ వెయిట్లు మరియు యాక్టివేషన్ విలువలు పరిమితి ప్రక్రియలోకి వస్తాయి, దాని లో స్కేలింగ్ మరియు ఆఫ్సెట్ ఉంటాయి, అసలు ఫ్లోటింగ్ పాయింట్ సమాచారం ఎక్కువగా నిల్వ చేయడానికి. ఇన్ఫరెన్స్ సమయంలో, ఈ పరిమితి విలువలు తిరిగి ఫ్లోటింగ్ పాయింట్ సంఖ్యలుగా డి-క్వాంటైజ్ చేయబడతాయి గణన కోసం, తదుపరి దశకి మళ్లీ INT8 కి పరిమితి చేయబడి వుంటాయి. ఈ పద్ధతి ఎక్కువ అనువర్తనాల్లో తగిన ఖాతరాస్యత మరియు అధిక గణన సామర్ధ్యాన్ని ఇస్తుంది.

### **FP16**

FP16 ఫార్మాట్ అంటే 16-బిట్ ఫ్లోటింగ్ పాయింట్ సంఖ్యలు (float16) కాగా, ఇది 32-బిట్ ఫ్లోటింగ్ పాయింట్ సంఖ్యలతో (float32) పోలిస్తే మెమరీ ఉపయోగాన్ని సగానికి తగ్గిస్తుంది, ఇది పెద్ద స్థాయి డీప్ లెర్నింగ్ అనువర్తనాలలో కీలకమైన లాభాలు కలిగిస్తుంది. FP16 ఫార్మాట్ పెద్ద మోడళ్లు లేదా ఎక్కువ డేటాను అదే GPU మెమరీ పరిమితులలో లోడ్ చేయడానికి లేదా ప్రాసెస్ చేయడానికి అనుమతిస్తుంది. ఆధునిక GPU హార్డ్‌వేర్ FP16 ఆపరేషన్లకు మద్దతు ఇవ్వడం కొనసాగుతుండడంతో, FP16 ఫార్మాట్ వాడటం గణన వేగంలో మెరుగుదలతో కూడి ఉండవచ్చు. అయితే FP16 ఫార్మాట్ inherent లోతైన లోపాలు కలిగి ఉంటుంది, అంటే తక్కువ ఖాతరాస్యత, ఇది కొన్ని సందర్భాల్లో సంఖ్యల స్థిరత్వంలో లేదా ఖాతరాస్య నష్టంలో దారితీస్తుంది.

### **FP32**

FP32 ఫార్మాట్ అధిక ఖాతరాస్యతని అందిస్తుంది మరియు విస్తృత విలువల పరిధిని సరిగ్గా ప్రాతినిధ్యం వహించగలదు. సంక్లిష్ట గణిత కార్యకలాపాలు జరిగే పరిస్థితుల్లో లేదా అధిక ఖాతరాస్యత ఫలితాలు అవసరమైన సందర్భాల్లో FP32 ఫార్మాట్ ప్రాధాన్యత ఇచ్చబడుతుంది. అయితే అధిక ఖాతరాస్యత ఎక్కువ మెమరీ వినియోగం మరియు లెంబద గణన సమయాన్ని సూచిస్తుంది. పెద్ద స్థాయి డీప్ లెర్నింగ్ మోడళ్లు, ప్రత్యేకంగా చాలా మోడల్ పరామితులు మరియు పెద్ద డేటా ఉన్నప్పుడు, FP32 ఫార్మాట్ GPU మెమరీ కొరత లేదా ఇన్ఫరెన్స్ వేగం తగ్గుదలకి కారణమవుతుంది.

మొబైల్ పరికరాలు లేదా IoT పరికరాల్లో మేము Phi-3.x మోడల్స్‌ను INT4 కి మార్చవచ్చు, అయితే AI PC / Copilot PC వంటి పరికరాలు INT8, FP16, FP32 వంటి అధిక ఖాతరాస్యత ఉపయోగించవచ్చు.

ప్రస్తుతానికి, వేర్వేరు హార్డ్‌వేర్ తయారీదారులు వేర్వేరు ఫ్రేమ్‌వర్క్‌లను జనరేటివ్ మోడళ్లకు మద్దతుగా కలిగి ఉన్నారు, ఉదాహరణకు Intel యొక్క OpenVINO, Qualcomm యొక్క QNN, Apple యొక్క MLX, Nvidia యొక్క CUDA మొదలైనవి, ఇవి మోడల్ పరిమితి తో కలిసి స్థానిక నిల్వ పూర్తి చేస్తాయి.

సాంకేతికంగా, పరిమితి తర్వాత మాకు వేర్వేరు ఫార్మాట్ మద్దతు ఉంది, ఉదాహరణకు PyTorch / TensorFlow ఫార్మాట్, GGUF, మరియు ONNX. నేను GGUF మరియు ONNX మధ్య ఫార్మాట్ పోలిక మరియు అప్లికేషన్ పరిసరాలు చేశాను. ఇక్కడ నేను ONNX పరిమితి ఫార్మాట్‌ను సిఫారసు చేస్తున్నాను, ఇది మోడల్ ఫ్రేమ్‌వర్క్ నుండీ హార్డ్‌వేర్ వరకు మంచిగా మద్దతు ఉంది. ఈ అధ్యాయంలో మేము GenAI కొరకు ONNX Runtime, OpenVINO, మరియు Apple MLX ను ఉపయోగించి మోడల్ పరిమితి పై దృష్టి పెట్టబోతున్నాము (మీకు మెరుగైన విధానం ఉంటే, PR సమర్పించి ఇవ్వవచ్చు)

**ఈ అధ్యాయం లో ఉన్నాయి**

1. [llama.cpp ఉపయోగించి Phi-3.5 / 4 పరిమితి](./UsingLlamacppQuantifyingPhi.md)

2. [onnxruntime కోసం జనరేటివ్ AI విస్తరణలతో Phi-3.5 / 4 పరిమితి](./UsingORTGenAIQuantifyingPhi.md)

3. [Intel OpenVINO ఉపయోగించి Phi-3.5 / 4 పరిమితి](./UsingIntelOpenVINOQuantifyingPhi.md)

4. [Apple MLX ఫ్రేమ్‌వర్క్ ఉపయోగించి Phi-3.5 / 4 పరిమితి](./UsingAppleMLXQuantifyingPhi.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**అస్పష్టత**:  
ఈ పత్రం AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మనము సూటిగా ఉండేందుకు ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో తప్పులు లేదా లోపాలు ఉండొచ్చు. స్వదేశీ భాషలో అసలు పత్రం అధికారిక మూలంగా పరిగణించాలి. కీలక సమాచారం కోసం ప్రొఫెషనల్ మానవ అనువాదం చేయించుకోవడం మంచిది. ఈ అనువాదం వలన సంభవించే ఏవైనా అపార్థాలు లేదా తప్పు అర్థాల కోసం మేము బాధ్యులం కాదు.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->