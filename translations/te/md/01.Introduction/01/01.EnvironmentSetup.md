# Phi-3తో స్థానికంగా ప్రారంభించండి

ఈ గైడ్ మీకు Ollama ఉపయోగించి Phi-3 మోడల్‌ను నడిపేందుకు మీ స్థానిక వాతావరణాన్ని సెట్ చేయడంలో సహాయపడుతుంది. మీరు మోడల్‌ను GitHub Codespaces, VS Code Dev Containers, లేదా మీ స్థానిక వాతావరణం వంటి కొన్ని వేరు మార్గాల ద్వారా నడిపించవచ్చు.

## పర్యావరణ సెటప్

### GitHub Codespaces

GitHub Codespaces ఉపయోగించి మీరు ఈ టెంప్లేట్‌ను వర్చువల్‌గా నడిపించవచ్చు. బటన్ మీ బ్రౌజర్లో వెబ్-ఆధారిత VS Code ఇన్స్టెన్స్‌ను ఓపెన్ చేస్తుంది:

1. టెంప్లేట్‌ను ఓపెన్ చేయండి (ఇది కొన్ని నిమిషాలు పట్టవచ్చు):

    [![GitHub Codespacesలో ఓపెన్ చేయండి](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. టెర్మినల్ విండో ఓపెన్ చేయండి

### VS Code Dev Containers

⚠️ ఈ ఎంపిక పనిచేయడానికి మీ Docker Desktopకి కనీసం 16 GB RAM కేటాయించబడాలి. మీ వద్ద 16 GB కన్నా తక్కువ RAM ఉంటే, మీరు [GitHub Codespaces ఎంపిక](../../../../../md/01.Introduction/01)ను ప్రయత్నించవచ్చు లేదా [స్థానికంగా సెటప్ చేయండి](../../../../../md/01.Introduction/01).

సంబంధిత ఎంపికగా VS Code Dev Containers ఉంది, ఇది మీ స్థానిక VS Codeలో ప్రాజెక్టును [Dev Containers విస్తరణ](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) ఉపయోగించి ఓపెన్ చేస్తుంది:

1. Docker Desktopను ప్రారంభించండి (ఇంకా ఇన్‌స్టాల్ చేయని ఉంటే ఇన్‌స్టాల్ చేయండి)
2. ప్రాజెక్టును ఓపెన్ చేయండి:

    [![Dev Containersలో ఓపెన్ చేయండి](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. ఓపెన్ అయిన VS Code విండోలో, ప్రాజెక్ట్ ఫైళ్లు కనిపిస్తాక (ఇది కొన్ని నిమిషాలు పట్టవచ్చు), ఒక టెర్మినల్ విండో ఓపెన్ చేయండి.
4. డిప్లాయ్‌మెంట్ దశలతో కొనసాగండి

### స్థానిక వాతావరణం

1. ఈ కింది టూల్స్ ఇన్‌స్టాల్ చేయబడినట్లు నిర్ధారించుకోండి:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## మోడల్‌ను పరీక్షించండి

1. Ollamaని phi3:mini మోడల్‌ను డౌన్లోడ్ చేసి నడిపించాలని అడగండి:

    ```shell
    ollama run phi3:mini
    ```

    మోడల్ డౌన్లోడ్ అయ్యే వరకు కొన్ని నిమిషాలు పట్టవచ్చు.

2. Once you see "success" in the output, you can send a message to that model from the prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. కొన్ని సెకన్ల తర్వాత, మీరు మోడల్ నుండి ప్రతిస్పందనా స్ట్రీమ్‌ను చూడగలరు.

4. భాషా మోడల్స్‌తో ఉపయోగించే వివిధ సాంకేతికతలను తెలుసుకోవడానికి, Python నోట్బుక్ [ollama.ipynb](../../../code/01.Introduce/ollama.ipynb) ను ఓపెన్ చేసి ప్రతి సెల్‌ను నడపండి . If you used a model other than 'phi3:mini', change the `MODEL_NAME` in the first cell.

5. Python నుండి phi3:mini మోడల్‌తో సంభాషించడానికి, Python ఫైల్ [chat.py](../../../../../code/01.Introduce/chat.py) ను ఓపెన్ చేసి అది నడిపండి. అవసరమైతే ఫైల్ శీఘ్ర భాగంలో ఉన్న `MODEL_NAME` ను మార్చవచ్చు, అలాగే సిస్టమ్ మెసేజ్‌ను మార్చవచ్చు లేదా కోరితే few-shot ఉదాహరణల్ని జోడించవచ్చు.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
డిస్క్లెయిమర్:
ఈ డాక్యుమెంట్‌ను AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ద్వారా అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో తప్పులు లేదా తప్పిదాలు ఉండవచ్చు. మూల భాషలోని అసలు పత్రాన్ని అధికారమైన ఆధారంగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి ప్రొఫెషనల్ మానవ అనువాదం చేయించుకోవాలని సిఫార్సు చేయబడుతుంది. ఈ అనువాదం ఉపయోగం వల్ల ఏర్పడే ఏ అపార్థాలు లేదా తప్పుగా అర్థం చేసుకోవడాలైన వాటికి మేము బాధ్యులు కాదు.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->