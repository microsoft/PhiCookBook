<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "006e8cf75211d3297f24e1b22e38955f",
  "translation_date": "2025-12-21T21:13:56+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "te"
}
-->
# ఇంటరాక్టివ్ Phi 3 Mini 4K Instruct చాట్‌బాట్ Whisperతో

## అవలోకనం

ఇంటరాక్టివ్ Phi 3 Mini 4K Instruct చాట్‌బాట్ అనేది వాడుకరులకు Microsoft Phi 3 Mini 4K instruct డెమోతో టెక్స్ట్ లేదా ఆడియో ఇన్పుట్ ద్వారా పరస్పరం చేయడానికి అనుమతించే ఒక సాధనం. ఈ చాట్‌బాట్ అనేక విధుల కోసం ఉపయోగించబడవచ్చు, ఉదాహరణకు అనువాదం, వాతావరణ అప్డేట్లు, మరియు సాధారణ సమాచారం సేకరణ.

### ప్రారంభించడం

ఈ చాట్‌బాట్‌ను ఉపయోగించడానికి, కేవలం ఈ సూచనలను అనుసరించండి:

1. Open a new [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb)
2. నోట్‌బుక్ యొక్క ప్రధాన విండోలో, మీరు ఒక చాట్‌బాక్స్ ఇంటర్‌ఫేస్‌ను టెక్స్ట్ ఇన్‌పుట్ బాక్స్ మరియు "Send" బటన్‌తో చూడగలరు.
3. టెక్స్ట్ ఆధారిత చాట్‌బాట్‌ను ఉపయోగించడానికి, కేవలం మీ సందేశాన్ని టెక్స్ట్ ఇన్‌పుట్ బాక్స్‌లో టైప్ చేసి "Send" బటన్‌ను క్లిక్ చేయండి. చాట్‌బాట్ నోట్బుక్‌లోనే నేరుగా ప్లే చేయగల ఒక ఆడియో ఫైల్‌తో స్పందిస్తుంది.

**గమనిక**: ఈ టూల్‌కు GPU మరియు స్పీచ్ రికగ్నిషన్ మరియు అనువాదానికి ఉపయోగించబడే Microsoft Phi-3 మరియు OpenAI Whisper మోడల్స్‌కి ప్రాప్యత అవసరం.

### GPU అవసరాలు

ఈ డెమోను నడపడానికి మీకు 12Gb GPU మెమరీ అవసరం.

GPU పై **Microsoft-Phi-3-Mini-4K instruct** డెమోను నడిపేందుకు అవసరమైన మెమరీ వివిధ అంశాలపై ఆధారపడి ఉంటుంది, ఉదాహరణకు ఇన్పుట్ డేటా పరిమాణం (ఆడియో లేదా టెక్స్ట్), అనువాదానికి ఉపయోగిస్తున్న భాష, మోడల్ స్పీడ్, మరియు GPU పై అందుబాటులో ఉన్న మెమరీ.

సాధారణంగా, Whisper మోడల్ GPUలపై నడవడానికి రూపొందించబడింది. Whisper మోడల్ నడపడానికి సిఫార్సు చేయబడే కనీస GPU మెమరీ 8 GB, కానీ అవసరమైతే ఇది పెద్ద పరిమాణాల మెమరీని కూడా నిర్వహించగలదు.

చాలా పెద్ద పరిమాణం డేటా లేదా అధిక వాల్యూమ్ అభ్యర్థనలను మోడల్‌పై నడిపించటం మరింత GPU మెమరీ అవసరం లేదా పనితీరులో సమస్యలు కలిగించవచ్చు. మీ ప్రత్యేక అవసరాలకు అనుకూలంగా వివిధ కాన్ఫిగరేషన్లతో మీ ఉపయోగకేస్‌ను పరీక్షించటం మరియు మెమరీ వినియోగాన్ని సమీక్షించడం ప్రతికూలం.

## E2E ఉదాహరణ — ఇంటరాక్టివ్ Phi 3 Mini 4K Instruct చాట్‌బాట్ Whisperతో

The jupyter notebook titled [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) Microsoft Phi 3 Mini 4K instruct డెమోను ఆడియో లేదా వ్రాయబడిన టెక్స్ట్ ఇన్పుట్ నుండి టెక్స్ట్ జనరేట్ చేయడానికి ఎలా ఉపయోగించాలో示ిస్తుందని చూపిస్తుంది. నోట్‌బుక్‌లో కొన్ని ఫంక్షన్‌లు నిర్వచించబడి ఉన్నాయి:

1. `tts_file_name(text)`: ఈ ఫంక్షన్ ఉత్పన్నమయ్యే ఆడియో ఫైలు సేవ్ చేయడానికి ఇన్పుట్ టెక్స్ట్ ఆధారంగా ఒక ఫైల్ పేరు రూపొందిస్తుంది.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: ఈ ఫంక్షన్ Edge TTS API ఉపయోగించి ఇన్పుట్ టెక్స్ట్ యొక్క భాగాల జాబితా నుండి ఒక ఆడియో ఫైల్‌ను రూపొందిస్తుంది. ఇన్పుట్ పరామితులు భాగాల జాబితా, స్పీచ్ రేటు, వాయిస్ పేరు, మరియు ఉత్పత్తి ఆడియో ఫైల్ సేవ్ చేయడానికి అవుట్‌పుట్ పాత్.
1. `talk(input_text)`: ఈ ఫంక్షన్ Edge TTS API ఉపయోగించి ఆడియో ఫైల్‌ను జనరేట్ చేసి /content/audio డైరెక్టరీలో ఒక యాదృచ్ఛిక ఫైల్ పేరుతో సేవ్ చేస్తుంది. ఇన్పుట్ పరామితి చ換డం కోసం ఇవ్వబడిన ఇన్పుట్ టెక్స్ట్.
1. `run_text_prompt(message, chat_history)`: ఈ ఫంక్షన్ Microsoft Phi 3 Mini 4K instruct డెమోను ఉపయోగించి ఒక సందేశ ఇన్పుట్ నుండి ఆడియో ఫైల్‌ను రూపొందించి దానిని చాట్ హిస్టరీకి జత చేస్తుంది.
1. `run_audio_prompt(audio, chat_history)`: ఈ ఫంక్షన్ ఒక ఆడియో ఫైల్‌ను Whisper మోడల్ API ఉపయోగించి టెక్స్ట్‌గా మార్చి, దాన్ని `run_text_prompt()` ఫంక్షన్‌కు జమ చేస్తుంది.
1. కోడ్ ఒక Gradio యాప్‌ను లాంచ్ చేస్తుంది, ఇది వాడుకరులకు Phi 3 Mini 4K instruct డెమోతో సందేశాలను టైప్ చేయడం లేదా ఆడియో ఫైళ్ళను అప్లోడ్ చేయడం ద్వారా పరస్పరం చేయగల అవకాశాన్ని ఇస్తుంది. అవుట్‌పుట్ యాప్‌లో టెక్స్ట్ సందేశంగా ప్రదర్శించబడుతుంది.

## సమస్యలు పరిష్కరించడం

Cuda GPU డ్రైవర్లు ఇన్‌స్టాల్ చేయడం

1. మీ Linux అప్లికేషన్లు నవీకరింపబడినవిగా ఉన్నాయని నిర్ధారించండి

    ```bash
    sudo apt update
    ```

1. Cuda డ్రైవర్లు ఇన్‌స్టాల్ చేయండి

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. cuda డ్రైవర్ స్థానం నమోదు చేయండి

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Nvidia GPU మెమరీ పరిమాణం తనిఖీ చేయడం (అవసరం: 12GB GPU మెమరీ)

    ```bash
    nvidia-smi
    ```

1. Empty Cache: మీరు PyTorch ఉపయోగిస్తునట్లయితే, torch.cuda.empty_cache() ను పిలిచి అన్ని వాడని క్యాచ్డ్ మెమరీని విడుదల చేయవచ్చు ताकि అది ఇతర GPU అప్లికేషన్ల ద్వారా ఉపయోగించబడేలా చేయబడుతుంది

    ```python
    torch.cuda.empty_cache() 
    ```

1. Nvidia Cuda తనిఖీ చేయడం

    ```bash
    nvcc --version
    ```

1. Hugging Face టోకెన్ సృష్టించడానికి క్రింది పనులను చేయండి.

    - [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo) కు నావిగేట్ చేయండి.
    - **New token** ని ఎంచుకోండి.
    - మీరు ఉపయోగించదలచిన ప్రాజెక్ట్ **Name** ను నమోదు చేయండి.
    - **Type** ని **Write** గా ఎంచుకోండి.

> **గమనిక**
>
> మీరు క్రింది తప్పిదాన్ని ఎదుర్కొనినట్లయితే:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> ఇలాంటి సమస్యను పరిష్కరించడానికి, మీ టెర్మినల్‌లో క్రింది కమాండ్‌ను టైప్ చేయండి.
>
> ```bash
> sudo ldconfig
> ```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
అస్పష్టం:
ఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటిక్ అనువాదాలలో తప్పులు లేదా అసమగ్రతలు ఉండవచ్చని దయచేసి గమనించండి. మూల భాషలో ఉన్న అసలు పత్రాన్నే అధికారిక మూలంగా పరిగణించాలి. కీలకమైన సమాచారానికి వృత్తిపరమైన మానవ అనువాదం సూచించబడుతుంది. ఈ అనువాదం ఉపయోగించడం వలనే కలిగే ఏవైనా అపార్థాలు లేదా తప్పుడు అర్థనిర్మణాల కోసం మేము బాధ్యులు కాదనే విషయం స్పష్టం చేస్తాం.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->