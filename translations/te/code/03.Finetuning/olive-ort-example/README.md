<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-12-21T16:49:40+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "te"
}
-->
# Olive ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø Phi3 ‡∞´‡±à‡∞®‡±ç‚Äë‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø

‡∞à ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞≤‡±ã ‡∞Æ‡±Ä‡∞∞‡±Å Olive ‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞ö‡±á‡∞Ø‡∞¨‡±ã‡∞§‡±Å‡∞®‡±ç‡∞®‡∞µ‡∞ø:

1. ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤‡∞®‡±Å Sad/Joy/Fear/Surprise ‡∞ó‡∞æ ‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø LoRA ‡∞Ö‡∞°‡∞æ‡∞™‡±ç‡∞ü‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞´‡±à‡∞®‡±ç‚Äë‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.
1. ‡∞Ö‡∞°‡∞æ‡∞™‡±ç‡∞ü‡∞∞‡±ç ‡∞µ‡±Ü‡∞Ø‡∞ø‡∞ü‡±ç‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞¨‡±á‡∞∏‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞≤‡±ã ‡∞Æ‡∞ø‡∞≥‡∞ø‡∞§‡∞Ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.
1. ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞Ü‡∞™‡±ç‡∞ü‡∞ø‡∞Æ‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞∏‡∞ø `int4`‡∞≤‡±ã ‡∞ï‡±ç‡∞µ‡∞æ‡∞Ç‡∞ü‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.

> **‚ö†Ô∏è ‡∞´‡±à‡∞®‡±ç‚Äë‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡∞ø‡∞Ç‡∞ó‡±ç‚Äå‡∞ï‡±Å, ‡∞Æ‡±Ä ‡∞µ‡∞¶‡±ç‡∞¶ ‡∞í‡∞ï ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤ GPU ‡∞â‡∞Ç‡∞°‡∞æ‡∞≤‡∞ø ‚Äî ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ï‡±Å, A10, V100, A100.**

## üíæ Install

‡∞ï‡±ä‡∞§‡±ç‡∞§ Python ‡∞µ‡∞∞‡±ç‡∞ö‡±Å‡∞µ‡∞≤‡±ç ‡∞™‡∞∞‡∞ø‡∞∏‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø (‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ï‡∞ø, `conda` ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Next, install the Olive and the dependencies for a fine-tuning workflow:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Olive ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø Phi3 ‡∞´‡±à‡∞®‡±ç‚Äë‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
The [Olive configuration file](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) contains a *‡∞µ‡∞∞‡±ç‡∞ï‡±ç‚Äå‡∞´‡±ç‡∞≤‡±ã* with the following *‡∞™‡∞æ‡∞∏‡±ç‚Äå‡∞≤‡±Å*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

‡∞∏‡∞æ‡∞Æ‡∞æ‡∞®‡±ç‡∞Ø‡∞Ç‡∞ó‡∞æ, ‡∞à ‡∞µ‡∞∞‡±ç‡∞ï‡±ç‚Äå‡∞´‡±ç‡∞≤‡±ã ‡∞à ‡∞ï‡±ç‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞™‡∞®‡±Å‡∞≤‡∞®‡±Å ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:

1. Phi3 ‡∞®‡±Å ‡∞´‡±à‡∞®‡±ç‚Äë‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø (150 ‡∞∏‡±ç‡∞ü‡±Ü‡∞™‡±ç‡∞∏‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å) using the [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) data.
1. Merge the LoRA adapter weights into the base model. This will give you a single model artifact in the ONNX format.
1. Model Builder will optimize the model for the ONNX runtime *and* quantize the model into `int4`.

To execute the workflow, run:

```bash
olive run --config phrase-classification.json
```

When Olive has completed, you're optimized `int4` fine-tuned Phi3 model is available in: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª ‡∞´‡±à‡∞®‡±ç‚Äë‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® Phi3 ‡∞®‡±Å ‡∞Æ‡±Ä ‡∞Ö‡∞™‡±ç‡∞≤‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç‚Äå‡∞≤‡±ã ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø

‡∞Ø‡∞æ‡∞™‡±ç‚Äå‡∞®‡±Å ‡¶ö‡¶æ‡¶≤‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

This response should be a single word classification of the phrase (Sad/Joy/Fear/Surprise).

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**‡∞Ö‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç**:
‡∞à ‡∞™‡∞§‡±ç‡∞∞‡∞Ç AI ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ö‡∞®‡±Å‡∞µ‡∞¶‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±á‡∞Æ‡±Å ‡∞ñ‡∞ö‡±ç‡∞ö‡∞ø‡∞§‡∞§‡±ç‡∞µ‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±Ä, ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡∞≤‡±ã ‡∞§‡∞™‡±ç‡∞™‡±Å‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞≤‡±ã‡∞™‡∞æ‡∞≤‡±Å ‡∞â‡∞Ç‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å ‡∞Ö‡∞®‡±ç‡∞® ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞ó‡∞Æ‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞ø‡∞ï ‡∞≠‡∞æ‡∞∑‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞Æ‡±Ç‡∞≤ ‡∞™‡∞§‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞æ‡∞∞‡∞ø‡∞ï ‡∞Æ‡±Ç‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø. ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞µ‡±É‡∞§‡±ç‡∞§‡∞ø‡∞™‡∞∞‡±Å‡∞≤‡±à‡∞® ‡∞Æ‡∞æ‡∞®‡∞µ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞∏‡±Ç‡∞ö‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å. ‡∞à ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞Ç ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞Ç ‡∞µ‡∞≤‡±ç‡∞≤ ‡∞ï‡∞≤‡∞ø‡∞ó‡±á ‡∞è‡∞µ‡±à‡∞®‡∞æ ‡∞Ö‡∞™‡∞æ‡∞∞‡±ç‡∞•‡∞æ‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞§‡∞™‡±ç‡∞™‡±Å‡∞ó‡∞æ ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç‡∞™‡±à ‡∞Æ‡±á‡∞Æ‡±Å ‡∞¨‡∞æ‡∞ß‡±ç‡∞Ø‡∞§ ‡∞µ‡∞π‡∞ø‡∞Ç‡∞ö‡∞Æ‡±Å.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->