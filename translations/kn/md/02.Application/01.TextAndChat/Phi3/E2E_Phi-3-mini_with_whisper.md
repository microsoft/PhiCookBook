<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "006e8cf75211d3297f24e1b22e38955f",
  "translation_date": "2025-12-21T21:17:26+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "kn"
}
-->
# Whisper ಜೊತೆ ಇಂಟರಾಕ್ಟಿವ್ Phi 3 Mini 4K Instruct ಚಾಟ್‌ಬಾಟ್

## ಅವಲೋಕನ

ಇಂಟರಾಕ್ಟಿವ್ Phi 3 Mini 4K Instruct ಚಾಟ್‌ಬಾಟ್ ಒಂದು ಉಪಕರಣವಾಗಿದೆ, ಇದು ಬಳಕೆದಾರರಿಗೆ ಪಠ್ಯ ಅಥವಾ ಆಡಿಯೋ ಇನ್ಪುಟ್ ಬಳಸಿ Microsoft Phi 3 Mini 4K instruct ಡೆಮೊ ಜೊತೆ ಪರಸ್ಪರ ಸಂವಹನ ನಡೆಸಲು ಅನುಮತಿಸುತ್ತದೆ. ಈ ಚಾಟ್‌ಬಾಟ್ ಅನ್ನು ಅನೇಕ ಕಾರ್ಯಗಳಿಗೆ ಉಪಯೋಗಿಸಬಹುದು, ಉದಾಹರಣೆಗೆ ಅನುವಾದ, ಹವಾಮಾನದ ಅಪ್‌ಡೇಟ್ಗಳು, ಮತ್ತು ಸಾಮಾನ್ಯ ಮಾಹಿತಿಯ ಸಂಗ್ರಹಣೆ.

### ಪ್ರಾರಂಭಿಸುವುದು

ಈ ಚಾಟ್‌ಬಾಟ್ ಬಳಸಲು, ಕೆಳಗಿನ ಸೂಚನೆಗಳನ್ನು ಅನುಸರಿಸಿ:

1. Open a new [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb)
2. ನೋಟ್‌ಬುಕ್‌ನ ಮುಖ್ಯ ವಿಂಡೋದಲ್ಲಿ, ನೀವು ಪಠ್ಯ ಇನ್‌ಪುಟ್ ಬಾಕ್ಸ್ ಮತ್ತು "Send" ಬಟನ್ ಹೊಂದಿರುವ ಚಾಟ್‌ಬಾಕ್ಸ್ ಇಂಟರ್‌ಫೇಸ್ ಅನ್ನು ಕಾಣುತ್ತೀರಿ.
3. ಪಠ್ಯ ಆಧಾರಿತ ಚಾಟ್‌ಬಾಟ್ ಬಳಸಲು, ನಿಮ್ಮ ಸಂದೇಶವನ್ನು ಪಠ್ಯ ಇನ್‌ಪುಟ್ ಬಾಕ್ಸಿನಲ್ಲಿ ಟೈಪ್ ಮಾಡಿ "Send" ಬಟನ್ ಕ್ಲಿಕ್ ಮಾಡಿ. ಚಾಟ್‌ಬಾಟ್ ನೋಟ್ಬುಕ್‌ನೊಳಗಿನಿಂದ ನೇರವಾಗಿ ಪ್ಲೇ ಮಾಡಬಹುದಾದ ಆಡಿಯೋ ಫೈಲ್‌ನೊಂದಿಗೆ ಪ್ರತಿಕ್ರಿಯಿಸುತ್ತದೆ.

**ಗಮನಿಸಿ**: ಈ ಉಪಕರಣಕ್ಕೆ GPU ಮತ್ತು Microsoft Phi-3 ಮತ್ತು OpenAI Whisper ಮಾದರಿಗಳ ಪ್ರವೇಶ ಬೇಕಾಗುತ್ತದೆ, ಇವು ಸ್ಪೀಚ್ ರೆಕಗ್ನಿಷನ್ ಮತ್ತು ಅನುವಾದಕ್ಕೆ ಬಳಸಲಾಗುತ್ತವೆ.

### GPU ಅಗತ್ಯಗಳು

ಈ ಡೆಮೋ ಅನ್ನು ಚಾಲನೆ ಮಾಡಲು ನಿಮಗೆ 12Gb GPU ಮೆಮೊರಿ ಬೇಕಾಗುತ್ತದೆ.

GPU ಮೇಲೆ **Microsoft-Phi-3-Mini-4K instruct** ಡೆಮೋ ಅನ್ನು ರನ್ ಮಾಡುವಾಗ ಮೇಮೊರಿ ಅಗತ್ಯಗಳು ಕೆಲವು ಅಂಶಗಳ ಮೇಲೆ ಅವಲಂಬಿತವಾಗಿರುತ್ತವೆ, ಉದಾಹರಣೆಗೆ ಇನ್ಪುಟ್ ಡೇಟಾದ ಗಾತ್ರ (ಆಡಿಯೋ ಅಥವಾ ಪಠ್ಯ), ಅನುವಾದಕ್ಕೆ ಬಳಸಲಾದ ಭಾಷೆ, ಮಾದರಿಯ ವೇಗ ಮತ್ತು GPU‌ನಲ್ಲಿ ಲಭ್ಯವಿರುವ ಮೆಮೊರಿ.

ಸಾಮಾನ್ಯವಾಗಿ, Whisper ಮಾದರಿ GPUs‌ನಲ್ಲಿ ರನ್ ಆಗಲು ವಿನ್ಯಾಸಗೊಳಿಸಲಾಗಿದೆ. Whisper ಮಾದರಿ ರನ್‌ಗಾಗಿ ಶಿಫಾರಸು ಮಾಡಲಾದ ಕನಿಷ್ಟ GPU ಮೆಮೊರಿ ಪ್ರಮಾಣ 8 GB ಆಗಿದೆ, ಆದರೆ ಅಗತ್ಯವಿದ್ದರೆ ಇದು ಹೆಚ್ಚಿನ ಮೆಮೊರಿಯನ್ನು ಕೂಡ ನಿರ್ವಹಿಸಬಹುದು.

ಬಹಳ ಪ್ರಮಾಣದ ಡೇಟಾ ಅಥವಾ ಹೆಚ್ಚಿನ ವಿನಂತಿಗಳ ವಾಲ್ಯೂಮ್ ಅನ್ನು ಮಾದರಿಯಲ್ಲಿ ರನ್ ಮಾಡಿದರೆ ಹೆಚ್ಚು GPU ಮೆಮೊರಿಯನ್ನು ಅಗತ್ಯವಿರಿಸಬಹುದು ಮತ್ತು/ಅಥವಾ ಕಾರ್ಯಕ್ಷಮತೆಯ ಸಮಸ್ಯೆಗಳನ್ನು ಉಂಟುಮಾಡಬಹುದು. ನಿಮ್ಮ ನಿರ್ದಿಷ್ಟ ಅವಶ್ಯಕತೆಗಳಿಗೆ ಅನುಗುಣವಾಗಿ ವಿವಿಧ ಸಂರಚನೆಗಳೊಂದಿಗೆ ಪರೀಕ್ಷಿಸಿ ಮತ್ತು ಮೆಮೊರಿ ಬಳಕೆಯನ್ನು ಗಮನಿಸಿ ಅತ್ಯುತ್ತಮ ಸೆಟ್ಟಿಂಗ್‌ಗಳನ್ನು ನಿರ್ಧರಿಸುವುದು ಶಿಫಾರಸು ಮಾಡಲಾಗಿದೆ.

## Whisper ಜೊತೆ ಇಂಟರಾಕ್ಟಿವ್ Phi 3 Mini 4K Instruct ಚಾಟ್‌ಬಾಟ್‌ಗಾಗಿ E2E ಮಾದರಿ

The jupyter notebook titled [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) ಪ್ರದರ್ಶಿಸುತ್ತದೆ Microsoft Phi 3 Mini 4K instruct ಡೆಮೊವನ್ನು ಆಡಿಯೋ ಅಥವಾ ಬರೆಯಲಾಗಿರುವ ಪಠ್ಯ ಇನ್‌ಪುಟ್‌ನಿಂದ ಪಠ್ಯವನ್ನು उत्पಾದಿಸಲು ಹೇಗೆ ಬಳಸುವುದು ಎಂಬುದನ್ನು. ನೋಟ್ಬುಕ್ ಕೆಲವು ಫಂಕ್ಷನ್‌ಗಳನ್ನು ವ್ಯಾಖ್ಯಾನಿಸುತ್ತದೆ:

1. `tts_file_name(text)`: ಈ ಫಂಕ್ಷನ್ ಇನ್‌ಪುಟ್ ಪಠ್ಯದ ಆಧಾರದ ಮೇಲೆ ಉತ್ಪಾದಿತ ಆಡಿಯೋ ಫೈಲ್ ಅನ್ನು ಉಳಿಸಲು ಫೈಲ್ ಹೆಸರು ರಚಿಸುತ್ತದೆ.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: ಈ ಫಂಕ್ಷನ್ Edge TTS API ಅನ್ನು ಬಳಸಿಕೊಂಡು ಇನ್‌ಪುಟ್ ಪಠ್ಯದ ಚಂಕ್‌ಗಳ ಪಟ್ಟಿಯಿಂದ ಆಡಿಯೋ ಫೈಲ್ ಹೊರತರುತ್ತದೆ. ಇನ್‌ಪುಟ್ ಪರಿಮಾಣಗಳು ಚಂಕ್‌ಗಳ ಪಟ್ಟಿ, ಮಾತಿನ ವೇಗ, ಧ್ವನಿ ಹೆಸರು ಮತ್ತು ಉತ್ಪಾದಿತ ಆಡಿಯೋ ಫೈಲ್ ಉಳಿಸಲು ಔಟ್‌ಪುಟ್ ಪಥವುಗಳಾಗಿವೆ.
1. `talk(input_text)`: ಈ ಫಂಕ್ಷನ್ Edge TTS API ಬಳಸಿಕೊಂಡು ಆಡಿಯೋ ಫೈಲ್ ಸೃಷ್ಟಿಸಿ /content/audio ಡೈರೆಕ್ಟರಿಯಲ್ಲಿ ಒಂದು ರ್ಯಾಂಡಮ್ ಫೈಲ್ ಹೆಸರಿನಲ್ಲಿ ಉಳಿಸುತ್ತದೆ. ಇನ್‌ಪುಟ್ ಪ್ಯಾರಾಮೀಟರ್ ಪರಿವರ್ತಿಸಬೇಕಾದ ಪಠ್ಯವಾಗಿರುತ್ತದೆ.
1. `run_text_prompt(message, chat_history)`: ಈ ಫಂಕ್ಷನ್ Microsoft Phi 3 Mini 4K instruct ಡೆಮೊವನ್ನು ಬಳಸಿಕೊಂಡು ಸಂದೇಶ ಇನ್‌ಪುಟ್‌ನಿಂದ ಆಡಿಯೋ ಫೈಲ್ ರಚಿಸಿ ಅದನ್ನು ಚಾಟ್ ಇತಿಹಾಸಕ್ಕೆ ಸೇರಿಸುತ್ತದೆ.
1. `run_audio_prompt(audio, chat_history)`: ಈ ಫಂಕ್ಷನ್ Whisper model API ಬಳಸಿ ಆಡಿಯೋ ಫೈಲ್ ಅನ್ನು ಪಠ್ಯಕ್ಕೆ ಪರಿವರ್ತಿಸಿ ಅದನ್ನು `run_text_prompt()` ಫಂಕ್ಷನ್‌ಗೆ ಪಾಸ್ ಮಾಡುತ್ತದೆ.
1. ಕೋಡ್ Gradio ಅಪ್ ಅನ್ನು ಪ್ರಾರಂಭಿಸುತ್ತದೆ, ಇದು ಬಳಕೆದಾರರಿಗೆ ಸಂದೇಶಗಳನ್ನು ಹಾಕುವುದು ಅಥವಾ ಆಡಿಯೋ ಫೈಲ್‌ಗಳನ್ನು ಅಪ್ಲೋಡ್ ಮಾಡುವ ಮೂಲಕ Phi 3 Mini 4K instruct ಡೆಮೊ ಜೊತೆ ಪರಸ್ಪರ ಕ್ರಿಯೆ ನಡೆಸಲು ಅನುಮತಿಸುತ್ತದೆ. ಔಟ್‌ಪುಟ್ ಅಪ್ಲಿಕೇಶನ್ ಒಳಗೆ ಪಠ್ಯ ಸಂದೇಶವಾಗಿ ಪ್ರದರ್ಶಿಸಲಾಗುತ್ತದೆ.

## ಸಮಸ್ಯೆಗಳ ಪರಿಹಾರ

Installing Cuda GPU drivers

1. Ensure your Linux application are upto date

    ```bash
    sudo apt update
    ```

1. Cuda ಡ್ರೈವರ್‌ಗಳನ್ನು ಇನ್‌ಸ್ಟಾಲ್ ಮಾಡಿ

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. cuda ಡ್ರೈವರ್ ಸ್ಥಳವನ್ನು ನೋಂದಣಿ ಮಾಡಿ

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Nvidia GPU ಮೆಮೊರಿ ಗಾತ್ರವನ್ನು ಪರಿಶೀಲಿಸಿ (ಅಗತ್ಯ 12GB GPU ಮೆಮೊರಿ)

    ```bash
    nvidia-smi
    ```

1. ಕ್ಯಾಶೆ ಖಾಲಿ ಮಾಡಿ: ನೀವು PyTorch ಬಳಸುತ್ತಿದ್ದರೆ, torch.cuda.empty_cache() ಅನ್ನು ಕರೆದು ಎಲ್ಲಾ ಬಳಕೆಯಿಲ್ಲದ ಕ್ಯಾಶೆ ಮಾಡಿದ ಮೆಮೊರಿಯನ್ನು ಬಿಡುಗಡೆ ಮಾಡಬಹುದು, ώστε ಇವನ್ನು ಇತರ GPU ಅಪ್ಲಿಕೇಶನ್‌ಗಳು ಬಳಸಬಹುದಾಗಿದೆ

    ```python
    torch.cuda.empty_cache() 
    ```

1. Nvidia Cuda ಅನ್ನು ಪರಿಶೀಲಿಸುವುದು

    ```bash
    nvcc --version
    ```

1. Hugging Face ಟೋಕನ್ ರಚಿಸಲು ಕೆಳಗಿನ ಕಾರ್ಯಗಳನ್ನು ನಿರ್ವಹಿಸಿ.

    - Navigate to the [Hugging Face ಟೋಕನ್ ಸೆಟ್ಟಿಂಗ್ಸ್ ಪುಟ](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo).
    - **New token** ಅನ್ನು ಆಯ್ಕೆಮಾಡಿ.
    - ನೀವು ಬಳಸಲು ಬಯಸುವ ಪ್ರಾಜೆಕ್ಟ್ **Name** ಅನ್ನು ನಮೂದಿಸಿ.
    - **Type** ಅನ್ನು **Write** ಆಗಿ ಆಯ್ಕೆಮಾಡಿ.

> **ಗಮನಿಸಿ**
>
> ನೀವು ಕೆಳಗಿನ ದೋಷವನ್ನು ಕಂಡುಕೊಂಡಿದ್ದರೆ:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> ಇದನ್ನು ಪರಿಹರಿಸಲು, ನಿಮ್ಮ ಟರ್ಮಿನಲ್‌ನಲ್ಲಿ ಕೆಳಗಿನ ಕಮಾಂಡ್ ಅನ್ನು ಟೈಪ್ ಮಾಡಿ.
>
> ```bash
> sudo ldconfig
> ```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ನಿರಾಕರಣೆ:
ಈ ದಾಖಲೆ AI ಅನುವಾದ ಸೇವೆ Co-op Translator (https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯತ್ತ ಪ್ರಯತ್ನಿಸಿದರೂ ಸಹ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅಸೂತ್ಯತೆಗಳಿರಬಹುದೆಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿರಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿನ ಮೂಲ ದಾಖಲೆಯನ್ನು ಪ್ರಾಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಪ್ರಮುಖ ಮಾಹಿತಿಗಾಗಿ ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಗರ್ಭತೆಗಳು ಅಥವಾ ಪರಿಣಾಮಗಳಿಗಾಗಿ ನಾವು ಹೊಣೆಗಾರರಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->