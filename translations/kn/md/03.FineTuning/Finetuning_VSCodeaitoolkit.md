<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2bc0950f44919ac75a88c1a871680c2",
  "translation_date": "2025-12-21T18:20:17+00:00",
  "source_file": "md/03.FineTuning/Finetuning_VSCodeaitoolkit.md",
  "language_code": "kn"
}
-->
## VS Code ಗಾಗಿ AI Toolkit ಗೆ ಸ್ವಾಗತ

[AI Toolkit for VS Code](https://github.com/microsoft/vscode-ai-toolkit/tree/main) Azure AI Studio Catalog ಮತ್ತು Hugging Face ಮುಂತಾದ ಇತರ ಕ್ಯಾಟಲಾಗ್‌ಗಳಿಂದ ವಿವಿಧ ಮಾದರಿಗಳನ್ನು ಒಟ್ಟುಗೂಡುತ್ತದೆ. ಈ ಟೂಲ್‌ಕಿಟ್ ಜನರೇಟಿವ್ AI ಸಾಧನಗಳು ಮತ್ತು ಮಾದರಿಗಳ ಮೂಲಕ AI ಅಪ್ಲಿಕೇಶನ್‌ಗಳನ್ನು ನಿರ್ಮಿಸುವ ಸಾಮಾನ್ಯ ಅಭಿವೃದ್ಧಿ ಕಾರ್ಯಗಳನ್ನು ಸರಳಗೊಳಿಸುತ್ತದೆ:
- ಮಾದರಿ ಅನ್ವೇಷಣೆ ಮತ್ತು ಪ್ಲೇಗ್ರೌಂಡ್ ಮೂಲಕ ಪ್ರಾರಂಭಿಸಿ.
- ಸ್ಥಳೀಯ ಕಂಪ್ಯೂಟಿಂಗ್ ಸಂಪನ್ಮೂಲಗಳನ್ನು ಬಳಸಿ ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮತ್ತು ಇನ್ಫರೆನ್ಸ್.
- Azure ಸಂಪನ್ಮೂಲಗಳನ್ನು ಬಳಸಿ ದೂರಸ್ಥ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮತ್ತು ಇನ್ಫರೆನ್ಸ್

[Install AI Toolkit for VSCode](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

![AI Toolkit ಫೈನ್‌ಟ್ಯೂನಿಂಗ್](../../../../translated_images/Aitoolkit.7157953df04812dced01c8815a5a4d4b139e6640cc19b1c7adb4eea15b5403e6.kn.png)


**[ಪ್ರೈವೇಟ್ ಪ್ರಿವ್ಯೂ]** ಒಂದು ಕ್ಲಿಕ್‌ನಲ್ಲಿ ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮತ್ತು ಇನ್ಫರೆನ್ಸ್ ಅನ್ನು ಕ್ಲೌಡ್‌ನಲ್ಲಿ ನಡೆಯಿಸುವಂತೆ Azure Container Apps ಗಾಗಿ ಪ್ರಾವಿಷನಿಂಗ್.

ಈಗ ನಿಮ್ಮ AI ಅಪ್ಲಿಕೇಶನ್ ಅಭಿವೃದ್ಧಿಯಲ್ಲಿ ಮುಂದಾಗೋಣ:

- [VS Code ಗಾಗಿ AI Toolkit ಗೆ ಸ್ವಾಗತ](../../../../md/03.FineTuning)
- [ಸ್ಥಳೀಯ ಅಭಿವೃದ್ಧಿ](../../../../md/03.FineTuning)
  - [ತಯಾರಿಕೆಗಳು](../../../../md/03.FineTuning)
  - [Conda ಸಕ್ರಿಯಗೊಳಿಸಿ](../../../../md/03.FineTuning)
  - [ಮೂಲ ಮಾದರಿಯ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮಾತ್ರ](../../../../md/03.FineTuning)
  - [ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮತ್ತು ಇನ್ಫರೆನ್ಸಿಂಗ್](../../../../md/03.FineTuning)
  - [ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್](../../../../md/03.FineTuning)
  - [Microsoft Olive](../../../../md/03.FineTuning)
  - [ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮಾದರಿಗಳು ಮತ್ತು ಸಂಪನ್ಮೂಲಗಳು](../../../../md/03.FineTuning)
- [**\[ಪ್ರೈವೇಟ್ ಪ್ರಿವ್ಯೂ\]** ದೂರಸ್ಥ ಅಭಿವೃದ್ಧಿ](../../../../md/03.FineTuning)
  - [ಅಗತ್ಯತೆಗಳು](../../../../md/03.FineTuning)
  - [ದೂರಸ್ಥ ಅಭಿವೃದ್ಧಿ ಪ್ರಾಜೆಕ್ಟ್ ಸಜ್ಜುಗೊಳಿಸುವುದು](../../../../md/03.FineTuning)
  - [Azure ಸಂಪನ್ಮೂಲಗಳನ್ನು ಪ್ರೊವಿಷನ್ ಮಾಡುವುದು](../../../../md/03.FineTuning)
  - [\[Optional\] Huggingface ಟೋಕನ್ ಅನ್ನು Azure Container App Secret ಗೆ ಸೇರಿಸಿ](../../../../md/03.FineTuning)
  - [ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಚಾಲನೆ ಮಾಡಿ](../../../../md/03.FineTuning)
  - [ಇನ್ಫರೆನ್ಸ್ ಎಂಡ್ಪಾಯಿಂಟ್ ಅನ್ನು ಪ್ರೊವಿಷನ್ ಮಾಡಿ](../../../../md/03.FineTuning)
  - [ಇನ್ಫರೆನ್ಸ್ ಎಂಡ್ಪಾಯಿಂಟ್ ಅನ್ನು ಡಿಪ್ಲಾಯ್ ಮಾಡಿ](../../../../md/03.FineTuning)
  - [ಉನ್ನತ ಬಳಕೆ](../../../../md/03.FineTuning)

## ಸ್ಥಳೀಯ ಅಭಿವೃದ್ಧಿ
### ತಯಾರಿಕೆಗಳು

1. ಹೋಸ್ಟ್‌ನಲ್ಲಿ NVIDIA ಡ್ರೈವರ್ ಸ್ಥಾಪಿತವಾಗಿದೆ ಎಂಬುದನ್ನು ಖಚಿತಪಡಿಸಿಕೊಳ್ಳಿ.
2. HFನ್ನು ಡೇಟಾಸೆಟ್ ಬಳಕೆಗೆ ಬಳಸುತ್ತಿದ್ದಲ್ಲಿ `huggingface-cli login` ಅನ್ನು ರನ್ ಮಾಡಿ.
3. `Olive` ಕೀ ಸೆಟ್ಟಿಂಗ್‌ಗಳು ಮೆಮೊರಿ ಬಳಕೆಯನ್ನು ಬದಲಾಯಿಸುವ ಯಾವುದೇ ಸೆಟ್ಟಿಂಗ್‌ಗಳ ವಿವರಣೆಗಳನ್ನು ಹೊಂದಿವೆ.

### Conda ಸಕ್ರಿಯಗೊಳಿಸಿ
ನಾವು WSL ಪರಿಸರವನ್ನು ಬಳಸುತ್ತಿದ್ದ ಕಾರಣ ಮತ್ತು ಅದು ಹಂಚಲ್ಪಟ್ಟಿದ್ದು, ನೀವು Conda ಪರಿಸರವನ್ನು ಕೈಯಿಂದ ಸಕ್ರಿಯಗೊಳಿಸುವ ಅಗತ್ಯವಿದೆ. ಈ ಹಂತದ ನಂತರ ನೀವು ಫೈನ್‌ಟ್ಯೂನಿಂಗ್ ಅಥವಾ ಇನ್ಫರೆನ್ಸ್ ಅನ್ನು ರನ್ ಮಾಡಬಹುದು.

```bash
conda activate [conda-env-name] 
```

### ಮೂಲ ಮಾದರಿಯ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮಾತ್ರ
Conda ಸಕ್ರಿಯಗೊಳಿಸಿದ ನಂತರ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮಾಡದೆ ಮಾತ್ರ ಮೂಲ ಮಾದರಿಯನ್ನು ಪ್ರಯತ್ನಿಸಲು ಈ ಕಮಾಂಡ್ ಅನ್ನು ರನ್ ಮಾಡಬಹುದು.

```bash
cd inference

# ವೆಬ್ ಬ್ರೌಸರ್ ಇಂಟರ್ಫೇಸ್ ಗರಿಷ್ಠ ಹೊಸ ಟೋಕನ್ ಉದ್ದ, ತಾಪಮಾನ ಮತ್ತು ಇತ್ಯಾದಿ ಕೆಲವು ಪ್ಯಾರಾಮೀಟರ್‌ಗಳನ್ನು ಹೊಂದಿಸಲು ಅವಕಾಶ ನೀಡುತ್ತದೆ.
# gradio ಸಂಪರ್ಕಗಳನ್ನು ಸ್ಥಾಪಿಸಿದ ನಂತರ ಬಳಕೆದಾರನು ಲಿಂಕ್ (ಉದಾ. http://0.0.0.0:7860) ಅನ್ನು ಬ್ರೌಸರ್‌ನಲ್ಲಿ ಕೈಯಿಂದ ತೆರೆಯಬೇಕು.
python gradio_chat.py --baseonly
```

### ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಮತ್ತು ಇನ್ಫರೆನ್ಸಿಂಗ್

ಒಮ್ಮೆ ವರ್ಕ್‌ಸ್ಪೇಸ್ ಅನ್ನು ಡೆವ್ ಕಂಟೈನರ್‌ನಲ್ಲಿ ತೆರೆಯಲಾಗಿದ್ದರೆ, ಟರ್ಮಿನಲ್ ತೆರೆಯಿರಿ (ಡೀಫಾಲ್ಟ್ ಪಾಥ್ ಪ್ರಾಜೆಕ್ಟ್ ರೂಟ್ ಆಗಿದೆ), ನಂತರ ಆಯ್ಕೆಮಾಡಿದ ಡೇಟಾಸೆಟ್ ಮೇಲೆ LLM ಅನ್ನು ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡಲು ಕೆಳಗಿನ ಕಮಾಂಡ್ ಅನ್ನು ರನ್ ಮಾಡಿ.

```bash
python finetuning/invoke_olive.py 
```

ಚೆಕ್ಪಾಯಿಂಟ್‌ಗಳು ಮತ್ತು ಅಂತಿಮ ಮಾದರಿ `models` ಫೋಲ್ಡರ್‌ನಲ್ಲಿ ಸಂರಕ್ಷಿಸಲಾಗುತ್ತವೆ.

ನಂತರ ಚಾಟ್‌ಗಳ ಮೂಲಕ ಫೈನ್-ಟ್ಯೂನಿಸಿದ ಮಾದರಿಯೊಂದಿಗೆ `console`, `web browser` ಅಥವಾ `prompt flow` ನಲ್ಲಿ ಇನ್ಫರೆನ್ಸಿಂಗ್ ನಡೆಸಿ.

```bash
cd inference

# ಕನ್ಸೋಲ್ ಇಂಟರ್ಫೇಸ್.
python console_chat.py

# ವೆಬ್ ಬ್ರೌಸರ್ ಇಂಟರ್ಫೇಸ್ ಗರಿಷ್ಠ ಹೊಸ ಟೋಕನ್ ಉದ್ದ, ಟೆಂಪರೆಚರ್ ಮತ್ತು ಇತ್ಯಾದಿ ಕೆಲವು ಪ್ಯಾರಾಮೀಟರ್ಗಳನ್ನು ಹೊಂದಾಣಿಕೆ ಮಾಡಲು ಅನುಮತಿಸುತ್ತದೆ.
# ಬಳಕೆದಾರರು gradio ಸಂಪರ್ಕಗಳನ್ನು ಸ್ಥಾಪಿಸಿದ ನಂತರ ಬ್ರೌಸರ್‌ನಲ್ಲಿ ಲಿಂಕ್ (ಉದಾ.: http://127.0.0.1:7860) ಅನ್ನು ಕೈಯಿಂದ ತೆರೆಯಬೇಕು.
python gradio_chat.py
```

VS Code ನಲ್ಲಿ `prompt flow` ಅನ್ನು ಬಳಸಲು, ದಯವಿಟ್ಟು ಈ [ಕ್ವಿಕ್ ಸ್ಟಾರ್ಟ್](https://microsoft.github.io/promptflow/how-to-guides/quick-start.html) ಅನ್ನು ನೋಡಿ.

### ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್

ಮುಂದೆ, ನಿಮ್ಮ ಡಿವೈಸ್‌ನಲ್ಲಿ GPU ಲಭ್ಯತೆ ಆಧರಿಸಿ ಕೆಳಗಿನ ಮಾದರಿಯನ್ನು ಡೌನ್ಲೋಡ್ ಮಾಡಿ.

QLoRA ಬಳಸಿ ಸ್ಥಳೀಯ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಸತ್ರವನ್ನು ಪ್ರಾರಂಭಿಸಲು, ನಮ್ಮ ಕ್ಯಾಟಲೋಗ್‌ನಿಂದ ನೀವು ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡಲು ಬಯಸುವ ಮಾದರಿಯನ್ನು ಆಯ್ಕೆಮಾಡಿ.
| Platform(s) | GPU ಲಭ್ಯತೆ | Model name | ಗಾತ್ರ (GB) |
|---------|---------|--------|--------|
| Windows | ಹೌದು | Phi-3-mini-4k-**directml**-int4-awq-block-128-onnx | 2.13GB |
| Linux | ಹೌದು | Phi-3-mini-4k-**cuda**-int4-onnx | 2.30GB |
| Windows<br>Linux | ಇಲ್ಲ | Phi-3-mini-4k-**cpu**-int4-rtn-block-32-acc-level-4-onnx | 2.72GB |

**_ಗಮನಿಸಿ_** ನಿಮಗೆ ಮಾದರಿಗಳನ್ನು ಡೌನ್ಲೋಡ್ ಮಾಡಲು Azure ಖಾತೆ ಅಗತ್ಯವಿಲ್ಲ

Phi3-mini (int4) ಮಾದರಿಯ ಗಾತ್ರವು ಸುಮಾರು 2GB–3GB ಇರುತ್ತದೆ. ನಿಮ್ಮ ನೆಟ್‌ವರ್ಕ್ ವೇಗದ ಮೇಲೆ ಅವಲಂಬಿಸಿ, ಡೌನ್ಲೋಡ್ ಮಾಡಲು ಕೆಲವು ನಿಮಿಷಗಳು ಬೇಕಾಗಬಹುದು.

ಪ್ರಾಜೆಕ್ಟ್ ಹೆಸರು ಮತ್ತು ಸ್ಥಳವನ್ನು ಆಯ್ಕೆಮಾಡುವುದರಿಂದ ಪ್ರಾರಂಭಿಸಿ.
ಮುಂದೆ, ಮಾದರಿ ಕ್ಯಾಟಲೋಗ್‌ನಿಂದ ಒಂದು ಮಾದರಿಯನ್ನು ಆಯ್ಕೆಮಾಡಿ. ನಿಮಗೆ ಪ್ರಾಜೆಕ್ಟ್ ಟೆಂಪ್ಲೇಟನ್ನು ಡೌನ್ಲೋಡ್ ಮಾಡಲು ಪ್ರಾಂಪ್ಟ್ ಆಗುತ್ತದೆ. ನಂತರ "Configure Project" ಕ್ಲಿಕ್ ಮಾಡಿ ವಿವಿಧ ಸೆಟ್ಟಿಂಗ್‌ಗಳನ್ನು ಹೊಂದಿಸಬಹುದು.

### Microsoft Olive 

ನಾವು ನಮ್ಮ ಕ್ಯಾಟಲಾಗ್‌ನ PyTorch ಮಾದರಿಯ ಮೇಲೆ QLoRA ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ನಡಿಸಲು [Olive](https://microsoft.github.io/Olive/why-olive.html) ಅನ್ನು ಬಳಸುತ್ತೇವೆ. ಎಲ್ಲ ಸೆಟ್ಟಿಂಗ್‌ಗಳು ಮೆಮೊರಿ ಬಳಕೆಯನ್ನು 최적ಗೊಳಿಸಲು ಡೀಫಾಲ್ಟ್ ಮೌಲ್ಯಗಳೊಂದಿಗೆ ಪೂರ್ವನಿಯೋಜಿತವಾಗಿವೆ, ಆದರೆ ನಿಮ್ಮ ಪರಿಸ್ಥಿತಿಗೆ ಅನುಗುಣವಾಗಿ ಅವುಗಳನ್ನು ಹೊಂದಿಸಬಹುದು.

### ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಉದಾಹರಣೆಗಳು ಮತ್ತು ಸಂಪನ್ಮೂಲಗಳು

- [ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪ್ರಾರಂಭಿಸುವ ಮಾರ್ಗದರ್ಶಿ](https://learn.microsoft.com/windows/ai/toolkit/toolkit-fine-tune)
- [HuggingFace Dataset ಸಹಿತ ಫೈನ್-ಟ್ಯೂನಿಂಗ್](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/walkthrough-hf-dataset.md)
- [ಸರಳ DataSet ಸಹಿತ ಫೈನ್-ಟ್ಯೂನಿಂಗ್](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/walkthrough-simple-dataset.md)

## **[ಪ್ರೈವೇಟ್ ಪ್ರಿವ್ಯೂ]** ದೂರಸ್ಥ ಅಭಿವೃದ್ಧಿ

### ಅಗತ್ಯತೆಗಳು

1. ನೀವು ದೂರಸ್ಥ Azure Container App ಪರಿಸರದಲ್ಲಿ ಮಾದರಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ನಡೆಸಲು ಬಯಸಿದರೆ, ನಿಮ್ಮ ಚಂದಾದಾರಿಕೆಯಲ್ಲಿ ಸಾಕಷ್ಟು GPU ಸಾಮರ್ಥ್ಯ ಹೊಂದಿರುವುದನ್ನು ಖಚಿತಪಡಿಸಿಕೊಳ್ಳಿ. ನಿಮ್ಮ ಅಪ್ಲಿಕೇಶನ್‌ಗೆ ಅಗತ್ಯವಾಗುವ ಸಾಮರ್ಥ್ಯವನ್ನು ವಿನಂತಿಸಲು [support ticket](https://azure.microsoft.com/support/create-ticket/) ಸಲ್ಲಿಸಿ. [GPU ಸಾಮರ್ಥ್ಯ ಕುರಿತು ಹೆಚ್ಚಿನ ಮಾಹಿತಿಗಾಗಿ](https://learn.microsoft.com/azure/container-apps/workload-profiles-overview) ನೋಡಿ.
2. ನೀವು HuggingFace ನಲ್ಲಿ ಖಾಸಗಿ ಡೇಟಾಸೆಟ್ ಬಳಸುತ್ತಿದ್ದರೆ, [HuggingFace account](https://huggingface.co/?WT.mc_id=aiml-137032-kinfeylo) ಹೊಂದಿರುವುದನ್ನು ಮತ್ತು ಪ್ರವೇಶ ಟೋಕನ್ ಅನ್ನು [ರಚಿಸಿರುವಿರಲುವಂತೆ](https://huggingface.co/docs/hub/security-tokens?WT.mc_id=aiml-137032-kinfeylo) ಖಚಿತಪಡಿಸಿಕೊಳ್ಳಿ.
3. VS Code ಗಾಗಿ AI Toolkit ನಲ್ಲಿ Remote Fine-tuning ಮತ್ತು Inference ಫೀಚರ್ ಫ್ಲ್ಯಾಗ್ ಅನ್ನು ಸಕ್ರಿಯಗೊಳಿಸಿ
   1. *File -> Preferences -> Settings* ಆಯ್ಕೆಮಾಡಿ VS Code ಸೆಟ್ಟಿಂಗ್‌ಗಳನ್ನು ತೆರೆಯಿರಿ.
   2. *Extensions* ಗೆ ನ್ಯಾವಿಗೇಟ್ ಮಾಡಿ ಮತ್ತು *AI Toolkit* ಆಯ್ಕೆಮಾಡಿ.
   3. *"Enable Remote Fine-tuning And Inference"* ಆಯ್ಕೆಯನ್ನು ಆಯ್ಕೆಮಾಡಿ.
   4. ಪರಿಣಾಮಕಾರಿಯಾಗಲು VS Code ಅನ್ನು ರಿಲೋಡ್ ಮಾಡಿ.

- [ದೂರಸ್ಥ ಫೈನ್ ಟ್ಯೂನಿಂಗ್](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/remote-finetuning.md)

### ದೂರಸ್ಥ ಡೆವಲಪ್‌ಮೆಂಟ್ ಪ್ರಾಜೆಕ್ಟ್ ಸೆಟ್‌ಅಪ್
1. ಕಮಾಂಡ್ ಪ್ಯಾಲೆಟ್‌ನಲ್ಲಿ `AI Toolkit: Focus on Resource View` ಅನ್ನು ಕಾರ್ಯಗತಗೊಳಿಸಿ.
2. ಮಾದರಿ ಕ್ಯಾಟಲოგ್ ಪ್ರವೇಶಿಸಲು *Model Fine-tuning* ಗೆ ನ್ಯಾವಿಗೇಟ್ ಮಾಡಿ. ನಿಮ್ಮ ಪ್ರಾಜೆಕ್ಟ್‌ಗೆ ಹೆಸರು ಒದಗಿಸಿ ಮತ್ತು ನಿಮ್ಮ ಯಂತ್ರದ ಮೇಲೆ ಸ್ಥಳ ಆಯ್ಕೆಮಾಡಿ. ನಂತರ *"Configure Project"* ಬಟನ್ ಕ್ಲಿಕ್ ಮಾಡಿ.
3. ಪ್ರಾಜೆಕ್ಟ್ ಕಾನ್ಫಿಗರೇಶನ್
    1. *"Fine-tune locally"* ಆಯ್ಕೆಯನ್ನು ಸಕ್ರಿಯಗೊಳಿಸಲು Telangana.
    2. Olive ಕಾನ್ಫಿಗರೇಶನ್ ಸೆಟ್ಟಿಂಗ್‌ಗಳು ಪೂರ್ವನಿಯೋಜಿತ ಡೀಫಾಲ್ಟ್ ಮೌಲ್ಯಗಳೊಂದಿಗೆ ತೋರಿಸಲಾಗುತ್ತದೆ. ಅಗತ್ಯವಿರುವಂತೆ ಈ ಕಾನ್ಫಿಗರೇಶನ್‌ಗಳನ್ನು ಹೊಂದಿಸಿ ಮತ್ತು ಭರ್ತಿ ಮಾಡಿ.
    3. *Generate Project* ڏಕ್ಕೆ ಮುಂದುವರಿಯಿರಿ. ಈ ಹಂತ WSL ಅನ್ನು ಉಪಯೋಗಿಸುತ್ತದೆ ಮತ್ತು ಹೊಸ Conda ಪರಿಸರವನ್ನು ಹೊಂದಿಸುವ ಪ್ರಕ್ರಿಯೆಯನ್ನು ಒಳಗೊಂಡಿದೆ, ಭವಿಷ್ಯದ Dev Containers ಅಪ್ಡೇಟ್ಗಳಿಗಾಗಿ ಸಿದ್ಧಪಡಿಸುತ್ತದೆ.
4. ನಿಮ್ಮ ದೂರಸ್ಥ ಅಭಿವೃದ್ಧಿ ಪ್ರಾಜೆಕ್ಟ್ ತೆರೆಯಲು *"Relaunch Window In Workspace"* ಕ್ಲಿಕ್ ಮಾಡಿ.

> **ಗಮನಿಸಿ:** ಪ್ರಾಜೆಕ್ಟ್ ಪ್ರಸ್ತುತ AI Toolkit for VS Code ಒಳಗೆ either ಸ್ಥಳೀಯವಾಗಿಯೇ ಅಥವಾ ದೂರಸ್ಥವಾಗಿ ಮಾತ್ರ ಕೆಲಸ ಮಾಡುತ್ತದೆ. ಪ್ರಾಜೆಕ್ಟ್ ರಚನೆಯ ಸಂದರ್ಭದಲ್ಲಿ ನೀವು *"Fine-tune locally"* ಆಯ್ಕೆಯನ್ನು ಆಯ್ಕೆಮಾಡಿದರೆ, ಇದು WSL ನಲ್ಲಿ ಮಾತ್ರ ನಡುತ್ತದೆ ಮತ್ತು ದೂರಸ್ಥ ಡೆವಲಪ್‌ಮೆಂಟ್ ಸಾಮರ್ಥ್ಯಗಳು ಇರುತ್ತವೆ. ಹೊರತಾಗಿ, ನೀವು *"Fine-tune locally"* ಅನ್ನು ಸಕ್ರಿಯಗೊಳಿಸದಿದ್ದರೆ, ಪ್ರಾಜೆಕ್ಟ್ Azure Container App ದೂರಸ್ಥ ಪರಿಸರಕ್ಕೆ ಸೀಮಿತವಾಗಿರುತ್ತದೆ.

### Azure ಸಂಪನ್ಮೂಲಗಳನ್ನು ಪ್ರೊವಿಷನ್ ಮಾಡುವುದು
ಆರಂಭಿಸಲು, ದೂರಸ್ಥ ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ Azure ಸಂಪನ್ಮೂಲಗಳನ್ನು ಪ್ರೊವಿಷನ್ ಮಾಡಬೇಕು. ಇದನ್ನು ಕಮಾಂಡ್ ಪ್ಯಾಲೆಟ್ ನಲ್ಲಿ `AI Toolkit: Provision Azure Container Apps job for fine-tuning` ಅನ್ನು ರನ್ ಮಾಡುವ ಮೂಲಕ ಮಾಡಿ.

ಪ್ರೊವಿಷನಿಂಗ್ ಪ್ರಗತಿಯನ್ನು output ಚಾನೆಲ್‌ನಲ್ಲಿ ತೋರಿಸಲಾಗುವ ಲಿಂಕ್ ಮೂಲಕ ಮೇಲ್ವಿಚಾರಣೆ ಮಾಡಿ.

### [Optional] Huggingface Token ಅನ್ನು Azure Container App Secret ಗೆ ಸೇರಿಸಿ
ನೀವು ಖಾಸಗಿ HuggingFace ಡೇಟಾಸೆಟ್ ಬಳಸುತ್ತಿದ್ದರೆ, HuggingFace ಹಬ್‌ನಲ್ಲಿ ಕೈಯಿಂದ ಲಾಗಿನ್ ಮಾಡಬೇಕಾಗದಂತೆ ನಿಮ್ಮ HuggingFace ಟೋಕನ್ ಅನ್ನು ಪರಿಸರ ಚರ as environment variable ಆಗಿ ಸೆಟ್ ಮಾಡಿ.
ಇದನ್ನು `AI Toolkit: Add Azure Container Apps Job secret for fine-tuning` ಕಮಾಂಡ್ ಬಳಸಿ ಮಾಡುವಿರಿ. ಈ ಕಮಾಂಡ್ ಮೂಲಕ, ಸೀಕ್ರೆಟ್ ಹೆಸರನ್ನು [`HF_TOKEN`](https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hftoken) ಎಂದು ನಿಗದಿಪಡಿಸಿ ಮತ್ತು ನಿಮ್ಮ Hugging Face ಟೋಕನ್ ಅನ್ನು ಸೀಕ್ರೆಟ್ ಮೌಲ್ಯವಾಗಿ ಬಳಸಿ.

### ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಚಾಲನೆ ಮಾಡಿ
ದೂರಸ್ಥ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಕೆಲಸವನ್ನು ಪ್ರಾರಂಭಿಸಲು `AI Toolkit: Run fine-tuning` ಕಮಾಂಡ್ ಅನ್ನು ಕಾರ್ಯಗತಗೊಳಿಸಿ.

ಸಿಸ್ಟಂ ಮತ್ತು ಕನ್‌ಸೋಲ್ ಲಾಗ್‌ಗಳನ್ನು ನೋಡಲು, output ಪ್ಯಾನೆಲ್ನಲ್ಲಿರುವ ಲಿಂಕ್ ಮೂಲಕ Azure ಪೋರ್ಟಲ್ ಅನ್ನು ತೆರೆಯಬಹುದು (ಹೆಚ್ಚು ಸೂಚನೆಗಳಿಗಾಗಿ [View and Query Logs on Azure](https://aka.ms/ai-toolkit/remote-provision#view-and-query-logs-on-azure) ನೋಡಿ). ಅಥವಾ, `AI Toolkit: Show the running fine-tuning job streaming logs` ಕಮಾಂಡ್ ಅನ್ನು ರನ್ ಮಾಡುವ ಮೂಲಕ VSCode output ಪ್ಯಾನೆಲ್ನಲ್ಲಿ ನೇರವಾಗಿ ಕನ್‌ಸೋಲ್ ಲಾಗ್‌ಗಳನ್ನು ವೀಕ್ಷಿಸಬಹುದು.
> **ಗಮನಿಸಿ:** ಸಂಪನ್ಮೂಲಗಳ ಕೊರತೆಯಿಂದ ಕೆಲಸ ಸಾಲಿನಲ್ಲಿ ಇರಬಹುದು. ಲಾಗ್ ತೋರಿಸದಿದ್ದರೆ, `AI Toolkit: Show the running fine-tuning job streaming logs` ಕಮಾಂಡ್ ಅನ್ನು ಕಾರ್ಯಗತಗೊಳಿಸಿ, ಸ್ವಲ್ಪ ಸಮಯ ಕಾಯಿರಿ ಮತ್ತು ತದನಂತರ ಪುನಃ ಸ್ಟ್ರೀಮಿಂಗ್ ಲಾಗ್‌ಗೆ ಮರು-ಕನೆಕ್ಟ್ ಮಾಡಲು ಆ ಕಮಾಂಡ್ ಅನ್ನು ಮತ್ತೆ ಕಾರ್ಯಗತಗೊಳಿಸಿ.

ಈ ಪ್ರಕ್ರಿಯೆಯ ವೇಳೆ QLoRA ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ಗೆ ಬಳಸಲಾಗುತ್ತದೆ ಮತ್ತು ಇನ್ಫರೆನ್ಸ್ ಸಮಯದಲ್ಲಿ ಮಾದರಿ ಬಳಸಲು LoRA ಅಡಾಪ್ಟರ್‌ಗಳು ರಚಿಸಲ್ಪಡುತ್ತವೆ.
ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಫಲಿತಾಂಶಗಳು Azure Files ನಲ್ಲಿ ಸಂರಕ್ಷಿಸಲ್ಪಡುತ್ತವೆ.

### ಇನ್ಫರೆನ್ಸ್ ಎಂಡ್ಪಾಯಿಂಟ್ ಅನ್ನು ಪ್ರೊವಿಷನ್ ಮಾಡಿ
ಅಡಾಪ್ಟರ್‌ಗಳು ದೂರಸ್ಥ ಪರಿಸರದಲ್ಲಿ ತರಬೇತಿ ಪಡೆದ ನಂತರ, ಮಾದರಿಯೊಂದಿಗೆ ಸಂವಹನ ಮಾಡಲು ಸರಳ Gradio ಅಪ್ಲಿಕೇಶನ್ ಬಳಸಿರಿ.
ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಪ್ರಕ್ರಿಯೆಯಂತೆ, ದೂರಸ್ಥ ಇನ್ಫರೆನ್ಸಿಗಾಗಿ Azure ಸಂಪನ್ಮೂಲಗಳನ್ನು ಸೆಟ್ ಅಪ್ ಮಾಡಲು ಕಮಾಂಡ್ ಪ್ಯಾಲೆಟ್‌ನಲ್ಲಿ `AI Toolkit: Provision Azure Container Apps for inference` ಅನ್ನು ಕಾರ್ಯಗತಗೊಳಿಸಬೇಕು.

ಡೆಫಾಲ್ಟ್ ಆಗಿ, ಸಬ್ಸ್ಕ್ರಿಪ್ಶನ್ ಮತ್ತು ರಿಸೋರ್ಸ್ ಗ್ರೂಪ್ ಫೈನ್-ಟ್ಯೂನಿಂಗ್‌ನಲ್ಲಿ ಉಪಯೋಗಿಸಲಾದವುಗಳೊಂದಿಗೆ ಸಮನಾಗಿ ಇರಬೇಕು. ಇನ್ಫರೆನ್ಸ್ ಅದೇ Azure Container App Environment ಅನ್ನು ಉಪಯೋಗಿಸಿ ಫೈನ್-ಟ್ಯೂನಿಂಗ್ ಹಂತದಲ್ಲಿ Azure Files ನಲ್ಲಿ ಸಂಗ್ರಹಿಸಲಾದ ಮಾದರಿ ಮತ್ತು ಮಾದರಿ ಅಡಾಪ್ಟರ್‌ಗಳಿಗೆ ಪ್ರವೇಶ ಪಡೆಯುತ್ತದೆ.

### ಇನ್ಫರೆನ್ಸ್ ಎಂಡ್ಪಾಯಿಂಟ್ ಅನ್ನು ಡಿಪ್ಲಾಯ್ ಮಾಡಿ
ಇನ್ಫರೆನ್ಸ್ ಕೋಡ್ ಅನ್ನು ಪರಿಶೀಲಿಸಲು ಅಥವಾ ಇನ್ಫರೆನ್ಸ್ ಮಾದರಿಯನ್ನು ಮರುಲೋಡ್ ಮಾಡಲು ಬಯಸಿದರೆ, ದಯವಿಟ್ಟು `AI Toolkit: Deploy for inference` ಕಮಾಂಡ್ ಅನ್ನು ಕಾರ್ಯಗತಗೊಳಿಸಿ. ಇದು ನಿಮಗೆ 최신 ಕೋಡ್ ಅನ್ನು Azure Container App ಜೊತೆಗೆ synchronization ಮಾಡಿ ರೆಪ್ಲಿಕಾವನ್ನು ಮರುಪ್ರಾರಂಭ ಮಾಡುತ್ತದೆ.

ಒಮ್ಮೆ ಡಿಪ್ಲಾಯ್ಮೆಂಟ್ ಯಶಸ್ವಿಯಾಗಿ ಪೂರ್ಣಗೊಂಡ ನಂತರ, VSCode ಸೂಚನೆಯಲ್ಲಿ ತೋರಿಸ leti olan "*Go to Inference Endpoint*" ಬಟನ್ ಕ್ಲಿಕ್ ಮಾಡುವ ಮೂಲಕ ನೀವು ಇನ್ಫರೆನ್ಸ್ API ಗೆ ಪ್ರವೇಶಿಸಬಹುದು. ಅಥವಾ, ವೆಬ್ API ಎಂಡ್ಪಾಯಿಂಟ್ ಅನ್ನು `ACA_APP_ENDPOINT` ಗೆ ಒಳಗೊಂಡ `./infra/inference.config.json` ಮತ್ತು output ಪ್ಯಾನೆಲ್‌ನಲ್ಲಿ ನೋಡಬಹುದು. ನೀವು ಈಗ ಈ ಎಂಡ್ಪಾಯಿಂಟ್ ಬಳಸಿ ಮಾದರಿಯನ್ನು ಮೌಲ್ಯಮಾಪನ ಮಾಡಲು ಸಜ್ಜಾಗಿದ್ದೀರಿ.

### ಉನ್ನತ ಬಳಕೆ
AI Toolkit ಮೂಲಕ ದೂರಸ್ಥ ಅಭಿವೃದ್ಧಿ ಬಗ್ಗೆ ಹೆಚ್ಚಿನ ಮಾಹಿತಿಗಾಗಿ, [ದೂರಸ್ಥವಾಗಿ ಮಾದರಿಗಳನ್ನು ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡುವುದು](https://aka.ms/ai-toolkit/remote-provision) ಮತ್ತು [ಫೈನ್-ಟ್ಯೂನ್ ಮಾಡಿದ ಮಾದರಿಯೊಂದಿಗೆ ಇನ್ಫರೆನ್ಸಿಂಗ್](https://aka.ms/ai-toolkit/remote-inference) ಡಾಕ್ಯುಮೆಂಟೇಷನ್‌ಗಳನ್ನು ನೋಡಿ.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ನಿರಾಕರಣೆ:
ಈ ದಸ್ತಾವೇಜನ್ನು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಮೂಲಕ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಗೆ ಪ್ರಯತ್ನಿಸಿದರೂ ಸಹ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅಸ್ಪಷ್ಟತೆಗಳಿರುವ ಸಾಧ್ಯತೆ ಇದೆ ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಗಂಭೀರ ಮಾಹಿತಿಗಾಗಿ ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗಿದೆ. ಈ ಅನುವಾದವನ್ನು ಬಳಕೆ ಮಾಡುತ್ತಿರುವರಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ಗೊಂದಲಗಳು ಅಥವಾ ತಪ್ಪು ಅರ್ಥಗಳ ಸಂಬಂಧವಾಗಿ ನಾವು ಹೊಣೆಗಾರರಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->