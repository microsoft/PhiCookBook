<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-12-22T00:09:39+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "kn"
}
-->
## NVIDIA NIM ನಲ್ಲಿ Phi ಕುಟುಂಬ

NVIDIA NIM_cloud, ಡೇಟಾ ಸೆಂಟರ್ ಮತ್ತು ವರ್ಕ್‌ಸ್ಟೇಷನ್‌ಗಳಲ್ಲಿ ಜನರೇಟಿವ್ AI ಮಾದರಿಗಳ ನಿಯೋಜನೆಯನ್ನು ವೇಗಗೊಳಿಸಲು ವಿನ್ಯಾಸಗೊಳಿಸಿದ ಸುಲಭವಾಗಿ ಬಳಸಬಹುದಾದ ಮೈಕ್ರೋಸರ್ವಿಸেসಿನ ಒಂದು ಸಂಗ್ರಹವಾಗಿದೆ. NIM ಗಳನ್ನು ಮಾದರಿ ಕುಟುಂಬ ಹಾಗೂ ಪ್ರತಿ ಮಾದರಿ ಆಧಾರದ ಮೇಲೆ ವರ್ಗೀಕರಿಸಲಾಗುತ್ತದೆ. ಉದಾಹರಣೆಗೆ, ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿಗಳು (LLMs)ಗಾಗಿ NVIDIA NIM ಸಂಸ್ಥಾ ಅನ್ವಯಗಳಲ್ಲಿ ಅತ್ಯಾಧುನಿಕ LLMಗಳ ಶಕ್ತಿ ಆಯ್ದು, ನಿರ್ವಿಚಾರյուն ನೈಸರ್ಗಿಕ ಭಾಷಾ ಪ್ರಕ್ರಿಯೆ ಮತ್ತು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವ ಸಾಮರ್ಥ್ಯಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ.

NIM IT ಮತ್ತು DevOps ತಂಡಗಳಿಗೆ ತಮ್ಮ ನಿರ್ವಹಿತ ಪರಿಸರಗಳಲ್ಲಿ ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿ (LLMs)ಗಳನ್ನು ಸ್ವಯಂ-ಹೋಸ್ಟ್ ಮಾಡಲು ಸುಲಭವಾಗುವಂತೆ ಮಾಡುತ್ತದೆ ಮತ್ತು ಜೊತೆಗೆ ಡೆವಲಪರ್‌ಗಳಿಗೆ ಕೈಗಾರಿಕಾ ಪ್ರಮಾಣದ APIಗಳನ್ನು ಒದಗಿಸುತ್ತವೆ, ಅವುಗಳು ಶಕ್ತಿಶಾಲಿ ಕಾಪೈಲಟ್ಗಳು, ಚಾಟ್‌ಬಾಟ್‌ಗಳು ಮತ್ತು ಅವರ ವ್ಯಾಪಾರವನ್ನು ಪರಿಗಳಿಸುವ AI ಸಹಾಯಕರನ್ನು ನಿರ್ಮಿಸಲು ಅವಕಾಶ ಮಾಡಿಕೊಡುತ್ತವೆ. NVIDIA ಯ ಅಗ್ರಗಣ್ಯ GPU ತ್ವರಕ ಮತ್ತು ಸ್ಕೇಲಬಲ್ ನಿಯೋಜನೆ ಉಪಯೋಗಿಸಿ, NIM ಅತೀ ವೇಗದ ಇನ್‌ಫರೆನ್ಸ್ ಪಥವನ್ನು ಅಪ್ರತಿಮ ಕಾರ್ಯಕ್ಷಮತೆಯೊಂದಿಗೆ ಒದಗಿಸುತ್ತದೆ.

You can use NIVIDIA NIM to inference Phi Family Models

![nim](../../../../../translated_images/Phi-NIM.09bebb743387ee4a.kn.png)

### **ಉದಾಹರಣೆಗಳು - NVIDIA NIM ನಲ್ಲಿ Phi-3-Vision**


Imagine you have an image (`demo.png`) and you want to generate Python code that processes this image and saves a new version of it (`phi-3-vision.jpg`). 

The code above automates this process by:

1. Setting up the environment and necessary configurations.
2. Creating a prompt that instructs the model to generate the required Python code.
3. Sending the prompt to the model and collecting the generated code.
4. Extracting and running the generated code.
5. Displaying the original and processed images.

This approach leverages the power of AI to automate image processing tasks, making it easier and faster to achieve your goals. 

[ಉದಾಹರಣೆ ಕೋಡ್ ಪರಿಹಾರ](../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

Let's break down what the entire code does step by step:

1. **ಆವಶ್ಯಕ ಪ್ಯಾಕೇಜ್ ಅನ್ನು ಸ್ಥಾಪಿಸಿ**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    ಈ ಕಮಾಂಡ್ `langchain_nvidia_ai_endpoints` ಪ್ಯಾಕೇಜ್ ಅನ್ನು ಸ್ಥಾಪಿಸುತ್ತದೆ ಮತ್ತು ಅದು ಹೊಸತೇ ಆದ ಆವೃತ್ತಿ ಆಗಿ ಸಾಂಕೇತಿಕವಾಗಿ ಖಚಿತಪಡಿಸುತ್ತದೆ.

2. **ಆವಶ್ಯಕ ಮಾಡ್ಯೂಲ್‌ಗಳನ್ನು ಆಮದು ಮಾಡಿ**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    ಈ ಆಮದುಗಳು NVIDIA AI ಎಂಡ್ಪಾಯಿಂಟ್‌ಗಳೊಂದಿಗೆ ಸಂವಾದಿಸುವ, ಪಾಸ್ವರ್ಡ್‌ಗಳನ್ನು ಸುರಕ್ಷಿತವಾಗಿ ನಿರ್ವಹಿಸುವ, ಆಪರೇಟಿಂಗ್ ಸಿಸ್ಟಂ ಜೊತೆಗೆ ಸಂವಹನ ಮಾಡುವ ಮತ್ತು base64 ಸ್ವರೂಪದಲ್ಲಿ ಡೇಟಾ ಎನ್‌ಕೋಡ್/ಡಿಕೋಡ್ ಮಾಡಲು ಅಗತ್ಯವಿರುವ ಮಾಡ್ಯೂಲ್‌ಗಳನ್ನು ತಂದೊಯ್ಯುತ್ತವೆ.

3. **API ಕೀ ಸೆಟ್ ಮಾಡಿ**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    ಈ ಕೋಡ್ `NVIDIA_API_KEY` ಪರಿಸರ ಚರವನ್ನು ಸಕ್ರಿಯವಾಗಿದೆಯೇ ಎಂದು ಪರಿಶೀಲಿಸುತ್ತದೆ. ಇದಲ್ಲದೇ ಇದ್ದರೆ, ಬಳಕೆದಾರನು ತನ್ನ API ಕೀ ಅನ್ನು ಸುರಕ್ಷಿತವಾಗಿ ನಮೂದಿಸಲು ಪ್ರಾಂಪ್ಟ್‌ ಮಾಡುತ್ತದೆ.

4. **ಮಾದರಿ ಮತ್ತು ಚಿತ್ರದ ಪಥವನ್ನು ವ್ಯಾಖ್ಯಾನಿಸಿ**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    ಇದು ಬಳಸಲಿಗಾಗಿ ಮಾದರಿಯನ್ನು ಹೊಂದಿಸುತ್ತದೆ, ನಿದರ್ಶಿತ ಮಾದರಿಯೊಂದಿಗೆ `ChatNVIDIA` ಇನ್ಸ್‌ಟೆನ್ಸ್ ಅನ್ನು ಸೃಷ್ಟಿಸುತ್ತದೆ, ಮತ್ತು ಚಿತ್ರ ಫೈಲ್‌ನ ಪಥವನ್ನು ನಿರ್ಧರಿಸುತ್ತದೆ.

5. **ಟೆಕ್ಸ್ಟ್ ಪ್ರಾಂಪ್ಟ್ ರಚಿಸಿ**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    ಇದು ಮಾದರಿಯನ್ನು ಅಗತ್ಯ Python ಕೋಡ್ ಅನ್ನು ರಚಿಸಲು ನಿರ್ದೇಶಿಸುವ ಟೆಕ್ಸ್ಟ್ ಪ್ರಾಂಪ್ಟ್ ಅನ್ನು ವ್ಯಾಖ್ಯಾನಿಸುತ್ತದೆ.

6. **ಚಿತ್ರವನ್ನು Base64 ನಲ್ಲಿ ಎನ್‌ಕೋಡ್ ಮಾಡಿ**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    ಈ ಕೋಡ್ ಚಿತ್ರ ಫೈಲ್ ಅನ್ನು ಓದಿ, ಅದನ್ನು base64 ನಲ್ಲಿ ಎನ್‌ಕೋಡ್ ಮಾಡಿ, ಮತ್ತು ಎನ್‌ಕೋಡೆಡ್ ಡೇಟಾದೊಂದಿಗೆ HTML ಚಿತ್ರ ಟ್ಯಾಗ್ ಅನ್ನು ರಚಿಸುತ್ತದೆ.

7. **ಟೆಕ್ಸ್ಟ್ ಮತ್ತು ಚಿತ್ರವನ್ನು ಪ್ರಾಂಪ್ಟ್‌ ಗೆ ಸಂಯೋಜಿಸಿ**:
    ```python
    prompt = f"{text} {image}"
    ```
    ಇದು ಟೆಕ್ಸ್ಟ್ ಪ್ರಾಂಪ್ಟ್ ಮತ್ತು HTML ಚಿತ್ರ ಟ್ಯಾಗ್ ಅನ್ನು ಒಂದು ಸ್ಟ್ರಿಂಗ್ ಆಗಿ ಸೇರಿಸುತ್ತದೆ.

8. **ChatNVIDIA ಬಳಸಿ ಕೋಡ್ ರಚಿಸಿ**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    ಈ ಕೋಡ್ ಪ್ರಾಂಪ್ಟ್ ಅನ್ನು `ChatNVIDIA` ಮಾದರಿಗೆ ಕಳುಹಿಸಿ, ಉತ್ಪಾದಿತ ಕೋಡ್ ಅನ್ನು ತುಂಡುಗಳಲ್ಲಿ ಸಂಗ್ರಹಿಸುತ್ತದೆ, ಪ್ರತಿ ತುಂಡುವನ್ನು ಮುದ್ರಿಸಿ ಮತ್ತು `code` ಸ್ಟ್ರಿಂಗ್‌ಗೆ ಸಂಯೋಜಿಸುತ್ತದೆ.

9. **ಉತ್ಪಾದಿತ ವಿಷಯದಿಂದ Python ಕೋಡ್ ಅನ್ನು ಹೊರತೆಗೆದು ಕೊಳ್ಳಿ**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    ಇದು ಮಾರ್ಕ್ಡೌನ್ ಫಾರ್ಮ್ಯಾಟ್‌ ಅನ್ನು ತೆಗೆದುಹಾಕಿ ಉತ್ಪಾದಿತ ವಿಷಯದಿಂದ ನಿಜವಾದ Python ಕೋಡ್ ಅನ್ನು ಹೊರತೆಗೆಯುತ್ತದೆ.

10. **ಉತ್ಪಾದಿತ ಕೋಡ್ ಅನ್ನು ಚಾಲನೆ ಮಾಡಿ**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    ಇದು ಹೊರತೆಗೆದ Python ಕೋಡ್ ಅನ್ನು subprocess ಆಗಿ ರನ್ ಮಾಡಿ ಅದರ ಔಟ್ಪುಟ್ ಅನ್ನು ಸೆರೆಹಿಡಿಯುತ್ತದೆ.

11. **ಚಿತ್ರಗಳನ್ನು ಪ್ರದರ್ಶಿಸಿ**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    ಈ ಸಾಲುಗಳು `IPython.display` മോ듊ಲ್ ಬಳಸಿಕೊಂಡು ಚಿತ್ರಗಳನ್ನು ಪ್ರದರ್ಶಿಸುತ್ತವೆ.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ಜವಾಬ್ದಾರಿ ನಿರಾಕರಣೆ:

ಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ Co-op Translator (https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯನ್ನು ಹಿಗ್ಗಿಸುತ್ತಿದ್ದು도, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅನಿಖರತೆಗಳಿರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿ ಇರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮತ್ತು ವಿಶ್ವಾಸಾರ್ಹ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಗಂಭೀರವಾದ ಮಾಹಿತಿಗಾಗಿ ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಗ್ರಹಣೆಗಳು ಅಥವಾ ಅರ್ಥಭ್ರಾಂತೆಗಳಿಗೆ ನಾವು ಜವಾಬ್ದಾರರಾಗುವುದಿಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->