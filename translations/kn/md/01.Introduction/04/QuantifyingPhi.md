<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d658062de70b131ef4c0bff69b5fc70e",
  "translation_date": "2025-12-22T01:54:13+00:00",
  "source_file": "md/01.Introduction/04/QuantifyingPhi.md",
  "language_code": "kn"
}
-->
# **Phi ಕುಟುಂಬದ ಕ್ವಾಂಟೈಸೇಶನ್**

ಮಾದರಿ ಕ್ವಾಂಟೈಸೇಶನ್ ಎಂದರೆ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್ ಮಾದರಿಯಲ್ಲಿನ ಪರಿಮಾಣಗಳನ್ನು (ಉದಾಹರಣೆಗೆ ತೂಕಗಳು ಮತ್ತು ಸಕ್ರಿಯತೆ ಮೌಲ್ಯಗಳು) ದೊಡ್ಡ ಮೌಲ್ಯ ಶ್ರೇಣಿಯಿಂದ (ಸಾಧಾರಣವಾಗಿ ಅಸಾಧಾರಣ ಮೌಲ್ಯ ಶ್ರೇಣಿ) ಚಿಕ್ಕ ಮತ್ತು ನಿರ್ದಿಷ್ಟ ಮೌಲ್ಯ ಶ್ರೇಣಿಗೆ ನಕ್ಷೆ ಮಾಡಲು ಸಂಬಂಧಿಸಿದ ಪ್ರಕ್ರಿಯೆ. ಈ ತಂತ್ರಜ್ಞಾನವು ಮಾದರಿಯ ಗಾತ್ರ ಮತ್ತು ಗಣನಾತ್ಮಕ ಜಟಿಲತೆಯನ್ನು ಕಡಿಮೆ ಮಾಡಿ ಮೊಬೈಲ್ ಸಾಧನಗಳು ಅಥವಾ ಎಂಬರ್‌ಡಡ್ ವ್ಯವಸ್ಥೆಗಳಂತಹ ಸಂಪನ್ಮೂಲ-ಕಡಿಮೆ ಪರಿಸರಗಳಲ್ಲಿ ಮಾದರಿಯ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ಸುಧಾರಿಸಬಹುದು. ಮಾದರಿ ಕ್ವಾಂಟೈಸೇಶನ್ ಪರಿಮಾಣಗಳ ನಿಖರತೆಯನ್ನು ಕಡಿಮೆ ಮಾಡುವ ಮೂಲಕ ಸಂಕುಚಿತಗೊಳಿಸುವಿಕೆಯನ್ನು ಸಾಧಿಸುತ್ತದೆ, ಆದರೆ ಇದರಿಂದ ಕೆಲವು ನಿಖರತೆಯ ನಷ್ಟವೂ ಉಂಟಾಗುತ್ತದೆ. ಆದ್ದರಿಂದ ಕ್ವಾಂಟೈಸೇಶನ್ ಪ್ರಕ್ರಿಯೆಯಲ್ಲಿ ಮಾದರಿಯ ಗಾತ್ರ, ಗಣನಾತ್ಮಕ ಜಟಿಲತೆ ಮತ್ತು ನಿಖರತೆಯ ನಡುವೆ ಸಮತೋಲನ ಕಾಪಾಡುವುದು ಅವಶ್ಯಕ. ಸಾಮಾನ್ಯ ಕ್ವಾಂಟೈಸೇಶನ್ ವಿಧಾನಗಳಲ್ಲಿ ಫಿಕ್ಸಡ್-ಪಾಯಿಂಟ್ ಕ್ವಾಂಟೈಸೇಶನ್, ಫ್ಲೋಟ್‌ಿಂಗ್-ಪಾಯಿಂಟ್ ಕ್ವಾಂಟೈಸೇಶನ್ ಇತ್ಯಾದಿ شاملವಾಗಿವೆ. ನಿರ್ದಿಷ್ಟ ದೃಶ್ಯಸ್ಥಿತಿ ಮತ್ತು ಅಗತ್ಯಗಳ ಆಧಾರದ ಮೇಲೆ ಸರಿಯಾದ ಕ್ವಾಂಟೈಸೇಶನ್ ತಂತ್ರವನ್ನು ಆಯ್ಕೆ ಮಾಡಬಹುದು.

ನಾವು GenAI ಮಾದರಿಗಳನ್ನು ಎಡ್ಜ್ ಸಾಧನಗಳಿಗೆ ನಿಯೋಜಿಸುವುದನ್ನು ಮತ್ತು ಹೆಚ್ಚಿನ ಸಾಧನಗಳನ್ನು GenAI ದೃಶ್ಯಾಂಕಗಳಲ್ಲಿ ಸೇರಿಸುವುದನ್ನು ಆಸೆಪಡುತ್ತೇವೆ, ಉದಾಹರಣೆಗೆ ಮೊಬೈಲ್ ಸಾಧನಗಳು, AI PC/Copilot+PC, ಮತ್ತು ಪರಂಪರাগত IoT ಸಾಧನಗಳು. ಕ್ವಾಂಟೈಸೇಶನ್ ಮಾಡಿದ ಮಾದರಿಗಳ ಮೂಲಕ ನಾವು ವಿವಿಧ ಸಾಧನಗಳ ಆಧಾರದ ಮೇಲೆ ಅವುಗಳನ್ನು ವಿಭಿನ್ನ ಎಡ್ಜ್ ಸಾಧನಗಳಲ್ಲಿ ನಿಯೋಜಿಸಬಹುದು. ಹಾರ್ಡ್‌ವೇರ್ ತಯಾರಕರಿಂದ ಒದಗಿಸಲಾದ ಮಾದರಿ ವೇಗಗೊಳಿಸುವ ಫ್ರೇಮ್ವರ್ಕ್ ಮತ್ತು ಕ್ವಾಂಟೈಸ್ಡ್ ಮಾದರಿಯನ್ನು ಸಂಯೋಜಿಸಿದರೆ, ಉತ್ತಮ SLM ಅಪ್ಲಿಕೇಶನ್ ದೃಶ್ಯವಸ್ಥೆಗಳನ್ನು ನಿರ್ಮಿಸಬಹುದು.

ಕ್ವಾಂಟೈಸೇಶನ್ ದೃಶ್ಯಸ್ಥಿತಿಗಳಲ್ಲಿ, ನಾವು ವಿವಿಧ ನಿಖರತೆಗಳಿದ್ದು (INT4, INT8, FP16, FP32). ಕೆಳಗೆ ಸಾಮಾನ್ಯವಾಗಿ ಬಳಕೆಯಾಗುವ ಕ್ವಾಂಟೈಸೇಶನ್ ನಿಖರತೆಗಳ ವಿವರಣೆ ಇದೆ

### **INT4**

INT4 ಕ್ವಾಂಟೈಸೇಶನ್ ಎಂದರೆ ಮಾದರಿಯ ತೂಕಗಳು ಮತ್ತು ಸಕ್ರಿಯತೆ ಮೌಲ್ಯಗಳನ್ನು 4-ಬಿಟ್ ಪೂರ್ಣಾಂಕಗಳಿಗೆ ಕ್ವಾಂಟೈಸ್ ಮಾಡುವ ತೀವ್ರವಾದ ವಿಧಾನ. ಪ್ರತಿನಿಧನಾ ಶ್ರೇಣಿ ಚಿಕ್ಕದಾಗಿಯೂ ಮತ್ತು ನಿಖರತೆ ಕಡಿಮೆಯಾಗಿರುವದರಿಂದ INT4 ಕ್ವಾಂಟೈಸೇಶನ್ ಸಾಮಾನ್ಯವಾಗಿ ಹೆಚ್ಚಿನ ನಿಖರತಾ ನಷ್ಟವನ್ನು ಉಂಟುಮಾಡುತ್ತದೆ. ಆದರೆ INT8 ಕ್ವಾಂಟೈಸೇಶನ್ ಹೋಲಿಸಿದಾಗ, INT4 ಕ್ವಾಂಟೈಸೇಶನ್ ಮಾದರಿಯ ಸಂಗ್ರಹಣಾ ಅಗತ್ಯಗಳು ಮತ್ತು ಗಣನಾತ್ಮಕ ಜಟಿಲತೆಯನ್ನು ಮತ್ತಷ್ಟು ಕಡಿಮೆ ಮಾಡಬಹುದು. ಪ್ರಾಯೋಗಿಕ ಅನ್ವಯಿಕತೆಗಳಲ್ಲಿ INT4 ಕ್ವಾಂಟೈಸೇಶನ್ ಅನ್ನು ಅಪರೂಪವಾಗಿ ಬಳಸಲಾಗುತ್ತದೆ, ಏಕೆಂದರೆ ತುಂಬಾ ಕಡಿಮೆ ನಿಖರತೆಯು ಮಾದರಿ ಪ್ರದರ್ಶನದಲ್ಲಿ ಬೃಹತ್ ಕುಸಿತವನ್ನು ಉಂಟುಮಾಡಬಹುದು. ಜೊತೆಗೆ, ಎಲ್ಲಾ ಹಾರ್ಡ್‌ವೇರ್‌ಗಳು INT4 ಕಾರ್ಯಾಚರಣೆಗಳನ್ನು ಬೆಂಬಲಿಸುವುದು ಬೇಡವಲ್ಲ, ಆದ್ದರಿಂದ ಕ್ವಾಂಟೈಸೇಶನ್ ವಿಧಾನ ಆಯ್ಕೆಮಾಡುವಾಗ ಹಾರ್ಡ್‌ವೇರ್ ಹೊಂದಾಣಿಕೆಯನ್ನು ಪರಿಗಣಿಸಬೇಕು.

### **INT8**

INT8 ಕ್ವಾಂಟೈಸೇಶನ್ ಎಂದರೆ ಮಾದರಿಯ ತೂಕಗಳು ಮತ್ತು ಸಕ್ರಿಯತೆಗಳನ್ನು ತೇಲುವಾಂಕ (floating point) ಸಂಖ್ಯೆಯಿಂದ 8-ಬಿಟ್ ಪೂರ್ಣಾಂಕಗಳಿಗೆ ಪರಿವರ್ತಿಸುವ ಪ್ರಕ್ರಿಯೆ. INT8 ಪೂರ್ಣಾಂಕಗಳು ಪ್ರತಿನಿಧಿಸುವ ಸಂಖ್ಯಾ ಶ್ರೇಣಿ ಚಿಕ್ಕದಾಗಿದ್ದು ನಿಖರತೆ ಕಡಿಮೆ ಆದರೂ, ಇದು ಸಂಗ್ರಹಣೆ ಮತ್ತು ಲೆಕ್ಕಾಚಾರ ಅಗತ್ಯಗಳನ್ನು ಬಹುಮಟ್ಟಿಗೆ ಕಡಿಮೆ ಮಾಡಬಹುದು. INT8 ಕ್ವಾಂಟೈಸೇಶನ್‌ನಲ್ಲಿ, ಮಾದರಿಯ ತೂಕಗಳು ಮತ್ತು ಸಕ್ರಿಯತೆ ಮೌಲ್ಯಗಳು ಮೂಲ ತೇಲುವಾಂಕ ಮಾಹಿತಿಯನ್ನು ಸಾಧ್ಯವಾದಷ್ಟು ಉಳಿಸುವಂತೆ ಸ್ಕೇಲಿಂಗ್ ಮತ್ತು ಆಫ್‌ಸೆಟ್ ಸೇರಿಸಿರುವ ಕ್ವಾಂಟೈಸೇಶನ್ ಪ್ರಕ್ರಿಯೆಯ ಮೂಲಕ ಹೋಗುತ್ತವೆ. ಇನ್ಫರೆನ್ಸ್ ಸಮಯದಲ್ಲಿ, ಈ ಕ್ವಾಂಟೈಸ್ ಮಾಡಿದ ಮೌಲ್ಯಗಳನ್ನು ಲೆಕ್ಕಾಚಾರದಿಗಾಗಿ ಮತ್ತೆ ತೇಲುವಾಂಕಗಳಾಗಿ ಡೀಕ್ವಾಂಟೈಸ್ ಮಾಡಲಾಗುತ್ತದೆ, ಮತ್ತು ನಂತರ ಮುಂದಿನ ಹಂತಕ್ಕಾಗಿ ಮತ್ತೆ INT8 ಗೆ ಕ್ವಾಂಟೈಸ್ ಮಾಡಲಾಗುತ್ತದೆ. ಈ ವಿಧಾನವು ಬಹುತೇಕ ಅನ್ವಯಗಳಲ್ಲಿ ಸಾಕಷ್ಟು ನಿಖರತೆಯನ್ನು ಒದಗಿಸುವಾಗಲೂ ಹೆಚ್ಚಿನ ಗಣನಾತ್ಮಕ કાર્યಕ್ಷಮತೆಯನ್ನು ಕಾಪಾಡುತ್ತದೆ.

### **FP16**

FP16 ಫಾರ್ಮ್ಯಾಟ್ ಅಂದರೆ 16-ಬಿಟ್ ತೇಲುವಾಂಕಗಳು (float16), ಇದು 32-ಬಿಟ್ ತೇಲುವಾಂಕಗಳ (float32) তুলನೆಯಲ್ಲಿ ಮೆ모ರಿ ಬಳಕೆಯನ್ನು ಅರ್ಧಕ್ಕಾಗಿಸುವದು, ಮತ್ತು ದೊಡ್ಡ ಮಟ್ಟದ ಡೀಪ್ ಲರ್ನಿಂಗ್ ಅನ್ವಯಗಳಲ್ಲಿ ಮಹತ್ವದ ಲಾಭವನ್ನು ಒದಗಿಸುತ್ತದೆ. FP16 ಫಾರ್ಮ್ಯಾಟ್ ಅದೇ GPU ಮೆಮೊರಿಯ ಮಿತಿಗಳೊಳಗೆ ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು ಲೋಡ್ ಮಾಡಬಹುದಾಗಿದೆ ಅಥವಾ ಹೆಚ್ಚು ಡೇಟಾವನ್ನು ಪ್ರಕ್ರಿಯೆ ಮಾಡಬಹುದು. ಆಧುನಿಕ GPU ಹಾರ್ಡ್‌ವೇರ್ FP16 ಕಾರ್ಯಾಚರಣೆಗಳನ್ನು ನಿರಂತರವಾಗಿ ಬೆಂಬಲಿಸುತ್ತಿದ್ದರಿಂದ, FP16 ಫಾರ್ಮ್ಯಾಟ್ ಅನ್ನು ಬಳಸುವುದರಿಂದ ಗಣನಾ ವೇಗದ ಸುಧಾರಣೆ ಕೂಡಂಟಾಗಬಹುದು. ಆದರೆ FP16 ಫಾರ್ಮ್ಯಾಟ್‌ಗೆ ಹೊಂದಿದ್ದ ತನ್ನ ಸ್ವಭಾವಿಕ ದುರ್ಬಲತೆಗಳಿವೆ, ಅಂದರೆ ಕಡಿಮೆ ನಿಖರತೆ, ಕೆಲ ಸಂದರ್ಭಗಳಲ್ಲಿ ಸಂಖ್ಯಾತ್ಮಕ ಅಸ್ಥಿರತೆ ಅಥವಾ ನಿಖರತೆಯ ನಷ್ಟ ಉಂಟಾಗಬಹುದು.

### **FP32**

FP32 ಫಾರ್ಮ್ಯಾಟ್ ಹೆಚ್ಚಿನ ನಿಖರತೆಯನ್ನು ಒದಗಿಸುತ್ತದೆ ಮತ್ತು ವಿಶಾಲ ಮೌಲ್ಯ ಶ್ರೇಣಿಯನ್ನು ನಿಖರವಾಗಿ ಪ್ರತಿನಿಧಿಸಬಹುದು. ಸಂಕೀರ್ಣ ಗಣಿತಾತ್ಮಕ ಕಾರ್ಯಗಳು ನಡೆಸಲ್ಪಡುವಾಗ ಅಥವಾ ಹೆಚ್ಚಿನ ನಿಖರತೆಯ ಫಲಿತಾಂಶಗಳ ಅಗತ್ಯವಿದ್ದಾಗ FP32 ಫಾರ್ಮ್ಯಾಟ್ ಅನ್ನು ಆದ್ಯತೆಯಿಂದ ಬಳಸಲಾಗುತ್ತದೆ. ಆದರೆ ಹೆಚ್ಚು ನಿಖರತೆಯು ಹೆಚ್ಚಿನ ಮೆಮೊರಿ ಬಳಕೆಯನ್ನು ಮತ್ತು ಹೆಚ್ಚಿನ ಲೆಕ್ಕಚಾರ ಸಮಯವನ್ನು ಸೂಚಿಸುತ್ತದೆ. ದೊಡ್ಡ ಮಟ್ಟದ ಡೀಪ್ ಲರ್ನಿಂಗ್ ಮಾದರಿಗಳಿಗಾಗಿ, ವಿಶೇಷವಾಗಿ ಹೆಚ್ಚು ಮಾದರಿ ಪರಿಮಾಣಗಳು ಮತ್ತು ಭಾರೀ ಪ್ರಮಾಣದ ಡೇಟಾ ಇದ್ದಾಗ, FP32 ಫಾರ್ಮ್ಯಾಟ್ GPU ಮೆಮೊರಿ ಅಪರ್ಯಾಯತೆ ಅಥವಾ ಇನ್ಫರೆನ್ಸ್ ವೇಗದ ಕಡಿತಕ್ಕೆ ಕಾರಣವಾಗಬಹುದು.

ಮೊಬೈಲ್ ಸಾಧನಗಳು ಅಥವಾ IoT ಸಾಧನಗಳ ಮೇಲೆ, ನಾವು Phi-3.x ಮಾದರಿಗಳನ್ನು INT4 ಗೆ ಪರಿವರ್ತಿಸಬಹುದು, ಹೀಗೆಯೇ AI PC / Copilot PC ಗಳು ಹೆಚ್ಚಿನ ನಿಖರತೆಗಳನ್ನು ಬಳಸಬಹುದು ಉದಾಹರಣೆಗೆ INT8, FP16, FP 32.

ಈಗಲೂ ವಿಭಿನ್ನ ಹಾರ್ಡ್‌ವೇರ್ ತಯಾರಕರು ಜೆರೇಟಿವ್ ಮಾದರಿಗಳನ್ನು ಬೆಂಬಲಿಸಲು ವಿಭಿನ್ನ ಫ್ರೇಮ್ವರ್ಕ್‌ಗಳನ್ನು ಒದಗಿಸುತ್ತಾರೆ, ಉದಾಹರಣೆಗೆ Intel ನ OpenVINO, Qualcomm ನ QNN, Apple ನ MLX, ಮತ್ತು Nvidia ನ CUDA ಇತ್ಯಾದಿ, ಮತ್ತು ಈ ಮೂಲಕ ಮಾದರಿ ಕ್ವಾಂಟೈಸೇಶನ್ ಅನ್ನು ಸಂಯೋಜಿಸಿ ಸ್ಥಳೀಯ ನಿಯೋಜನೆಯನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು.

ತಂತ್ರಜ್ಞಾನದ ದೃಷ್ಟಿಯಿಂದ, ನಾವು ಕ್ವಾಂಟೈಸೇಶನ್ ನಂತರ ವಿಭಿನ್ನ ಫಾರ್ಮ್ಯಾಟ್ ಬೆಂಬಲಗಳನ್ನು ಹೊಂದಿದ್ದೇವೆ, ಉದಾಹರಣೆಗೆ PyTorch / Tensorflow ಫಾರ್ಮ್ಯಾಟ್, GGUF, ಮತ್ತು ONNX. ನಾನು GGUF ಮತ್ತು ONNX ನಡುವಿನ ಫಾರ್ಮ್ಯಾಟ್ ಹೋಲಿಕೆ ಮತ್ತು ಅನ್ವಯ ದೃಶ್ಯಸ್ಥಿತಿಗಳನ್ನು ಮಾಡಿದ್ದೇನೆ. ಇಲ್ಲಿ ನಾನು ONNX ಕ್ವಾಂಟೈಸೇಶನ್ ಫಾರ್ಮ್ಯಾಟ್ ಅನ್ನು薦ಿಸುತ್ತೇನೆ, ಇದಕ್ಕೆ ಮಾದರಿ ಫ್ರೇಮ್ವರ್ಕ್‌ನಿಂದ ಹಿಡಿದು ಹಾರ್ಡ್‌ವೇರ್ ತನಕ ಉತ್ತಮ ಬೆಂಬಲವಿದೆ. ಈ ಅಧ್ಯಾಯದಲ್ಲಿ, ನಾವು ONNX Runtime for GenAI, OpenVINO, ಮತ್ತು Apple MLX ಬಳಸಿಕೊಂಡು ಮಾದರಿ ಕ್ವಾಂಟೈಸೇಶನ್ ಮೇಲೆ ಕೇಂದ್ರೀಕರಿಸುವೆವು (ನಿಮಗೆ ಉತ್ತಮ ವಿಧಾನ ಇದ್ದರೆ, ನೀವು PR ಸಲ್ಲಿಸುವ ಮೂಲಕ ಅದನ್ನು ನಮಗೆ ನೀಡಬಹುದು)

**ಈ ಅಧ್ಯಾಯದಲ್ಲಿ ಒಳಗೊಂಡಿದೆ**

1. [Phi-3.5 / 4 ಅನ್ನು llama.cpp ಬಳಸಿ ಕ್ವಾಂಟೈಸೇಶನ್](./UsingLlamacppQuantifyingPhi.md)

2. [onnxruntimeಗಾಗಿ Generative AI ವಿಸ್ತರಣೆಗಳನ್ನು ಬಳಸಿ Phi-3.5 / 4 ಕ್ವಾಂಟೈಸೇಶನ್](./UsingORTGenAIQuantifyingPhi.md)

3. [Intel OpenVINO ಬಳಸಿ Phi-3.5 / 4 ಕ್ವಾಂಟೈಸೇಶನ್](./UsingIntelOpenVINOQuantifyingPhi.md)

4. [Apple MLX ಫ್ರೇಮ್ವರ್ಕ್ ಬಳಸಿ Phi-3.5 / 4 ಕ್ವಾಂಟೈಸೇಶನ್](./UsingAppleMLXQuantifyingPhi.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
ಜವಾಬ್ದಾರಿ ನಿರಾಕರಣೆ:
ಈ ದಸ್ತಾವೇಜುವನ್ನು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯತ್ತ ಪ್ರಯತ್ನಿಸುತ್ತೇವೆ; ಆದಾಗ್ಯೂ ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅಸತ್ಯತೆಗಳಿರಬಹುದು ಎಂಬುದನ್ನು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅದರ ಸ್ವದೇಶಿ ಭಾಷೆಯಲ್ಲಿ ಅಧಿಕೃತ աղբWind?—ಕ್ಷಮಿಸಿ—ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಪ್ರಮುಖ ಮಾಹಿತಿಗಾಗಿ ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದದ ಬಳಸಿಕೊಂಡು ಉಂಟಾಗುವ ಯಾವುದೇ ಅರ್ಥವ್ಯತ್ಯಾಸಗಳಿಗಾಗಿ ಅಥವಾ தவறಾಗಿ ವಿವರಿಸುವಿಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ misunderstandings/ಮಿಸ್ಇಂಟರ್ಪ್ರೆಟೇಷನ್‌ಗಳಿಗಾಗಿ ನಾವು ಹೊಣೆಗಾರರಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->