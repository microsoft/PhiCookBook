{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama + OpenAI + Python\n",
    "\n",
    "## 1. ಮಾದರಿ ಹೆಸರನ್ನು ನಿರ್ದಿಷ್ಟಪಡಿಸಿ\n",
    "\n",
    "ನೀವು \"phi3:mini\" ಗಿಂತ ಬೇರೆ ಮಾದರಿಯನ್ನು ಆಮದು ಮಾಡಿಕೊಂಡಿದ್ದರೆ, ಕೆಳಗಿನ ಸೆಲ್‌ನಲ್ಲಿನ ಮೌಲ್ಯವನ್ನು ಬದಲಾಯಿಸಿ.\n",
    "ಆ ಚರವನ್ನು ನೋಟ್ಬುಕ್‌ನಾದ್ಯಂತ ಇರುವ ಕೋಡ್‌ನಲ್ಲಿ ಬಳಸಲಾಗುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"phi3:mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open AI ಕ್ಲೈಯಂಟ್ ಅನ್ನು ಸೆಟ್‌ಅಪ್ ಮಾಡಿ\n",
    "\n",
    "ಸಾಮಾನ್ಯವಾಗಿ OpenAI ಕ್ಲೈಯಂಟ್ ಅನ್ನು ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿಗಳೊಂದಿಗೆ ಸಂವಹನ ಮಾಡಲು OpenAI.com ಅಥವಾ Azure OpenAI ಜೊತೆಗೆ ಬಳಸಲಾಗುತ್ತದೆ.\n",
    "ಆದರೆ, ಇದನ್ನು Ollama ಜೊತೆ ಕೂಡ ಬಳಸಬಹುದು, ಏಕೆಂದರೆ Ollama \"http://localhost:11434/v1\" ನಲ್ಲಿ OpenAI-ಅನುಕೂಲ ಎಂಡ್ಪಾಯಿಂಟ್ ಒದಗಿಸುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"nokeyneeded\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ಚಾಟ್ ಪೂರ್ಣಗೊಳಿಸುವಿಕೆಯನ್ನು ರಚಿಸಿ\n",
    "\n",
    "ಈಗ ನಾವು ಸಂಭಾಷಣೆಗೆ ಉತ್ತರವನ್ನು ರಚಿಸಲು OpenAI SDK ಅನ್ನು ಬಳಸಬಹುದು. ಈ ವಿನಂತಿಯು ಬೆಕ್ಕುಗಳ ಕುರಿತು ಒಂದು ಹೈಕು ರಚಿಸಬೇಕು:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about a hungry cat\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ಪ್ರಾಂಪ್ಟ್ ಇಂಜಿನಿಯರಿಂಗ್\n",
    "\n",
    "ಭಾಷಾ ಮಾದರಿಗೆ ಮೊದಲಿಗೆ ಕಳುಹಿಸಲಾದ ಸಂದೇಶವನ್ನು \"ಸಿಸ್ಟಮ್ ಮೆಸೇಜ್\" ಅಥವಾ \"ಸಿಸ್ಟಮ್ ಪ್ರಾಂಪ್ಟ್\" ಎಂದು ಕರೆಯುತ್ತಾರೆ, ಮತ್ತು ಅದು ಮಾದರಿಗಾಗಿ ಒಟ್ಟಾರೆ ಸೂಚನೆಗಳನ್ನು ನಿಗದಿಪಡಿಸುತ್ತದೆ.\n",
    "ಭಾಷಾ ಮಾದರಿಯನ್ನು ವಿಭಿನ್ನ ರೀತಿಯಲ್ಲಿ ಫಲಿತಾಂಶ ರಚಿಸಲು ಮಾರ್ಗದರ್ಶನ ಮಾಡಲು ನೀವು ನಿಮ್ಮದೇ ಕಸ್ಟಮ್ ಸಿಸ್ಟಮ್ ಪ್ರಾಂಪ್ಟ್ ಒದಗಿಸಬಹುದು.\n",
    "Modify the `SYSTEM_MESSAGE` below to answer like your favorite famous movie/TV character, or get inspiration for other system prompts from [ಅದ್ಭುತ ChatGPT ಪ್ರಾಂಪ್ಟ್‌ಗಳು](https://github.com/f/awesome-chatgpt-prompts?tab=readme-ov-file#prompts).\n",
    "\n",
    "Once you've customized the system message, provide the first user question in the `USER_MESSAGE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "I want you to act like Elmo from Sesame Street.\n",
    "I want you to respond and answer like Elmo using the tone, manner and vocabulary that Elmo would use.\n",
    "Do not write any explanations. Only answer like Elmo.\n",
    "You must know all of the knowledge of Elmo, and nothing more.\n",
    "\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"\"\"\n",
    "Hi Elmo, how are you doing today?\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ಕೆಲವು ಶಾಟ್ ಉದಾಹರಣೆಗಳು\n",
    "\n",
    "ಭಾಷಾ ಮಾದರಿಯನ್ನು ಮಾರ್ಗದರ್ಶನ ಮಾಡಲು ಮತ್ತೊಂದು ವಿಧಾನವೆಂದರೆ \"few shots\" ಅನ್ನು ಒದಗಿಸುವುದು, ಅದು ಮಾದರಿ ಹೇಗೆ ಪ್ರತಿಕ್ರಿಯಿಸಬೇಕು ಎಂಬುದನ್ನು ತೋರಿಸುವ ಉದಾಹರಣೆಯ ಪ್ರಶ್ನೆ/ಉತ್ತರಗಳ ಸರಣಿಯಾಗಿದೆ.\n",
    "\n",
    "ಕೆಳಗಿನ ಉದಾಹರಣೆ ಒಂದು ಭಾಷಾ ಮಾದರಿಯನ್ನು ಟೀಚಿಂಗ್ ಅಸಿಸ್ಟೆಂಟ್‌ನಂತೆ ವರ್ತಿಸಲು ಪ್ರಯತ್ನಿಸುತ್ತದೆ; ಅದು TA ನೀಡಬಹುದಾದ ಕೆಲವು ಪ್ರಶ್ನೆಗಳು ಮತ್ತು ಉತ್ತರಗಳ ಉದಾಹರಣೆಗಳನ್ನು ಒದಗಿಸುವ ಮೂಲಕ ಮುನ್ನಡೆಸುತ್ತದೆ, ಮತ್ತು ನಂತರ ವಿದ್ಯಾರ್ಥಿ ಕೇಳಬಹುದು ಎಂಬ ಪ್ರಶ್ನೆಯೊಂದರಿಂದ ಮಾದರಿಯನ್ನು ಪ್ರಾಂಪ್ಟ್ ಮಾಡುತ್ತದೆ.\n",
    "\n",
    "ಮೊದಲಿಗೆ ಇದನ್ನು ಪ್ರಯತ್ನಿಸಿ, ನಂತರ ಹೊಸ ಸನ್ನಿವೇಶಕ್ಕಾಗಿ `SYSTEM_MESSAGE`, `EXAMPLES`, ಮತ್ತು `USER_MESSAGE` ಅನ್ನು تعديل ಮಾಡಿ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that helps students with their homework.\n",
    "Instead of providing the full answer, you respond with a hint or a clue.\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLES = [\n",
    "    (\n",
    "        \"What is the capital of France?\",\n",
    "        \"Can you remember the name of the city that is known for the Eiffel Tower?\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the square root of 144?\",\n",
    "        \"What number multiplied by itself equals 144?\"\n",
    "    ),\n",
    "    (   \"What is the atomic number of oxygen?\",\n",
    "        \"How many protons does an oxygen atom have?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "USER_MESSAGE = \"What is the largest planet in our solar system?\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": EXAMPLES[0][0]},\n",
    "        {\"role\": \"assistant\", \"content\": EXAMPLES[0][1]},\n",
    "        {\"role\": \"user\", \"content\": EXAMPLES[1][0]},\n",
    "        {\"role\": \"assistant\", \"content\": EXAMPLES[1][1]},\n",
    "        {\"role\": \"user\", \"content\": EXAMPLES[2][0]},\n",
    "        {\"role\": \"assistant\", \"content\": EXAMPLES[2][1]},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ರಿಟ್ರೀವಲ್-ಆಗ್ಮೆಂಟೆಡ್ ಜನರೇಷನ್\n",
    "\n",
    "RAG (Retrieval Augmented Generation) ಒಂದು ತಂತ್ರವಾಗಿದೆ, ಇದು ನಿರ್ದಿಷ್ಟ ಕ್ಷೇತ್ರಕ್ಕಾಗಿ ಭಾಷಾ ಮಾದರಿಯನ್ನು ಪ್ರಶ್ನೆಗಳಿಗೆ ನಿಖರವಾಗಿ ಉತ್ತರ ನೀಡುವಂತೆ ಮಾಡುವುದಕ್ಕೆ ಬಳಸಲಾಗುತ್ತದೆ; ಮೊದಲು ಜ್ಞಾನ ಮೂಲದಿಂದ ಸಂಬಂಧಿತ ಮಾಹಿತಿಯನ್ನು ಹಿಂಪಡೆಯಲು ಮತ್ತು ನಂತರ ಆ ಮಾಹಿತಿಯನ್ನು ಆಧರಿಸಿ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ರಚಿಸಲು ಇದು ನೆರವಾಗುತ್ತದೆ.\n",
    "\n",
    "ನಾವು ಹೈಬ್ರಿಡ್ ಕಾರುಗಳ ಬಗ್ಗೆ ಡೇಟಾವನ್ನು ಒಳಗೊಂಡಿರುವ ಸ್ಥಳೀಯ CSV ಫೈಲ್ ಅನ್ನು ಒದಗಿಸಿದ್ದೇವೆ. ಕೆಳಗಿನ ಕೋಡ್ ಆ CSV ಫೈಲ್ ಅನ್ನು ಓದುತ್ತದೆ, ಬಳಕೆದಾರರ ಪ್ರಶ್ನೆಗೆ ಹೊಂದುವ ಸಾಲುಗಳನ್ನು ಹುಡುಕುತ್ತದೆ, ಮತ್ತು ಕಂಡುಹಿಡಿದ ಮಾಹಿತಿಯ ಆಧಾರದ ಮೇಲೆ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ರಚಿಸುತ್ತದೆ. ಇದು ಮಾದರಿಗೆ ಹೆಚ್ಚು ಡೇಟಾವನ್ನು ಕಳುಹಿಸುವುದರಿಂದ ಹಿಂದಿನ ಉದಾಹರಣೆಗಳಿಗಿಂತ ಹೆಚ್ಚು ಸಮಯ ತೆಗೆದುಕೊಳ್ಳುವುದು ಗಮನದಲ್ಲಿರಲಿ. ಉತ್ತರವು ಇನ್ನೂ ಡೇಟಾದಲ್ಲಿ ನೆಲೆಯಿಲ್ಲ ಎನಿಸಿದರೆ, ನೀವು ಸಿಸ್ಟಮ್ ಇಂಜಿನಿಯರಿಂಗ್ ಪ್ರಯತ್ನಿಸಬಹುದು ಅಥವಾ ಬೇರೆ ಮಾದರಿಗಳನ್ನು ಪರೀಕ್ಷಿಸಬಹುದು. ಸಾಮಾನ್ಯವಾಗಿ, RAG ದೊಡ್ಡ ಮಾದರಿಗಳೊಂದಿಗೆ ಅಥವಾ SLMs ಗಳ ಫೈನ್-ಟ್ಯೂನ್ಡ್ ಆವೃತ್ತಿಗಳೊಂದಿಗೆ ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗಿದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that answers questions about cars based off a hybrid car data set.\n",
    "You must use the data set to answer the questions, you should not provide any information that is not in the provided sources.\n",
    "\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"how fast is a prius?\"\n",
    "\n",
    "# Open the CSV and store in a list\n",
    "with open(\"hybrid.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Normalize the user question to replace punctuation and make lowercase\n",
    "normalized_message = USER_MESSAGE.lower().replace(\"?\", \"\").replace(\"(\", \" \").replace(\")\", \" \")\n",
    "\n",
    "# Search the CSV for user question using very naive search\n",
    "words = normalized_message.split()\n",
    "matches = []\n",
    "for row in rows[1:]:\n",
    "    # if the word matches any word in row, add the row to the matches\n",
    "    if any(word in row[0].lower().split() for word in words) or any(word in row[5].lower().split() for word in words):\n",
    "        matches.append(row)\n",
    "\n",
    "# Format as a markdown table, since language models understand markdown\n",
    "matches_table = \" | \".join(rows[0]) + \"\\n\" + \" | \".join(\" --- \" for _ in range(len(rows[0]))) + \"\\n\"\n",
    "matches_table += \"\\n\".join(\" | \".join(row) for row in matches)\n",
    "print(f\"Found {len(matches)} matches:\")\n",
    "print(matches_table)\n",
    "\n",
    "# Now we can use the matches to generate a response\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE + \"\\nSources: \" + matches_table},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\nಅಸ್ವೀಕರಣ:\nಈ ದಸ್ತಾವೇಜನ್ನು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿಕೊಂಡು ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯತ್ತ ಪ್ರಯತ್ನಿಸುವಾಗಿಯೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ದೋಷಗಳು ಅಥವಾ ಅಸಂಜaatತೆಗಳು ಇರಬಹುದೆಂದು ದಯವಿಟ್ಟು ಗಮನದಲ್ಲಿರಿಸಿಕೊಂಡಿರಿರಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವಾಗಿ ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಸಲಹೆ ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದದ ಬಳಕೆಯಿಂದ ಉಂಟಾದ ಯಾವುದೇ ತಪ್ಪು ಗ್ರಹಿಕೆಗಳು ಅಥವಾ ತಪ್ಪಾದ ವಿವರಣೆಗಳಿಗೆ ನಾವು ಜವಾಬ್ದಾರರಾಗುವುದಿಲ್ಲ.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "coopTranslator": {
   "original_hash": "6f9e40a7dbbd892aae50aff77da4b4be",
   "translation_date": "2025-12-22T04:14:33+00:00",
   "source_file": "code/01.Introduce/ollama.ipynb",
   "language_code": "kn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}