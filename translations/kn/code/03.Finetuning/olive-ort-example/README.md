<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-12-21T16:52:31+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "kn"
}
-->
# Olive ‡≤¨‡≤≥‡≤∏‡≤ø Phi3 ‡≤Ö‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ç‡≤ï‡≥ç‡≤∑‡≥ç‡≤Æ-‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü (Fine-tune) ‡≤Æ‡≤æ‡≤°‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å

In this example you'll use Olive to:

1. Fine-tune a LoRA adapter to classify phrases into Sad, Joy, Fear, Surprise.
1. Merge the adapter weights into the base model.
1. Optimize and Quantize the model into `int4`.

We'll also show you how to inference the fine-tuned model using the ONNX Runtime (ORT) Generate API.

> **‚ö†Ô∏è ‡≤∏‡≥Ç‡≤ï‡≥ç‡≤∑‡≥ç‡≤Æ-‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü‡≤ó‡≤æ‡≤ó‡≤ø, ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤¨‡≤≥‡≤ø ‡≤∏‡≥Ç‡≤ï‡≥ç‡≤§ GPU ‡≤≤‡≤≠‡≥ç‡≤Ø‡≤µ‡≤ø‡≤∞‡≤¨‡≥á‡≤ï‡≥Å - ‡≤â‡≤¶‡≤æ‡≤π‡≤∞‡≤£‡≥Ü‡≤ó‡≥Ü, A10, V100, A100.**

## üíæ ‡≤∏‡≥ç‡≤•‡≤æ‡≤™‡≤®‡≥Ü

Create a new Python virtual environment (for example, using `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Next, install the Olive and the dependencies for a fine-tuning workflow:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Olive ‡≤¨‡≤≥‡≤∏‡≤ø Phi3 ‡≤Ö‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ç‡≤ï‡≥ç‡≤∑‡≥ç‡≤Æ-‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü (Fine-tune) ‡≤Æ‡≤æ‡≤°‡≤ø
The [Olive configuration file](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) contains a *workflow* with the following *passes*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

At a high-level, this workflow will:

1. [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) ‡≤°‡≥á‡≤ü‡≤æ ‡≤¨‡≤≥‡≤∏‡≤ø Phi3 ‡≤Ö‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ç‡≤ï‡≥ç‡≤∑‡≥ç‡≤Æ-‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü ‡≤Æ‡≤æ‡≤°‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å (150 ‡≤π‡≥Ü‡≤ú‡≥ç‡≤ú‡≥Ü‡≤ó‡≤≥‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø, ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤á‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤¨‡≤¶‡≤≤‡≤æ‡≤Ø‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≥Å).
1. LoRA ‡≤Ö‡≤°‡≤æ‡≤™‡≥ç‡≤ü‡≤∞‡≥ç ‡≤§‡≥Ç‡≤ï‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤¨‡≥á‡≤∏‡≥ç ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤µ‡≤ø‡≤≤‡≥Ä‡≤®‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å. ‡≤á‡≤¶‡≤∞‡≤ø‡≤Ç‡≤¶ ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ONNX ‡≤´‡≤æ‡≤∞‡≥ç‡≤Æ‡≥ç‡≤Ø‡≤æ‡≤ü‡≥ç‚Äå‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤í‡≤Ç‡≤¶‡≥á ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Ü‡≤∞‡≥ç‡≤ü‡≤ø‡≤´‡≥ç‡≤Ø‡≤æ‡≤ï‡≥ç ‡≤∏‡≤ø‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü.
1. Model Builder ONNX runtime ‡≤ó‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≥Å‡≤ï‡≥ç‡≤§‡≤µ‡≤æ‡≤ó‡≥Å‡≤µ‡≤Ç‡≤§‡≥Ü ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤∏‡≥ç ‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü *‡≤Æ‡≤§‡≥ç‡≤§‡≥Å* ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å `int4` ‡≤ó‡≥Ü ‡≤ï‡≥ç‡≤µ‡≤æ‡≤Ç‡≤ü‡≥à‡≤ú‡≥ç ‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü.

To execute the workflow, run:

```bash
olive run --config phrase-classification.json
```

When Olive has completed, you're optimized `int4` fine-tuned Phi3 model is available in: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª ‡≤∏‡≥Ç‡≤ï‡≥ç‡≤∑‡≥ç‡≤Æ-‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤ø‡≤§ Phi3 ‡≤Ö‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤™‡≥ç‡≤≤‡≤ø‡≤ï‡≥á‡≤∂‡≤®‡≥ç‚Äå‡≤ó‡≥Ü ‡≤í‡≤ó‡≥ç‡≤ó‡≥Ç‡≤°‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å

To run the app:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

This response should be a single word classification of the phrase (Sad/Joy/Fear/Surprise).

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
‡≤®‡≤ø‡≤∞‡≤æ‡≤ï‡≤∞‡≤£‡≥Ü:
‡≤à ‡≤¶‡≤∏‡≥ç‡≤§‡≤æ‡≤µ‡≥á‡≤ú‡≤®‡≥ç‡≤®‡≥Å AI ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤∏‡≥á‡≤µ‡≥Ü [Co-op Translator](https://github.com/Azure/co-op-translator) ‡≤¨‡≤≥‡≤∏‡≤ø ‡≤Ö‡≤®‡≥Å‡≤µ‡≤¶‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤®‡≤æ‡≤µ‡≥Å ‡≤∂‡≥Å‡≤¶‡≥ç‡≤ß‡≤§‡≥Ü‡≤ó‡≤æ‡≤ó‡≤ø ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≤∞‡≥Ç ‡≤∏‡≤π, ‡≤∏‡≥ç‡≤µ‡≤Ø‡≤Ç‡≤ö‡≤æ‡≤≤‡≤ø‡≤§ ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤¶‡≥ã‡≤∑‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤Ö‡≤∏‡≤§‡≥ç‡≤Ø‡≤§‡≥Ü‡≤ó‡≤≥‡≥Å ‡≤á‡≤∞‡≥Å‡≤µ ‡≤∏‡≤Ç‡≤≠‡≤µ‡≤®‡≥Ä‡≤Ø‡≤§‡≥Ü ‡≤á‡≤¶‡≥Ü ‡≤é‡≤Ç‡≤¶‡≥Å ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤ó‡≤Æ‡≤®‡≤ø‡≤∏‡≤ø. ‡≤Æ‡≥Ç‡≤≤ ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤á‡≤∞‡≥Å‡≤µ ‡≤Æ‡≥Ç‡≤≤ ‡≤¶‡≤∏‡≥ç‡≤§‡≤æ‡≤µ‡≥á‡≤ú‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤ß‡≤ø‡≤ï‡≥É‡≤§ ‡≤Æ‡≥Ç‡≤≤‡≤µ‡≥Ü‡≤®‡≥ç‡≤®‡≤ø‡≤∏‡≤ø ‡≤™‡≤∞‡≤ø‡≤ó‡≤£‡≤ø‡≤∏‡≤¨‡≥á‡≤ï‡≥Å. ‡≤ó‡≤Ç‡≤≠‡≥Ä‡≤∞ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø ‡≤µ‡≥É‡≤§‡≥ç‡≤§‡≤ø‡≤™‡≤∞ ‡≤Æ‡≤æ‡≤®‡≤µ ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤∂‡≤ø‡≤´‡≤æ‡≤∞‡≤∏‡≥Å ‡≤Æ‡≤æ‡≤°‡≤≤‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤à ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤¶ ‡≤¨‡≤≥‡≤ï‡≥Ü‡≤Ø‡≤ø‡≤Ç‡≤¶ ‡≤â‡≤Ç‡≤ü‡≤æ‡≤ó‡≥Å‡≤µ ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤Ö‡≤∏‡≤Æoju? (‡≤Ö‡≤∏‡≤Æ‡≤Ç‡≤ú‡≤∏‡≥ç‡≤Ø‡≤§‡≥Ü‡≤ó‡≤≥‡≥Å) ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤§‡≤™‡≥ç‡≤™‡≥Å ‡≤Ö‡≤∞‡≥ç‡≤•‡≤ó‡≤∞‡≥ç‡≤≠‡≤ø‡≤§‡≤ï‡≥ç‡≤ï‡≤æ‡≤ó‡≤ø ‡≤®‡≤æ‡≤µ‡≥Å ‡≤ú‡≤µ‡≤æ‡≤¨‡≥ç‡≤¶‡≤æ‡≤∞‡≤ø‡≤Ø‡≤≤‡≥ç‡≤≤.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->