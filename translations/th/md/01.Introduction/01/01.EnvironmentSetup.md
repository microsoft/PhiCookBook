<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:09:18+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "th"
}
-->
# เริ่มต้นใช้งาน Phi-3 แบบโลคอล

คำแนะนำนี้จะช่วยคุณตั้งค่าสภาพแวดล้อมในเครื่องเพื่อรันโมเดล Phi-3 โดยใช้ Ollama คุณสามารถรันโมเดลได้หลายวิธี เช่น ใช้ GitHub Codespaces, VS Code Dev Containers หรือสภาพแวดล้อมในเครื่องของคุณเอง

## การตั้งค่าสภาพแวดล้อม

### GitHub Codespaces

คุณสามารถรันเทมเพลตนี้แบบเสมือนโดยใช้ GitHub Codespaces ปุ่มนี้จะเปิด VS Code เวอร์ชันเว็บในเบราว์เซอร์ของคุณ:

1. เปิดเทมเพลต (อาจใช้เวลาหลายนาที):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. เปิดหน้าต่างเทอร์มินัล

### VS Code Dev Containers

⚠️ ตัวเลือกนี้จะใช้งานได้ก็ต่อเมื่อ Docker Desktop ของคุณมี RAM อย่างน้อย 16 GB หาก RAM ของคุณน้อยกว่า 16 GB คุณสามารถลองใช้ [GitHub Codespaces option](../../../../../md/01.Introduction/01) หรือ [ตั้งค่าแบบโลคอล](../../../../../md/01.Introduction/01)

อีกตัวเลือกหนึ่งคือ VS Code Dev Containers ซึ่งจะเปิดโปรเจกต์ใน VS Code บนเครื่องของคุณโดยใช้ [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. เริ่ม Docker Desktop (ติดตั้งถ้ายังไม่มี)
2. เปิดโปรเจกต์:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. ในหน้าต่าง VS Code ที่เปิดขึ้น เมื่อไฟล์โปรเจกต์แสดงขึ้น (อาจใช้เวลาหลายนาที) ให้เปิดหน้าต่างเทอร์มินัล
4. ดำเนินการต่อด้วย [ขั้นตอนการดีพลอย](../../../../../md/01.Introduction/01)

### สภาพแวดล้อมในเครื่อง

1. ตรวจสอบให้แน่ใจว่าเครื่องมือดังต่อไปนี้ถูกติดตั้งแล้ว:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## ทดสอบโมเดล

1. ขอให้ Ollama ดาวน์โหลดและรันโมเดล phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    การดาวน์โหลดโมเดลนี้อาจใช้เวลาสักครู่

2. เมื่อเห็นข้อความ "success" ในผลลัพธ์ คุณสามารถส่งข้อความไปยังโมเดลนั้นจากพรอมต์ได้

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. หลังจากไม่กี่วินาที คุณจะเห็นการตอบกลับแบบสตรีมจากโมเดล

4. เพื่อเรียนรู้เทคนิคต่าง ๆ ที่ใช้กับโมเดลภาษา ให้เปิดโน้ตบุ๊ก Python [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) และรันแต่ละเซลล์ หากคุณใช้โมเดลอื่นที่ไม่ใช่ 'phi3:mini' ให้เปลี่ยน `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` ที่ด้านบนของไฟล์ตามต้องการ และคุณยังสามารถแก้ไขข้อความระบบหรือเพิ่มตัวอย่าง few-shot ได้ตามต้องการ

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษาอัตโนมัติ [Co-op Translator](https://github.com/Azure/co-op-translator) แม้เราจะพยายามให้ความถูกต้องสูงสุด แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นทางถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้การแปลโดยผู้เชี่ยวชาญมนุษย์ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดใด ๆ ที่เกิดจากการใช้การแปลนี้