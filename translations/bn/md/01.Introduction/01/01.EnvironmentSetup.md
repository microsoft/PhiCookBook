<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:02:46+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "bn"
}
-->
# Phi-3 স্থানীয়ভাবে শুরু করুন

এই গাইডটি আপনাকে Ollama ব্যবহার করে Phi-3 মডেল চালানোর জন্য আপনার লোকাল পরিবেশ সেটআপ করতে সাহায্য করবে। আপনি মডেলটি বিভিন্নভাবে চালাতে পারেন, যেমন GitHub Codespaces, VS Code Dev Containers, অথবা আপনার লোকাল পরিবেশ ব্যবহার করে।

## পরিবেশ সেটআপ

### GitHub Codespaces

আপনি GitHub Codespaces ব্যবহার করে এই টেমপ্লেটটি ভার্চুয়ালি চালাতে পারেন। নিচের বোতামটি আপনার ব্রাউজারে একটি ওয়েব-ভিত্তিক VS Code ইন্সট্যান্স খুলবে:

1. টেমপ্লেটটি খুলুন (এতে কয়েক মিনিট সময় লাগতে পারে):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. একটি টার্মিনাল উইন্ডো খুলুন

### VS Code Dev Containers

⚠️ এই অপশনটি শুধুমাত্র তখনই কাজ করবে যদি আপনার Docker Desktop-এ কমপক্ষে 16 GB RAM বরাদ্দ করা থাকে। যদি আপনার RAM 16 GB এর কম হয়, তাহলে আপনি [GitHub Codespaces অপশন](../../../../../md/01.Introduction/01) ব্যবহার করতে পারেন অথবা [লোকালভাবে সেটআপ করতে পারেন](../../../../../md/01.Introduction/01)।

একটি সংশ্লিষ্ট অপশন হল VS Code Dev Containers, যা আপনার লোকাল VS Code-এ প্রজেক্টটি খুলবে [Dev Containers এক্সটেনশন](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) ব্যবহার করে:

1. Docker Desktop চালু করুন (যদি ইনস্টল না করা থাকে তবে ইনস্টল করুন)
2. প্রজেক্টটি খুলুন:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. VS Code উইন্ডোতে, যখন প্রজেক্ট ফাইলগুলো দেখা যাবে (এতে কয়েক মিনিট সময় লাগতে পারে), একটি টার্মিনাল উইন্ডো খুলুন।
4. [ডিপ্লয়মেন্ট ধাপগুলো](../../../../../md/01.Introduction/01) অনুসরণ করুন

### লোকাল পরিবেশ

1. নিচের টুলগুলো ইনস্টল করা আছে কিনা নিশ্চিত করুন:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## মডেল পরীক্ষা করুন

1. Ollama-কে phi3:mini মডেল ডাউনলোড ও চালানোর জন্য বলুন:

    ```shell
    ollama run phi3:mini
    ```

    মডেলটি ডাউনলোড হতে কিছু সময় লাগবে।

2. আউটপুটে "success" দেখার পর, আপনি প্রম্পট থেকে ওই মডেলে মেসেজ পাঠাতে পারবেন।

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. কয়েক সেকেন্ডের মধ্যে, মডেল থেকে একটি রেসপন্স স্ট্রিম আসতে শুরু করবে।

4. ভাষার মডেলগুলোর বিভিন্ন প্রযুক্তি সম্পর্কে জানতে, Python নোটবুক [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) খুলুন এবং প্রতিটি সেল রান করুন। আপনি যদি 'phi3:mini' ছাড়া অন্য মডেল ব্যবহার করেন, তাহলে ফাইলের শীর্ষে `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` পরিবর্তন করুন, এবং চাইলে সিস্টেম মেসেজ বা few-shot উদাহরণ যোগ করতে পারেন।

**অস্বীকারোক্তি**:  
এই নথিটি AI অনুবাদ সেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনূদিত হয়েছে। আমরা যথাসাধ্য সঠিকতার চেষ্টা করি, তবে দয়া করে লক্ষ্য করুন যে স্বয়ংক্রিয় অনুবাদে ভুল বা অসঙ্গতি থাকতে পারে। মূল নথিটি তার নিজস্ব ভাষায় কর্তৃত্বপূর্ণ উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য পেশাদার মানব অনুবাদের পরামর্শ দেওয়া হয়। এই অনুবাদের ব্যবহারে সৃষ্ট কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।