{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **নমুনা: Apple MLX ফ্রেমওয়ার্ক দিয়ে Phi-4-mini-reasoning এর ফাইন-টিউনিং**\n",
    "\n",
    "এটি FreedomIntelligence/medical-o1-reasoning-SFT এর ডেটার উপর ভিত্তি করে তৈরি, যা Phi-4-mini-reasoning এর মেডিকেল ইভেন্ট সম্পর্কে যুক্তি প্রদানের ক্ষমতা উন্নত করে। যদি আপনি ডেটা সম্পর্কে আরও জানতে চান, তাহলে এই লিঙ্কটি ব্যবহার করে আরও জানতে পারেন: https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT \n",
    "\n",
    "*নোট: অনুগ্রহ করে আপনার GPU হিসেবে A100 ব্যবহার করুন*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UifUppNJUHvb",
    "outputId": "9effcd16-7157-485e-d994-e7342474eb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U575hhJFVAYy",
    "outputId": "424e00d4-4a61-4429-c5b2-8944fea3e555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/microsoft/Olive.git\n",
      "  Cloning https://github.com/microsoft/Olive.git to /tmp/pip-req-build-pyv0hj3q\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/Olive.git /tmp/pip-req-build-pyv0hj3q\n",
      "  Resolved https://github.com/microsoft/Olive.git to commit 422353ecb6ca724495e7a6f366fb53a8b3146818\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from olive-ai==0.9.0.dev0) (2.0.2)\n",
      "Collecting onnx (from olive-ai==0.9.0.dev0)\n",
      "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxscript>=0.2.5 (from olive-ai==0.9.0.dev0)\n",
      "  Downloading onnxscript-0.2.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting optuna (from olive-ai==0.9.0.dev0)\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from olive-ai==0.9.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from olive-ai==0.9.0.dev0) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from olive-ai==0.9.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from olive-ai==0.9.0.dev0) (2.6.0+cu124)\n",
      "Collecting torchmetrics>=1.0.0 (from olive-ai==0.9.0.dev0)\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from olive-ai==0.9.0.dev0) (4.51.3)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from onnxscript>=0.2.5->olive-ai==0.9.0.dev0) (4.13.2)\n",
      "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.11/dist-packages (from onnxscript>=0.2.5->olive-ai==0.9.0.dev0) (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxscript>=0.2.5->olive-ai==0.9.0.dev0) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->olive-ai==0.9.0.dev0) (5.29.4)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics>=1.0.0->olive-ai==0.9.0.dev0)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->olive-ai==0.9.0.dev0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->olive-ai==0.9.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->olive-ai==0.9.0.dev0) (1.3.0)\n",
      "Collecting alembic>=1.5.0 (from optuna->olive-ai==0.9.0.dev0)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna->olive-ai==0.9.0.dev0)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->olive-ai==0.9.0.dev0) (2.0.40)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->olive-ai==0.9.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->olive-ai==0.9.0.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->olive-ai==0.9.0.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->olive-ai==0.9.0.dev0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->olive-ai==0.9.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->olive-ai==0.9.0.dev0) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->olive-ai==0.9.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->olive-ai==0.9.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->olive-ai==0.9.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->olive-ai==0.9.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->olive-ai==0.9.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->olive-ai==0.9.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->olive-ai==0.9.0.dev0) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics>=1.0.0->olive-ai==0.9.0.dev0) (75.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->olive-ai==0.9.0.dev0) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->olive-ai==0.9.0.dev0) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->olive-ai==0.9.0.dev0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->olive-ai==0.9.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->olive-ai==0.9.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->olive-ai==0.9.0.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->olive-ai==0.9.0.dev0) (2025.1.31)\n",
      "Downloading onnxscript-0.2.5-py3-none-any.whl (689 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.4/689.4 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: olive-ai\n",
      "  Building wheel for olive-ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for olive-ai: filename=olive_ai-0.9.0.dev0-py3-none-any.whl size=678047 sha256=133069a53286d8574a83091305a9403d7a8b6a43f7fd30f306432e7a9e063479\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qyw2f_it/wheels/c2/08/a8/f19f55dd14ff36a1d7709e82e53bf27670e8cd7b38ce62bc23\n",
      "Successfully built olive-ai\n",
      "Installing collected packages: onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorlog, onnxscript, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12, torchmetrics, olive-ai\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed alembic-1.15.2 colorlog-6.9.0 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 olive-ai-0.9.0.dev0 onnx-1.17.0 onnxscript-0.2.5 optuna-4.3.0 torchmetrics-1.7.1\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/microsoft/Olive.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzDt47bDV9-j",
    "outputId": "42eae376-1786-4175-f7e2-c6bc8c639e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.49.0\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0) (2025.1.31)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed transformers-4.49.0\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers==4.49.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "5PC7LxU6Y1KV",
    "outputId": "e3ba23da-0f13-4eda-8fb1-329091e4c7de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/162.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.4\n",
      "    Uninstalling protobuf-5.29.4:\n",
      "      Successfully uninstalled protobuf-5.29.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "08b09667304b421cb563ff96c6bcbe32",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install protobuf==3.20.3 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "SKeqO0NpOwVW",
    "outputId": "982129f7-8ae7-4e12-b5dc-85e04cf2d510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime-genai-cuda\n",
      "  Downloading onnxruntime_genai_cuda-0.7.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (525 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-genai-cuda) (2.0.2)\n",
      "Collecting onnxruntime-gpu>=1.21.0 (from onnxruntime-genai-cuda)\n",
      "  Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (25.2.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (24.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (1.13.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu>=1.21.0->onnxruntime-genai-cuda) (1.3.0)\n",
      "Downloading onnxruntime_genai_cuda-0.7.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime-gpu, onnxruntime-genai-cuda\n",
      "Successfully installed onnxruntime-genai-cuda-0.7.1 onnxruntime-gpu-1.21.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "2565d9516e25415d9affef02ed42620c",
       "pip_warning": {
        "packages": [
         "onnxruntime_genai"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install onnxruntime-genai-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fsBY6j8OobP",
    "outputId": "6645703c-6b64-422f-e211-1659686e7cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                               Version\n",
      "------------------------------------- ---------------------\n",
      "absl-py                               1.4.0\n",
      "accelerate                            1.6.0\n",
      "aiohappyeyeballs                      2.6.1\n",
      "aiohttp                               3.11.15\n",
      "aiosignal                             1.3.2\n",
      "alabaster                             1.0.0\n",
      "albucore                              0.0.23\n",
      "albumentations                        2.0.5\n",
      "ale-py                                0.10.2\n",
      "alembic                               1.15.2\n",
      "altair                                5.5.0\n",
      "annotated-types                       0.7.0\n",
      "anyio                                 4.9.0\n",
      "argon2-cffi                           23.1.0\n",
      "argon2-cffi-bindings                  21.2.0\n",
      "array_record                          0.7.1\n",
      "arviz                                 0.21.0\n",
      "astropy                               7.0.1\n",
      "astropy-iers-data                     0.2025.4.21.0.37.6\n",
      "astunparse                            1.6.3\n",
      "atpublic                              5.1\n",
      "attrs                                 25.3.0\n",
      "audioread                             3.0.1\n",
      "autograd                              1.7.0\n",
      "babel                                 2.17.0\n",
      "backcall                              0.2.0\n",
      "backports.tarfile                     1.2.0\n",
      "beautifulsoup4                        4.13.4\n",
      "betterproto                           2.0.0b6\n",
      "bigframes                             2.1.0\n",
      "bigquery-magics                       0.9.0\n",
      "bleach                                6.2.0\n",
      "blinker                               1.9.0\n",
      "blis                                  1.3.0\n",
      "blosc2                                3.3.1\n",
      "bokeh                                 3.7.2\n",
      "Bottleneck                            1.4.2\n",
      "bqplot                                0.12.44\n",
      "branca                                0.8.1\n",
      "CacheControl                          0.14.2\n",
      "cachetools                            5.5.2\n",
      "catalogue                             2.0.10\n",
      "certifi                               2025.1.31\n",
      "cffi                                  1.17.1\n",
      "chardet                               5.2.0\n",
      "charset-normalizer                    3.4.1\n",
      "chex                                  0.1.89\n",
      "clarabel                              0.10.0\n",
      "click                                 8.1.8\n",
      "cloudpathlib                          0.21.0\n",
      "cloudpickle                           3.1.1\n",
      "cmake                                 3.31.6\n",
      "cmdstanpy                             1.2.5\n",
      "colorcet                              3.1.0\n",
      "coloredlogs                           15.0.1\n",
      "colorlog                              6.9.0\n",
      "colorlover                            0.3.0\n",
      "colour                                0.1.5\n",
      "community                             1.0.0b1\n",
      "confection                            0.1.5\n",
      "cons                                  0.4.6\n",
      "contourpy                             1.3.2\n",
      "cramjam                               2.10.0\n",
      "cryptography                          43.0.3\n",
      "cuda-python                           12.6.2.post1\n",
      "cudf-cu12                             25.2.1\n",
      "cudf-polars-cu12                      25.2.2\n",
      "cufflinks                             0.17.3\n",
      "cuml-cu12                             25.2.1\n",
      "cupy-cuda12x                          13.3.0\n",
      "cuvs-cu12                             25.2.1\n",
      "cvxopt                                1.3.2\n",
      "cvxpy                                 1.6.5\n",
      "cycler                                0.12.1\n",
      "cyipopt                               1.5.0\n",
      "cymem                                 2.0.11\n",
      "Cython                                3.0.12\n",
      "dask                                  2024.12.1\n",
      "dask-cuda                             25.2.0\n",
      "dask-cudf-cu12                        25.2.2\n",
      "dask-expr                             1.1.21\n",
      "datascience                           0.17.6\n",
      "datasets                              3.5.1\n",
      "db-dtypes                             1.4.2\n",
      "dbus-python                           1.2.18\n",
      "debugpy                               1.8.0\n",
      "decorator                             4.4.2\n",
      "defusedxml                            0.7.1\n",
      "Deprecated                            1.2.18\n",
      "diffusers                             0.33.1\n",
      "dill                                  0.3.8\n",
      "distributed                           2024.12.1\n",
      "distributed-ucxx-cu12                 0.42.0\n",
      "distro                                1.9.0\n",
      "dlib                                  19.24.6\n",
      "dm-tree                               0.1.9\n",
      "docker-pycreds                        0.4.0\n",
      "docstring_parser                      0.16\n",
      "docutils                              0.21.2\n",
      "dopamine_rl                           4.1.2\n",
      "duckdb                                1.2.2\n",
      "earthengine-api                       1.5.12\n",
      "easydict                              1.13\n",
      "editdistance                          0.8.1\n",
      "eerepr                                0.1.1\n",
      "einops                                0.8.1\n",
      "en_core_web_sm                        3.8.0\n",
      "entrypoints                           0.4\n",
      "et_xmlfile                            2.0.0\n",
      "etils                                 1.12.2\n",
      "etuples                               0.3.9\n",
      "Farama-Notifications                  0.0.4\n",
      "fastai                                2.7.19\n",
      "fastcore                              1.7.29\n",
      "fastdownload                          0.0.7\n",
      "fastjsonschema                        2.21.1\n",
      "fastprogress                          1.0.3\n",
      "fastrlock                             0.8.3\n",
      "filelock                              3.18.0\n",
      "firebase-admin                        6.8.0\n",
      "Flask                                 3.1.0\n",
      "flatbuffers                           25.2.10\n",
      "flax                                  0.10.6\n",
      "folium                                0.19.5\n",
      "fonttools                             4.57.0\n",
      "frozendict                            2.4.6\n",
      "frozenlist                            1.6.0\n",
      "fsspec                                2025.3.0\n",
      "future                                1.0.0\n",
      "gast                                  0.6.0\n",
      "gcsfs                                 2025.3.2\n",
      "GDAL                                  3.6.4\n",
      "gdown                                 5.2.0\n",
      "geemap                                0.35.3\n",
      "geocoder                              1.38.1\n",
      "geographiclib                         2.0\n",
      "geopandas                             1.0.1\n",
      "geopy                                 2.4.1\n",
      "gin-config                            0.5.0\n",
      "gitdb                                 4.0.12\n",
      "GitPython                             3.1.44\n",
      "glob2                                 0.7\n",
      "google                                2.0.3\n",
      "google-ai-generativelanguage          0.6.15\n",
      "google-api-core                       2.24.2\n",
      "google-api-python-client              2.168.0\n",
      "google-auth                           2.38.0\n",
      "google-auth-httplib2                  0.2.0\n",
      "google-auth-oauthlib                  1.2.2\n",
      "google-cloud-aiplatform               1.90.0\n",
      "google-cloud-bigquery                 3.31.0\n",
      "google-cloud-bigquery-connection      1.18.2\n",
      "google-cloud-bigquery-storage         2.31.0\n",
      "google-cloud-bigtable                 2.30.1\n",
      "google-cloud-core                     2.4.3\n",
      "google-cloud-dataproc                 5.18.1\n",
      "google-cloud-datastore                2.21.0\n",
      "google-cloud-firestore                2.20.2\n",
      "google-cloud-functions                1.20.3\n",
      "google-cloud-iam                      2.19.0\n",
      "google-cloud-language                 2.17.1\n",
      "google-cloud-pubsub                   2.29.0\n",
      "google-cloud-resource-manager         1.14.2\n",
      "google-cloud-spanner                  3.53.0\n",
      "google-cloud-storage                  2.19.0\n",
      "google-cloud-translate                3.20.2\n",
      "google-colab                          1.0.0\n",
      "google-crc32c                         1.7.1\n",
      "google-genai                          1.12.1\n",
      "google-generativeai                   0.8.5\n",
      "google-pasta                          0.2.0\n",
      "google-resumable-media                2.7.2\n",
      "google-spark-connect                  0.5.2\n",
      "googleapis-common-protos              1.70.0\n",
      "googledrivedownloader                 1.1.0\n",
      "graphviz                              0.20.3\n",
      "greenlet                              3.2.1\n",
      "grpc-google-iam-v1                    0.14.2\n",
      "grpc-interceptor                      0.15.4\n",
      "grpcio                                1.71.0\n",
      "grpcio-status                         1.71.0\n",
      "grpclib                               0.4.7\n",
      "gspread                               6.2.0\n",
      "gspread-dataframe                     4.0.0\n",
      "gym                                   0.25.2\n",
      "gym-notices                           0.0.8\n",
      "gymnasium                             1.1.1\n",
      "h11                                   0.16.0\n",
      "h2                                    4.2.0\n",
      "h5netcdf                              1.6.1\n",
      "h5py                                  3.13.0\n",
      "hdbscan                               0.8.40\n",
      "highspy                               1.10.0\n",
      "holidays                              0.71\n",
      "holoviews                             1.20.2\n",
      "hpack                                 4.1.0\n",
      "html5lib                              1.1\n",
      "httpcore                              1.0.9\n",
      "httpimport                            1.4.1\n",
      "httplib2                              0.22.0\n",
      "httpx                                 0.28.1\n",
      "huggingface-hub                       0.30.2\n",
      "humanfriendly                         10.0\n",
      "humanize                              4.12.2\n",
      "hyperframe                            6.1.0\n",
      "hyperopt                              0.2.7\n",
      "ibis-framework                        9.5.0\n",
      "idna                                  3.10\n",
      "imageio                               2.37.0\n",
      "imageio-ffmpeg                        0.6.0\n",
      "imagesize                             1.4.1\n",
      "imbalanced-learn                      0.13.0\n",
      "immutabledict                         4.2.1\n",
      "importlib_metadata                    8.6.1\n",
      "importlib_resources                   6.5.2\n",
      "imutils                               0.5.4\n",
      "inflect                               7.5.0\n",
      "iniconfig                             2.1.0\n",
      "intel-cmplr-lib-ur                    2025.1.0\n",
      "intel-openmp                          2025.1.0\n",
      "ipyevents                             2.0.2\n",
      "ipyfilechooser                        0.6.0\n",
      "ipykernel                             6.17.1\n",
      "ipyleaflet                            0.19.2\n",
      "ipyparallel                           8.8.0\n",
      "ipython                               7.34.0\n",
      "ipython-genutils                      0.2.0\n",
      "ipython-sql                           0.5.0\n",
      "ipytree                               0.2.2\n",
      "ipywidgets                            7.7.1\n",
      "itsdangerous                          2.2.0\n",
      "jaraco.classes                        3.4.0\n",
      "jaraco.context                        6.0.1\n",
      "jaraco.functools                      4.1.0\n",
      "jax                                   0.5.2\n",
      "jax-cuda12-pjrt                       0.5.1\n",
      "jax-cuda12-plugin                     0.5.1\n",
      "jaxlib                                0.5.1\n",
      "jeepney                               0.9.0\n",
      "jieba                                 0.42.1\n",
      "Jinja2                                3.1.6\n",
      "jiter                                 0.9.0\n",
      "joblib                                1.4.2\n",
      "jsonpatch                             1.33\n",
      "jsonpickle                            4.0.5\n",
      "jsonpointer                           3.0.0\n",
      "jsonschema                            4.23.0\n",
      "jsonschema-specifications             2025.4.1\n",
      "jupyter-client                        6.1.12\n",
      "jupyter-console                       6.1.0\n",
      "jupyter_core                          5.7.2\n",
      "jupyter-leaflet                       0.19.2\n",
      "jupyter-server                        1.16.0\n",
      "jupyterlab_pygments                   0.3.0\n",
      "jupyterlab_widgets                    3.0.14\n",
      "kaggle                                1.7.4.2\n",
      "kagglehub                             0.3.12\n",
      "keras                                 3.8.0\n",
      "keras-hub                             0.18.1\n",
      "keras-nlp                             0.18.1\n",
      "keyring                               25.6.0\n",
      "keyrings.google-artifactregistry-auth 1.1.2\n",
      "kiwisolver                            1.4.8\n",
      "langchain                             0.3.24\n",
      "langchain-core                        0.3.56\n",
      "langchain-text-splitters              0.3.8\n",
      "langcodes                             3.5.0\n",
      "langsmith                             0.3.34\n",
      "language_data                         1.3.0\n",
      "launchpadlib                          1.10.16\n",
      "lazr.restfulclient                    0.14.4\n",
      "lazr.uri                              1.0.6\n",
      "lazy_loader                           0.4\n",
      "libclang                              18.1.1\n",
      "libcudf-cu12                          25.2.1\n",
      "libcugraph-cu12                       25.2.0\n",
      "libcuml-cu12                          25.2.1\n",
      "libcuvs-cu12                          25.2.1\n",
      "libkvikio-cu12                        25.2.1\n",
      "libraft-cu12                          25.2.0\n",
      "librosa                               0.11.0\n",
      "libucx-cu12                           1.18.0.post1\n",
      "libucxx-cu12                          0.42.0\n",
      "lightgbm                              4.5.0\n",
      "lightning-utilities                   0.14.3\n",
      "linkify-it-py                         2.0.3\n",
      "llvmlite                              0.43.0\n",
      "locket                                1.0.0\n",
      "logical-unification                   0.4.6\n",
      "lxml                                  5.4.0\n",
      "Mako                                  1.1.3\n",
      "marisa-trie                           1.2.1\n",
      "Markdown                              3.8\n",
      "markdown-it-py                        3.0.0\n",
      "MarkupSafe                            3.0.2\n",
      "matplotlib                            3.10.0\n",
      "matplotlib-inline                     0.1.7\n",
      "matplotlib-venn                       1.1.2\n",
      "mdit-py-plugins                       0.4.2\n",
      "mdurl                                 0.1.2\n",
      "miniKanren                            1.0.3\n",
      "missingno                             0.5.2\n",
      "mistune                               3.1.3\n",
      "mizani                                0.13.3\n",
      "mkl                                   2025.0.1\n",
      "ml-dtypes                             0.4.1\n",
      "mlxtend                               0.23.4\n",
      "more-itertools                        10.7.0\n",
      "moviepy                               1.0.3\n",
      "mpmath                                1.3.0\n",
      "msgpack                               1.1.0\n",
      "multidict                             6.4.3\n",
      "multipledispatch                      1.0.0\n",
      "multiprocess                          0.70.16\n",
      "multitasking                          0.0.11\n",
      "murmurhash                            1.0.12\n",
      "music21                               9.3.0\n",
      "namex                                 0.0.9\n",
      "narwhals                              1.36.0\n",
      "natsort                               8.4.0\n",
      "nbclassic                             1.3.0\n",
      "nbclient                              0.10.2\n",
      "nbconvert                             7.16.6\n",
      "nbformat                              5.10.4\n",
      "ndindex                               1.9.2\n",
      "nest-asyncio                          1.6.0\n",
      "networkx                              3.4.2\n",
      "nibabel                               5.3.2\n",
      "nltk                                  3.9.1\n",
      "notebook                              6.5.7\n",
      "notebook_shim                         0.2.4\n",
      "numba                                 0.60.0\n",
      "numba-cuda                            0.2.0\n",
      "numexpr                               2.10.2\n",
      "numpy                                 2.0.2\n",
      "nvidia-cublas-cu12                    12.4.5.8\n",
      "nvidia-cuda-cupti-cu12                12.4.127\n",
      "nvidia-cuda-nvcc-cu12                 12.5.82\n",
      "nvidia-cuda-nvrtc-cu12                12.4.127\n",
      "nvidia-cuda-runtime-cu12              12.4.127\n",
      "nvidia-cudnn-cu12                     9.1.0.70\n",
      "nvidia-cufft-cu12                     11.2.1.3\n",
      "nvidia-curand-cu12                    10.3.5.147\n",
      "nvidia-cusolver-cu12                  11.6.1.9\n",
      "nvidia-cusparse-cu12                  12.3.1.170\n",
      "nvidia-cusparselt-cu12                0.6.2\n",
      "nvidia-ml-py                          12.570.86\n",
      "nvidia-nccl-cu12                      2.21.5\n",
      "nvidia-nvcomp-cu12                    4.2.0.11\n",
      "nvidia-nvjitlink-cu12                 12.4.127\n",
      "nvidia-nvtx-cu12                      12.4.127\n",
      "nvtx                                  0.2.11\n",
      "nx-cugraph-cu12                       25.2.0\n",
      "oauth2client                          4.1.3\n",
      "oauthlib                              3.2.2\n",
      "olive-ai                              0.9.0.dev0\n",
      "onnx                                  1.17.0\n",
      "onnxruntime                           1.23.0.dev20250429003\n",
      "onnxruntime-genai                     0.8.0.dev0\n",
      "onnxscript                            0.2.5\n",
      "openai                                1.76.0\n",
      "opencv-contrib-python                 4.11.0.86\n",
      "opencv-python                         4.11.0.86\n",
      "opencv-python-headless                4.11.0.86\n",
      "openpyxl                              3.1.5\n",
      "opentelemetry-api                     1.32.1\n",
      "opentelemetry-sdk                     1.32.1\n",
      "opentelemetry-semantic-conventions    0.53b1\n",
      "opt_einsum                            3.4.0\n",
      "optax                                 0.2.4\n",
      "optree                                0.15.0\n",
      "optuna                                4.3.0\n",
      "orbax-checkpoint                      0.11.12\n",
      "orjson                                3.10.16\n",
      "osqp                                  1.0.3\n",
      "packaging                             24.2\n",
      "pandas                                2.2.2\n",
      "pandas-datareader                     0.10.0\n",
      "pandas-gbq                            0.28.0\n",
      "pandas-stubs                          2.2.2.240909\n",
      "pandocfilters                         1.5.1\n",
      "panel                                 1.6.3\n",
      "param                                 2.2.0\n",
      "parso                                 0.8.4\n",
      "parsy                                 2.1\n",
      "partd                                 1.4.2\n",
      "pathlib                               1.0.1\n",
      "patsy                                 1.0.1\n",
      "peewee                                3.17.9\n",
      "peft                                  0.15.2\n",
      "pexpect                               4.9.0\n",
      "pickleshare                           0.7.5\n",
      "pillow                                11.2.1\n",
      "pip                                   24.1.2\n",
      "platformdirs                          4.3.7\n",
      "plotly                                5.24.1\n",
      "plotnine                              0.14.5\n",
      "pluggy                                1.5.0\n",
      "ply                                   3.11\n",
      "polars                                1.21.0\n",
      "pooch                                 1.8.2\n",
      "portpicker                            1.5.2\n",
      "preshed                               3.0.9\n",
      "prettytable                           3.16.0\n",
      "proglog                               0.1.11\n",
      "progressbar2                          4.5.0\n",
      "prometheus_client                     0.21.1\n",
      "promise                               2.3\n",
      "prompt_toolkit                        3.0.51\n",
      "propcache                             0.3.1\n",
      "prophet                               1.1.6\n",
      "proto-plus                            1.26.1\n",
      "protobuf                              3.20.3\n",
      "psutil                                5.9.5\n",
      "psycopg2                              2.9.10\n",
      "ptyprocess                            0.7.0\n",
      "py-cpuinfo                            9.0.0\n",
      "py4j                                  0.10.9.7\n",
      "pyarrow                               18.1.0\n",
      "pyasn1                                0.6.1\n",
      "pyasn1_modules                        0.4.2\n",
      "pycairo                               1.28.0\n",
      "pycocotools                           2.0.8\n",
      "pycparser                             2.22\n",
      "pydantic                              2.11.3\n",
      "pydantic_core                         2.33.1\n",
      "pydata-google-auth                    1.9.1\n",
      "pydot                                 3.0.4\n",
      "pydotplus                             2.0.2\n",
      "PyDrive                               1.3.1\n",
      "PyDrive2                              1.21.3\n",
      "pyerfa                                2.0.1.5\n",
      "pygame                                2.6.1\n",
      "pygit2                                1.18.0\n",
      "Pygments                              2.19.1\n",
      "PyGObject                             3.42.0\n",
      "PyJWT                                 2.10.1\n",
      "pylibcudf-cu12                        25.2.1\n",
      "pylibcugraph-cu12                     25.2.0\n",
      "pylibraft-cu12                        25.2.0\n",
      "pymc                                  5.22.0\n",
      "pymystem3                             0.2.0\n",
      "pynndescent                           0.5.13\n",
      "pynvjitlink-cu12                      0.5.2\n",
      "pynvml                                12.0.0\n",
      "pyogrio                               0.10.0\n",
      "pyomo                                 6.9.2\n",
      "PyOpenGL                              3.1.9\n",
      "pyOpenSSL                             24.2.1\n",
      "pyparsing                             3.2.3\n",
      "pyperclip                             1.9.0\n",
      "pyproj                                3.7.1\n",
      "pyshp                                 2.3.1\n",
      "PySocks                               1.7.1\n",
      "pyspark                               3.5.5\n",
      "pytensor                              2.30.3\n",
      "pytest                                8.3.5\n",
      "python-apt                            0.0.0\n",
      "python-box                            7.3.2\n",
      "python-dateutil                       2.9.0.post0\n",
      "python-louvain                        0.16\n",
      "python-slugify                        8.0.4\n",
      "python-snappy                         0.7.3\n",
      "python-utils                          3.9.1\n",
      "pytz                                  2025.2\n",
      "pyviz_comms                           3.0.4\n",
      "PyYAML                                6.0.2\n",
      "pyzmq                                 24.0.1\n",
      "raft-dask-cu12                        25.2.0\n",
      "rapids-dask-dependency                25.2.0\n",
      "ratelim                               0.1.6\n",
      "referencing                           0.36.2\n",
      "regex                                 2024.11.6\n",
      "requests                              2.32.3\n",
      "requests-oauthlib                     2.0.0\n",
      "requests-toolbelt                     1.0.0\n",
      "requirements-parser                   0.9.0\n",
      "rich                                  13.9.4\n",
      "rmm-cu12                              25.2.0\n",
      "roman-numerals-py                     3.1.0\n",
      "rpds-py                               0.24.0\n",
      "rpy2                                  3.5.17\n",
      "rsa                                   4.9.1\n",
      "safetensors                           0.5.3\n",
      "scikit-image                          0.25.2\n",
      "scikit-learn                          1.6.1\n",
      "scipy                                 1.15.2\n",
      "scooby                                0.10.0\n",
      "scs                                   3.2.7.post2\n",
      "seaborn                               0.13.2\n",
      "SecretStorage                         3.3.3\n",
      "Send2Trash                            1.8.3\n",
      "sentence-transformers                 3.4.1\n",
      "sentencepiece                         0.2.0\n",
      "sentry-sdk                            2.27.0\n",
      "setproctitle                          1.3.5\n",
      "setuptools                            75.2.0\n",
      "shap                                  0.47.2\n",
      "shapely                               2.1.0\n",
      "shellingham                           1.5.4\n",
      "simple-parsing                        0.1.7\n",
      "simplejson                            3.20.1\n",
      "simsimd                               6.2.1\n",
      "six                                   1.17.0\n",
      "sklearn-compat                        0.1.3\n",
      "sklearn-pandas                        2.2.0\n",
      "slicer                                0.0.8\n",
      "smart-open                            7.1.0\n",
      "smmap                                 5.0.2\n",
      "sniffio                               1.3.1\n",
      "snowballstemmer                       2.2.0\n",
      "sortedcontainers                      2.4.0\n",
      "soundfile                             0.13.1\n",
      "soupsieve                             2.7\n",
      "soxr                                  0.5.0.post1\n",
      "spacy                                 3.8.5\n",
      "spacy-legacy                          3.0.12\n",
      "spacy-loggers                         1.0.5\n",
      "spanner-graph-notebook                1.1.6\n",
      "Sphinx                                8.2.3\n",
      "sphinxcontrib-applehelp               2.0.0\n",
      "sphinxcontrib-devhelp                 2.0.0\n",
      "sphinxcontrib-htmlhelp                2.1.0\n",
      "sphinxcontrib-jsmath                  1.0.1\n",
      "sphinxcontrib-qthelp                  2.0.0\n",
      "sphinxcontrib-serializinghtml         2.0.0\n",
      "SQLAlchemy                            2.0.40\n",
      "sqlglot                               25.20.2\n",
      "sqlparse                              0.5.3\n",
      "srsly                                 2.5.1\n",
      "stanio                                0.5.1\n",
      "statsmodels                           0.14.4\n",
      "stringzilla                           3.12.5\n",
      "sympy                                 1.13.1\n",
      "tables                                3.10.2\n",
      "tabulate                              0.9.0\n",
      "tbb                                   2022.1.0\n",
      "tblib                                 3.1.0\n",
      "tcmlib                                1.3.0\n",
      "tenacity                              9.1.2\n",
      "tensorboard                           2.18.0\n",
      "tensorboard-data-server               0.7.2\n",
      "tensorflow                            2.18.0\n",
      "tensorflow-datasets                   4.9.8\n",
      "tensorflow_decision_forests           1.11.0\n",
      "tensorflow-hub                        0.16.1\n",
      "tensorflow-io-gcs-filesystem          0.37.1\n",
      "tensorflow-metadata                   1.17.1\n",
      "tensorflow-probability                0.25.0\n",
      "tensorflow-text                       2.18.1\n",
      "tensorstore                           0.1.74\n",
      "termcolor                             3.0.1\n",
      "terminado                             0.18.1\n",
      "text-unidecode                        1.3\n",
      "textblob                              0.19.0\n",
      "tf_keras                              2.18.0\n",
      "tf-slim                               1.1.0\n",
      "thinc                                 8.3.6\n",
      "threadpoolctl                         3.6.0\n",
      "tifffile                              2025.3.30\n",
      "timm                                  1.0.15\n",
      "tinycss2                              1.4.0\n",
      "tokenizers                            0.21.1\n",
      "toml                                  0.10.2\n",
      "toolz                                 0.12.1\n",
      "torch                                 2.6.0+cu124\n",
      "torchaudio                            2.6.0+cu124\n",
      "torchmetrics                          1.7.1\n",
      "torchsummary                          1.5.1\n",
      "torchvision                           0.21.0+cu124\n",
      "tornado                               6.4.2\n",
      "tqdm                                  4.67.1\n",
      "traitlets                             5.7.1\n",
      "traittypes                            0.2.1\n",
      "transformers                          4.49.0\n",
      "treelite                              4.4.1\n",
      "treescope                             0.1.9\n",
      "triton                                3.2.0\n",
      "tweepy                                4.15.0\n",
      "typeguard                             4.4.2\n",
      "typer                                 0.15.2\n",
      "types-pytz                            2025.2.0.20250326\n",
      "types-setuptools                      79.0.0.20250422\n",
      "typing_extensions                     4.13.2\n",
      "typing-inspection                     0.4.0\n",
      "tzdata                                2025.2\n",
      "tzlocal                               5.3.1\n",
      "uc-micro-py                           1.0.3\n",
      "ucx-py-cu12                           0.42.0\n",
      "ucxx-cu12                             0.42.0\n",
      "umap-learn                            0.5.7\n",
      "umf                                   0.10.0\n",
      "uritemplate                           4.1.1\n",
      "urllib3                               2.4.0\n",
      "vega-datasets                         0.9.0\n",
      "wadllib                               1.3.6\n",
      "wandb                                 0.19.10\n",
      "wasabi                                1.1.3\n",
      "wcwidth                               0.2.13\n",
      "weasel                                0.4.1\n",
      "webcolors                             24.11.1\n",
      "webencodings                          0.5.1\n",
      "websocket-client                      1.8.0\n",
      "websockets                            15.0.1\n",
      "Werkzeug                              3.1.3\n",
      "wheel                                 0.45.1\n",
      "widgetsnbextension                    3.6.10\n",
      "wordcloud                             1.9.4\n",
      "wrapt                                 1.17.2\n",
      "wurlitzer                             3.1.1\n",
      "xarray                                2025.3.1\n",
      "xarray-einstats                       0.8.0\n",
      "xgboost                               2.1.4\n",
      "xlrd                                  2.0.1\n",
      "xxhash                                3.5.0\n",
      "xyzservices                           2025.1.0\n",
      "yarl                                  1.20.0\n",
      "ydf                                   0.11.0\n",
      "yellowbrick                           1.5\n",
      "yfinance                              0.2.56\n",
      "zict                                  3.0.0\n",
      "zipp                                  3.21.0\n",
      "zstandard                             0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90_IPAabXD6d",
    "outputId": "99ed4456-41b9-4a6f-d375-6243446bfeeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n"
     ]
    }
   ],
   "source": [
    "! pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVm7g9AoXe_D",
    "outputId": "caa80445-d5d6-4b63-c3cc-64833a48381f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rFetching 16 files:   0% 0/16 [00:00<?, ?it/s]Downloading 'generation_config.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.a1562c3d6b956dcd04131264c8ea6b8c14b57532.incomplete'\n",
      "Downloading 'configuration_phi3.py' to 'phi-4-mini-reasoning/.cache/huggingface/download/vEnnZuZbPjs88GEHAS5wEyJ0R4s=.6b45af10b3b6a87768350fc9b026e0b6b626373e.incomplete'\n",
      "Downloading 'merges.txt' to 'phi-4-mini-reasoning/.cache/huggingface/download/PtHk0z_I45atnj23IIRhTExwT3w=.dcecc4524288b351bbd0da8028e74e9b5bcdb9b5.incomplete'\n",
      "Downloading 'model-00001-of-00002.safetensors' to 'phi-4-mini-reasoning/.cache/huggingface/download/aoe4E07IMh7reFyUkVoVk040mQk=.a0c24f128e33afb9e406915229af56171e0a2353bc78c1ea1b5260a36b3e6707.incomplete'\n",
      "Downloading 'added_tokens.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.af52cde61cc39aca58f7b7f04116b317116e75dd.incomplete'\n",
      "Downloading 'config.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.4bcc7eadfe79fe2e41f26b5fb5f06c9a330bdef4.incomplete'\n",
      "Downloading '.gitattributes' to 'phi-4-mini-reasoning/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'\n",
      "Downloading 'README.md' to 'phi-4-mini-reasoning/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.7be5fc7f47d5db027d120b8024982df93db95b74.incomplete'\n",
      "\n",
      "generation_config.json: 100% 190/190 [00:00<00:00, 1.58MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/generation_config.json\n",
      "\n",
      "configuration_phi3.py: 100% 10.9k/10.9k [00:00<00:00, 47.6MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/configuration_phi3.py\n",
      "\n",
      "merges.txt:   0% 0.00/2.42M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "added_tokens.json: 100% 249/249 [00:00<00:00, 2.58MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/added_tokens.json\n",
      "\n",
      "\n",
      "README.md: 100% 24.0/24.0 [00:00<00:00, 196kB/s]\n",
      "\n",
      "\n",
      "config.json: 100% 2.56k/2.56k [00:00<00:00, 29.5MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/config.json\n",
      "Download complete. Moving file to phi-4-mini-reasoning/README.md\n",
      "\n",
      "\n",
      ".gitattributes: 100% 1.57k/1.57k [00:00<00:00, 18.3MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/.gitattributes\n",
      "Fetching 16 files:   6% 1/16 [00:00<00:08,  1.82it/s]Downloading 'model-00002-of-00002.safetensors' to 'phi-4-mini-reasoning/.cache/huggingface/download/Dr_lZJDwE1cnGAQMwA77jJEQIk8=.b4bfcc826b3c637333c6bd24b0dfe38fffd45eff7f4718df454366e875a12415.incomplete'\n",
      "\n",
      "merges.txt: 100% 2.42M/2.42M [00:00<00:00, 10.2MB/s]\u001b[ADownloading 'model.safetensors.index.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.d87cc3650f8e8dec46fc6871826ef30b941d0c94.incomplete'\n",
      "merges.txt: 100% 2.42M/2.42M [00:00<00:00, 10.1MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/merges.txt\n",
      "Fetching 16 files:  44% 7/16 [00:00<00:00, 11.45it/s]\n",
      "model-00002-of-00002.safetensors:   0% 0.00/2.77G [00:00<?, ?B/s]\u001b[ADownloading 'modeling_phi3.py' to 'phi-4-mini-reasoning/.cache/huggingface/download/LlzfabVCMqA3OEpgzTLO_-uTIq4=.dd40bb0e2aec9d2cf1cab81a942a92d24039cd96.incomplete'\n",
      "Downloading 'tokenizer_config.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.d85b0903a1f838152673a48906193aca61aaf853.incomplete'\n",
      "Downloading 'tokenizer.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.f08ed885956f70d877a4d9078ec9e3119d8b68a8d579003e230be18cad66911c.incomplete'\n",
      "Downloading 'special_tokens_map.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.156262f7d61a27706bdcad9d117c579e88e2fa27.incomplete'\n",
      "\n",
      "\n",
      "tokenizer.json:   0% 0.00/15.5M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "tokenizer.json: 100% 15.5M/15.5M [00:00<00:00, 209MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/tokenizer.json\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 0.00/4.90G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors.index.json: 100% 16.3k/16.3k [00:00<00:00, 79.4MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/model.safetensors.index.json\n",
      "\n",
      "model-00002-of-00002.safetensors:   3% 83.9M/2.77G [00:00<00:07, 359MB/s]\u001b[ADownloading 'vocab.json' to 'phi-4-mini-reasoning/.cache/huggingface/download/j3m-Hy6QvBddw8RXA1uSWl1AJ0c=.ea953a43348cdb3776cb7fd9ea02e3784febde34.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "modeling_phi3.py: 100% 71.5k/71.5k [00:00<00:00, 26.9MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/modeling_phi3.py\n",
      "\n",
      "\n",
      "\n",
      "special_tokens_map.json: 100% 587/587 [00:00<00:00, 6.36MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/special_tokens_map.json\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json: 100% 3.08k/3.08k [00:00<00:00, 32.8MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/tokenizer_config.json\n",
      "\n",
      "model-00002-of-00002.safetensors:   5% 126M/2.77G [00:00<00:07, 373MB/s] \u001b[ADownloading 'zero_to_fp32.py' to 'phi-4-mini-reasoning/.cache/huggingface/download/ePbCs_PRHW1G2t5kQ3SE3uFWKpE=.e69ecd9acb5a235ffbf927091051106d902b3d39.incomplete'\n",
      "\n",
      "model-00002-of-00002.safetensors:   6% 178M/2.77G [00:00<00:06, 404MB/s]\u001b[A\n",
      "\n",
      "\n",
      "vocab.json:   0% 0.00/3.91M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   8% 231M/2.77G [00:00<00:05, 424MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "zero_to_fp32.py: 100% 29.2k/29.2k [00:00<00:00, 109MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/zero_to_fp32.py\n",
      "\n",
      "model-00002-of-00002.safetensors:  10% 283M/2.77G [00:00<00:05, 426MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  12% 336M/2.77G [00:00<00:06, 400MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  14% 377M/2.77G [00:00<00:06, 364MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15% 419M/2.77G [00:01<00:06, 344MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17% 461M/2.77G [00:01<00:06, 341MB/s]\u001b[A\n",
      "\n",
      "\n",
      "vocab.json: 100% 3.91M/3.91M [00:00<00:00, 5.01MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/vocab.json\n",
      "\n",
      "model-00002-of-00002.safetensors:  19% 514M/2.77G [00:01<00:06, 374MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20% 566M/2.77G [00:01<00:05, 402MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22% 608M/2.77G [00:01<00:05, 372MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  23% 650M/2.77G [00:01<00:05, 381MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 10.5M/4.90G [00:01<12:06, 6.74MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  25% 692M/2.77G [00:01<00:07, 286MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  27% 734M/2.77G [00:02<00:06, 300MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28% 786M/2.77G [00:02<00:05, 339MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30% 828M/2.77G [00:02<00:05, 333MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 21.0M/4.90G [00:02<07:56, 10.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 870M/2.77G [00:02<00:06, 304MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33% 912M/2.77G [00:02<00:06, 306MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34% 954M/2.77G [00:02<00:05, 318MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 31.5M/4.90G [00:02<05:51, 13.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  36% 996M/2.77G [00:02<00:05, 321MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.04G/2.77G [00:02<00:05, 337MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39% 1.08G/2.77G [00:03<00:04, 353MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41% 1.13G/2.77G [00:03<00:04, 378MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 41.9M/4.90G [00:03<04:52, 16.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  43% 1.18G/2.77G [00:03<00:03, 396MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  45% 1.24G/2.77G [00:03<00:03, 427MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  47% 1.29G/2.77G [00:03<00:03, 440MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  48% 1.34G/2.77G [00:03<00:03, 438MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50% 1.39G/2.77G [00:03<00:03, 447MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52% 1.45G/2.77G [00:03<00:03, 434MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 52.4M/4.90G [00:03<04:56, 16.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  54% 1.50G/2.77G [00:04<00:02, 449MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56% 1.55G/2.77G [00:04<00:02, 452MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58% 1.60G/2.77G [00:04<00:02, 440MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60% 1.66G/2.77G [00:04<00:02, 429MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 1.71G/2.77G [00:04<00:02, 443MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 62.9M/4.90G [00:04<04:58, 16.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  64% 1.76G/2.77G [00:04<00:02, 448MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66% 1.81G/2.77G [00:04<00:02, 437MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67% 1.87G/2.77G [00:04<00:02, 436MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69% 1.92G/2.77G [00:04<00:01, 433MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 73.4M/4.90G [00:04<04:27, 18.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  71% 1.97G/2.77G [00:05<00:02, 383MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73% 2.02G/2.77G [00:05<00:01, 410MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  75% 2.08G/2.77G [00:05<00:01, 379MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  77% 2.12G/2.77G [00:05<00:01, 376MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78% 2.16G/2.77G [00:05<00:01, 346MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2% 83.9M/4.90G [00:05<04:37, 17.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  80% 2.20G/2.77G [00:05<00:01, 305MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 2.24G/2.77G [00:06<00:01, 292MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2% 94.4M/4.90G [00:05<04:13, 19.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  82% 2.28G/2.77G [00:06<00:01, 285MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 2.34G/2.77G [00:06<00:01, 344MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86% 2.38G/2.77G [00:06<00:01, 349MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  88% 2.44G/2.77G [00:06<00:00, 405MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2% 105M/4.90G [00:06<03:57, 20.2MB/s] \u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  90% 2.50G/2.77G [00:06<00:00, 427MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  92% 2.55G/2.77G [00:06<00:00, 440MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94% 2.60G/2.77G [00:06<00:00, 410MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96% 2.65G/2.77G [00:06<00:00, 418MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  98% 2.71G/2.77G [00:07<00:00, 425MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2% 115M/4.90G [00:07<04:15, 18.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors: 100% 2.77G/2.77G [00:07<00:00, 379MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/model-00002-of-00002.safetensors\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   3% 126M/4.90G [00:07<03:58, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3% 136M/4.90G [00:07<03:46, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3% 147M/4.90G [00:08<03:37, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3% 157M/4.90G [00:08<03:31, 22.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3% 168M/4.90G [00:09<03:27, 22.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4% 178M/4.90G [00:09<03:25, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4% 189M/4.90G [00:10<03:22, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4% 199M/4.90G [00:10<03:20, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4% 210M/4.90G [00:10<03:18, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4% 220M/4.90G [00:11<03:18, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5% 231M/4.90G [00:11<03:16, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5% 241M/4.90G [00:12<03:15, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5% 252M/4.90G [00:12<03:15, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5% 262M/4.90G [00:13<03:14, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6% 273M/4.90G [00:13<03:14, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6% 283M/4.90G [00:14<03:13, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6% 294M/4.90G [00:14<03:13, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6% 304M/4.90G [00:14<03:13, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6% 315M/4.90G [00:15<03:11, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 325M/4.90G [00:15<03:12, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 336M/4.90G [00:16<03:10, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 346M/4.90G [00:16<03:10, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 357M/4.90G [00:17<03:13, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 367M/4.90G [00:17<03:12, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8% 377M/4.90G [00:18<03:11, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8% 388M/4.90G [00:18<03:10, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Fetching 16 files:  44% 7/16 [00:19<00:00, 11.45it/s]\n",
      "\n",
      "model-00001-of-00002.safetensors:   8% 409M/4.90G [00:19<03:09, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 419M/4.90G [00:19<03:08, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 430M/4.90G [00:20<03:07, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 440M/4.90G [00:20<03:07, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 451M/4.90G [00:21<03:06, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 461M/4.90G [00:21<03:29, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10% 472M/4.90G [00:22<03:23, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10% 482M/4.90G [00:22<03:44, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10% 493M/4.90G [00:23<03:59, 18.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10% 503M/4.90G [00:23<03:43, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10% 514M/4.90G [00:24<03:57, 18.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11% 524M/4.90G [00:25<03:42, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11% 535M/4.90G [00:25<03:56, 18.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11% 545M/4.90G [00:26<03:50, 18.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11% 556M/4.90G [00:26<03:52, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 566M/4.90G [00:27<03:36, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 577M/4.90G [00:27<03:51, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 587M/4.90G [00:28<03:37, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 598M/4.90G [00:28<03:27, 20.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 608M/4.90G [00:29<03:43, 19.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 619M/4.90G [00:29<03:30, 20.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 629M/4.90G [00:30<03:21, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 640M/4.90G [00:30<03:39, 19.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 650M/4.90G [00:31<03:27, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 661M/4.90G [00:32<03:42, 19.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 671M/4.90G [00:32<03:30, 20.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 682M/4.90G [00:32<03:21, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 692M/4.90G [00:33<03:37, 19.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 703M/4.90G [00:34<03:25, 20.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 713M/4.90G [00:34<03:17, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 724M/4.90G [00:35<03:34, 19.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 734M/4.90G [00:35<03:23, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 744M/4.90G [00:36<03:15, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 755M/4.90G [00:36<03:37, 19.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 765M/4.90G [00:37<03:19, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 776M/4.90G [00:37<03:12, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 786M/4.90G [00:38<03:29, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 797M/4.90G [00:38<03:18, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 807M/4.90G [00:39<03:10, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 818M/4.90G [00:39<03:08, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 828M/4.90G [00:40<03:22, 20.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 839M/4.90G [00:40<03:13, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 849M/4.90G [00:41<03:06, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 860M/4.90G [00:41<03:02, 22.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 870M/4.90G [00:42<03:07, 21.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 881M/4.90G [00:42<03:14, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 891M/4.90G [00:43<03:06, 21.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 902M/4.90G [00:43<03:00, 22.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 912M/4.90G [00:43<02:56, 22.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 923M/4.90G [00:44<02:53, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 933M/4.90G [00:44<02:50, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 944M/4.90G [00:45<02:50, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 954M/4.90G [00:45<02:47, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20% 965M/4.90G [00:46<02:46, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20% 975M/4.90G [00:46<02:45, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20% 986M/4.90G [00:46<02:44, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20% 996M/4.90G [00:47<02:44, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 1.01G/4.90G [00:47<02:43, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 1.02G/4.90G [00:48<02:42, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 1.03G/4.90G [00:48<02:42, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 1.04G/4.90G [00:49<02:42, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 1.05G/4.90G [00:49<02:41, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 1.06G/4.90G [00:50<02:41, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 1.07G/4.90G [00:50<02:40, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 1.08G/4.90G [00:50<02:40, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 1.09G/4.90G [00:51<02:39, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 1.10G/4.90G [00:51<02:39, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 1.11G/4.90G [00:52<02:38, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 1.12G/4.90G [00:52<02:38, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 1.13G/4.90G [00:53<02:37, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 1.14G/4.90G [00:53<02:37, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 1.15G/4.90G [00:54<02:37, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 1.16G/4.90G [00:54<02:36, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 1.17G/4.90G [00:54<02:36, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 1.18G/4.90G [00:55<02:37, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 1.20G/4.90G [00:55<02:34, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 1.21G/4.90G [00:56<02:34, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 1.22G/4.90G [00:56<02:33, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 1.23G/4.90G [00:57<02:34, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 1.24G/4.90G [00:57<02:34, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 1.25G/4.90G [00:58<02:45, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26% 1.26G/4.90G [00:58<02:28, 24.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26% 1.27G/4.90G [00:58<02:29, 24.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26% 1.28G/4.90G [00:59<02:29, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26% 1.29G/4.90G [00:59<02:33, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27% 1.30G/4.90G [01:00<02:28, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27% 1.31G/4.90G [01:00<02:28, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27% 1.32G/4.90G [01:01<02:28, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27% 1.33G/4.90G [01:01<02:28, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27% 1.34G/4.90G [01:01<02:29, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28% 1.35G/4.90G [01:02<02:28, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28% 1.36G/4.90G [01:02<02:28, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28% 1.37G/4.90G [01:03<02:28, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28% 1.38G/4.90G [01:03<02:29, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28% 1.39G/4.90G [01:04<02:25, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29% 1.41G/4.90G [01:04<02:25, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29% 1.42G/4.90G [01:04<02:25, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29% 1.43G/4.90G [01:05<02:25, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29% 1.44G/4.90G [01:05<02:25, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 1.45G/4.90G [01:06<02:24, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 1.46G/4.90G [01:06<02:26, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 1.47G/4.90G [01:07<02:29, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 1.48G/4.90G [01:07<02:34, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 1.49G/4.90G [01:08<02:33, 22.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 1.50G/4.90G [01:08<02:29, 22.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 1.51G/4.90G [01:09<02:26, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 1.52G/4.90G [01:09<02:24, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 1.53G/4.90G [01:09<02:22, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 1.54G/4.90G [01:10<02:21, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 1.55G/4.90G [01:10<02:20, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 1.56G/4.90G [01:11<02:22, 23.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 1.57G/4.90G [01:11<02:43, 20.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 1.58G/4.90G [01:12<03:14, 17.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33% 1.59G/4.90G [01:13<03:18, 16.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33% 1.60G/4.90G [01:14<03:39, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33% 1.61G/4.90G [01:15<03:56, 13.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33% 1.63G/4.90G [01:16<04:04, 13.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33% 1.64G/4.90G [01:16<04:12, 12.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 1.65G/4.90G [01:18<04:36, 11.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 1.66G/4.90G [01:18<04:33, 11.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 1.67G/4.90G [01:19<04:31, 11.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 1.68G/4.90G [01:20<04:29, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 1.69G/4.90G [01:21<04:27, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 1.70G/4.90G [01:22<04:26, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 1.71G/4.90G [01:23<04:25, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 1.72G/4.90G [01:24<04:23, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 1.73G/4.90G [01:24<04:22, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 1.74G/4.90G [01:25<04:21, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36% 1.75G/4.90G [01:26<04:20, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36% 1.76G/4.90G [01:27<04:19, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36% 1.77G/4.90G [01:28<04:01, 13.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36% 1.78G/4.90G [01:29<04:06, 12.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37% 1.79G/4.90G [01:29<04:08, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37% 1.80G/4.90G [01:30<04:09, 12.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37% 1.81G/4.90G [01:31<04:10, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37% 1.82G/4.90G [01:32<03:53, 13.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37% 1.84G/4.90G [01:33<03:57, 12.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 1.85G/4.90G [01:33<03:43, 13.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 1.86G/4.90G [01:34<03:50, 13.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 1.87G/4.90G [01:35<03:37, 14.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 1.88G/4.90G [01:36<03:28, 14.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 1.89G/4.90G [01:36<03:21, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39% 1.90G/4.90G [01:37<03:16, 15.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39% 1.91G/4.90G [01:37<02:55, 17.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39% 1.92G/4.90G [01:38<02:56, 16.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39% 1.93G/4.90G [01:38<02:41, 18.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 1.94G/4.90G [01:39<02:46, 17.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 1.95G/4.90G [01:39<02:34, 19.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 1.96G/4.90G [01:40<02:23, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 1.97G/4.90G [01:40<02:16, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 1.98G/4.90G [01:41<02:11, 22.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 1.99G/4.90G [01:41<02:08, 22.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 2.00G/4.90G [01:42<02:05, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 2.01G/4.90G [01:42<02:03, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 2.02G/4.90G [01:43<02:02, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 2.03G/4.90G [01:43<02:00, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42% 2.04G/4.90G [01:43<01:59, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42% 2.06G/4.90G [01:44<01:59, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42% 2.07G/4.90G [01:44<01:57, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42% 2.08G/4.90G [01:45<01:57, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 2.09G/4.90G [01:45<01:56, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 2.10G/4.90G [01:46<01:56, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 2.11G/4.90G [01:46<01:55, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 2.12G/4.90G [01:46<01:56, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 2.13G/4.90G [01:47<01:54, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 2.14G/4.90G [01:47<01:54, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 2.15G/4.90G [01:48<01:54, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 2.16G/4.90G [01:48<01:53, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 2.17G/4.90G [01:49<01:52, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 2.18G/4.90G [01:49<01:55, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45% 2.19G/4.90G [01:50<01:56, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45% 2.20G/4.90G [01:50<01:54, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45% 2.21G/4.90G [01:50<01:53, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45% 2.22G/4.90G [01:51<01:55, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46% 2.23G/4.90G [01:51<01:56, 22.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46% 2.24G/4.90G [01:52<01:57, 22.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46% 2.25G/4.90G [01:52<01:55, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46% 2.26G/4.90G [01:53<01:53, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46% 2.28G/4.90G [01:53<01:51, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 2.29G/4.90G [01:54<01:50, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 2.30G/4.90G [01:54<01:49, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 2.31G/4.90G [01:54<01:48, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 2.32G/4.90G [01:55<01:47, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 2.33G/4.90G [01:55<01:47, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48% 2.34G/4.90G [01:56<01:46, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48% 2.35G/4.90G [01:56<01:45, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48% 2.36G/4.90G [01:57<01:45, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48% 2.37G/4.90G [01:57<01:45, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49% 2.38G/4.90G [01:57<01:44, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49% 2.39G/4.90G [01:58<01:43, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49% 2.40G/4.90G [01:58<01:43, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49% 2.41G/4.90G [01:59<01:43, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49% 2.42G/4.90G [01:59<01:42, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 2.43G/4.90G [02:00<01:42, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 2.44G/4.90G [02:00<01:41, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 2.45G/4.90G [02:00<01:42, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 2.46G/4.90G [02:01<01:48, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 2.47G/4.90G [02:02<02:00, 20.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51% 2.49G/4.90G [02:02<02:11, 18.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51% 2.50G/4.90G [02:03<02:18, 17.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51% 2.51G/4.90G [02:04<02:17, 17.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51% 2.52G/4.90G [02:04<02:07, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52% 2.53G/4.90G [02:05<01:58, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52% 2.54G/4.90G [02:05<01:52, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52% 2.55G/4.90G [02:05<01:47, 21.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52% 2.56G/4.90G [02:06<01:44, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52% 2.57G/4.90G [02:06<01:41, 23.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 2.58G/4.90G [02:07<01:39, 23.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 2.59G/4.90G [02:07<01:38, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 2.60G/4.90G [02:08<01:36, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 2.61G/4.90G [02:08<01:35, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 2.62G/4.90G [02:09<01:49, 20.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54% 2.63G/4.90G [02:09<01:45, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54% 2.64G/4.90G [02:10<01:55, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54% 2.65G/4.90G [02:10<02:01, 18.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54% 2.66G/4.90G [02:11<01:52, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55% 2.67G/4.90G [02:11<01:46, 20.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55% 2.68G/4.90G [02:12<01:55, 19.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55% 2.69G/4.90G [02:12<01:47, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55% 2.71G/4.90G [02:13<01:42, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55% 2.72G/4.90G [02:13<01:38, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 2.73G/4.90G [02:14<01:40, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 2.74G/4.90G [02:14<01:44, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 2.75G/4.90G [02:15<01:39, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 2.76G/4.90G [02:15<01:36, 22.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 2.77G/4.90G [02:16<01:33, 22.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57% 2.78G/4.90G [02:16<01:31, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57% 2.79G/4.90G [02:16<01:30, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57% 2.80G/4.90G [02:17<01:28, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57% 2.81G/4.90G [02:17<01:28, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58% 2.82G/4.90G [02:18<01:27, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58% 2.83G/4.90G [02:18<01:26, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58% 2.84G/4.90G [02:19<01:25, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58% 2.85G/4.90G [02:19<01:25, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58% 2.86G/4.90G [02:20<01:24, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 2.87G/4.90G [02:20<01:24, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 2.88G/4.90G [02:20<01:23, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 2.89G/4.90G [02:21<01:23, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 2.90G/4.90G [02:21<01:22, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 2.92G/4.90G [02:22<01:22, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60% 2.93G/4.90G [02:22<01:21, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60% 2.94G/4.90G [02:23<01:21, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60% 2.95G/4.90G [02:23<01:21, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60% 2.96G/4.90G [02:23<01:20, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 2.97G/4.90G [02:24<01:20, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 2.98G/4.90G [02:24<01:19, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 2.99G/4.90G [02:25<01:25, 22.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 3.00G/4.90G [02:25<01:17, 24.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 3.01G/4.90G [02:26<01:17, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62% 3.02G/4.90G [02:26<01:17, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62% 3.03G/4.90G [02:26<01:17, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62% 3.04G/4.90G [02:27<01:16, 24.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62% 3.05G/4.90G [02:27<01:16, 24.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62% 3.06G/4.90G [02:28<01:16, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 3.07G/4.90G [02:28<01:15, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 3.08G/4.90G [02:29<01:15, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 3.09G/4.90G [02:29<01:14, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 3.10G/4.90G [02:30<01:14, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64% 3.11G/4.90G [02:30<01:13, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64% 3.12G/4.90G [02:30<01:13, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64% 3.14G/4.90G [02:31<01:13, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64% 3.15G/4.90G [02:31<01:12, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64% 3.16G/4.90G [02:32<01:12, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 3.17G/4.90G [02:32<01:12, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 3.18G/4.90G [02:33<01:11, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 3.19G/4.90G [02:33<01:11, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 3.20G/4.90G [02:33<01:10, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 3.21G/4.90G [02:34<01:10, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66% 3.22G/4.90G [02:34<01:09, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66% 3.23G/4.90G [02:35<01:09, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66% 3.24G/4.90G [02:35<01:08, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66% 3.25G/4.90G [02:36<01:08, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67% 3.26G/4.90G [02:36<01:07, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67% 3.27G/4.90G [02:36<01:07, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67% 3.28G/4.90G [02:37<01:07, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67% 3.29G/4.90G [02:37<01:08, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67% 3.30G/4.90G [02:38<01:08, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68% 3.31G/4.90G [02:38<01:07, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68% 3.32G/4.90G [02:39<01:06, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68% 3.33G/4.90G [02:39<01:06, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68% 3.34G/4.90G [02:40<01:05, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68% 3.36G/4.90G [02:40<01:04, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69% 3.37G/4.90G [02:40<01:04, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69% 3.38G/4.90G [02:41<01:03, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69% 3.39G/4.90G [02:41<01:02, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69% 3.40G/4.90G [02:42<01:02, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69% 3.41G/4.90G [02:42<01:02, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70% 3.42G/4.90G [02:43<01:01, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70% 3.43G/4.90G [02:43<01:01, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70% 3.44G/4.90G [02:43<01:00, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70% 3.45G/4.90G [02:44<01:01, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 3.46G/4.90G [02:44<01:03, 22.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 3.47G/4.90G [02:45<01:02, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 3.48G/4.90G [02:45<01:01, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 3.49G/4.90G [02:46<01:00, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 3.50G/4.90G [02:46<00:59, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 3.51G/4.90G [02:47<00:58, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 3.52G/4.90G [02:47<00:57, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 3.53G/4.90G [02:47<00:57, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 3.54G/4.90G [02:48<00:56, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 3.55G/4.90G [02:48<00:56, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 3.57G/4.90G [02:49<00:55, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 3.58G/4.90G [02:49<00:55, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 3.59G/4.90G [02:50<00:54, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 3.60G/4.90G [02:50<00:54, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74% 3.61G/4.90G [02:51<00:53, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74% 3.62G/4.90G [02:51<00:53, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74% 3.63G/4.90G [02:51<00:52, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74% 3.64G/4.90G [02:52<00:52, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74% 3.65G/4.90G [02:52<00:52, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 3.66G/4.90G [02:53<00:51, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 3.67G/4.90G [02:53<00:51, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 3.68G/4.90G [02:54<00:50, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 3.69G/4.90G [02:54<00:50, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 3.70G/4.90G [02:54<00:49, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76% 3.71G/4.90G [02:55<00:49, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76% 3.72G/4.90G [02:55<00:48, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76% 3.73G/4.90G [02:56<00:48, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76% 3.74G/4.90G [02:56<00:47, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 3.75G/4.90G [02:57<00:47, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 3.76G/4.90G [02:57<00:47, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 3.77G/4.90G [02:57<00:46, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 3.79G/4.90G [02:58<00:46, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 3.80G/4.90G [02:58<00:46, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78% 3.81G/4.90G [02:59<00:45, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78% 3.82G/4.90G [02:59<00:45, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78% 3.83G/4.90G [03:00<00:44, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78% 3.84G/4.90G [03:00<00:44, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78% 3.85G/4.90G [03:01<00:43, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79% 3.86G/4.90G [03:01<00:43, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79% 3.87G/4.90G [03:01<00:42, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79% 3.88G/4.90G [03:02<00:42, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79% 3.89G/4.90G [03:02<00:41, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 3.90G/4.90G [03:03<00:41, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 3.91G/4.90G [03:03<00:41, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 3.92G/4.90G [03:04<00:41, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 3.93G/4.90G [03:04<00:40, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 3.94G/4.90G [03:04<00:39, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81% 3.95G/4.90G [03:05<00:39, 24.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81% 3.96G/4.90G [03:05<00:38, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81% 3.97G/4.90G [03:06<00:38, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81% 3.98G/4.90G [03:06<00:43, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81% 4.00G/4.90G [03:07<00:41, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82% 4.01G/4.90G [03:07<00:45, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82% 4.02G/4.90G [03:08<00:47, 18.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82% 4.03G/4.90G [03:09<00:44, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82% 4.04G/4.90G [03:09<00:46, 18.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83% 4.05G/4.90G [03:10<00:43, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83% 4.06G/4.90G [03:10<00:45, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83% 4.07G/4.90G [03:11<00:42, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83% 4.08G/4.90G [03:11<00:44, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83% 4.09G/4.90G [03:12<00:40, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 4.10G/4.90G [03:12<00:42, 18.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 4.11G/4.90G [03:13<00:39, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 4.12G/4.90G [03:13<00:37, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 4.13G/4.90G [03:14<00:39, 19.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 4.14G/4.90G [03:14<00:37, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85% 4.15G/4.90G [03:15<00:35, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85% 4.16G/4.90G [03:15<00:37, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85% 4.17G/4.90G [03:16<00:35, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85% 4.18G/4.90G [03:17<00:37, 19.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 4.19G/4.90G [03:17<00:34, 20.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 4.20G/4.90G [03:17<00:32, 21.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 4.22G/4.90G [03:18<00:35, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 4.23G/4.90G [03:19<00:32, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 4.24G/4.90G [03:19<00:31, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87% 4.25G/4.90G [03:20<00:33, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87% 4.26G/4.90G [03:20<00:31, 20.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87% 4.27G/4.90G [03:20<00:29, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87% 4.28G/4.90G [03:21<00:31, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87% 4.29G/4.90G [03:22<00:29, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88% 4.30G/4.90G [03:22<00:27, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88% 4.31G/4.90G [03:23<00:30, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88% 4.32G/4.90G [03:23<00:28, 20.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88% 4.33G/4.90G [03:24<00:26, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89% 4.34G/4.90G [03:24<00:25, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89% 4.35G/4.90G [03:25<00:27, 20.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89% 4.36G/4.90G [03:25<00:25, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89% 4.37G/4.90G [03:25<00:24, 22.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89% 4.38G/4.90G [03:26<00:23, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 4.39G/4.90G [03:27<00:24, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 4.40G/4.90G [03:27<00:23, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 4.41G/4.90G [03:27<00:22, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 4.42G/4.90G [03:28<00:21, 22.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 4.44G/4.90G [03:28<00:21, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91% 4.45G/4.90G [03:29<00:22, 20.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91% 4.46G/4.90G [03:30<00:23, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91% 4.47G/4.90G [03:30<00:21, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91% 4.48G/4.90G [03:31<00:22, 18.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92% 4.49G/4.90G [03:31<00:20, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92% 4.50G/4.90G [03:32<00:21, 18.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92% 4.51G/4.90G [03:32<00:19, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92% 4.52G/4.90G [03:33<00:18, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92% 4.53G/4.90G [03:33<00:17, 21.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93% 4.54G/4.90G [03:34<00:18, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93% 4.55G/4.90G [03:34<00:16, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93% 4.56G/4.90G [03:35<00:15, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93% 4.57G/4.90G [03:35<00:14, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93% 4.58G/4.90G [03:36<00:14, 22.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94% 4.59G/4.90G [03:36<00:13, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94% 4.60G/4.90G [03:36<00:13, 22.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94% 4.61G/4.90G [03:37<00:13, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94% 4.62G/4.90G [03:37<00:12, 22.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 4.63G/4.90G [03:38<00:11, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 4.65G/4.90G [03:38<00:11, 22.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 4.66G/4.90G [03:39<00:10, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 4.67G/4.90G [03:39<00:10, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 4.68G/4.90G [03:40<00:09, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 4.69G/4.90G [03:40<00:09, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 4.70G/4.90G [03:41<00:08, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 4.71G/4.90G [03:41<00:08, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 4.72G/4.90G [03:41<00:07, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 4.73G/4.90G [03:42<00:07, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97% 4.74G/4.90G [03:42<00:06, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97% 4.75G/4.90G [03:43<00:06, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97% 4.76G/4.90G [03:43<00:05, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97% 4.77G/4.90G [03:44<00:05, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 4.78G/4.90G [03:44<00:05, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 4.79G/4.90G [03:44<00:04, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 4.80G/4.90G [03:45<00:04, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 4.81G/4.90G [03:45<00:03, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 4.82G/4.90G [03:46<00:03, 22.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 4.83G/4.90G [03:46<00:03, 21.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 4.84G/4.90G [03:47<00:02, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 4.85G/4.90G [03:47<00:02, 22.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 4.87G/4.90G [03:48<00:01, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 4.88G/4.90G [03:48<00:01, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100% 4.89G/4.90G [03:49<00:00, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100% 4.90G/4.90G [03:49<00:00, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100% 4.90G/4.90G [03:49<00:00, 21.3MB/s]\n",
      "Download complete. Moving file to phi-4-mini-reasoning/model-00001-of-00002.safetensors\n",
      "Fetching 16 files: 100% 16/16 [03:50<00:00, 14.41s/it]\n",
      "/content/phi-4-mini-reasoning\n"
     ]
    }
   ],
   "source": [
    "! huggingface-cli download {Phi-4-mini-reasoning hugging face id} --local-dir {Your Phi-4-mini-reasoning model location}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "14nAK48WZZGU"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318,
     "referenced_widgets": [
      "60a7ae8ebb9f4c929377e9728a332c57",
      "8b78b15cfcee46b89c06825fb0c8f317",
      "65548dd1c9d14dfca1f91f889a967e00",
      "b5635dda4d7d4fbb85965531f1109e0a",
      "550969d6ad534df49a5f8369c2eab820",
      "75e5c63249c444878ff56a8ff76f2063",
      "e56eded8fce94a61aea15d41081ae1dc",
      "6d14a6da1909493db5c78516da9694f0",
      "e8262ee0334c44d8bbb3eb74eeaef033",
      "e0b3529257ba4a34becbb413009ea9fc",
      "4f2bbd0a6ffe4d3e8679df08c84aa661",
      "247e6b9246434ff2a437aa4dd9e8e430",
      "4f6ee757420e4384a6563d47718db437",
      "8fe2c0adf60246af972e8f42f9ef279e",
      "31da299ba48e43ac9b5005365892171c",
      "f9167aff986347afab423ab5d7c5e7c8",
      "2670c1daf2d34a3ba8af10be8702fd30",
      "d08ffe320c4644f69bff07b67ef3c2d1",
      "220dc26139ae429cb696198e5d79654a",
      "f5fd2ca404c84c66b50c62acc88a4124",
      "e9eada962fd34eb0a014c58e93bf732e",
      "e46d3b59fd6f46619c09809527501d69",
      "3e20d4e3b0f34224adabf75b1ecac34f",
      "bc46778ff2aa422288917c971dc277b7",
      "dc2d550d148b48c99b659341008d729f",
      "7a92587a59554c87babf305061eda026",
      "9384c5ad38b6453f9a4efeef92f572ec",
      "c7f69740b7d9478e9e3339b0518a0efc",
      "0754f780703a4a32a51fa8c27c69a460",
      "4d12a72021044839861d448cde4e0eaa",
      "98ddf4f49f4d4011a0f4dcb76e17a2d4",
      "c5762143009245999824b7f5f036ba16",
      "271ae264766a4153ab316c107579af77",
      "465b20646b56478d9d40a4ce3cec8247",
      "a2cd205fa607417da69e93ef2ef9d1e4",
      "1786df0bec2640999945e6a8a1953ecf",
      "6ab7b20251924f9a8c6dedfb8a1038cb",
      "9227435037fa4fccbb8642b55bae1eee",
      "84f92d50d54e405c8e7ec0b365b5bce3",
      "4f4f74b5c9d14ecdaf882b51a09a47d6",
      "0abb5d6f65b74c179a42b995e7d9b91a",
      "378fea5576554169b9deb0d6c94968c3",
      "db8cde78a601454097ab9a36c15785e5",
      "4d3ef7313a574323ac0d4b6bbdbb8366",
      "c44e5f166e2b4852b088b2709630c276",
      "f8213f2dced54dd58cce20509d666555",
      "f9e72370022b476a9a23f49537f73ac8",
      "9088c9ac5215436380b87af65230d497",
      "fcaac2751a344393b8d3471caaa90a89",
      "60e4cc2fccd74bb89b6161ad6319e02c",
      "278855f34ff24ce1b60b00fba584498f",
      "1239108cd0f542608cb4a09ddbb260db",
      "4f7a5e1944124b358a1f7a23241fdfb2",
      "5e72b08350f142b4917049d21529ac4c",
      "eaa7921ff199497e91de437a55ee19a8"
     ]
    },
    "id": "wXCUgS9DZemr",
    "outputId": "4e3da24d-5d29-46a1-feda-9d7cd2cfc5a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a7ae8ebb9f4c929377e9728a332c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247e6b9246434ff2a437aa4dd9e8e430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medical_o1_sft.json:   0%|          | 0.00/58.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e20d4e3b0f34224adabf75b1ecac34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/19704 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465b20646b56478d9d40a4ce3cec8247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19704 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44e5f166e2b4852b088b2709630c276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "57964055"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"<|user|>{}<|end|><|assistant|><think>{}</think>{}\"\"\"\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"Question\"]\n",
    "    cots = examples[\"Complex_CoT\"]\n",
    "    outputs = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        text = prompt_template.format(input, cot, output) + \"<|end|>\"\n",
    "        # text = prompt_template.format(input, cot, output) + \"<|endoftext|>\"\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "    }\n",
    "\n",
    "# Create the English dataset\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train\",trust_remote_code=True)\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,remove_columns=[\"Question\", \"Complex_CoT\", \"Response\"])\n",
    "dataset.to_json(\"en_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **মাইক্রোসফট অলিভ দিয়ে ফাইন-টিউনিং**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKRw6_E3ZnCI",
    "outputId": "7174c469-fb10-49d3-b85c-4d946cf35c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HuggingFace model from ./phi-4-mini-reasoning\n",
      "[2025-04-30 04:54:21,528] [INFO] [run.py:142:run_engine] Running workflow default_workflow\n",
      "[2025-04-30 04:54:21,529] [INFO] [cache.py:138:__init__] Using cache directory: /content/.olive-cache/default_workflow\n",
      "[2025-04-30 04:54:21,531] [INFO] [accelerator_creator.py:217:create_accelerators] Running workflow on accelerator specs: gpu-cuda\n",
      "[2025-04-30 04:54:21,558] [INFO] [engine.py:223:run] Running Olive on accelerator: gpu-cuda\n",
      "[2025-04-30 04:54:21,558] [INFO] [engine.py:864:_create_system] Creating target system ...\n",
      "[2025-04-30 04:54:21,559] [INFO] [engine.py:867:_create_system] Target system created in 0.000796 seconds\n",
      "[2025-04-30 04:54:21,559] [INFO] [engine.py:879:_create_system] Creating host system ...\n",
      "[2025-04-30 04:54:21,559] [INFO] [engine.py:882:_create_system] Host system created in 0.000076 seconds\n",
      "[2025-04-30 04:54:43,430] [INFO] [engine.py:683:_run_pass] Running pass f:lora\n",
      "2025-04-30 04:54:43.738250: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-30 04:54:43.755734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745988883.777849    9887 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745988883.784567    9887 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-30 04:54:43.807494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.45s/it]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[2025-04-30 04:54:57,675] [INFO] [lora.py:459:train_and_save_new_model] Running fine-tuning\n",
      "  0% 0/100 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "{'loss': 2.4632, 'grad_norm': 0.29499655961990356, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      " 10% 10/100 [00:21<03:07,  2.08s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.23it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.62it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.9818514585494995, 'eval_runtime': 19.8548, 'eval_samples_per_second': 12.894, 'eval_steps_per_second': 1.612, 'epoch': 0.31}\n",
      " 10% 10/100 [00:41<03:07,  2.08s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.8642, 'grad_norm': 0.15466062724590302, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      " 20% 20/100 [01:02<03:04,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.23it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.7856942415237427, 'eval_runtime': 19.8581, 'eval_samples_per_second': 12.891, 'eval_steps_per_second': 1.611, 'epoch': 0.62}\n",
      " 20% 20/100 [01:22<03:04,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.7277, 'grad_norm': 0.08563224971294403, 'learning_rate': 0.0002, 'epoch': 0.94}\n",
      " 30% 30/100 [01:42<02:41,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.7160663604736328, 'eval_runtime': 19.8597, 'eval_samples_per_second': 12.89, 'eval_steps_per_second': 1.611, 'epoch': 0.94}\n",
      " 30% 30/100 [02:02<02:41,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.695, 'grad_norm': 0.08090092241764069, 'learning_rate': 0.0002, 'epoch': 1.25}\n",
      " 40% 40/100 [02:23<02:18,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.62it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.6832425594329834, 'eval_runtime': 19.8572, 'eval_samples_per_second': 12.892, 'eval_steps_per_second': 1.612, 'epoch': 1.25}\n",
      " 40% 40/100 [02:43<02:18,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.6602, 'grad_norm': 0.07778627425432205, 'learning_rate': 0.0002, 'epoch': 1.56}\n",
      " 50% 50/100 [03:03<01:55,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.62it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.662233591079712, 'eval_runtime': 19.8558, 'eval_samples_per_second': 12.893, 'eval_steps_per_second': 1.612, 'epoch': 1.56}\n",
      " 50% 50/100 [03:23<01:55,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.6495, 'grad_norm': 0.0774785503745079, 'learning_rate': 0.0002, 'epoch': 1.88}\n",
      " 60% 60/100 [03:44<01:32,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.62it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.6472687721252441, 'eval_runtime': 19.8561, 'eval_samples_per_second': 12.893, 'eval_steps_per_second': 1.612, 'epoch': 1.88}\n",
      " 60% 60/100 [04:04<01:32,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.6077, 'grad_norm': 0.07231836020946503, 'learning_rate': 0.0002, 'epoch': 2.19}\n",
      " 70% 70/100 [04:24<01:09,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.23it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.6386148929595947, 'eval_runtime': 19.8557, 'eval_samples_per_second': 12.893, 'eval_steps_per_second': 1.612, 'epoch': 2.19}\n",
      " 70% 70/100 [04:44<01:09,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.6263, 'grad_norm': 0.07908853888511658, 'learning_rate': 0.0002, 'epoch': 2.5}\n",
      " 80% 80/100 [05:05<00:46,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.62it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.62it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.631971001625061, 'eval_runtime': 19.8567, 'eval_samples_per_second': 12.892, 'eval_steps_per_second': 1.612, 'epoch': 2.5}\n",
      " 80% 80/100 [05:25<00:46,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.5808, 'grad_norm': 0.08782722055912018, 'learning_rate': 0.0002, 'epoch': 2.81}\n",
      " 90% 90/100 [05:45<00:23,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.28it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                    \n",
      "\u001b[A{'eval_loss': 1.6269280910491943, 'eval_runtime': 19.8578, 'eval_samples_per_second': 12.892, 'eval_steps_per_second': 1.611, 'epoch': 2.81}\n",
      " 90% 90/100 [06:05<00:23,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'loss': 1.5847, 'grad_norm': 0.08583717793226242, 'learning_rate': 0.0002, 'epoch': 3.12}\n",
      "100% 100/100 [06:26<00:00,  2.31s/it]\n",
      "  0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 2/32 [00:00<00:09,  3.22it/s]\u001b[A\n",
      "  9% 3/32 [00:01<00:12,  2.27it/s]\u001b[A\n",
      " 12% 4/32 [00:01<00:14,  1.97it/s]\u001b[A\n",
      " 16% 5/32 [00:02<00:14,  1.83it/s]\u001b[A\n",
      " 19% 6/32 [00:03<00:14,  1.75it/s]\u001b[A\n",
      " 22% 7/32 [00:03<00:14,  1.70it/s]\u001b[A\n",
      " 25% 8/32 [00:04<00:14,  1.67it/s]\u001b[A\n",
      " 28% 9/32 [00:04<00:13,  1.65it/s]\u001b[A\n",
      " 31% 10/32 [00:05<00:13,  1.64it/s]\u001b[A\n",
      " 34% 11/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 38% 12/32 [00:06<00:12,  1.63it/s]\u001b[A\n",
      " 41% 13/32 [00:07<00:11,  1.62it/s]\u001b[A\n",
      " 44% 14/32 [00:08<00:11,  1.62it/s]\u001b[A\n",
      " 47% 15/32 [00:08<00:10,  1.62it/s]\u001b[A\n",
      " 50% 16/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 53% 17/32 [00:09<00:09,  1.61it/s]\u001b[A\n",
      " 56% 18/32 [00:10<00:08,  1.61it/s]\u001b[A\n",
      " 59% 19/32 [00:11<00:08,  1.61it/s]\u001b[A\n",
      " 62% 20/32 [00:11<00:07,  1.61it/s]\u001b[A\n",
      " 66% 21/32 [00:12<00:06,  1.61it/s]\u001b[A\n",
      " 69% 22/32 [00:13<00:06,  1.61it/s]\u001b[A\n",
      " 72% 23/32 [00:13<00:05,  1.61it/s]\u001b[A\n",
      " 75% 24/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 78% 25/32 [00:14<00:04,  1.61it/s]\u001b[A\n",
      " 81% 26/32 [00:15<00:03,  1.61it/s]\u001b[A\n",
      " 84% 27/32 [00:16<00:03,  1.61it/s]\u001b[A\n",
      " 88% 28/32 [00:16<00:02,  1.61it/s]\u001b[A\n",
      " 91% 29/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 94% 30/32 [00:17<00:01,  1.61it/s]\u001b[A\n",
      " 97% 31/32 [00:18<00:00,  1.61it/s]\u001b[A\n",
      "                                     \n",
      "\u001b[A{'eval_loss': 1.6234115362167358, 'eval_runtime': 19.8546, 'eval_samples_per_second': 12.894, 'eval_steps_per_second': 1.612, 'epoch': 3.12}\n",
      "100% 100/100 [06:46<00:00,  2.31s/it]\n",
      "100% 32/32 [00:19<00:00,  1.61it/s]\u001b[A\n",
      "{'train_runtime': 406.8296, 'train_samples_per_second': 1.966, 'train_steps_per_second': 0.246, 'train_loss': 1.7459353351593017, 'epoch': 3.12}\n",
      "100% 100/100 [06:46<00:00,  4.07s/it]\n",
      "[2025-04-30 05:01:45,195] [INFO] [engine.py:757:_run_pass] Pass f:lora finished in 421.764954 seconds\n",
      "[2025-04-30 05:01:45,196] [INFO] [engine.py:241:run] Run history for gpu-cuda:\n",
      "[2025-04-30 05:01:45,217] [INFO] [engine.py:497:dump_run_history] run history:\n",
      "+------------+-------------------+-------------+----------------+-----------+\n",
      "| model_id   | parent_model_id   | from_pass   |   duration_sec | metrics   |\n",
      "+============+===================+=============+================+===========+\n",
      "| 9ec28ddd   |                   |             |                |           |\n",
      "+------------+-------------------+-------------+----------------+-----------+\n",
      "| 53f955f3   | 9ec28ddd          | lora        |        421.765 |           |\n",
      "+------------+-------------------+-------------+----------------+-----------+\n",
      "[2025-04-30 05:01:45,217] [INFO] [cache.py:195:load_model] Loading model 53f955f3 from cache.\n",
      "[2025-04-30 05:02:09,751] [INFO] [engine.py:266:run] Saved output model to /content/models/phi-4-mini-reasoning/ft\n",
      "Model is saved at /content/models/phi-4-mini-reasoning/ft\n"
     ]
    }
   ],
   "source": [
    "!olive finetune \\\n",
    "    --method lora \\\n",
    "    --model_name_or_path \"./phi-4-mini-reasoning\" \\\n",
    "    --trust_remote_code \\\n",
    "    --data_name json \\\n",
    "    --data_files ./en_dataset.jsonl \\\n",
    "    --train_split \"train[:16000]\" \\\n",
    "    --eval_split \"train[16000:19700]\" \\\n",
    "    --text_field \"text\" \\\n",
    "    --max_steps 100 \\\n",
    "    --logging_steps 10 \\\n",
    "    --output_path models/phi-4-mini-reasoning/ft \\\n",
    "    --log_level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w18OVFLKcZcW",
    "outputId": "a12f6c13-f70a-49e0-c8d0-b903a5821119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "  Downloading optimum-1.24.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum) (2.6.0+cu124)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from optimum) (24.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optimum) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum) (0.30.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2025.1.31)\n",
      "Downloading optimum-1.24.0-py3-none-any.whl (433 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: optimum\n",
      "Successfully installed optimum-1.24.0\n"
     ]
    }
   ],
   "source": [
    "! pip install optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **মাইক্রোসফট অলিভ দিয়ে রূপান্তর করুন**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxDhYkLIO9q0",
    "outputId": "d7381d1c-7e7d-4935-e9a4-4bfd66406d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HuggingFace model from ./phi-4-mini-reasoning\n",
      "[2025-04-30 05:49:08,616] [INFO] [run.py:142:run_engine] Running workflow default_workflow\n",
      "[2025-04-30 05:49:08,617] [INFO] [cache.py:138:__init__] Using cache directory: /content/.olive-cache/default_workflow\n",
      "[2025-04-30 05:49:08,620] [INFO] [accelerator_creator.py:217:create_accelerators] Running workflow on accelerator specs: gpu-cuda\n",
      "[2025-04-30 05:49:08,621] [INFO] [engine.py:223:run] Running Olive on accelerator: gpu-cuda\n",
      "[2025-04-30 05:49:08,621] [INFO] [engine.py:864:_create_system] Creating target system ...\n",
      "[2025-04-30 05:49:08,621] [INFO] [engine.py:867:_create_system] Target system created in 0.000097 seconds\n",
      "[2025-04-30 05:49:08,621] [INFO] [engine.py:879:_create_system] Creating host system ...\n",
      "[2025-04-30 05:49:08,622] [INFO] [engine.py:882:_create_system] Host system created in 0.000082 seconds\n",
      "[2025-04-30 05:49:49,722] [INFO] [engine.py:683:_run_pass] Running pass m:modelbuilder\n",
      "2025-04-30 05:49:50.801110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-30 05:49:51.084769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745992191.115651   26455 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745992191.124385   26455 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-30 05:49:51.165741: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "GroupQueryAttention (GQA) is used in this model.\n",
      "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.26s/it]\n",
      "Reading embedding layer\n",
      "Reading decoder layer 0\n",
      "Reading decoder layer 1\n",
      "Reading decoder layer 2\n",
      "Reading decoder layer 3\n",
      "Reading decoder layer 4\n",
      "Reading decoder layer 5\n",
      "Reading decoder layer 6\n",
      "Reading decoder layer 7\n",
      "Reading decoder layer 8\n",
      "Reading decoder layer 9\n",
      "Reading decoder layer 10\n",
      "Reading decoder layer 11\n",
      "Reading decoder layer 12\n",
      "Reading decoder layer 13\n",
      "Reading decoder layer 14\n",
      "Reading decoder layer 15\n",
      "Reading decoder layer 16\n",
      "Reading decoder layer 17\n",
      "Reading decoder layer 18\n",
      "Reading decoder layer 19\n",
      "Reading decoder layer 20\n",
      "Reading decoder layer 21\n",
      "Reading decoder layer 22\n",
      "Reading decoder layer 23\n",
      "Reading decoder layer 24\n",
      "Reading decoder layer 25\n",
      "Reading decoder layer 26\n",
      "Reading decoder layer 27\n",
      "Reading decoder layer 28\n",
      "Reading decoder layer 29\n",
      "Reading decoder layer 30\n",
      "Reading decoder layer 31\n",
      "Reading LM head\n",
      "Saving ONNX model in /content/.olive-cache/default_workflow/runs/87002c87/models\n",
      "Saving GenAI config in /content/.olive-cache/default_workflow/runs/87002c87/models\n",
      "Saving processing files in /content/.olive-cache/default_workflow/runs/87002c87/models for GenAI\n",
      "[2025-04-30 05:58:29,603] [INFO] [engine.py:757:_run_pass] Pass m:modelbuilder finished in 519.881211 seconds\n",
      "[2025-04-30 05:58:29,606] [INFO] [engine.py:241:run] Run history for gpu-cuda:\n",
      "[2025-04-30 05:58:29,611] [INFO] [engine.py:497:dump_run_history] run history:\n",
      "+------------+-------------------+--------------+----------------+-----------+\n",
      "| model_id   | parent_model_id   | from_pass    |   duration_sec | metrics   |\n",
      "+============+===================+==============+================+===========+\n",
      "| 9015cf1e   |                   |              |                |           |\n",
      "+------------+-------------------+--------------+----------------+-----------+\n",
      "| 87002c87   | 9015cf1e          | modelbuilder |        519.881 |           |\n",
      "+------------+-------------------+--------------+----------------+-----------+\n",
      "[2025-04-30 05:58:29,611] [INFO] [cache.py:195:load_model] Loading model 87002c87 from cache.\n",
      "[2025-04-30 06:03:06,182] [INFO] [engine.py:266:run] Saved output model to /content/models/phi-4-mini-reasoning/onnx\n",
      "Model is saved at /content/models/phi-4-mini-reasoning/onnx\n"
     ]
    }
   ],
   "source": [
    "! olive capture-onnx-graph \\\n",
    "    --model_name_or_path \"./phi-4-mini-reasoning\" \\\n",
    "    --adapter_path models/phi-4-mini-reasoning/ft/adapter \\\n",
    "    --use_model_builder  \\\n",
    "    --output_path models/phi-4-mini-reasoning/onnx \\\n",
    "    --log_level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTr_XWqfP98T",
    "outputId": "495c0359-f7a4-4544-9ce8-e6fb66d3dcb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous command output of type onnxmodel from models/phi-4-mini-reasoning/onnx\n",
      "[2025-04-30 06:03:48,499] [INFO] [run.py:142:run_engine] Running workflow default_workflow\n",
      "[2025-04-30 06:03:48,501] [INFO] [cache.py:138:__init__] Using cache directory: /content/.olive-cache/default_workflow\n",
      "[2025-04-30 06:03:48,504] [INFO] [accelerator_creator.py:217:create_accelerators] Running workflow on accelerator specs: cpu-cpu\n",
      "[2025-04-30 06:03:48,505] [INFO] [engine.py:223:run] Running Olive on accelerator: cpu-cpu\n",
      "[2025-04-30 06:03:48,505] [INFO] [engine.py:864:_create_system] Creating target system ...\n",
      "[2025-04-30 06:03:48,505] [INFO] [engine.py:867:_create_system] Target system created in 0.000091 seconds\n",
      "[2025-04-30 06:03:48,505] [INFO] [engine.py:879:_create_system] Creating host system ...\n",
      "[2025-04-30 06:03:48,505] [INFO] [engine.py:882:_create_system] Host system created in 0.000071 seconds\n",
      "[2025-04-30 06:04:14,207] [INFO] [engine.py:683:_run_pass] Running pass e:extractadapters\n",
      "[2025-04-30 06:11:14,960] [INFO] [engine.py:757:_run_pass] Pass e:extractadapters finished in 420.752557 seconds\n",
      "[2025-04-30 06:11:14,983] [INFO] [engine.py:241:run] Run history for cpu-cpu:\n",
      "[2025-04-30 06:11:14,988] [INFO] [engine.py:497:dump_run_history] run history:\n",
      "+------------+-------------------+-----------------+----------------+-----------+\n",
      "| model_id   | parent_model_id   | from_pass       |   duration_sec | metrics   |\n",
      "+============+===================+=================+================+===========+\n",
      "| d2014459   |                   |                 |                |           |\n",
      "+------------+-------------------+-----------------+----------------+-----------+\n",
      "| 62ad037f   | d2014459          | extractadapters |        420.753 |           |\n",
      "+------------+-------------------+-----------------+----------------+-----------+\n",
      "[2025-04-30 06:11:14,988] [INFO] [cache.py:195:load_model] Loading model 62ad037f from cache.\n",
      "[2025-04-30 06:15:20,208] [INFO] [engine.py:266:run] Saved output model to /content/models/phi-4-mini-reasoning/adapter-onnx\n",
      "Model is saved at /content/models/phi-4-mini-reasoning/adapter-onnx\n"
     ]
    }
   ],
   "source": [
    "! olive generate-adapter \\\n",
    "    --model_name_or_path models/phi-4-mini-reasoning/onnx \\\n",
    "    --output_path models/phi-4-mini-reasoning/adapter-onnx \\\n",
    "    --log_level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ONNXRuntime-GenAI দিয়ে ইনফারেন্স ফাইন-টিউনিং মডেল**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "caxqbp3HlxHJ"
   },
   "outputs": [],
   "source": [
    "import onnxruntime_genai as og\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jHWgjJyyl0To"
   },
   "outputs": [],
   "source": [
    "model_folder = \"./models/phi-4-mini-reasoning/adapter-onnx/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NUe99Odtl_s-"
   },
   "outputs": [],
   "source": [
    "model = og.Model(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oiX9fJOfmCON"
   },
   "outputs": [],
   "source": [
    "adapters = og.Adapters(model)\n",
    "adapters.load('./models/phi-4-mini-reasoning/adapter-onnx/model/adapter_weights.onnx_adapter', \"en_medical_reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6u0rLK-gmRA0"
   },
   "outputs": [],
   "source": [
    "tokenizer = og.Tokenizer(model)\n",
    "tokenizer_stream = tokenizer.create_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "LTDPq-I6mTly"
   },
   "outputs": [],
   "source": [
    "search_options = {}\n",
    "search_options['max_length'] = 200\n",
    "search_options['past_present_share_buffer'] = False\n",
    "search_options['temperature'] = 1\n",
    "search_options['top_k'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "zWW8NZ3Km609"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<|user|>{}<|end|><|assistant|><think>\"\"\"\n",
    "\n",
    "question = \"\"\" A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110\\/min, respirations 22\\/min, and blood pressure 90\\/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured? \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "ZOXvs84ynA14"
   },
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "jZE4haq9_kr2",
    "outputId": "c866839c-393d-4db6-df77-ad901a4ea08d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<|user|> A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110\\\\/min, respirations 22\\\\/min, and blood pressure 90\\\\/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured? <|end|><|assistant|><think>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "1FVfDZ-lnBmZ"
   },
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.encode(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "IlRZNUJCnDmG"
   },
   "outputs": [],
   "source": [
    "params = og.GeneratorParams(model)\n",
    "params.set_search_options(**search_options)\n",
    "generator = og.Generator(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "MSRL2yfHnFQD"
   },
   "outputs": [],
   "source": [
    "generator.set_active_adapter(adapters, \"en_medical_reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "D-4GWxT5nHf9"
   },
   "outputs": [],
   "source": [
    "generator.append_tokens(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGAL0ZScnMop",
    "outputId": "b5974bf5-3c33-411b-b403-4e3941264253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's dig deeper into figuring out what's going on internally with Ms.A's chest wound. She's experiencing severe symptoms—a fast-tickling pulse, rapid breathing, dropping blood pressure—and she's visibly struggling internally. Fast breathing signals hyperventilating hyperactive lungs—a symptom tied tightly to hyperactive breathing triggered internally—not externally triggered hyperventilations—which wouldn't trigger hyperactive breathing externally—or hyperactive breathing triggered externally—which relies exclusively on external stimuli/hypersensitisation/hyp"
     ]
    }
   ],
   "source": [
    "while not generator.is_done():\n",
    "    generator.generate_next_token()\n",
    "    new_token = generator.get_next_tokens()[0]\n",
    "    print(tokenizer_stream.decode(new_token), end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**অস্বীকৃতি**:  \nএই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসম্ভব সঠিকতার জন্য চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। মূল ভাষায় থাকা নথিটিকে প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদ ব্যবহারের ফলে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যা হলে আমরা তার জন্য দায়ী থাকব না।\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0754f780703a4a32a51fa8c27c69a460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0abb5d6f65b74c179a42b995e7d9b91a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1239108cd0f542608cb4a09ddbb260db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1786df0bec2640999945e6a8a1953ecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0abb5d6f65b74c179a42b995e7d9b91a",
      "max": 19704,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_378fea5576554169b9deb0d6c94968c3",
      "value": 19704
     }
    },
    "1f300a0bfd41418cbec0eb618e348730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "220dc26139ae429cb696198e5d79654a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "247e6b9246434ff2a437aa4dd9e8e430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f6ee757420e4384a6563d47718db437",
       "IPY_MODEL_8fe2c0adf60246af972e8f42f9ef279e",
       "IPY_MODEL_31da299ba48e43ac9b5005365892171c"
      ],
      "layout": "IPY_MODEL_f9167aff986347afab423ab5d7c5e7c8"
     }
    },
    "2670c1daf2d34a3ba8af10be8702fd30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "271ae264766a4153ab316c107579af77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "278855f34ff24ce1b60b00fba584498f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31da299ba48e43ac9b5005365892171c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9eada962fd34eb0a014c58e93bf732e",
      "placeholder": "​",
      "style": "IPY_MODEL_e46d3b59fd6f46619c09809527501d69",
      "value": " 58.2M/58.2M [00:00&lt;00:00, 202MB/s]"
     }
    },
    "378fea5576554169b9deb0d6c94968c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e20d4e3b0f34224adabf75b1ecac34f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc46778ff2aa422288917c971dc277b7",
       "IPY_MODEL_dc2d550d148b48c99b659341008d729f",
       "IPY_MODEL_7a92587a59554c87babf305061eda026"
      ],
      "layout": "IPY_MODEL_9384c5ad38b6453f9a4efeef92f572ec"
     }
    },
    "465b20646b56478d9d40a4ce3cec8247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2cd205fa607417da69e93ef2ef9d1e4",
       "IPY_MODEL_1786df0bec2640999945e6a8a1953ecf",
       "IPY_MODEL_6ab7b20251924f9a8c6dedfb8a1038cb"
      ],
      "layout": "IPY_MODEL_9227435037fa4fccbb8642b55bae1eee"
     }
    },
    "4d12a72021044839861d448cde4e0eaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3ef7313a574323ac0d4b6bbdbb8366": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f2bbd0a6ffe4d3e8679df08c84aa661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f4f74b5c9d14ecdaf882b51a09a47d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f6ee757420e4384a6563d47718db437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2670c1daf2d34a3ba8af10be8702fd30",
      "placeholder": "​",
      "style": "IPY_MODEL_d08ffe320c4644f69bff07b67ef3c2d1",
      "value": "medical_o1_sft.json: 100%"
     }
    },
    "4f7a5e1944124b358a1f7a23241fdfb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "550969d6ad534df49a5f8369c2eab820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ae4121f2f6e4da8a7926c81604c480b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_8e41320caf0d4bc0bf02952c206617f5",
      "style": "IPY_MODEL_7e6ba9d4146f44cda3a07a978080307e",
      "value": true
     }
    },
    "5e72b08350f142b4917049d21529ac4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60a7ae8ebb9f4c929377e9728a332c57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b78b15cfcee46b89c06825fb0c8f317",
       "IPY_MODEL_65548dd1c9d14dfca1f91f889a967e00",
       "IPY_MODEL_b5635dda4d7d4fbb85965531f1109e0a"
      ],
      "layout": "IPY_MODEL_550969d6ad534df49a5f8369c2eab820"
     }
    },
    "60e4cc2fccd74bb89b6161ad6319e02c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65548dd1c9d14dfca1f91f889a967e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d14a6da1909493db5c78516da9694f0",
      "max": 1967,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8262ee0334c44d8bbb3eb74eeaef033",
      "value": 1967
     }
    },
    "680dfa8fabac4da29ef5af115f5119db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab26aec9bac84bc4bce845b50fe7c9c3",
      "placeholder": "​",
      "style": "IPY_MODEL_7fb7d4ed68d2411bb059f943e992d6f7",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "6ab7b20251924f9a8c6dedfb8a1038cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db8cde78a601454097ab9a36c15785e5",
      "placeholder": "​",
      "style": "IPY_MODEL_4d3ef7313a574323ac0d4b6bbdbb8366",
      "value": " 19704/19704 [00:00&lt;00:00, 63463.10 examples/s]"
     }
    },
    "6d14a6da1909493db5c78516da9694f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75e5c63249c444878ff56a8ff76f2063": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a0822f62d65460ebc427e86a86f4f39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "7a92587a59554c87babf305061eda026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5762143009245999824b7f5f036ba16",
      "placeholder": "​",
      "style": "IPY_MODEL_271ae264766a4153ab316c107579af77",
      "value": " 19704/19704 [00:01&lt;00:00, 16135.20 examples/s]"
     }
    },
    "7e6ba9d4146f44cda3a07a978080307e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fb7d4ed68d2411bb059f943e992d6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84f92d50d54e405c8e7ec0b365b5bce3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8905ea43b37e40028f47ea111422c2e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_7a0822f62d65460ebc427e86a86f4f39"
     }
    },
    "8b78b15cfcee46b89c06825fb0c8f317": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75e5c63249c444878ff56a8ff76f2063",
      "placeholder": "​",
      "style": "IPY_MODEL_e56eded8fce94a61aea15d41081ae1dc",
      "value": "README.md: 100%"
     }
    },
    "8e41320caf0d4bc0bf02952c206617f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fe2c0adf60246af972e8f42f9ef279e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_220dc26139ae429cb696198e5d79654a",
      "max": 58177051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5fd2ca404c84c66b50c62acc88a4124",
      "value": 58177051
     }
    },
    "9088c9ac5215436380b87af65230d497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e72b08350f142b4917049d21529ac4c",
      "placeholder": "​",
      "style": "IPY_MODEL_eaa7921ff199497e91de437a55ee19a8",
      "value": " 20/20 [00:00&lt;00:00, 33.31ba/s]"
     }
    },
    "9227435037fa4fccbb8642b55bae1eee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "928487dc2dfb4ae091462e7d86efc39e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_a4ed454ea3c64c4bb2e42bf0cfe5bc17",
      "placeholder": "​",
      "style": "IPY_MODEL_94aedfd4c9004dbc91a641705f0ff560",
      "value": ""
     }
    },
    "9384c5ad38b6453f9a4efeef92f572ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94aedfd4c9004dbc91a641705f0ff560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98ddf4f49f4d4011a0f4dcb76e17a2d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2cd205fa607417da69e93ef2ef9d1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84f92d50d54e405c8e7ec0b365b5bce3",
      "placeholder": "​",
      "style": "IPY_MODEL_4f4f74b5c9d14ecdaf882b51a09a47d6",
      "value": "Map: 100%"
     }
    },
    "a4ed454ea3c64c4bb2e42bf0cfe5bc17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa07edae47314c7a853e1b9e2aec97c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "ab26aec9bac84bc4bce845b50fe7c9c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9eb39ddf5940879b3250ac416511a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5635dda4d7d4fbb85965531f1109e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0b3529257ba4a34becbb413009ea9fc",
      "placeholder": "​",
      "style": "IPY_MODEL_4f2bbd0a6ffe4d3e8679df08c84aa661",
      "value": " 1.97k/1.97k [00:00&lt;00:00, 222kB/s]"
     }
    },
    "b6c70198f0e84173beb32aeb995c27ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_1f300a0bfd41418cbec0eb618e348730",
      "style": "IPY_MODEL_aa07edae47314c7a853e1b9e2aec97c3",
      "tooltip": ""
     }
    },
    "bc46778ff2aa422288917c971dc277b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7f69740b7d9478e9e3339b0518a0efc",
      "placeholder": "​",
      "style": "IPY_MODEL_0754f780703a4a32a51fa8c27c69a460",
      "value": "Generating train split: 100%"
     }
    },
    "c44e5f166e2b4852b088b2709630c276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8213f2dced54dd58cce20509d666555",
       "IPY_MODEL_f9e72370022b476a9a23f49537f73ac8",
       "IPY_MODEL_9088c9ac5215436380b87af65230d497"
      ],
      "layout": "IPY_MODEL_fcaac2751a344393b8d3471caaa90a89"
     }
    },
    "c5762143009245999824b7f5f036ba16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7f69740b7d9478e9e3339b0518a0efc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caea5af60f3c40a791ce460371016f6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d08ffe320c4644f69bff07b67ef3c2d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db8cde78a601454097ab9a36c15785e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc2d550d148b48c99b659341008d729f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d12a72021044839861d448cde4e0eaa",
      "max": 19704,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98ddf4f49f4d4011a0f4dcb76e17a2d4",
      "value": 19704
     }
    },
    "dde7cf590f0742cb93eedc8aad121efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caea5af60f3c40a791ce460371016f6e",
      "placeholder": "​",
      "style": "IPY_MODEL_ebed45359f7940daa6fd781fbe80155c",
      "value": "Connecting..."
     }
    },
    "e0b3529257ba4a34becbb413009ea9fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e46d3b59fd6f46619c09809527501d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e56eded8fce94a61aea15d41081ae1dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8262ee0334c44d8bbb3eb74eeaef033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9eada962fd34eb0a014c58e93bf732e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa7921ff199497e91de437a55ee19a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebed45359f7940daa6fd781fbe80155c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5fd2ca404c84c66b50c62acc88a4124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8213f2dced54dd58cce20509d666555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60e4cc2fccd74bb89b6161ad6319e02c",
      "placeholder": "​",
      "style": "IPY_MODEL_278855f34ff24ce1b60b00fba584498f",
      "value": "Creating json from Arrow format: 100%"
     }
    },
    "f9167aff986347afab423ab5d7c5e7c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9e72370022b476a9a23f49537f73ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1239108cd0f542608cb4a09ddbb260db",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f7a5e1944124b358a1f7a23241fdfb2",
      "value": 20
     }
    },
    "fb9601d0756f4715b5de09b219c62a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcaac2751a344393b8d3471caaa90a89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feb0daf2ea974515aa56550485d8e13f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af9eb39ddf5940879b3250ac416511a6",
      "placeholder": "​",
      "style": "IPY_MODEL_fb9601d0756f4715b5de09b219c62a14",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    }
   }
  },
  "coopTranslator": {
   "original_hash": "9fffb9d2432813be90392fbfab3de223",
   "translation_date": "2025-09-12T18:35:43+00:00",
   "source_file": "md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb",
   "language_code": "bn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}