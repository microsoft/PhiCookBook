<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "006e8cf75211d3297f24e1b22e38955f",
  "translation_date": "2025-05-09T18:29:16+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "bn"
}
-->
# Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper

## ওভারভিউ

Interactive Phi 3 Mini 4K Instruct Chatbot একটি টুল যা ব্যবহারকারীদের Microsoft Phi 3 Mini 4K instruct ডেমোর সাথে টেক্সট বা অডিও ইনপুট ব্যবহার করে ইন্টারঅ্যাক্ট করার সুযোগ দেয়। এই চ্যাটবট বিভিন্ন কাজের জন্য ব্যবহার করা যায়, যেমন অনুবাদ, আবহাওয়ার আপডেট, এবং সাধারণ তথ্য সংগ্রহ।

### শুরু করা

এই চ্যাটবট ব্যবহার করতে, নিচের নির্দেশনাগুলো অনুসরণ করুন:

1. একটি নতুন [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) খুলুন
2. নোটবুকের প্রধান উইন্ডোতে, আপনি একটি চ্যাটবক্স ইন্টারফেস দেখতে পাবেন যেখানে একটি টেক্সট ইনপুট বক্স এবং "Send" বাটন রয়েছে।
3. টেক্সট-ভিত্তিক চ্যাটবট ব্যবহার করতে, শুধু টেক্সট ইনপুট বক্সে আপনার মেসেজ টাইপ করুন এবং "Send" বাটনে ক্লিক করুন। চ্যাটবট একটি অডিও ফাইল দিয়ে উত্তর দেবে যা সরাসরি নোটবুক থেকে প্লে করা যাবে।

**Note**: এই টুলটির জন্য একটি GPU এবং Microsoft Phi-3 ও OpenAI Whisper মডেলগুলোর অ্যাক্সেস প্রয়োজন, যা স্পিচ রিকগনিশন এবং অনুবাদের জন্য ব্যবহৃত হয়।

### GPU প্রয়োজনীয়তা

এই ডেমো চালাতে আপনার ১২ জিবি GPU মেমোরি প্রয়োজন।

**Microsoft-Phi-3-Mini-4K instruct** ডেমো চালানোর জন্য GPU তে মেমোরি প্রয়োজনীয়তা বিভিন্ন ফ্যাক্টরের উপর নির্ভর করবে, যেমন ইনপুট ডেটার আকার (অডিও বা টেক্সট), অনুবাদের জন্য ব্যবহৃত ভাষা, মডেলের গতি, এবং GPU তে উপলব্ধ মেমোরি।

সাধারণভাবে, Whisper মডেল GPU তে চলার জন্য ডিজাইন করা হয়েছে। Whisper মডেল চালানোর জন্য সুপারিশকৃত ন্যূনতম GPU মেমোরি ৮ জিবি, তবে প্রয়োজনে এটি বড় মেমোরিও হ্যান্ডেল করতে পারে।

মডেলে বড় পরিমাণ ডেটা বা উচ্চ ভলিউম রিকোয়েস্ট চালালে বেশি GPU মেমোরির প্রয়োজন হতে পারে এবং/অথবা পারফরম্যান্স ইস্যু দেখা দিতে পারে। আপনার ব্যবহারের ক্ষেত্রে বিভিন্ন কনফিগারেশন দিয়ে পরীক্ষা করা এবং মেমোরি ব্যবহারের পর্যবেক্ষণ করে সেরা সেটিংস নির্ধারণ করার পরামর্শ দেওয়া হয়।

## E2E স্যাম্পল for Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper

[Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) শিরোনামের জুপিটার নোটবুকটি Microsoft Phi 3 Mini 4K instruct ডেমো ব্যবহার করে অডিও বা লিখিত টেক্সট ইনপুট থেকে টেক্সট জেনারেট করার পদ্ধতি দেখায়। নোটবুকটি কয়েকটি ফাংশন সংজ্ঞায়িত করে:

1. `tts_file_name(text)`: এই ফাংশনটি ইনপুট টেক্সটের ভিত্তিতে একটি ফাইল নাম তৈরি করে যা জেনারেট করা অডিও ফাইল সংরক্ষণের জন্য ব্যবহৃত হয়।
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: এই ফাংশনটি Edge TTS API ব্যবহার করে ইনপুট টেক্সটের বিভিন্ন অংশ থেকে একটি অডিও ফাইল তৈরি করে। ইনপুট প্যারামিটার হিসেবে অংশগুলোর তালিকা, স্পিচ রেট, ভয়েস নাম, এবং আউটপুট ফাইলের পাথ থাকে।
1. `talk(input_text)`: এই ফাংশনটি Edge TTS API ব্যবহার করে একটি অডিও ফাইল তৈরি করে এবং /content/audio ডিরেক্টরিতে র‍্যান্ডম নামের ফাইলে সেভ করে। ইনপুট প্যারামিটার হলো স্পিচে রূপান্তর করার জন্য ইনপুট টেক্সট।
1. `run_text_prompt(message, chat_history)`: এই ফাংশনটি Microsoft Phi 3 Mini 4K instruct ডেমো ব্যবহার করে মেসেজ ইনপুট থেকে একটি অডিও ফাইল তৈরি করে এবং সেটি চ্যাট ইতিহাসে যোগ করে।
1. `run_audio_prompt(audio, chat_history)`: এই ফাংশনটি Whisper মডেল API ব্যবহার করে একটি অডিও ফাইলকে টেক্সটে রূপান্তর করে এবং সেটি `run_text_prompt()` ফাংশনে পাঠায়।
1. কোডটি একটি Gradio অ্যাপ চালু করে যা ব্যবহারকারীদের Phi 3 Mini 4K instruct ডেমোর সাথে মেসেজ টাইপ করে বা অডিও ফাইল আপলোড করে ইন্টারঅ্যাক্ট করার সুযোগ দেয়। আউটপুট অ্যাপের মধ্যে টেক্সট মেসেজ হিসেবে প্রদর্শিত হয়।

## সমস্যা সমাধান

Cuda GPU ড্রাইভার ইনস্টল করা

1. নিশ্চিত করুন আপনার লিনাক্স অ্যাপ্লিকেশন আপডেটেড আছে

    ```bash
    sudo apt update
    ```

1. Cuda ড্রাইভার ইনস্টল করুন

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. Cuda ড্রাইভার লোকেশন রেজিস্টার করুন

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Nvidia GPU মেমোরি সাইজ চেক করুন (প্রয়োজন ১২ জিবি GPU মেমোরি)

    ```bash
    nvidia-smi
    ```

1. ক্যাশে খালি করুন: যদি আপনি PyTorch ব্যবহার করেন, তাহলে torch.cuda.empty_cache() কল করে সব অব্যবহৃত ক্যাশড মেমোরি মুক্ত করতে পারেন যাতে অন্য GPU অ্যাপ্লিকেশনগুলো ব্যবহার করতে পারে

    ```python
    torch.cuda.empty_cache() 
    ```

1. Nvidia Cuda চেক করুন

    ```bash
    nvcc --version
    ```

1. একটি Hugging Face টোকেন তৈরি করতে নিচের কাজগুলো করুন।

    - [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo) এ যান।
    - **New token** নির্বাচন করুন।
    - আপনি যে প্রজেক্টের জন্য টোকেন ব্যবহার করতে চান তার **Name** দিন।
    - **Type** হিসেবে **Write** নির্বাচন করুন।

> **Note**
>
> যদি নিচের এররটি পান:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> এটি সমাধান করতে, আপনার টার্মিনালে নিচের কমান্ডটি টাইপ করুন।
>
> ```bash
> sudo ldconfig
> ```

**অস্বীকারোক্তি**:  
এই নথিটি AI অনুবাদ সেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনূদিত হয়েছে। আমরা যথাসাধ্য সঠিকতার চেষ্টা করি, তবে অনুগ্রহ করে জানুন যে স্বয়ংক্রিয় অনুবাদে ভুল বা অসঙ্গতি থাকতে পারে। মূল নথিটি তার নিজস্ব ভাষায় প্রামাণিক উৎস হিসেবে বিবেচিত হওয়া উচিত। গুরুত্বপূর্ণ তথ্যের জন্য পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদের ব্যবহারের ফলে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।