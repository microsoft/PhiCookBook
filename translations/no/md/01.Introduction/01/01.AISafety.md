<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-07-16T17:49:27+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "no"
}
-->
# AI-sikkerhet for Phi-modeller  
Phi-familien av modeller ble utviklet i samsvar med [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl), som er et selskapsovergripende sett med krav basert på følgende seks prinsipper: ansvarlighet, åpenhet, rettferdighet, pålitelighet og sikkerhet, personvern og sikkerhet, samt inkludering, som utgjør [Microsofts Responsible AI-prinsipper](https://www.microsoft.com/ai/responsible-ai).

Som med de tidligere Phi-modellene, ble det tatt i bruk en flerfasettert sikkerhetsevaluering og sikkerhetspost-treningstilnærming, med ekstra tiltak for å ta hensyn til flerspråklige egenskaper i denne utgivelsen. Vår tilnærming til sikkerhetstrening og evalueringer, inkludert testing på tvers av flere språk og risikokategorier, er beskrevet i [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833). Selv om Phi-modellene drar nytte av denne tilnærmingen, bør utviklere anvende ansvarlige AI-praksiser, inkludert kartlegging, måling og risikoredusering knyttet til deres spesifikke brukstilfelle og kulturelle og språklige kontekst.

## Beste praksis

Som med andre modeller kan Phi-familien potensielt oppføre seg på måter som er urettferdige, upålitelige eller støtende.

Noen av begrensningene ved SLM og LLM som du bør være oppmerksom på inkluderer:

- **Tjenestekvalitet:** Phi-modellene er hovedsakelig trent på engelsk tekst. Språk andre enn engelsk vil oppleve dårligere ytelse. Engelske språkvarianter med mindre representasjon i treningsdataene kan oppleve dårligere ytelse enn standard amerikansk engelsk.  
- **Representasjon av skader og opprettholdelse av stereotyper:** Disse modellene kan over- eller underrepresentere grupper av mennesker, slette representasjon av enkelte grupper, eller forsterke nedsettende eller negative stereotyper. Til tross for sikkerhetspost-trening kan disse begrensningene fortsatt være til stede på grunn av ulik grad av representasjon av ulike grupper eller forekomst av negative stereotyper i treningsdata som reflekterer virkelige mønstre og samfunnsmessige skjevheter.  
- **Upassende eller støtende innhold:** Disse modellene kan produsere andre typer upassende eller støtende innhold, noe som kan gjøre det uegnet å bruke dem i sensitive sammenhenger uten ekstra tiltak som er spesifikke for brukstilfellet.  
- **Informasjonspålitelighet:** Språkmodeller kan generere meningsløst innhold eller fabrikkert innhold som kan høres rimelig ut, men som er unøyaktig eller utdatert.  
- **Begrenset omfang for kode:** Størstedelen av Phi-3 treningsdata er basert på Python og bruker vanlige pakker som "typing, math, random, collections, datetime, itertools". Hvis modellen genererer Python-skript som bruker andre pakker eller skript i andre språk, anbefaler vi sterkt at brukere manuelt verifiserer all API-bruk.

Utviklere bør anvende ansvarlige AI-praksiser og er ansvarlige for å sikre at et spesifikt brukstilfelle overholder gjeldende lover og regler (f.eks. personvern, handel osv.).

## Ansvarlige AI-hensyn

Som med andre språkmodeller kan Phi-serien potensielt oppføre seg på måter som er urettferdige, upålitelige eller støtende. Noen av begrensningene du bør være oppmerksom på inkluderer:

**Tjenestekvalitet:** Phi-modellene er hovedsakelig trent på engelsk tekst. Språk andre enn engelsk vil oppleve dårligere ytelse. Engelske språkvarianter med mindre representasjon i treningsdataene kan oppleve dårligere ytelse enn standard amerikansk engelsk.

**Representasjon av skader og opprettholdelse av stereotyper:** Disse modellene kan over- eller underrepresentere grupper av mennesker, slette representasjon av enkelte grupper, eller forsterke nedsettende eller negative stereotyper. Til tross for sikkerhetspost-trening kan disse begrensningene fortsatt være til stede på grunn av ulik grad av representasjon av ulike grupper eller forekomst av negative stereotyper i treningsdata som reflekterer virkelige mønstre og samfunnsmessige skjevheter.

**Upassende eller støtende innhold:** Disse modellene kan produsere andre typer upassende eller støtende innhold, noe som kan gjøre det uegnet å bruke dem i sensitive sammenhenger uten ekstra tiltak som er spesifikke for brukstilfellet.  
**Informasjonspålitelighet:** Språkmodeller kan generere meningsløst innhold eller fabrikkert innhold som kan høres rimelig ut, men som er unøyaktig eller utdatert.

**Begrenset omfang for kode:** Størstedelen av Phi-3 treningsdata er basert på Python og bruker vanlige pakker som "typing, math, random, collections, datetime, itertools". Hvis modellen genererer Python-skript som bruker andre pakker eller skript i andre språk, anbefaler vi sterkt at brukere manuelt verifiserer all API-bruk.

Utviklere bør anvende ansvarlige AI-praksiser og er ansvarlige for å sikre at et spesifikt brukstilfelle overholder gjeldende lover og regler (f.eks. personvern, handel osv.). Viktige områder for vurdering inkluderer:

**Tildeling:** Modeller kan være uegnet for situasjoner som kan ha betydelig innvirkning på juridisk status eller tildeling av ressurser eller livsmuligheter (f.eks. bolig, arbeid, kreditt osv.) uten ytterligere vurderinger og ekstra teknikker for å redusere skjevheter.

**Høyrisikoscenarier:** Utviklere bør vurdere egnetheten av å bruke modeller i høyrisikoscenarier hvor urettferdige, upålitelige eller støtende resultater kan være svært kostbare eller føre til skade. Dette inkluderer å gi råd i sensitive eller ekspertområder hvor nøyaktighet og pålitelighet er avgjørende (f.eks. juridisk eller helserelatert rådgivning). Ytterligere sikkerhetstiltak bør implementeres på applikasjonsnivå i henhold til distribusjonskonteksten.

**Feilinformasjon:** Modeller kan produsere unøyaktig informasjon. Utviklere bør følge beste praksis for åpenhet og informere sluttbrukere om at de interagerer med et AI-system. På applikasjonsnivå kan utviklere bygge inn tilbakemeldingsmekanismer og prosesser for å forankre svar i brukstilfellespesifikk, kontekstuell informasjon, en teknikk kjent som Retrieval Augmented Generation (RAG).

**Generering av skadelig innhold:** Utviklere bør vurdere utdata i konteksten og bruke tilgjengelige sikkerhetsklassifiserere eller tilpassede løsninger som passer for deres brukstilfelle.

**Misbruk:** Andre former for misbruk som svindel, spam eller produksjon av skadelig programvare kan være mulig, og utviklere bør sikre at deres applikasjoner ikke bryter gjeldende lover og regler.

### Finjustering og AI-innholdssikkerhet

Etter finjustering av en modell anbefaler vi sterkt å benytte [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) for å overvåke innholdet som genereres av modellene, identifisere og blokkere potensielle risikoer, trusler og kvalitetsproblemer.

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c40507c5e8be556615b8377a63b8764865d057d4faac3757a478.no.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) støtter både tekst- og bildeinnhold. Det kan distribueres i skyen, i isolerte containere og på edge-/innbygde enheter.

## Oversikt over Azure AI Content Safety

Azure AI Content Safety er ikke en løsning som passer for alle; den kan tilpasses for å samsvare med virksomheters spesifikke retningslinjer. I tillegg gjør dens flerspråklige modeller det mulig å forstå flere språk samtidig.

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a56cf708aff010a541799d002ae7ae84bb819b19ab8950591.no.png)

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5 videoer**

Azure AI Content Safety-tjenesten oppdager skadelig bruker- og AI-generert innhold i applikasjoner og tjenester. Den inkluderer tekst- og bilde-APIer som lar deg oppdage skadelig eller upassende materiale.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vennligst vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på originalspråket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.