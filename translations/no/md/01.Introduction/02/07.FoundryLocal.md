<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-07-16T19:47:54+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "no"
}
-->
## Komme i gang med Phi-Family-modeller i Foundry Local

### Introduksjon til Foundry Local

Foundry Local er en kraftig AI-inferensl√∏sning p√• enheten som bringer AI-funksjonalitet p√• bedriftsniv√• direkte til din lokale maskinvare. Denne veiledningen vil lede deg gjennom oppsett og bruk av Phi-Family-modeller med Foundry Local, og gir deg full kontroll over AI-arbeidsbelastningene dine samtidig som personvernet ivaretas og kostnadene reduseres.

Foundry Local gir fordeler innen ytelse, personvern, tilpasning og kostnad ved √• kj√∏re AI-modeller lokalt p√• enheten din. Det integreres s√∏ml√∏st i dine eksisterende arbeidsflyter og applikasjoner gjennom en intuitiv CLI, SDK og REST API.


![arch](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7.no.png)

### Hvorfor velge Foundry Local?

√Ö forst√• fordelene med Foundry Local vil hjelpe deg med √• ta informerte beslutninger om din AI-distribusjonsstrategi:

- **Inferens p√• enheten:** Kj√∏r modeller lokalt p√• din egen maskinvare, reduser kostnadene og behold all data p√• enheten din.

- **Modelltilpasning:** Velg mellom forh√•ndsinnstilte modeller eller bruk dine egne for √• m√∏te spesifikke krav og bruksomr√•der.

- **Kostnadseffektivitet:** Fjern l√∏pende kostnader for skytjenester ved √• bruke eksisterende maskinvare, noe som gj√∏r AI mer tilgjengelig.

- **S√∏ml√∏s integrasjon:** Koble til applikasjonene dine via SDK, API-endepunkter eller CLI, med enkel skalering til Azure AI Foundry n√•r behovene vokser.

> **Getting Started Note:** Denne veiledningen fokuserer p√• bruk av Foundry Local gjennom CLI og SDK. Du vil l√¶re begge tiln√¶rmingene for √• hjelpe deg med √• velge den beste metoden for ditt brukstilfelle.

## Del 1: Sette opp Foundry Local CLI

### Steg 1: Installasjon

Foundry Local CLI er inngangsporten din for √• administrere og kj√∏re AI-modeller lokalt. La oss starte med √• installere den p√• systemet ditt.

**St√∏ttede plattformer:** Windows og macOS

For detaljerte installasjonsinstruksjoner, vennligst se [offisiell Foundry Local-dokumentasjon](https://github.com/microsoft/Foundry-Local/blob/main/README.md).

### Steg 2: Utforske tilgjengelige modeller

N√•r du har installert Foundry Local CLI, kan du finne ut hvilke modeller som er tilgjengelige for ditt brukstilfelle. Denne kommandoen viser alle st√∏ttede modeller:


```bash
foundry model list
```

### Steg 3: Forst√• Phi Family-modellene

Phi Family tilbyr et utvalg modeller optimalisert for ulike bruksomr√•der og maskinvarekonfigurasjoner. Her er Phi-modellene som er tilgjengelige i Foundry Local:

**Tilgjengelige Phi-modeller:** 

- **phi-3.5-mini** - Kompakt modell for grunnleggende oppgaver
- **phi-3-mini-128k** - Utvidet kontekstversjon for lengre samtaler
- **phi-3-mini-4k** - Standard kontekstmodell for generell bruk
- **phi-4** - Avansert modell med forbedrede egenskaper
- **phi-4-mini** - Lettvektsversjon av Phi-4
- **phi-4-mini-reasoning** - Spesialisert for komplekse resonnementoppgaver

> **Maskinvarekompatibilitet:** Hver modell kan konfigureres for ulik maskinvareakselerasjon (CPU, GPU) avhengig av systemets kapasitet.

### Steg 4: Kj√∏re din f√∏rste Phi-modell

La oss starte med et praktisk eksempel. Vi kj√∏rer `phi-4-mini-reasoning`-modellen, som er spesielt god til √• l√∏se komplekse problemer steg for steg.


**Kommando for √• kj√∏re modellen:**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **F√∏rste gangs oppsett:** N√•r du kj√∏rer en modell for f√∏rste gang, vil Foundry Local automatisk laste den ned til din lokale enhet. Nedlastningstiden varierer med nettverkshastigheten, s√• v√¶r t√•lmodig under oppsettet.

### Steg 5: Teste modellen med et ekte problem

N√• skal vi teste modellen med et klassisk logikkproblem for √• se hvordan den h√•ndterer stegvis resonnement:

**Eksempelproblem:**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**Forventet oppf√∏rsel:** Modellen skal dele opp problemet i logiske steg, og bruke at fasaner har 2 ben og kaniner har 4 ben for √• l√∏se ligningssystemet.

**Resultater:**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d91.no.png)

## Del 2: Bygge applikasjoner med Foundry Local SDK

### Hvorfor bruke SDK?

Mens CLI er perfekt for testing og raske interaksjoner, gj√∏r SDK det mulig √• integrere Foundry Local i applikasjonene dine programmessig. Dette √•pner for muligheter som:

- √Ö bygge skreddersydde AI-drevne applikasjoner
- Lage automatiserte arbeidsflyter
- Integrere AI-funksjoner i eksisterende systemer
- Utvikle chatboter og interaktive verkt√∏y

### St√∏ttede programmeringsspr√•k

Foundry Local tilbyr SDK-st√∏tte for flere programmeringsspr√•k for √• passe dine utviklingspreferanser:

**üì¶ Tilgjengelige SDK-er:**

- **C# (.NET):** [SDK-dokumentasjon og eksempler](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)
- **Python:** [SDK-dokumentasjon og eksempler](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **JavaScript:** [SDK-dokumentasjon og eksempler](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)
- **Rust:** [SDK-dokumentasjon og eksempler](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### Neste steg

1. **Velg SDK-en du foretrekker** basert p√• ditt utviklingsmilj√∏
2. **F√∏lg SDK-spesifikk dokumentasjon** for detaljerte implementasjonsveiledninger
3. **Start med enkle eksempler** f√∏r du bygger mer komplekse applikasjoner
4. **Utforsk eksempel-koden** som f√∏lger med hver SDK-repo

## Konklusjon

Du har n√• l√¶rt hvordan du:
- ‚úÖ Installerer og setter opp Foundry Local CLI
- ‚úÖ Oppdager og kj√∏rer Phi Family-modeller
- ‚úÖ Tester modeller med virkelige problemer
- ‚úÖ Forst√•r SDK-alternativer for applikasjonsutvikling

Foundry Local gir et kraftig grunnlag for √• bringe AI-funksjonalitet direkte til ditt lokale milj√∏, og gir deg kontroll over ytelse, personvern og kostnader, samtidig som du beholder fleksibiliteten til √• skalere til skyl√∏sninger ved behov.

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• originalspr√•ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.