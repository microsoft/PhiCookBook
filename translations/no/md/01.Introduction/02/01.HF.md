<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-07-16T18:53:21+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "no"
}
-->
# **Bruke Phi Family i Hugging Face**


[Hugging Face](https://huggingface.co/) er et veldig populært AI-fellesskap med rike data- og åpen kildekode-modellressurser. Ulike produsenter vil slippe åpne LLM- og SLM-modeller gjennom Hugging Face, som Microsoft, Meta, Mistral, Apple, Google, osv.

Microsoft Phi Family er lansert på Hugging Face. Utviklere kan laste ned den tilsvarende Phi Family-modellen basert på scenarioer og forretningsbehov. I tillegg til å distribuere Phi Pytorch-modeller på Hugging Face, har vi også lansert kvantiserte modeller, ved bruk av GGUF- og ONNX-formater for å gi sluttbrukere flere valgmuligheter.


## **Last ned modeller i Hugging Face**

Du kan laste ned Phi Family-modellen med denne lenken

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Du kan laste ned modellen på forskjellige måter, for eksempel ved å installere ***Hugging face CLI SDK*** eller bruke ***git clone***.

### **Bruke Hugging Face CLI for å laste ned Phi Family-modellen**

- Installer Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Bruke huggingface-cli for å logge inn

Logg inn på Hugging Face med [User Access Token](https://huggingface.co/docs/hub/security-tokens) fra din [Innstillinger-side](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Last ned 


Du kan laste ned modellen og lagre den i cache 

```bash

huggingface-cli download microsoft/phi-4

```

Du kan sette plassering til et egendefinert sted


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Bruke git clone for å laste ned Phi Family-modellen**

Du kan også bruke ***git clone*** for å laste ned modellen

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Eksempler - Inference Microsoft Phi-4**

- **Installere transformers-biblioteket**

```bash

pip install transformers -U

```

- **Kjøre denne koden i VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vennligst vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på originalspråket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.