<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-05-09T08:52:31+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "no"
}
-->
## Phi-familien i GitHub Models

Velkommen til [GitHub Models](https://github.com/marketplace/models)! Vi har alt klart for at du skal utforske AI-modeller som er hostet på Azure AI.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.4fc858ab26afe64c43f5e423ad0c5c733878bb536fdb027a5bcf1f80c41b0633.no.png)

For mer informasjon om modellene som er tilgjengelige på GitHub Models, sjekk ut [GitHub Model Marketplace](https://github.com/marketplace/models)

## Tilgjengelige modeller

Hver modell har en egen playground og eksempel-kode

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.998e294f6ee69c3ca174c880b32af9feec4221d0d787de899ad9bb2da3b58981.no.png)

### Phi-familien i GitHub Model Catalog

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## Kom i gang

Det finnes noen enkle eksempler som er klare til å kjøres. Du finner dem i samples-mappen. Hvis du vil hoppe rett til ditt favorittspråk, kan du finne eksemplene i følgende språk:

- Python
- JavaScript
- C#
- Java
- cURL

Det finnes også et dedikert Codespaces-miljø for å kjøre eksempler og modeller.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.b4b839a081583da39bc976c2f0d8ac4603d3b8c23194b16cc9e0a1014f5611d0.no.png)

## Eksempel-kode

Nedenfor finner du eksempel-kodesnutter for noen brukstilfeller. For mer informasjon om Azure AI Inference SDK, se full dokumentasjon og eksempler.

## Oppsett

1. Opprett en personlig tilgangstoken  
Du trenger ikke gi noen spesielle tillatelser til tokenet. Merk at tokenet vil bli sendt til en Microsoft-tjeneste.

For å bruke kodesnuttene nedenfor, opprett en miljøvariabel der du setter tokenet som nøkkel for klientkoden.

Hvis du bruker bash:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
Hvis du bruker powershell:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

Hvis du bruker Windows kommandoprompt:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## Python-eksempel

### Installer avhengigheter  
Installer Azure AI Inference SDK med pip (krever: Python >=3.8):

```
pip install azure-ai-inference
```  
### Kjør et enkelt kodeeksempel

Dette eksempelet viser et enkelt kall til chat completion API. Det bruker GitHub AI-modellens inferens-endepunkt og din GitHub-token. Kallet er synkront.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### Kjør en samtale med flere runder

Dette eksempelet viser en samtale med flere runder med chat completion API. Når du bruker modellen i en chat-applikasjon, må du håndtere samtalehistorikken og sende de siste meldingene til modellen.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### Strøm utdata

For en bedre brukeropplevelse vil du strømme modellens respons slik at det første tokenet vises tidlig, og du unngår å vente lenge på svar.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## GRATIS bruk og ratebegrensninger for GitHub Models

![Model Catalog](../../../../../translated_images/GitHub_Model.0c2abb992151c5407046e2b763af51505ff709f04c0950785e0300fdc8c55a0c.no.png)

[Ratebegrensningene for playground og gratis API-bruk](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) er ment for at du skal kunne eksperimentere med modeller og prototype AI-applikasjonen din. For bruk utover disse grensene, og for å skalere applikasjonen din, må du skaffe ressurser fra en Azure-konto og autentisere derfra i stedet for med din GitHub personlige tilgangstoken. Du trenger ikke å endre noe annet i koden din. Bruk denne lenken for å finne ut hvordan du kan gå utover gratisnivået i Azure AI.

### Viktig informasjon

Husk at når du samhandler med en modell, eksperimenterer du med AI, så innholdet kan inneholde feil.

Funksjonen har ulike begrensninger (inkludert forespørsler per minutt, forespørsler per dag, tokens per forespørsel og samtidige forespørsler) og er ikke laget for produksjonsbruk.

GitHub Models bruker Azure AI Content Safety. Disse filtrene kan ikke slås av som del av GitHub Models-opplevelsen. Hvis du velger å bruke modeller gjennom en betalt tjeneste, må du konfigurere innholdsfiltrene dine i henhold til dine behov.

Denne tjenesten er underlagt GitHubs Pre-release Terms.

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved bruk av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vennligst vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på dets opprinnelige språk skal betraktes som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.