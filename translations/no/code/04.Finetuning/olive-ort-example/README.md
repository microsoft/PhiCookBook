<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-07-16T16:26:52+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "no"
}
-->
# Finjuster Phi3 med Olive

I dette eksempelet skal du bruke Olive til √•:

1. Finjustere en LoRA-adapter for √• klassifisere setninger som Sad, Joy, Fear, Surprise.  
1. Sl√• sammen adaptervektene med basismodellen.  
1. Optimalisere og kvantisere modellen til `int4`.  

Vi viser deg ogs√• hvordan du kan kj√∏re inferens med den finjusterte modellen ved hjelp av ONNX Runtime (ORT) Generate API.

> **‚ö†Ô∏è For finjustering trenger du en egnet GPU tilgjengelig ‚Äì for eksempel A10, V100, A100.**

## üíæ Installer

Opprett et nytt Python-virtuelt milj√∏ (for eksempel med `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Deretter installerer du Olive og avhengighetene for en finjusteringsarbeidsflyt:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Finjuster Phi3 med Olive  
[Olive-konfigurasjonsfilen](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) inneholder en *workflow* med f√∏lgende *passes*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

P√• et overordnet niv√• vil denne arbeidsflyten:

1. Finjustere Phi3 (i 150 steg, som du kan endre) ved bruk av dataene i [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).  
1. Sl√• sammen LoRA-adaptervektene med basismodellen. Dette gir deg en enkelt modellfil i ONNX-format.  
1. Model Builder vil optimalisere modellen for ONNX runtime *og* kvantisere modellen til `int4`.  

For √• kj√∏re arbeidsflyten, bruk:

```bash
olive run --config phrase-classification.json
```

N√•r Olive er ferdig, finner du den optimaliserte `int4` finjusterte Phi3-modellen her: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Integrer finjustert Phi3 i applikasjonen din

For √• kj√∏re appen:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Svaret skal v√¶re en enkeltord-klassifisering av setningen (Sad/Joy/Fear/Surprise).

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• originalspr√•ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.