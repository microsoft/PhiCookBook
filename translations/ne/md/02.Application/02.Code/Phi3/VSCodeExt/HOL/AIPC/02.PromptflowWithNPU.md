<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-05-09T19:22:16+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "ne"
}
-->
# **Lab 2 - Phi-3-mini सँग AIPC मा Prompt flow चलाउनुहोस्**

## **Prompt flow के हो**

Prompt flow LLM-आधारित AI एप्लिकेशनहरूको अन्त्यदेखि अन्त्य विकास चक्रलाई सहज बनाउन डिजाइन गरिएको विकास उपकरणहरूको सेट हो, जसमा विचार सिर्जना, प्रोटोटाइप, परीक्षण, मूल्यांकनदेखि उत्पादन परिनियोजन र निगरानी सम्म समावेश छ। यसले prompt engineering लाई धेरै सजिलो बनाउँछ र तपाईलाई उत्पादन गुणस्तरका LLM एपहरू बनाउन सक्षम बनाउँछ।

Prompt flow सँग, तपाईले निम्न गर्न सक्नुहुन्छ:

- LLMs, prompts, Python कोड र अन्य उपकरणहरूलाई एक कार्यान्वयनयोग्य workflow मा जोड्ने flows सिर्जना गर्नुहोस्।

- तपाईका flows लाई डिबग र पुनरावृत्ति गर्नुहोस्, विशेष गरी LLMs सँगको अन्तरक्रिया सजिलैसँग।

- तपाईका flows लाई मूल्यांकन गर्नुहोस्, ठूलो डेटासेटहरूसँग गुणस्तर र प्रदर्शन मेट्रिक्स गणना गर्नुहोस्।

- तपाईको CI/CD प्रणालीमा परीक्षण र मूल्यांकनलाई एकीकृत गर्नुहोस् ताकि flow को गुणस्तर सुनिश्चित गर्न सकियोस्।

- तपाईका flows लाई तपाईले रोजेको सेवा प्लेटफर्ममा परिनियोजित गर्नुहोस् वा सजिलै तपाईको एपको कोड बेसमा समावेश गर्नुहोस्।

- (वैकल्पिक तर अत्यन्त सिफारिस गरिएको) Azure AI मा Prompt flow को क्लाउड संस्करण प्रयोग गरेर आफ्नो टिमसँग सहकार्य गर्नुहोस्।

## **AIPC के हो**

एआई पीसीमा CPU, GPU र NPU हुन्छन्, प्रत्येकसँग विशिष्ट AI acceleration क्षमता हुन्छ। NPU, वा neural processing unit, एक विशेषीकृत एक्सेलेरेटर हो जसले तपाईको PC मा नै AI र ML कार्यहरू प्रशोधन गर्छ, डेटा क्लाउडमा पठाउनुको सट्टा। GPU र CPU पनि यी कार्यहरू गर्न सक्छन्, तर NPU विशेषगरी कम-शक्ति AI गणनाहरूमा दक्ष हुन्छ। AI PC हाम्रो कम्प्युटरहरू कसरी काम गर्छन् भन्ने कुरामा एक मौलिक परिवर्तन हो। यो पहिले नअवस्थित समस्याको समाधान होइन, बरु दैनिक PC प्रयोगका लागि ठूलो सुधारको वाचा हो।

त्यसैले यो कसरी काम गर्छ? जनरेटिभ AI र विशाल LLMs जुन धेरै सार्वजनिक डेटामा प्रशिक्षित छन् भन्दा फरक, तपाईको PC मा हुने AI सबै तहमा बढी पहुँचयोग्य हुन्छ। यो अवधारणा बुझ्न सजिलो छ, र किनभने यो तपाईको डेटा मा प्रशिक्षित हुन्छ, क्लाउड पहुँच आवश्यक नपरेर, यसको फाइदाहरू व्यापक जनसमूहका लागि तुरुन्तै आकर्षक हुन्छन्।

छिट्टै, AI PC संसारमा व्यक्तिगत सहायकहरू र साना AI मोडेलहरू तपाईको PC मा सिधै चल्नेछन्, तपाईको डेटा प्रयोग गरेर व्यक्तिगत, निजी, बढी सुरक्षित AI सुधारहरू प्रदान गर्ने – बैठकका मिनेट लिन, फ्यान्टासी फुटबल लिग व्यवस्थित गर्न, फोटो र भिडियो सम्पादनका लागि स्वचालित सुधारहरू गर्ने, वा सबैको आगमन र प्रस्थान समय अनुसार परिवारको पुनर्मिलनको लागि उत्तम यात्रा तालिका तयार गर्ने जस्ता दैनिक कार्यहरूमा।

## **AIPC मा generation कोड flows निर्माण गर्ने**

***Note*** ：यदि तपाईले वातावरण स्थापना पूरा गर्नुभएको छैन भने, कृपया [Lab 0 -Installations](./01.Installations.md) भ्रमण गर्नुहोस्।

1. Visual Studio Code मा Prompt flow Extension खोल्नुहोस् र एउटा खाली flow परियोजना सिर्जना गर्नुहोस्

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.ne.png)

2. Inputs र Outputs प्यारामिटरहरू थप्नुहोस् र नयाँ flow को रूपमा Python Code थप्नुहोस्

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.ne.png)

तपाई यो संरचना (flow.dag.yaml) लाई आफ्नो flow निर्माण गर्न सन्दर्भको रूपमा लिन सक्नुहुन्छ

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. ***Chat_With_Phi3.py*** मा कोड थप्नुहोस्

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. तपाई Debug वा Run बाट flow परीक्षण गर्न सक्नुहुन्छ कि generation कोड ठीक छ कि छैन

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.ne.png)

5. टर्मिनलमा विकास API को रूपमा flow चलाउनुहोस्

```

pf flow serve --source ./ --port 8080 --host localhost   

```

तपाई यसलाई Postman / Thunder Client मा परीक्षण गर्न सक्नुहुन्छ

### **Note**

1. पहिलो रनमा धेरै समय लाग्न सक्छ। Hugging face CLI बाट phi-3 मोडेल डाउनलोड गर्न सिफारिस गरिन्छ।

2. Intel NPU को सीमित कम्प्युटिङ शक्ति विचार गरेर Phi-3-mini-4k-instruct प्रयोग गर्न सिफारिस गरिन्छ।

3. हामी Intel NPU Acceleration प्रयोग गरेर INT4 क्वान्टाइजेशन गर्छौं, तर सेवा पुन: चलाउँदा cache र nc_workshop फोल्डरहरू मेटाउन आवश्यक पर्छ।

## **स्रोतहरू**

1. Promptflow सिक्नुहोस् [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Intel NPU Acceleration सिक्नुहोस् [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. नमूना कोड, डाउनलोड गर्नुहोस् [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**अस्वीकरण**:  
यो दस्तावेज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी शुद्धताका लागि प्रयासरत छौं, तर कृपया जानकार हुनुहोस् कि स्वचालित अनुवादमा त्रुटि वा अशुद्धता हुन सक्छ। मूल दस्तावेज यसको मूल भाषामा नै अधिकारिक स्रोत मानिनु पर्छ। महत्वपूर्ण जानकारीको लागि व्यावसायिक मानवीय अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार छैनौं।