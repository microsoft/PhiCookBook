<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T16:52:59+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ne"
}
-->
# Phi मोडेलहरूको लागि एआई सुरक्षा
Phi परिवारका मोडेलहरू [Microsoft Responsible AI Standard](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard)अनुसार विकास गरिएका हुन्, जुन कम्पनीव्यापी आवश्यकताहरूको सेट हो जुन तलका छ वटा सिद्धान्तहरूमा आधारित छ: जवाफदेहो, पारदर्शिता, निष्पक्षता, विश्वसनीयता र सुरक्षा, गोपनीयता र सुरक्षा, र समावेशिता जसले [Microsoft को उत्तरदायी AI सिद्धान्तहरू](https://www.microsoft.com/ai/responsible-ai) गठन गर्दछ। 

पहिला भएका Phi मोडेलहरू जस्तै, बहुपक्षीय सुरक्षा मूल्यांकन र सुरक्षा पश्चात प्रशिक्षण विधि अपनाइएको छ, यस रिलीज़का बहुभाषिक क्षमताहरूलाई ध्यानमा राखेर थप उपायहरू लिइएको छ। हाम्रो सुरक्षा प्रशिक्षण र मूल्यांकनको दृष्टिकोण, जसमा धेरै भाषाहरू र जोखिम कोटीहरूमा परीक्षण समावेश छ, [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) मा वर्णन गरिएको छ। Phi मोडेलहरूले यस दृष्टिकोणबाट लाभ उठाउँछन् भने पनि विकासकर्ताहरूले आफ्नो विशिष्ट प्रयोग केस र सांस्कृतिक तथा भाषिक सन्दर्भसँग सम्बन्धित जोखिमहरू नक्साङ्कन, मापन, र न्यूनीकरण गर्न समवेदनशील एआई सर्वोत्तम अभ्यासहरू लागू गर्नुपर्छ।

## सर्वोत्तम अभ्यासहरू

अरु मोडेलहरू जस्तै, Phi परिवारका मोडेलहरूले असामान्य, अविश्वसनीय, वा अपमानजनक व्यवहार प्रदर्शन गर्न सक्छन्।

SLM र LLM का केही सीमित व्यवहारहरू जुन तपाईंले जान्नु आवश्यक छ, समावेश हुन्:

- **सेवाको गुणस्तर:** Phi मोडेलहरू मुख्यतः अंग्रेजी भाषाको पाठमा प्रशिक्षित छन्। अंग्रेजी बाहेक अन्य भाषाहरूले खराब प्रदर्शन अनुभव गर्नेछन्। प्रशिक्षण डेटामा कम प्रतिनिधित्व भएका अंग्रेजी भाषा भेराइटीहरूले अमेरिकी अंग्रेजीको तुलनामा खराब प्रदर्शन गर्न सक्छन्।
- **हानिकारक प्रतिनिधित्व र रूढीवादी पुनरुत्थान:** यी मोडेलहरूले मानिसहरूको केही समूहरूलाई बढी वा कम प्रतिनिधित्व गर्न सक्छन्, केही समूहहरूको प्रतिनिधित्व मेटाउन सक्छन्, वा अपमानजनक वा नकारात्मक रूढीवादी दृष्टिकोणहरूलाई मजबुत बनाउन सक्छन्। सुरक्षा पश्चात प्रशिक्षण भए तापनि, प्रशिक्षण डेटामा विभिन्न समूहहरूको प्रतिनिधित्व स्तरमा भिन्नता वा वास्तविक विश्व नमुनाहरू र सामाजिक पक्षपात झल्काउने नकारात्मक रूढीवादी दृष्टान्तहरूको प्रचलनका कारण यी सीमितताहरू अझै रहन सक्छन्।
- **अशोभनीय वा अपमानजनक सामग्री:** यी मोडेलहरूले अरु प्रकारका अशोभनीय वा अपमानजनक सामग्री उत्पादन गर्न सक्छन्, जसले संवेदनशील सन्दर्भहरूमा प्रयोग गर्न असамर्थ हुन सक्छ यदि प्रयोग केसअनुसार थप न्यूनीकरण उपायहरू लागू नगरिएमा।
सूचना विश्वसनीयता: भाषा मोडेलहरूले कहिलेकाहीं असंगत सामग्री वा यस्तै देखिने सामग्री फेब्रिकेट गर्न सक्छन् जसले यथार्थ वा पुरानो जानकारी हुन सक्छ।
- **कोडको सीमित क्षेत्र:** Phi-3 को अधिकांश प्रशिक्षण डेटा पाइथनमा आधारित छ र "typing, math, random, collections, datetime, itertools" जस्ता सामान्य प्याकेजहरू प्रयोग गर्छ। यदि मोडेलले अर्को प्याकेज वा अन्य भाषा कोड उत्पादन गर्छ भने, हामी प्रयोगकर्तालाई सबै API प्रयोगहरू म्यानुअली जाँच्न कडा सिफारिस गर्छौं।

विकासकर्ताहरूले जवाफदेही AI सर्वोत्तम अभ्यासहरू अपनाउनुपर्छ र निश्चित प्रयोग केसले सम्बन्धित कानुन र नियमहरू (जस्तै गोपनीयता, व्यापार आदि) पालन गर्दछ भन्ने सुनिश्चित गर्न जिम्मेवार हुन्छन्। 

## उत्तरदायी एआई विचारहरू

अरु भाषा मोडेलहरू जस्तै, Phi श्रृंखला मोडेलहरूले असामान्य, अविश्वसनीय, वा अपमानजनक व्यवहार प्रदर्शन गर्न सक्छन्। जान्नुपर्ने केही सीमित व्यवहारहरू समावेश छन्:

**सेवाको गुणस्तर:** Phi मोडेलहरू मुख्य रूपमा अंग्रेजी पाठमा प्रशिक्षित छन्। अंग्रेजी बाहेकका भाषाहरूले खराब प्रदर्शन अनुभव गर्नेछन्। कम प्रतिनिधित्व भएका अंग्रेजी भाषा भेराइटीहरूले अमेरिकी अंग्रेजीभन्दा खराब प्रदर्शन गर्न सक्छन्।

**हानिकारक प्रतिनिधित्व र रूढीवादी पुनरुत्थान:** मोडेलहरूले केही मानिस समूहहरूलाई बढी वा कम प्रतिनिधित्व गर्न सक्छन्, केही समूहहरूको प्रतिनिधित्व मेटाउन सक्छन्, वा अपमानजनक वा नकारात्मक रूढीहरूलाई मजबुत बनाउन सक्छन्। सुरक्षा पछिको प्रशिक्षण भए तापनि, यी सीमितताहरू समूहहरूको प्रतिनिधित्व स्तर फरक र नकारात्मक रूढीवादी दृष्टान्तहरूको प्रचलनका कारण अझै विद्यमान हुन सक्छ।

**अशोभनीय वा अपमानजनक सामग्री:** यी मोडेलहरूले अरु प्रकारका अशोभनीय वा अपमानजनक सामग्री उत्पादन गर्न सक्छन्, जसले संवेदनशील सन्दर्भहरूमा प्रयोग गर्न उपयुक्त नहुन सक्छ यदि विशिष्ट प्रयोग केसका लागि थप न्यूनीकरण उपायहरू लागू नगरिएमा।
सूचना विश्वसनीयता: भाषा मोडेलहरूले असम्बन्धित सामग्री वा ठिक देखिने तर गलत वा पुरानो सामग्री फेब्रिकेट गर्न सक्छन्।

**कोडको सीमित क्षेत्र:** Phi-3 को अधिकांश प्रशिक्षण डेटा पाइथनमा आधारित छ र "typing, math, random, collections, datetime, itertools" जस्ता सामान्य प्याकेजहरू प्रयोग गर्छ। मोडेलले अन्य प्याकेज अथवा अन्य भाषाका स्क्रिप्टहरू प्रयोग गरेको पाइएमा, सबै API प्रयोग म्यानुअली जाँच्न हामी कडा सिफारिस गर्छौं।

विकासकर्ताहरूले उत्तरदायी AI सर्वोत्तम अभ्यासहरू अपनाउनुपर्छ र निश्चित प्रयोग केसले सम्बन्धित कानुन र नियमहरू (जस्तै गोपनीयता, व्यापार आदि) पालना गर्ने सुनिश्चित गर्न जिम्मेवार हुन्छन्। विचार गर्न महत्वपूर्ण क्षेत्रहरू समावेश छन्:

**आवंटन:** मोडेलहरू कानुनी स्थिति वा स्रोत वा जीवन अवसर (जस्तै घर, रोजगार, क्रेडिट आदि) को आवंटनमा महत्वपूर्ण प्रभाव पार्न सक्ने परिदृश्यहरूका लागि उपयुक्त नहुन सक्छन्, थप मूल्यांकन र अतिरिक्त पूर्वाग्रह हटाउने प्रविधिहरू बिना।

**उच्च जोखिम परिदृश्यहरू:** विकासकर्ताहरूले ती उच्च जोखिम परिदृश्यहरूमा मोडेल प्रयोगको उपयुक्तता मूल्यांकन गर्नुपर्छ जहाँ असामान्य, अविश्वसनीय वा अपमानजनक उत्तरहरूले अत्यधिक लागत वा हानि निम्त्याउन सक्छ। यसमा संवेदनशील वा विशेषज्ञ क्षेत्रहरूमा सटीकता र विश्वसनीयता अत्यावश्यक हुने सल्लाह दिनु पर्दछ (जस्तै कानुनी वा स्वास्थ्य सल्लाह)। लागू गर्ने सन्दर्भ अनुसार अतिरिक्त सुरक्षात्मक उपायहरू अनुप्रयोग तहमा लागू गर्नु पर्छ।

**गलत सूचना:** मोडेलहरूले गलत जानकारी उत्पादन गर्न सक्छन्। विकासकर्ताहरूले पारदर्शिता सर्वोत्तम अभ्यासहरू पालना गर्नुपर्छ र अन्त-प्रयोगकर्तालाई उनीहरू एआई प्रणालीसँग अन्तरक्रिया गरिरहेका छन् भन्नुपर्छ। अनुप्रयोग तहमा, विकासकर्ताले प्रतिक्रिया यन्त्र र पाइपलाइनहरू निर्माण गर्न सक्छन् जसले प्रयोग केस विशेष सन्दर्भमा जवाफहरू आधारभूत बनाउँछन्, जसलाई Retrieval Augmented Generation (RAG) भनिन्छ।

**हानिकारक सामग्री उत्पादन:** विकासकर्ताले आफ्नो सन्दर्भका लागि आउटपुट मूल्यांकन गर्नुपर्छ र उपलब्ध सुरक्षा वर्गीकरणकर्ता वा प्रयोग केसअनुसारका अनुकूल समाधानहरू प्रयोग गर्नुपर्छ।

**दुरुपयोग:** धोखाधडी, स्प्याम, वा मालवेयर उत्पादन जस्ता अन्य दुरुपयोगका रूपहरू सम्भव छन्, र विकासकर्ताले सुनिश्चित गर्नुपर्छ कि तिनका अनुप्रयोगहरूले लागू कानुन र नियमहरूको उल्लंघन नगर्न।

### फाइनट्यूनिङ र एआई सामग्री सुरक्षा

मोडेललाई फाइनट्यूनिङ गरेपछि, हामी [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) मापनहरू प्रयोग गरी मोडेलहरूले उत्पादन गरेको सामग्री निगरानी गर्न, सम्भावित जोखिम, धम्की, र गुणस्तरका समस्याहरू पहिचान र अवरुद्ध गर्न अत्यधिक सिफारिस गर्छौं।

![Phi3AISafety](../../../../../translated_images/ne/01.phi3aisafety.c0d7fc42f5a5c405.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) पाठ र छवि दुवै सामग्रीलाई समर्थन गर्दछ। यो क्लाउड, डिसकनेक्टेड कन्टेनरहरू, र एज/एम्बेडेड उपकरणहरूमा तैनाथ गर्न सकिन्छ।

## Azure AI Content Safety को अवलोकन

Azure AI Content Safety सबैका लागि एउटै समाधान होइन; यसलाई व्यवसायका विशेष नीतिहरूसँग मेल खाने गरी अनुकूलन गर्न सकिन्छ। थप रूपमा, यसको बहुभाषिक मोडेलहरूले धेरै भाषाहरूलाई एकै पटक बुझ्न सक्षम बनाउँछन्।

![AIContentSafety](../../../../../translated_images/ne/01.AIcontentsafety.a288819b8ce8da1a.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 भिडियोहरू**

Azure AI Content Safety सेवा अनुप्रयोगहरू र सेवाहरूमा हानिकारक प्रयोगकर्ता-निर्मित र एआई-निर्मित सामग्री पत्ता लगाउँछ। यसमा पाठ र छवि API हरू समावेश छन् जसले हानिकारक वा अनुपयुक्त सामग्री पत्ता लगाउन अनुमति दिन्छ।

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**अस्वीकरण**:
यो दस्तावेज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामीले शुद्धताका लागि प्रयास गर्छौं, तर कृपया ज्ञान हुनुस् कि स्वचालित अनुवादमा त्रुटि वा असंगतिहरू हुन सक्छन्। मूल दस्तावेज यसको मूल भाषामा आधिकारिक स्रोत मानिनु पर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानिस अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न कुनै पनि गलत बुझाइ वा गलत व्याख्याको लागि हामी उत्तरदायी छैनौं।
<!-- CO-OP TRANSLATOR DISCLAIMER END -->