<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-07-16T17:45:58+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ne"
}
-->
# Phi मोडेलहरूको लागि AI सुरक्षा  
Phi परिवारका मोडेलहरू [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) अनुसार विकास गरिएका हुन्, जुन कम्पनीभर लागू हुने आवश्यकताहरूको सेट हो र यसमा छ वटा मुख्य सिद्धान्तहरू समावेश छन्: जवाफदेहिता, पारदर्शिता, निष्पक्षता, विश्वसनीयता र सुरक्षा, गोपनीयता र सुरक्षा, र समावेशिता, जुन [Microsoft का Responsible AI सिद्धान्तहरू](https://www.microsoft.com/ai/responsible-ai) हुन्।  

अघिल्ला Phi मोडेलहरू जस्तै, बहु-आयामिक सुरक्षा मूल्यांकन र सुरक्षा पोस्ट-ट्रेनिङ विधि अपनाइएको छ, साथै यस रिलिजको बहुभाषिक क्षमताहरूलाई ध्यानमा राखेर थप उपायहरू पनि लिइएको छ। हाम्रो सुरक्षा प्रशिक्षण र मूल्यांकनको दृष्टिकोण, जसमा विभिन्न भाषाहरू र जोखिम वर्गहरूमा परीक्षण समावेश छ, [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) मा विस्तृत रूपमा उल्लेख गरिएको छ। यद्यपि Phi मोडेलहरूले यस दृष्टिकोणबाट लाभ उठाउँछन्, विकासकर्ताहरूले आफ्नो विशिष्ट प्रयोग केस र सांस्कृतिक तथा भाषागत सन्दर्भसँग सम्बन्धित जोखिमहरू नक्सांकन, मापन, र न्यूनीकरण गर्ने जिम्मेवार AI अभ्यासहरू अपनाउनुपर्छ।  

## उत्तम अभ्यासहरू  

अन्य मोडेलहरू जस्तै, Phi परिवारका मोडेलहरूले कहिलेकाहीं अन्यायपूर्ण, अविश्वसनीय, वा अपमानजनक व्यवहार देखाउन सक्छन्।  

SLM र LLM का केही सीमित व्यवहारहरू जुन तपाईंले जान्न आवश्यक छ:  

- **सेवाको गुणस्तर:** Phi मोडेलहरू मुख्य रूपमा अंग्रेजी पाठमा प्रशिक्षित छन्। अंग्रेजी बाहेकका भाषाहरूमा प्रदर्शन कमजोर हुन सक्छ। प्रशिक्षण डाटामा कम प्रतिनिधित्व भएका अंग्रेजी भाषाका भेरिएन्टहरूले मानक अमेरिकी अंग्रेजीको तुलनामा खराब प्रदर्शन गर्न सक्छन्।  
- **हानिकारक प्रतिनिधित्व र रूढीवादी प्रवृत्तिको निरन्तरता:** यी मोडेलहरूले केही समूहहरूको प्रतिनिधित्व बढी वा कम गर्न सक्छन्, केही समूहहरूको प्रतिनिधित्व मेटाउन सक्छन्, वा अपमानजनक वा नकारात्मक रूढीवादी छविहरूलाई बल दिन सक्छन्। सुरक्षा पोस्ट-ट्रेनिङ भए तापनि, यी सीमितताहरू अझै रहन सक्छन् किनभने विभिन्न समूहहरूको प्रतिनिधित्वको स्तर फरक हुन सक्छ वा प्रशिक्षण डाटामा नकारात्मक रूढीवादी उदाहरणहरूको प्रचलनले वास्तविक विश्वका ढाँचाहरू र सामाजिक पूर्वाग्रहहरू प्रतिबिम्बित गर्दछ।  
- **अशोभनीय वा अपमानजनक सामग्री:** यी मोडेलहरूले अन्य प्रकारका अशोभनीय वा अपमानजनक सामग्री उत्पादन गर्न सक्छन्, जसले संवेदनशील सन्दर्भहरूमा थप न्यूनीकरण उपायहरू बिना प्रयोग गर्न अनुपयुक्त हुन सक्छ।  
- **जानकारीको विश्वसनीयता:** भाषा मोडेलहरूले अर्थहीन सामग्री उत्पादन गर्न सक्छन् वा यस्ता सामग्री बनाउन सक्छन् जुन सुनिन त ठीक लाग्छ तर गलत वा पुरानो हुन्छ।  
- **कोडको सीमित दायरा:** Phi-3 को अधिकांश प्रशिक्षण डाटा Python मा आधारित छ र सामान्य प्याकेजहरू जस्तै "typing, math, random, collections, datetime, itertools" प्रयोग गर्छ। यदि मोडेलले अन्य प्याकेजहरू वा अन्य भाषाका स्क्रिप्टहरू प्रयोग गरेर Python स्क्रिप्टहरू उत्पादन गर्छ भने, हामी प्रयोगकर्ताहरूलाई सबै API प्रयोगहरू म्यानुअली जाँच गर्न कडा सिफारिस गर्छौं।  

विकासकर्ताहरूले जिम्मेवार AI उत्तम अभ्यासहरू अपनाउनुपर्छ र सुनिश्चित गर्नुपर्छ कि विशिष्ट प्रयोग केस सम्बन्धित कानुन र नियमहरू (जस्तै गोपनीयता, व्यापार आदि) अनुसार छ।  

## जिम्मेवार AI विचारहरू  

अन्य भाषा मोडेलहरू जस्तै, Phi श्रृंखला मोडेलहरूले कहिलेकाहीं अन्यायपूर्ण, अविश्वसनीय, वा अपमानजनक व्यवहार देखाउन सक्छन्। जान्नुपर्ने केही सीमित व्यवहारहरू:  

**सेवाको गुणस्तर:** Phi मोडेलहरू मुख्य रूपमा अंग्रेजी पाठमा प्रशिक्षित छन्। अंग्रेजी बाहेकका भाषाहरूमा प्रदर्शन कमजोर हुन सक्छ। प्रशिक्षण डाटामा कम प्रतिनिधित्व भएका अंग्रेजी भाषाका भेरिएन्टहरूले मानक अमेरिकी अंग्रेजीको तुलनामा खराब प्रदर्शन गर्न सक्छन्।  

**हानिकारक प्रतिनिधित्व र रूढीवादी प्रवृत्तिको निरन्तरता:** यी मोडेलहरूले केही समूहहरूको प्रतिनिधित्व बढी वा कम गर्न सक्छन्, केही समूहहरूको प्रतिनिधित्व मेटाउन सक्छन्, वा अपमानजनक वा नकारात्मक रूढीवादी छविहरूलाई बल दिन सक्छन्। सुरक्षा पोस्ट-ट्रेनिङ भए तापनि, यी सीमितताहरू अझै रहन सक्छन् किनभने विभिन्न समूहहरूको प्रतिनिधित्वको स्तर फरक हुन सक्छ वा प्रशिक्षण डाटामा नकारात्मक रूढीवादी उदाहरणहरूको प्रचलनले वास्तविक विश्वका ढाँचाहरू र सामाजिक पूर्वाग्रहहरू प्रतिबिम्बित गर्दछ।  

**अशोभनीय वा अपमानजनक सामग्री:** यी मोडेलहरूले अन्य प्रकारका अशोभनीय वा अपमानजनक सामग्री उत्पादन गर्न सक्छन्, जसले संवेदनशील सन्दर्भहरूमा थप न्यूनीकरण उपायहरू बिना प्रयोग गर्न अनुपयुक्त हुन सक्छ।  
जानकारीको विश्वसनीयता: भाषा मोडेलहरूले अर्थहीन सामग्री उत्पादन गर्न सक्छन् वा यस्ता सामग्री बनाउन सक्छन् जुन सुनिन त ठीक लाग्छ तर गलत वा पुरानो हुन्छ।  

**कोडको सीमित दायरा:** Phi-3 को अधिकांश प्रशिक्षण डाटा Python मा आधारित छ र सामान्य प्याकेजहरू जस्तै "typing, math, random, collections, datetime, itertools" प्रयोग गर्छ। यदि मोडेलले अन्य प्याकेजहरू वा अन्य भाषाका स्क्रिप्टहरू प्रयोग गरेर Python स्क्रिप्टहरू उत्पादन गर्छ भने, हामी प्रयोगकर्ताहरूलाई सबै API प्रयोगहरू म्यानुअली जाँच गर्न कडा सिफारिस गर्छौं।  

विकासकर्ताहरूले जिम्मेवार AI उत्तम अभ्यासहरू अपनाउनुपर्छ र सुनिश्चित गर्नुपर्छ कि विशिष्ट प्रयोग केस सम्बन्धित कानुन र नियमहरू (जस्तै गोपनीयता, व्यापार आदि) अनुसार छ। विचार गर्नुपर्ने महत्वपूर्ण क्षेत्रहरू:  

**वितरण:** मोडेलहरू कानुनी स्थिति वा स्रोतहरू वा जीवन अवसरहरूको वितरणमा महत्वपूर्ण प्रभाव पार्ने परिदृश्यहरू (जस्तै: आवास, रोजगार, क्रेडिट आदि) का लागि उपयुक्त नहुन सक्छन्, जबसम्म थप मूल्यांकन र अतिरिक्त पूर्वाग्रह हटाउने प्रविधिहरू लागू नगरिएको हो।  

**उच्च जोखिम परिदृश्यहरू:** विकासकर्ताहरूले उच्च जोखिम परिदृश्यहरूमा मोडेलहरूको उपयुक्तता मूल्यांकन गर्नुपर्छ जहाँ अन्यायपूर्ण, अविश्वसनीय, वा अपमानजनक नतिजाहरू अत्यन्त महँगो वा हानिकारक हुन सक्छ। यसमा संवेदनशील वा विशेषज्ञ क्षेत्रहरूमा सल्लाह दिनु समावेश छ जहाँ शुद्धता र विश्वसनीयता अत्यावश्यक हुन्छ (जस्तै: कानुनी वा स्वास्थ्य सल्लाह)। लागू गर्ने सन्दर्भ अनुसार थप सुरक्षा उपायहरू एप्लिकेसन स्तरमा लागू गर्नुपर्छ।  

**गलत सूचना:** मोडेलहरूले गलत जानकारी उत्पादन गर्न सक्छन्। विकासकर्ताहरूले पारदर्शिता उत्तम अभ्यासहरू पालना गर्नुपर्छ र अन्तिम प्रयोगकर्ताहरूलाई उनीहरूले AI प्रणालीसँग अन्तरक्रिया गरिरहेका छन् भनी जानकारी दिनुपर्छ। एप्लिकेसन स्तरमा, विकासकर्ताहरूले प्रतिक्रिया संयन्त्रहरू र पाइपलाइनहरू निर्माण गर्न सक्छन् जसले प्रयोग केस विशेष, सन्दर्भगत जानकारीमा आधारित जवाफहरू दिन्छ, जसलाई Retrieval Augmented Generation (RAG) भनिन्छ।  

**हानिकारक सामग्रीको उत्पादन:** विकासकर्ताहरूले आफ्नो सन्दर्भका लागि नतिजाहरूको मूल्यांकन गर्नुपर्छ र उपलब्ध सुरक्षा वर्गीकरण उपकरणहरू वा आफ्नो प्रयोग केसका लागि उपयुक्त अनुकूल समाधानहरू प्रयोग गर्नुपर्छ।  

**दुरुपयोग:** ठगी, स्प्याम, वा मालवेयर उत्पादन जस्ता अन्य प्रकारका दुरुपयोग सम्भव हुन सक्छन्, र विकासकर्ताहरूले सुनिश्चित गर्नुपर्छ कि उनीहरूको एप्लिकेसनहरूले लागू हुने कानुन र नियमहरू उल्लंघन नगरेको हो।  

### फाइनट्युनिङ र AI सामग्री सुरक्षा  

मोडेल फाइनट्युनिङ गरेपछि, हामी [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) उपायहरू प्रयोग गरेर मोडेलहरूले उत्पादन गर्ने सामग्रीलाई अनुगमन गर्न, सम्भावित जोखिम, खतरा, र गुणस्तर समस्याहरू पहिचान र अवरुद्ध गर्न अत्यन्त सिफारिस गर्छौं।  

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c405.ne.png)  

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) ले पाठ र छवि सामग्री दुवैलाई समर्थन गर्दछ। यसलाई क्लाउड, डिस्कनेक्टेड कन्टेनरहरू, र एज/एम्बेडेड उपकरणहरूमा तैनाथ गर्न सकिन्छ।  

## Azure AI Content Safety को अवलोकन  

Azure AI Content Safety सबैका लागि एउटै समाधान होइन; यसलाई व्यवसायहरूको विशिष्ट नीतिहरूसँग मेल खाने गरी अनुकूलन गर्न सकिन्छ। साथै, यसको बहुभाषिक मोडेलहरूले एकै समयमा धेरै भाषाहरू बुझ्न सक्षम बनाउँछ।  

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a.ne.png)  

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5 भिडियोहरू**  

Azure AI Content Safety सेवा एप्लिकेसन र सेवाहरूमा हानिकारक प्रयोगकर्ता-उत्पन्न र AI-उत्पन्न सामग्री पत्ता लगाउँछ। यसमा पाठ र छवि API हरू समावेश छन् जसले हानिकारक वा अनुपयुक्त सामग्री पत्ता लगाउन अनुमति दिन्छ।  

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**अस्वीकरण**:  
यो दस्तावेज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी शुद्धताका लागि प्रयासरत छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादमा त्रुटि वा अशुद्धता हुन सक्छ। मूल दस्तावेज यसको मूल भाषामा नै अधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीका लागि व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार छैनौं।