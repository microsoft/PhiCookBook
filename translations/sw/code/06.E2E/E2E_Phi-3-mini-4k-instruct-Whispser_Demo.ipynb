{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot ya Maingiliano ya Phi 3 Mini 4K Instruct na Whisper\n",
    "\n",
    "### Utangulizi:\n",
    "Chatbot ya Maingiliano ya Phi 3 Mini 4K Instruct ni chombo kinachoruhusu watumiaji kuwasiliana na onyesho la Microsoft Phi 3 Mini 4K instruct kwa kutumia maandishi au sauti. Chatbot hii inaweza kutumika kwa kazi mbalimbali, kama vile tafsiri, taarifa za hali ya hewa, na ukusanyaji wa taarifa za jumla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "Unda Token yako ya Huggingface ya Ufikiaji\n",
    "\n",
    "Unda token mpya  \n",
    "Toa jina jipya  \n",
    "Chagua ruhusa za kuandika  \n",
    "Nakili token na uiweke mahali salama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python na inafanya kazi mbili kuu: kuingiza moduli ya `os` na kuweka thamani ya mazingira.\n",
    "\n",
    "1. Kuingiza moduli ya `os`:\n",
    "   - Moduli ya `os` katika Python inatoa njia ya kuwasiliana na mfumo wa uendeshaji. Inakuruhusu kufanya kazi mbalimbali zinazohusiana na mfumo wa uendeshaji, kama vile kufikia thamani za mazingira, kufanya kazi na faili na saraka, n.k.\n",
    "   - Katika msimbo huu, moduli ya `os` imeingizwa kwa kutumia kauli ya `import`. Kauli hii inafanya uwezo wa moduli ya `os` kupatikana kwa matumizi katika skiripti ya sasa ya Python.\n",
    "\n",
    "2. Kuweka thamani ya mazingira:\n",
    "   - Thamani ya mazingira ni thamani inayoweza kufikiwa na programu zinazoendesha kwenye mfumo wa uendeshaji. Ni njia ya kuhifadhi mipangilio ya usanidi au taarifa nyingine ambayo inaweza kutumiwa na programu nyingi.\n",
    "   - Katika msimbo huu, thamani mpya ya mazingira inawekwa kwa kutumia kamusi ya `os.environ`. Kitufe cha kamusi ni `'HF_TOKEN'`, na thamani inatolewa kutoka kwa kigezo `HUGGINGFACE_TOKEN`.\n",
    "   - Kigezo `HUGGINGFACE_TOKEN` kimeelezwa juu kidogo ya kipande hiki cha msimbo, na kimepewa thamani ya kamba `\"hf_**************\"` kwa kutumia sintaksia ya `#@param`. Sintaksia hii mara nyingi hutumika katika daftari za Jupyter kuruhusu maingizo ya mtumiaji na usanidi wa vigezo moja kwa moja kwenye kiolesura cha daftari.\n",
    "   - Kwa kuweka thamani ya mazingira `'HF_TOKEN'`, inaweza kufikiwa na sehemu nyingine za programu au programu nyingine zinazoendesha kwenye mfumo huo wa uendeshaji.\n",
    "\n",
    "Kwa ujumla, msimbo huu unaingiza moduli ya `os` na kuweka thamani ya mazingira inayoitwa `'HF_TOKEN'` na thamani iliyotolewa katika kigezo `HUGGINGFACE_TOKEN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kipande hiki cha msimbo kinafafanua kazi inayoitwa `clear_output` ambayo hutumika kusafisha matokeo ya seli ya sasa katika Jupyter Notebook au IPython. Hebu tuchambue msimbo huu na kuelewa jinsi unavyofanya kazi:\n",
    "\n",
    "Kazi ya `clear_output` inachukua kipengele kimoja kinachoitwa `wait`, ambacho ni thamani ya boolean. Kwa chaguo-msingi, `wait` imewekwa kuwa `False`. Kipengele hiki huamua kama kazi inapaswa kusubiri hadi matokeo mapya yapatikane ili kuchukua nafasi ya matokeo yaliyopo kabla ya kuyasafisha.\n",
    "\n",
    "Kazi yenyewe hutumika kusafisha matokeo ya seli ya sasa. Katika Jupyter Notebook au IPython, wakati seli inazalisha matokeo, kama vile maandishi yaliyochapishwa au michoro ya grafu, matokeo hayo huonyeshwa chini ya seli. Kazi ya `clear_output` inakuruhusu kusafisha matokeo hayo.\n",
    "\n",
    "Utekelezaji wa kazi haujatolewa katika kipande cha msimbo, kama inavyoonyeshwa na alama za ellipsis (...). Alama hizi zinawakilisha nafasi ya msimbo halisi unaofanya kazi ya kusafisha matokeo. Utekelezaji wa kazi unaweza kuhusisha kuingiliana na API ya Jupyter Notebook au IPython ili kuondoa matokeo yaliyopo kutoka kwenye seli.\n",
    "\n",
    "Kwa ujumla, kazi hii inatoa njia rahisi ya kusafisha matokeo ya seli ya sasa katika Jupyter Notebook au IPython, na hivyo kurahisisha usimamizi na uboreshaji wa matokeo yanayoonyeshwa wakati wa vipindi vya usimbaji wa maingiliano.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tumia huduma ya Edge TTS kufanya maandishi kuwa sauti. Hebu tuangalie utekelezaji wa kazi husika moja baada ya nyingine:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: Kazi hii inachukua thamani ya pembejeo na kuhesabu kiwango cha kasi ya sauti ya TTS. Thamani ya pembejeo inawakilisha kasi inayotakiwa ya sauti, ambapo thamani ya 1 inawakilisha kasi ya kawaida. Kazi hii inahesabu kiwango cha kasi kwa kutoa 1 kutoka thamani ya pembejeo, kuzidisha kwa 100, na kisha kuamua ishara kulingana na kama thamani ya pembejeo ni kubwa au sawa na 1. Kazi hii inarejesha kiwango cha kasi katika muundo \"{sign}{rate}\".\n",
    "\n",
    "2. `make_chunks(input_text, language)`: Kazi hii inachukua maandishi ya pembejeo na lugha kama vigezo. Inagawanya maandishi ya pembejeo katika vipande kulingana na sheria maalum za lugha. Katika utekelezaji huu, ikiwa lugha ni \"English\", kazi inagawanya maandishi kwenye kila nukta (\".\") na kuondoa nafasi zozote mwanzoni au mwishoni. Kisha inaongeza nukta kwa kila kipande na kurejesha orodha ya vipande vilivyofanyiwa uchujaji.\n",
    "\n",
    "3. `tts_file_name(text)`: Kazi hii inazalisha jina la faili ya sauti ya TTS kulingana na maandishi ya pembejeo. Inafanya mabadiliko kadhaa kwenye maandishi: kuondoa nukta mwishoni (ikiwa ipo), kubadilisha maandishi kuwa herufi ndogo, kuondoa nafasi mwanzoni na mwishoni, na kubadilisha nafasi kuwa alama za chini. Kisha inakata maandishi hadi urefu wa herufi 25 (ikiwa ni marefu zaidi) au inatumia maandishi kamili ikiwa ni mafupi. Hatimaye, inazalisha mfululizo wa nasibu kwa kutumia moduli ya [`uuid`] na kuunganisha na maandishi yaliyokatwa ili kuunda jina la faili katika muundo \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\".\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: Kazi hii inaunganisha faili nyingi za sauti kuwa faili moja ya sauti. Inachukua orodha ya njia za faili za sauti na njia ya matokeo kama vigezo. Kazi hii inaanzisha kitu tupu cha `AudioSegment` kinachoitwa [`merged_audio`]. Kisha inazunguka kupitia kila njia ya faili ya sauti, inasoma faili ya sauti kwa kutumia njia ya `AudioSegment.from_file()` kutoka maktaba ya `pydub`, na inaongeza faili ya sauti ya sasa kwenye kitu cha [`merged_audio`]. Hatimaye, inasafirisha sauti iliyounganishwa kwenye njia ya matokeo iliyotajwa katika muundo wa MP3.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: Kazi hii inafanya operesheni ya TTS kwa kutumia huduma ya Edge TTS. Inachukua orodha ya vipande vya maandishi, kasi ya sauti, jina la sauti, na njia ya kuhifadhi kama vigezo. Ikiwa idadi ya vipande ni zaidi ya 1, kazi hii inaunda saraka ya kuhifadhi faili za sauti za vipande vya mtu mmoja mmoja. Kisha inazunguka kupitia kila kipande, inaunda amri ya Edge TTS kwa kutumia kazi ya `calculate_rate_string()`, jina la sauti, na maandishi ya kipande, na inatekeleza amri kwa kutumia kazi ya `os.system()`. Ikiwa utekelezaji wa amri unafanikiwa, inaongeza njia ya faili ya sauti iliyozalishwa kwenye orodha. Baada ya kushughulikia vipande vyote, inaunganisha faili za sauti za mtu mmoja mmoja kwa kutumia kazi ya `merge_audio_files()` na kuhifadhi sauti iliyounganishwa kwenye njia ya kuhifadhi iliyotajwa. Ikiwa kuna kipande kimoja tu, inazalisha moja kwa moja amri ya Edge TTS na kuhifadhi sauti kwenye njia ya kuhifadhi. Hatimaye, inarejesha njia ya kuhifadhi ya faili ya sauti iliyozalishwa.\n",
    "\n",
    "6. `random_audio_name_generate()`: Kazi hii inazalisha jina la faili ya sauti ya nasibu kwa kutumia moduli ya [`uuid`]. Inazalisha UUID ya nasibu, inabadilisha kuwa mfululizo, inachukua herufi 8 za kwanza, inaongeza kiendelezi cha \".mp3\", na kurejesha jina la faili ya sauti ya nasibu.\n",
    "\n",
    "7. `talk(input_text)`: Kazi hii ni sehemu kuu ya kuendesha operesheni ya TTS. Inachukua maandishi ya pembejeo kama kigezo. Kwanza inakagua urefu wa maandishi ya pembejeo ili kuamua ikiwa ni sentensi ndefu (zaidi au sawa na herufi 600). Kulingana na urefu na thamani ya kigezo cha `translate_text_flag`, inatambua lugha na inazalisha orodha ya vipande vya maandishi kwa kutumia kazi ya `make_chunks()`. Kisha inazalisha njia ya kuhifadhi faili ya sauti kwa kutumia kazi ya `random_audio_name_generate()`. Hatimaye, inaita kazi ya `edge_free_tts()` kufanya operesheni ya TTS na kurejesha njia ya kuhifadhi ya faili ya sauti iliyozalishwa.\n",
    "\n",
    "Kwa ujumla, kazi hizi zinashirikiana kugawanya maandishi ya pembejeo katika vipande, kuzalisha jina la faili ya sauti, kufanya operesheni ya TTS kwa kutumia huduma ya Edge TTS, na kuunganisha faili za sauti za mtu mmoja mmoja kuwa faili moja ya sauti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utekelezaji wa kazi mbili: convert_to_text na run_text_prompt, pamoja na tangazo la madarasa mawili: str na Audio.\n",
    "\n",
    "Kazi ya convert_to_text inachukua audio_path kama ingizo na kutafsiri sauti kuwa maandishi kwa kutumia mfano unaoitwa whisper_model. Kazi hii kwanza inakagua ikiwa bendera ya gpu imewekwa kuwa True. Ikiwa imewekwa, whisper_model inatumika na vigezo fulani kama word_timestamps=True, fp16=True, language='English', na task='translate'. Ikiwa bendera ya gpu ni False, whisper_model inatumika na fp16=False. Matokeo ya tafsiri yanahifadhiwa kwenye faili inayoitwa 'scan.txt' na kurudishwa kama maandishi.\n",
    "\n",
    "Kazi ya run_text_prompt inachukua ujumbe na chat_history kama ingizo. Inatumia kazi ya phi_demo kuunda jibu kutoka kwa chatbot kulingana na ujumbe uliotolewa. Jibu lililoundwa linapitishwa kwa kazi ya talk, ambayo hubadilisha jibu kuwa faili ya sauti na kurudisha njia ya faili. Darasa la Audio linatumika kuonyesha na kucheza faili ya sauti. Sauti inaonyeshwa kwa kutumia kazi ya display kutoka moduli ya IPython.display, na kitu cha Audio kinaundwa na parameter autoplay=True, ili sauti ianze kucheza moja kwa moja. chat_history inasasishwa na ujumbe wa ingizo na jibu lililoundwa, na kamba tupu pamoja na chat_history iliyosasishwa zinarejeshwa.\n",
    "\n",
    "Darasa la str ni darasa lililojengwa ndani ya Python ambalo linawakilisha mlolongo wa herufi. Linatoa mbinu mbalimbali za kudhibiti na kufanya kazi na kamba, kama capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill, na zaidi. Mbinu hizi zinakuruhusu kufanya shughuli kama kutafuta, kubadilisha, kuunda, na kudhibiti kamba.\n",
    "\n",
    "Darasa la Audio ni darasa maalum linalowakilisha kitu cha sauti. Linatumika kuunda kicheza sauti katika mazingira ya Jupyter Notebook. Darasa hili linakubali vigezo mbalimbali kama data, filename, url, embed, rate, autoplay, na normalize. Parameter ya data inaweza kuwa array ya numpy, orodha ya sampuli, kamba inayowakilisha jina la faili au URL, au data ghafi ya PCM. Parameter ya filename inatumika kubainisha faili ya ndani ya kupakia data ya sauti, na parameter ya url inatumika kubainisha URL ya kupakua data ya sauti. Parameter ya embed inaamua ikiwa data ya sauti inapaswa kuingizwa kwa kutumia URI ya data au kurejelewa kutoka chanzo asili. Parameter ya rate inabainisha kiwango cha sampuli cha data ya sauti. Parameter ya autoplay inaamua ikiwa sauti inapaswa kuanza kucheza moja kwa moja. Parameter ya normalize inabainisha ikiwa data ya sauti inapaswa kusawazishwa (kurekebishwa) kwa kiwango cha juu kinachowezekana. Darasa la Audio pia linatoa mbinu kama reload ya kupakia tena data ya sauti kutoka faili au URL, na sifa kama src_attr, autoplay_attr, na element_id_attr za kupata sifa zinazolingana kwa kipengele cha sauti katika HTML.\n",
    "\n",
    "Kwa ujumla, kazi hizi na madarasa haya yanatumika kutafsiri sauti kuwa maandishi, kuunda majibu ya sauti kutoka kwa chatbot, na kuonyesha na kucheza sauti katika mazingira ya Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Kanusho**:  \nHati hii imetafsiriwa kwa kutumia huduma ya kutafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuhakikisha usahihi, tafadhali fahamu kuwa tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati ya asili katika lugha yake ya awali inapaswa kuzingatiwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa kutoelewana au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-13T06:59:19+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "sw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}