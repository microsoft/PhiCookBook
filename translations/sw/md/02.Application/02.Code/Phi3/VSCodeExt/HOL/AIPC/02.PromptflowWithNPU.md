<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-07-17T04:00:51+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "sw"
}
-->
# **Maabara 2 - Endesha Prompt flow na Phi-3-mini katika AIPC**

## **Prompt flow ni nini**

Prompt flow ni seti ya zana za maendeleo zilizoundwa kurahisisha mzunguko mzima wa maendeleo ya programu za AI zinazotumia LLM, kuanzia mawazo, uundaji wa mfano, upimaji, tathmini hadi uzalishaji na ufuatiliaji. Inafanya uhandisi wa prompt kuwa rahisi zaidi na inakuwezesha kujenga programu za LLM zenye ubora wa uzalishaji.

Kwa kutumia prompt flow, utaweza:

- Kuunda mizunguko inayounganisha LLMs, prompts, msimbo wa Python na zana nyingine pamoja katika mtiririko unaotekelezeka.

- Kurekebisha na kurudia mizunguko yako, hasa mwingiliano na LLMs kwa urahisi.

- Kutathmini mizunguko yako, kuhesabu viwango vya ubora na utendaji kwa seti kubwa za data.

- Kuunganisha upimaji na tathmini katika mfumo wako wa CI/CD kuhakikisha ubora wa mtiririko wako.

- Kuweka mizunguko yako kwenye jukwaa la huduma unalolichagua au kuingiza kwa urahisi kwenye msimbo wa programu yako.

- (Hiari lakini inashauriwa sana) Kushirikiana na timu yako kwa kutumia toleo la Prompt flow linalotegemea wingu katika Azure AI.

## **AIPC ni nini**

Kompyuta ya AI ina CPU, GPU na NPU, kila moja ikiwa na uwezo maalum wa kuharakisha AI. NPU, au neural processing unit, ni kiendeshi maalum kinachoshughulikia kazi za akili bandia (AI) na ujifunzaji wa mashine (ML) moja kwa moja kwenye kompyuta yako badala ya kutuma data kwa usindikaji kwenye wingu. GPU na CPU pia zinaweza kushughulikia kazi hizi, lakini NPU ni bora hasa kwa mahesabu ya AI yenye matumizi ya chini ya nguvu. Kompyuta ya AI ni mabadiliko makubwa katika jinsi tunavyotumia kompyuta zetu. Sio suluhisho la tatizo ambalo halikuwepo hapo awali. Badala yake, inaahidi kuboresha kwa kiasi kikubwa matumizi ya kawaida ya kompyuta.

Basi inafanya kazi vipi? Ikilinganishwa na AI ya kizazi na mifano mikubwa ya lugha (LLMs) iliyofunzwa kwa data nyingi za umma, AI itakayofanyika kwenye kompyuta yako ni rahisi kufikiwa kwa karibu kila kiwango. Dhana ni rahisi kueleweka, na kwa kuwa imefunzwa kwa data yako, bila hitaji la kufikia wingu, faida zake zinavutia zaidi kwa watu wengi.

Kwa muda mfupi, dunia ya AI PC inahusisha wasaidizi binafsi na mifano midogo ya AI inayotumia data yako kutoa maboresho ya AI ya kibinafsi, ya faragha, na salama zaidi kwa mambo unayofanya kila siku – kuchukua kumbukumbu za mikutano, kupanga ligi ya fantasy football, kuendesha maboresho ya kiotomatiki kwa uhariri wa picha na video, au kupanga ratiba kamili ya mkutano wa familia kulingana na nyakati za kuwasili na kuondoka kwa kila mtu.

## **Kuunda mizunguko ya msimbo wa kizazi kwenye AIPC**

***Note*** ：Kama bado hujakamilisha usakinishaji wa mazingira, tafadhali tembelea [Lab 0 -Installations](./01.Installations.md)

1. Fungua Prompt flow Extension katika Visual Studio Code na unda mradi wa mtiririko tupu

![create](../../../../../../../../../translated_images/pf_create.bde888dc83502eba082a058175bbf1eee6791219795393a386b06fd3043ec54d.sw.png)

2. Ongeza vigezo vya Ingizo na Matokeo na Ongeza Msimbo wa Python kama mtiririko mpya

![flow](../../../../../../../../../translated_images/pf_flow.520824c0969f2a94f17e947f86bdc4b4c6c88a2efa394fe3bcfb58c0dbc578a7.sw.png)

Unaweza kurejelea muundo huu (flow.dag.yaml) kujenga mtiririko wako

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Ongeza Msimbo katika ***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Unaweza kujaribu mtiririko kutoka Debug au Run ili kuangalia kama msimbo wa kizazi unafanya kazi vizuri au la

![RUN](../../../../../../../../../translated_images/pf_run.4239e8a0b420a58284edf6ee1471c1697c345670313c8e7beac0edaee15b9a9d.sw.png)

5. Endesha mtiririko kama API ya maendeleo kwenye terminal

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Unaweza kujaribu katika Postman / Thunder Client

### **Note**

1. Mara ya kwanza kuendesha huchukua muda mrefu. Inashauriwa kupakua mfano wa phi-3 kutoka Hugging face CLI.

2. Kwa kuzingatia uwezo mdogo wa kompyuta wa Intel NPU, inashauriwa kutumia Phi-3-mini-4k-instruct

3. Tunatumia Kuongeza Kasi ya Intel NPU kwa kubadilisha kuwa INT4, lakini ukirudia kuendesha huduma, unahitaji kufuta folda za cache na nc_workshop.

## **Rasilimali**

1. Jifunze Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Jifunze Kuongeza Kasi ya Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Msimbo wa Mfano, pakua [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Kiarifu cha Msamaha**:  
Hati hii imetafsiriwa kwa kutumia huduma ya tafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuhakikisha usahihi, tafadhali fahamu kwamba tafsiri za kiotomatiki zinaweza kuwa na makosa au upungufu wa usahihi. Hati ya asili katika lugha yake ya asili inapaswa kuchukuliwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu inayofanywa na binadamu inashauriwa. Hatuna dhamana kwa kutoelewana au tafsiri potofu zinazotokana na matumizi ya tafsiri hii.