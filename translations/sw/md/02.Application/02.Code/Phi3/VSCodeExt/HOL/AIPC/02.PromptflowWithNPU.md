<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-05-09T19:25:39+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "sw"
}
-->
# **Lab 2 - Endesha Prompt flow na Phi-3-mini katika AIPC**

## **Prompt flow ni nini**

Prompt flow ni seti ya zana za maendeleo iliyoundwa kurahisisha mzunguko mzima wa maendeleo ya programu za AI zinazotumia LLM, kuanzia mawazo, kuunda mfano, kupima, kutathmini hadi uzalishaji na ufuatiliaji. Inafanya uhandisi wa prompt kuwa rahisi zaidi na inakuwezesha kujenga programu za LLM zenye ubora wa uzalishaji.

Kwa kutumia prompt flow, utaweza:

- Kuunda flows zinazounganisha LLMs, prompts, msimbo wa Python na zana nyingine pamoja katika mtiririko wa kazi unaotekelezeka.

- Kurekebisha na kurudia flows zako, hasa mwingiliano na LLMs kwa urahisi.

- Kutathmini flows zako, kuhesabu viashiria vya ubora na utendaji kwa seti kubwa za data.

- Kuingiza upimaji na tathmini katika mfumo wako wa CI/CD kuhakikisha ubora wa flow yako.

- Kupeleka flows zako kwenye jukwaa la kuhudumia ulilochagua au kuziingiza kwa urahisi kwenye msimbo wa programu yako.

- (Hiari lakini inashauriwa sana) Kushirikiana na timu yako kwa kutumia toleo la Prompt flow la wingu katika Azure AI.

## **AIPC ni nini**

AI PC ina CPU, GPU na NPU, kila moja ikiwa na uwezo maalum wa kuharakisha AI. NPU, au neural processing unit, ni kiendeshi maalum kinachoshughulikia kazi za akili bandia (AI) na ujifunzaji wa mashine (ML) moja kwa moja kwenye kompyuta yako badala ya kutuma data kusindikwa wingu. GPU na CPU pia zinaweza kushughulikia kazi hizi, lakini NPU ni bora hasa kwa mahesabu ya AI yenye matumizi ya chini ya nguvu. AI PC ni mabadiliko makubwa katika jinsi kompyuta zetu zinavyofanya kazi. Sio suluhisho la tatizo ambalo halikuwahi kuwepo hapo awali. Badala yake, inaahidi kuboresha matumizi ya kila siku ya PC kwa kiasi kikubwa.

Basi inafanya kazi vipi? Ikilinganishwa na AI ya kizazi na modeli kubwa za lugha (LLMs) zilizofunzwa kwa data nyingi za umma, AI itakayofanyika kwenye PC yako ni rahisi kufikiwa kwa karibu kila kiwango. Dhana hii ni rahisi kueleweka, na kwa kuwa inafunzwa kwa data yako, bila hitaji la kufikia wingu, faida zake zinavutia zaidi watu wengi.

Kwa muda mfupi, dunia ya AI PC inahusisha wasaidizi binafsi na modeli ndogo za AI zinazotumia data yako moja kwa moja kwenye PC, kutoa maboresho ya AI binafsi, ya faragha na salama zaidi kwa mambo unayofanya kila siku – kuchukua kumbukumbu za mikutano, kupanga ligi ya fantasy football, kuendesha maboresho ya kiotomatiki kwa uhariri wa picha na video, au kupanga ratiba kamili ya mkutano wa familia kulingana na nyakati za kuwasili na kuondoka kwa kila mtu.

## **Kuunda flows za kizazi kwenye AIPC**

***Note*** ：Kama bado hujakamilisha usakinishaji wa mazingira, tafadhali tembelea [Lab 0 -Installations](./01.Installations.md)

1. Fungua Prompt flow Extension katika Visual Studio Code na tengeneza mradi wa flow tupu

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.sw.png)

2. Ongeza vigezo vya Inputs na Outputs na Ongeza Msimbo wa Python kama flow mpya

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.sw.png)

Unaweza kurejelea muundo huu (flow.dag.yaml) kuunda flow yako

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Ongeza Msimbo katika ***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Unaweza kupima flow kutoka Debug au Run kuona kama msimbo wa kizazi unafanya kazi vizuri

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.sw.png)

5. Endesha flow kama API ya maendeleo katika terminal

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Unaweza kuipima katika Postman / Thunder Client

### **Note**

1. Mara ya kwanza kuendesha huchukua muda mrefu. Inashauriwa kupakua modeli ya phi-3 kutoka Hugging face CLI.

2. Kwa kuzingatia uwezo mdogo wa Intel NPU, inashauriwa kutumia Phi-3-mini-4k-instruct

3. Tunatumia Kuongeza Kasi ya Intel NPU kwa kubadilisha kuwa INT4, lakini kama utaendesha huduma tena, unahitaji kufuta folda za cache na nc_workshop.

## **Rasilimali**

1. Jifunze Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Jifunze Kuongeza Kasi ya Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Msimbo wa Mfano, pakua [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Kiasi cha Jibu**:  
Hati hii imetafsiriwa kwa kutumia huduma ya tafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuwa sahihi, tafadhali fahamu kwamba tafsiri za kiotomatiki zinaweza kuwa na makosa au upungufu wa usahihi. Hati ya asili katika lugha yake ya asili inapaswa kuchukuliwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatuna dhamana kwa kutoelewana au tafsiri potofu zinazotokana na matumizi ya tafsiri hii.