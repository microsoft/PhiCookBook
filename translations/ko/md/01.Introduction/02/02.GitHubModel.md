<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-05-08T06:27:41+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "ko"
}
-->
## GitHub Models의 Phi Family

[GitHub Models](https://github.com/marketplace/models)에 오신 것을 환영합니다! Azure AI에 호스팅된 AI 모델을 탐색할 준비가 모두 완료되었습니다.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.aa43c51c36454747ca1cc1ffa799db02cc66b4fb7e8495311701adb072442df8.ko.png)

GitHub Models에서 제공하는 모델에 대한 자세한 내용은 [GitHub Model Marketplace](https://github.com/marketplace/models)를 참고하세요.

## 사용 가능한 모델

각 모델마다 전용 플레이그라운드와 샘플 코드가 제공됩니다.

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.cf6a9f1106e048535478f17ed0078551c3959884e4083eb62a895bb089dd831c.ko.png)

### GitHub 모델 카탈로그의 Phi Family

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## 시작하기

바로 실행할 수 있는 기본 예제들이 몇 가지 준비되어 있습니다. samples 디렉터리에서 확인할 수 있습니다. 선호하는 언어로 바로 이동하고 싶다면 다음 언어별 예제를 참고하세요:

- Python
- JavaScript
- C#
- Java
- cURL

샘플과 모델 실행을 위한 전용 Codespaces 환경도 제공됩니다.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.150220a802da6fb67944ad93c1a4c7b8a9811e43d77879a149ecf54c02928c6b.ko.png)


## 샘플 코드

아래는 몇 가지 사용 사례에 대한 예제 코드 스니펫입니다. Azure AI Inference SDK에 대한 추가 정보는 전체 문서와 샘플을 참고하세요.

## 설정

1. 개인 액세스 토큰 생성  
토큰에 별도의 권한을 부여할 필요는 없습니다. 단, 토큰은 Microsoft 서비스로 전송된다는 점을 유의하세요.

아래 코드 스니펫을 사용하려면 환경 변수를 생성하여 클라이언트 코드의 키로 토큰을 설정하세요.

bash를 사용하는 경우:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
powershell을 사용하는 경우:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

Windows 명령 프롬프트를 사용하는 경우:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## Python 샘플

### 의존성 설치  
pip를 사용해 Azure AI Inference SDK를 설치하세요 (필수: Python >=3.8):

```
pip install azure-ai-inference
```  
### 기본 코드 샘플 실행

이 샘플은 chat completion API를 기본적으로 호출하는 예제입니다. GitHub AI 모델 추론 엔드포인트와 GitHub 토큰을 활용하며, 호출은 동기 방식입니다.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### 다중 대화 실행

이 샘플은 chat completion API를 사용한 다중 턴 대화를 보여줍니다. 채팅 애플리케이션에 모델을 사용할 때는 대화 내역을 관리하고 최신 메시지를 모델에 전달해야 합니다.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### 출력 스트리밍

더 나은 사용자 경험을 위해, 모델의 응답을 스트리밍하여 첫 토큰이 빠르게 표시되고 긴 응답을 기다리지 않도록 할 수 있습니다.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## GitHub Models의 무료 사용 및 요율 제한

![Model Catalog](../../../../../translated_images/GitHub_Model.ca6c125cb3117d0ea7c2e204b066ee4619858d28e7b1a419c262443c5e9a2d5b.ko.png)

[플레이그라운드와 무료 API 사용에 대한 요율 제한](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits)은 모델 실험과 AI 애플리케이션 프로토타입 제작을 돕기 위한 것입니다. 이 한도를 초과하여 사용하거나 애플리케이션을 확장하려면 Azure 계정에서 리소스를 프로비저닝하고 GitHub 개인 액세스 토큰 대신 해당 계정으로 인증해야 합니다. 코드의 다른 부분을 변경할 필요는 없습니다. Azure AI에서 무료 등급 한도를 초과하는 방법은 이 링크를 참고하세요.

### 고지사항

모델과 상호작용할 때는 AI를 실험하는 것이므로 내용에 오류가 있을 수 있음을 기억하세요.

이 기능은 분당 요청 수, 일일 요청 수, 요청당 토큰 수, 동시 요청 수 등 다양한 제한이 있으며, 프로덕션 용도로 설계되지 않았습니다.

GitHub Models는 Azure AI Content Safety를 사용합니다. 이 필터는 GitHub Models 환경에서 비활성화할 수 없습니다. 유료 서비스로 모델을 사용할 경우, 필요에 맞게 콘텐츠 필터를 설정하세요.

이 서비스는 GitHub의 사전 출시 약관에 따라 제공됩니다.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 유의해 주시기 바랍니다. 원문 문서는 해당 언어의 권위 있는 자료로 간주되어야 합니다. 중요한 정보의 경우, 전문 인간 번역을 권장합니다. 본 번역 사용으로 인한 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.