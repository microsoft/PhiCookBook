<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "826ed5d9fb4212529764bf7526f1252c",
  "translation_date": "2025-04-04T05:46:18+00:00",
  "source_file": "md\\01.Introduction\\02\\01.HF.md",
  "language_code": "ko"
}
-->
# **Hugging Face에서 Phi Family 사용하기**

[Hugging Face](https://huggingface.co/)는 풍부한 데이터와 오픈 소스 모델 리소스를 제공하는 매우 인기 있는 AI 커뮤니티입니다. 다양한 제조업체들이 Hugging Face를 통해 오픈 소스 LLM 및 SLM을 공개하고 있으며, Microsoft, Meta, Mistral, Apple, Google 등이 그 예입니다.

Microsoft Phi Family 모델도 Hugging Face에 공개되었습니다. 개발자는 시나리오와 비즈니스에 따라 해당 Phi Family 모델을 다운로드할 수 있습니다. Hugging Face에서 Phi Pytorch 모델을 배포하는 것 외에도, GGUF 및 ONNX 형식을 사용한 양자화된 모델도 제공하여 최종 사용자에게 선택의 폭을 넓혔습니다.

## **Hugging Face에서 모델 다운로드하기**

아래 링크를 통해 Phi Family 모델을 다운로드할 수 있습니다:

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

모델은 ***Hugging Face CLI SDK***를 설치하거나 ***git clone***을 사용하여 다양한 방식으로 다운로드할 수 있습니다.

### **Hugging Face CLI를 사용하여 Phi Family 모델 다운로드하기**

- Hugging Face CLI 설치

```bash

pip install -U "huggingface_hub[cli]"

```

- huggingface-cli로 로그인

[설정 페이지](https://huggingface.co/settings/tokens)에서 [사용자 액세스 토큰](https://huggingface.co/docs/hub/security-tokens)을 통해 Hugging Face에 로그인하세요.

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- 다운로드

모델을 다운로드하여 캐시에 저장할 수 있습니다.

```bash

huggingface-cli download microsoft/phi-4

```

특정 위치에 저장하려면 아래와 같이 설정할 수 있습니다.

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **git clone을 사용하여 Phi Family 모델 다운로드하기**

***git clone***을 사용하여 모델을 다운로드할 수도 있습니다.

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **예제 - Microsoft Phi-4 추론**

- **transformers 라이브러리 설치**

```bash

pip install transformers -U

```

- **VSCode에서 코드 실행**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확한 내용이 포함될 수 있습니다. 원본 문서의 원어 버전이 권위 있는 출처로 간주되어야 합니다. 중요한 정보에 대해서는 전문적인 인간 번역을 권장합니다. 이 번역을 사용하는 과정에서 발생하는 오해나 잘못된 해석에 대해 책임지지 않습니다.