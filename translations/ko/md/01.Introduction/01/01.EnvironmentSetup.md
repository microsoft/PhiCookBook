<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7e58d5075509bcb4a65bc8370bd21a8b",
  "translation_date": "2025-04-04T05:41:15+00:00",
  "source_file": "md\\01.Introduction\\01\\01.EnvironmentSetup.md",
  "language_code": "ko"
}
-->
# Phi-3 로컬 시작하기

이 가이드는 Ollama를 사용하여 Phi-3 모델을 실행하기 위해 로컬 환경을 설정하는 방법을 안내합니다. GitHub Codespaces, VS Code Dev Containers, 또는 로컬 환경을 사용하여 모델을 실행할 수 있습니다.

## 환경 설정

### GitHub Codespaces

GitHub Codespaces를 사용하여 이 템플릿을 가상으로 실행할 수 있습니다. 버튼을 클릭하면 브라우저에서 웹 기반 VS Code 인스턴스가 열립니다:

1. 템플릿을 엽니다 (몇 분이 걸릴 수 있습니다):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. 터미널 창을 엽니다.

### VS Code Dev Containers

⚠️ 이 옵션은 Docker Desktop에 최소 16GB RAM이 할당된 경우에만 작동합니다. RAM이 16GB보다 적다면 [GitHub Codespaces 옵션](../../../../../md/01.Introduction/01)이나 [로컬 설정](../../../../../md/01.Introduction/01)을 시도해보세요.

관련 옵션으로 VS Code Dev Containers를 사용하면 [Dev Containers 확장](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)을 통해 로컬 VS Code에서 프로젝트를 열 수 있습니다:

1. Docker Desktop을 시작합니다 (설치되어 있지 않다면 먼저 설치하세요).
2. 프로젝트를 엽니다:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. VS Code 창이 열리고 프로젝트 파일이 표시되면 (몇 분이 걸릴 수 있습니다), 터미널 창을 엽니다.
4. [배포 단계](../../../../../md/01.Introduction/01)를 계속 진행합니다.

### 로컬 환경

1. 다음 도구가 설치되어 있는지 확인하세요:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## 모델 테스트

1. Ollama를 사용하여 phi3:mini 모델을 다운로드하고 실행하세요:

    ```shell
    ollama run phi3:mini
    ```

    모델을 다운로드하는 데 몇 분이 걸립니다.

2. 출력에서 "success" 메시지가 보이면 프롬프트에서 해당 모델로 메시지를 보낼 수 있습니다.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. 몇 초 후 모델에서 응답 스트림이 표시될 것입니다.

4. 언어 모델에서 사용하는 다양한 기술을 배우고 싶다면 Python 노트북 [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb)를 열어 각 셀을 실행하세요. 'phi3:mini' 이외의 모델을 사용했다면 파일 상단에서 `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME`을 변경하고, 필요에 따라 시스템 메시지를 수정하거나 몇 가지 예제를 추가할 수도 있습니다.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 최대한 정확성을 기하기 위해 노력했으나, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원문이 작성된 원어 문서를 신뢰할 수 있는 권위 있는 자료로 간주해야 합니다. 중요한 정보에 대해서는 전문적인 인간 번역을 권장합니다. 이 번역을 사용하는 데서 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.