<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5d936ffe4dfbab2244f6eb21b11f3b3",
  "translation_date": "2025-07-16T18:30:56+00:00",
  "source_file": "md/01.Introduction/01/01.PhiFamily.md",
  "language_code": "ko"
}
-->
# Microsoft의 Phi 패밀리

Phi 모델은 가장 뛰어나고 비용 효율적인 소형 언어 모델(SLM)로, 다양한 언어, 추론, 코딩, 오디오, 비전, 수학 벤치마크에서 동일 크기 및 한 단계 큰 모델들을 능가합니다. 이번 릴리스는 고객에게 고품질 모델 선택지를 확대하여 생성 AI 애플리케이션을 구성하고 구축하는 데 더 실용적인 선택지를 제공합니다.

Phi 패밀리는 Python 코드 생성을 위한 Phi-1에서 시작해, 텍스트 및 채팅 완성을 기반으로 한 Phi-1.5 / 2, Phi-3-mini/small/medium-instruct 및 Phi-3.5/4-mini-instruct, 비전을 위한 Phi-3/3.5-vision, 강력한 추론 기반의 Phi-4, MoE용 Phi-3.5-MoE, 그리고 현재는 풀 모달 모델인 Phi-4-multimodal까지 발전해 왔습니다. 고품질 데이터 세트를 통해 벤치마크를 훈련시켜 더 큰 파라미터를 가진 모델과 견줄 수 있습니다.

## Phi 패밀리 모델

<div style="font-size:8px">

| Model Card |Parameters|Coding|Text/Chat Completion|Advanced Reasoning| Vision | Audio | MoE
| - | -  | - | - |- |- |- |- |
|[Phi-1](https://huggingface.co/microsoft/phi-1)|1.3B| 예| 아니오 | 아니오 |아니오 |아니오 |아니오 |
|[Phi-1.5](https://huggingface.co/microsoft/phi-1_5)|1.3B| 예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-2](https://huggingface.co/microsoft/phi-1_5)|2.7B| 예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)<br/>[Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)|3.8B| 예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-3-small-8k-instruct](https://huggingface.co/microsoft/Phi-3-small-8k-instruct)<br/>[Phi-3-small-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct)<br/>|7B| 예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-3-mediumn-4k-instruct](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)<br>[Phi-3-mediumn-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)|14B|예|아니오| 아니오 |아니오 |아니오 |아니오 |
|[Phi-3-vision-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)|4.2B|예|예|아니오 |아니오 |아니오 |아니오 |
|[Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)|3.8B|예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct)|42B|예|예| 아니오 |아니오 |아니오 |예 |
|[Phi-3.5-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3.5-vision-instruct)|4.2B|예|예| 아니오 |예 |아니오 |아니오 |
|[Phi-4](https://huggingface.co/microsoft/phi-4)|14B|예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-4-mini](https://huggingface.co/microsoft/Phi-4-mini-instruct)|3.8B|예|예| 아니오 |아니오 |아니오 |아니오 |
|[Phi-4-multimodal](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)|5.6B|예|예| 아니오 |예 |예 |아니오 |
|[Phi-4-reasoning](../../../../../md/01.Introduction/01)|3.8B|예|예| 예 |아니오 |아니오 |아니오 |
|[Phi-4-mini-reasoning](../../../../../md/01.Introduction/01)|3.8B|예|예| 예 |아니오 |아니오 |아니오 |

</div>

## **다양한 모델 플랫폼에서 모든 Phi 모델 찾기**

- [Azure AI Foundry Model catalog](https://ai.azure.com/explore/models?selectedCollection=phi)
- [GitHub Models](https://github.com/marketplace?query=Phi&type=models)
- Hugging Face
  - [Phi-1 /1.5](https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572)
  - [Phi-2](https://huggingface.co/microsoft/phi-2)
  - [Phi-3](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)
  - [Phi-4](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4) 
- [NVIDIA NIM](https://build.nvidia.com/search?q=Phi)

## 모델 선택 예시

| | | | |
|-|-|-|-|
|고객 요구|작업|시작 모델|상세 설명|
|단순히 메시지 스레드를 요약하는 모델 필요|대화 요약|Phi-3 / 3.5 텍스트 모델|고객의 언어 작업이 명확하고 직관적이라는 점이 결정 요인입니다|
|어린이를 위한 무료 수학 튜터 앱|수학 및 추론|Phi-3 / 3.5 / 4 텍스트 모델|앱이 무료이기 때문에 고객은 반복 비용이 들지 않는 솔루션을 원합니다|
|자가 순찰 차량 카메라|비전 분석|Phi-3 /3.5 -Vision 또는 Phi-4-multimodal|인터넷 없이 엣지에서 작동 가능한 솔루션이 필요합니다|
|AI 기반 여행 예약 에이전트 구축 희망|복잡한 계획, 함수 호출 및 오케스트레이션 필요|GPT 모델|계획 수립, API 호출을 통한 정보 수집 및 실행 기능이 필요합니다|
|직원용 코파일럿 구축 희망|RAG, 다중 도메인, 복잡하고 개방형|GPT 모델 + Phi 패밀리|개방형 시나리오로 더 넓은 세계 지식이 필요하므로 더 큰 모델이 적합합니다. 지식 콘텐츠를 분할해야 하며, SLM이 적합할 수 있습니다|

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확한 부분이 있을 수 있음을 유의해 주시기 바랍니다. 원문은 해당 언어의 원본 문서가 권위 있는 출처로 간주되어야 합니다. 중요한 정보의 경우 전문적인 인간 번역을 권장합니다. 본 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.