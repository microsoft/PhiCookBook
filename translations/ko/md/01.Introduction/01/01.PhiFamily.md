<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8ef41b679d85adc42be3e0cbee97f7f1",
  "translation_date": "2025-07-18T21:24:21+00:00",
  "source_file": "md/01.Introduction/01/01.PhiFamily.md",
  "language_code": "ko"
}
-->
# Microsoft의 Phi 패밀리

Phi 모델은 가장 성능이 뛰어나고 비용 효율적인 소형 언어 모델(SLM)로, 다양한 언어, 추론, 코딩, 오디오, 비전, 수학 벤치마크에서 동일한 크기 및 더 큰 크기의 모델을 능가합니다. 이번 릴리스는 고객들에게 고품질 모델의 선택지를 확장하여 생성형 AI 애플리케이션을 구성하고 구축하는 데 더 실용적인 옵션을 제공합니다.

Phi 패밀리는 Python 코드 생성용 Phi-1로 시작하여 텍스트 및 채팅 완성을 기반으로 한 Phi-1.5/2, Phi-3-mini/small/medium-instruct 및 Phi-3.5/4-mini-instruct로 이어졌으며, 비전용 Phi-3/3.5-vision, 강력한 추론을 기반으로 한 Phi-4, MoE용 Phi-3.5-MoE, 그리고 이제는 풀 모달 모델인 Phi-4-multimodal로 발전했습니다. 고품질 데이터 세트를 통해 벤치마크는 더 큰 학습 매개변수를 가진 모델과 비교할 수 있는 수준으로 훈련될 수 있습니다.

## Phi 패밀리 모델

<div style="font-size:8px">

| 모델 카드 | 매개변수 | 코딩 | 텍스트/채팅 완성 | 고급 추론 | 비전 | 오디오 | MoE |
| - | -  | - | - | - | - | - | - |
|[Phi-1](https://huggingface.co/microsoft/phi-1)|1.3B| 예 | 아니오 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-1.5](https://huggingface.co/microsoft/phi-1_5)|1.3B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-2](https://huggingface.co/microsoft/phi-1_5)|2.7B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)<br/>[Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)|3.8B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-3-small-8k-instruct](https://huggingface.co/microsoft/Phi-3-small-8k-instruct)<br/>[Phi-3-small-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct)<br/>|7B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-3-mediumn-4k-instruct](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)<br>[Phi-3-mediumn-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct)|14B| 예 | 아니오 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-3-vision-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)|4.2B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)|3.8B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct)|42B| 예 | 예 | 아니오 | 아니오 | 아니오 | 예 |
|[Phi-3.5-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3.5-vision-instruct)|4.2B| 예 | 예 | 아니오 | 예 | 아니오 | 아니오 |
|[Phi-4](https://huggingface.co/microsoft/phi-4)|14B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-4-mini](https://huggingface.co/microsoft/Phi-4-mini-instruct)|3.8B| 예 | 예 | 아니오 | 아니오 | 아니오 | 아니오 |
|[Phi-4-multimodal](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)|5.6B| 예 | 예 | 아니오 | 예 | 예 | 아니오 |
|[Phi-4-reasoning](https://huggingface.co/microsoft/Phi-4-reasoning)|3.8B| 예 | 예 | 예 | 아니오 | 아니오 | 아니오 |
|[Phi-4-mini-reasoning](https://huggingface.co/microsoft/Phi-4-mini-reasoning)|3.8B| 예 | 예 | 예 | 아니오 | 아니오 | 아니오 |

</div>

## **다양한 모델 플랫폼에서 모든 Phi 모델 찾기**

- [Azure AI Foundry Model catalog](https://ai.azure.com/explore/models?selectedCollection=phi)
- [GitHub Models](https://github.com/marketplace?query=Phi&type=models)
- Hugging Face
  - [Phi-1 /1.5](https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572)
  - [Phi-2](https://huggingface.co/microsoft/phi-2)
  - [Phi-3](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)
  - [Phi-4](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4) 
- [NVIDIA NIM](https://build.nvidia.com/search?q=Phi)

## 모델 선택 예시

| | | | |
|-|-|-|-|
|고객 요구|작업|추천 모델|추가 설명|
|메시지 스레드를 간단히 요약하는 모델이 필요|대화 요약|Phi-3 / 3.5 텍스트 모델|고객이 명확하고 간단한 언어 작업을 가지고 있다는 점이 결정 요인|
|아이들을 위한 무료 수학 튜터 앱|수학 및 추론|Phi-3 / 3.5 / 4 텍스트 모델|앱이 무료이므로 고객은 반복 비용이 들지 않는 솔루션을 원함|
|자율 순찰 차량 카메라|비전 분석|Phi-3 / 3.5-Vision 또는 Phi-4-multimodal|인터넷 없이 엣지에서 작동할 수 있는 솔루션 필요|
|AI 기반 여행 예약 에이전트를 구축하고 싶음|복잡한 계획, 함수 호출 및 오케스트레이션 필요|GPT 모델|정보를 수집하고 실행하기 위해 API를 호출하고 계획할 수 있는 능력이 필요|
|직원을 위한 코파일럿을 구축하고 싶음|RAG, 다중 도메인, 복잡하고 개방형|GPT 모델 + Phi 패밀리|개방형 시나리오로, 더 넓은 세계 지식이 필요하므로 더 큰 모델이 적합. 지식 콘텐츠를 분할해야 하며, SLM이 적합할 수 있음|

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 책임을 지지 않습니다.