<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "839ccc4b3886ef10cfd4e64977f5792d",
  "translation_date": "2026-01-05T16:26:37+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "ko"
}
-->
# Phi 모델을 위한 AI 안전
Phi 모델 계열은 다음 여섯 가지 원칙을 기반으로 하는 회사 전반의 요구 사항인 [Microsoft 책임 있는 AI 표준](https://www.microsoft.com/ai/principles-and-approach#responsible-ai-standard)에 따라 개발되었습니다: 책임성, 투명성, 공정성, 신뢰성 및 안전성, 개인정보 보호 및 보안, 포용성, 이들은 [Microsoft의 책임 있는 AI 원칙](https://www.microsoft.com/ai/responsible-ai)을 형성합니다.

이전 Phi 모델들과 마찬가지로 다면적 안전 평가 및 안전 후 학습 접근법이 채택되었으며, 이번 릴리즈의 다국어 기능을 고려한 추가 조치가 이루어졌습니다. 다국어 및 위험 카테고리별 테스트를 포함한 안전 훈련 및 평가 접근법은 [Phi 안전 후 학습 논문](https://arxiv.org/abs/2407.13833)에 개략적으로 설명되어 있습니다. Phi 모델이 이러한 접근법으로 혜택을 받지만, 개발자는 특정 사용 사례 및 문화적, 언어적 맥락과 관련된 위험을 매핑, 측정 및 완화하는 책임 있는 AI 모범 사례를 적용해야 합니다.

## 모범 사례

다른 모델과 마찬가지로 Phi 모델 계열은 불공정하거나 신뢰할 수 없거나 불쾌감을 줄 수 있는 방식으로 동작할 수 있습니다.

SLM과 LLM의 일부 제한적 동작은 다음과 같습니다:

- **서비스 품질:** Phi 모델은 주로 영어 텍스트로 학습되었습니다. 영어가 아닌 언어는 성능이 저하될 수 있습니다. 학습 데이터에 적게 반영된 영어 변종은 표준 미국 영어보다 성능이 떨어질 수 있습니다.
- **해악의 재현 및 고정관념의 영속:** 이 모델들은 특정 집단을 과대 또는 과소 대표하거나 일부 집단의 대표성을 지우거나 모욕적이거나 부정적인 고정관념을 강화할 수 있습니다. 안전 후 학습에도 불구하고, 다양한 집단의 대표성 차이나 실제 세계 패턴 및 사회적 편견을 반영하는 학습 데이터 내 부정적 고정관념 사례의 유병률로 인해 이러한 한계가 여전히 존재할 수 있습니다.
- **부적절하거나 불쾌한 콘텐츠:** 이 모델들은 민감한 상황에 배치하기에 부적절할 수 있는 다른 유형의 부적절하거나 불쾌한 콘텐츠를 생성할 수 있으며, 이는 특정 사용 사례에 맞춘 추가 완화 조치 없이는 부적합할 수 있습니다.
정보 신뢰성: 언어 모델은 말이 안 되거나 그럴듯하게 들리지만 부정확하거나 오래된 내용을 생성할 수 있습니다.
- **코드 범위 제한:** Phi-3 학습 데이터 대부분은 Python 기반이며 "typing, math, random, collections, datetime, itertools"와 같은 일반 패키지를 사용합니다. 모델이 다른 패키지를 사용하거나 다른 언어의 스크립트를 생성하는 경우 사용자가 모든 API 사용을 수동으로 확인할 것을 강력히 권장합니다.

개발자는 책임 있는 AI 모범 사례를 적용해야 하며, 특정 사용 사례가 관련 법률 및 규정을 준수하는지(예: 개인정보 보호, 무역 등) 확인할 책임이 있습니다.

## 책임 있는 AI 고려 사항

다른 언어 모델과 마찬가지로 Phi 시리즈 모델은 불공정하고 신뢰할 수 없거나 불쾌한 방식으로 동작할 가능성이 있습니다. 인지해야 할 제한적 동작은 다음과 같습니다:

**서비스 품질:** Phi 모델은 주로 영어 텍스트로 학습되었습니다. 영어 외 언어는 성능이 저하될 수 있습니다. 학습 데이터에서 덜 반영된 영어 변종은 표준 미국 영어보다 성능이 떨어질 수 있습니다.

**해악 재현 및 고정관념 영속:** 이 모델들은 특정 집단을 과대 또는 과소 대표하거나 일부 집단의 대표성을 지우거나 모욕적이거나 부정적인 고정관념을 강화할 수 있습니다. 안전 후 학습 후에도, 다양한 집단 대표성 차이 또는 사회적 편견을 반영하는 부정적 고정관념 사례의 학습 데이터 내 존재 때문에 여전히 제한점이 있을 수 있습니다.

**부적절하거나 불쾌한 콘텐츠:** 이 모델들은 민감한 상황에 배치하기에 부적절할 수 있는 다른 유형의 부적절하거나 불쾌한 콘텐츠를 생성할 수 있으며, 이는 특정 사용 사례에 맞춘 추가 완화 조치 없이는 적합하지 않을 수 있습니다.
정보 신뢰성: 언어 모델은 무의미하거나 그럴듯하게 들리지만 부정확하거나 오래된 정보를 생성할 수 있습니다.

**코드 범위 제한:** Phi-3 학습 데이터 대부분은 Python 기반이며 "typing, math, random, collections, datetime, itertools"와 같은 일반 패키지를 사용합니다. 모델이 다른 패키지나 타 언어 스크립트를 생성하는 경우 모든 API 사용을 수동으로 확인할 것을 강력히 권장합니다.

개발자는 책임 있는 AI 모범 사례를 적용해야 하며, 특정 사용 사례가 관련 법률 및 규정을 준수하는지(예: 개인정보, 무역 등) 책임져야 합니다. 고려해야 할 중요한 영역은 다음과 같습니다:

**배분:** 모델은 법적 지위 또는 자원 혹은 인생 기회의 배분에 중대한 영향을 미칠 수 있는 시나리오(예: 주택, 고용, 신용 등)에는 추가 평가 및 추가 편향 제거 기술 없이는 적합하지 않을 수 있습니다.

**고위험 시나리오:** 불공정하거나 신뢰할 수 없거나 불쾌한 출력이 매우 비용이 크거나 해를 끼칠 수 있는 고위험 시나리오에서 모델을 사용하는 적합 여부를 개발자가 평가해야 합니다. 이는 정확성과 신뢰성이 중요한 민감하거나 전문적인 영역(예: 법률 또는 건강 조언)에서의 조언 제공을 포함합니다. 배포 맥락에 따라 애플리케이션 수준에서 추가 안전장치가 구현되어야 합니다.

**허위 정보:** 모델은 부정확한 정보를 생성할 수 있습니다. 개발자는 투명성 모범 사례를 준수하고 최종 사용자에게 AI 시스템과 상호 작용 중임을 알리는 것이 좋습니다. 애플리케이션 수준에서는 피드백 메커니즘과 특정 사용 사례 맥락 정보를 기반으로 응답을 생성하는 파이프라인(검색 증강 생성, RAG) 구축이 가능합니다.

**유해 콘텐츠 생성:** 개발자는 출력물의 맥락을 평가하고 사용 가능한 안전 분류기 또는 해당 사용 사례에 적합한 맞춤형 솔루션을 사용해야 합니다.

**오용:** 사기, 스팸, 악성 코드 생성과 같은 다른 형태의 오용 가능성도 있으므로 개발자는 애플리케이션이 관련 법률 및 규정을 위반하지 않도록 해야 합니다.

### 미세 조정 및 AI 콘텐츠 안전

모델을 미세 조정한 후에는 [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) 조치를 활용하여 모델이 생성하는 콘텐츠를 모니터링하고 잠재적 위험, 위협 및 품질 문제를 식별 및 차단하는 것을 강력히 권장합니다.

![Phi3AISafety](../../../../../translated_images/ko/01.phi3aisafety.c0d7fc42f5a5c405.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)는 텍스트 및 이미지 콘텐츠 모두를 지원하며, 클라우드, 분리된 컨테이너, 엣지/임베디드 장치에 배포할 수 있습니다.

## Azure AI Content Safety 개요

Azure AI Content Safety는 모든 상황에 맞는 단일 솔루션이 아니며, 기업의 특정 정책에 맞게 맞춤화할 수 있습니다. 또한 다국어 모델이 다수 언어를 동시에 이해할 수 있게 합니다.

![AIContentSafety](../../../../../translated_images/ko/01.AIcontentsafety.a288819b8ce8da1a.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5 videos**

Azure AI Content Safety 서비스는 애플리케이션과 서비스 내 사용자 생성 및 AI 생성의 유해한 콘텐츠를 감지합니다. 이는 부적절하거나 유해한 콘텐츠를 탐지할 수 있는 텍스트 및 이미지 API를 포함합니다.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있으나, 자동 번역에는 오류나 부정확한 부분이 있을 수 있음을 양지해 주시기 바랍니다. 원본 문서는 해당 원어로 된 문서가 권위 있는 출처로 간주되어야 합니다. 중요한 정보의 경우 전문가에 의한 인간 번역을 권장합니다. 본 번역 사용으로 인한 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->