<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e0a07fd2a30fe2af30b1373df207a5bf",
  "translation_date": "2025-07-17T08:07:21+00:00",
  "source_file": "md/03.FineTuning/FineTuning_Phi-3-visionWandB.md",
  "language_code": "ko"
}
-->
# Phi-3-Vision-128K-Instruct 프로젝트 개요

## 모델

Phi-3-Vision-128K-Instruct는 경량화된 최첨단 멀티모달 모델로, 이 프로젝트의 핵심입니다. Phi-3 모델 패밀리의 일부이며 최대 128,000 토큰의 컨텍스트 길이를 지원합니다. 이 모델은 합성 데이터와 신중하게 필터링된 공개 웹사이트를 포함한 다양한 데이터셋으로 학습되었으며, 고품질의 추론 중심 콘텐츠에 중점을 두었습니다. 학습 과정에는 감독된 미세 조정과 직접 선호도 최적화가 포함되어 있어 지침을 정확히 따르며 강력한 안전 조치를 보장합니다.

## 샘플 데이터 생성이 중요한 이유는 다음과 같습니다:

1. **테스트**: 샘플 데이터는 실제 데이터에 영향을 주지 않고 다양한 시나리오에서 애플리케이션을 테스트할 수 있게 해줍니다. 이는 특히 개발 및 스테이징 단계에서 중요합니다.

2. **성능 조정**: 실제 데이터의 규모와 복잡성을 모방한 샘플 데이터를 통해 성능 병목 현상을 파악하고 애플리케이션을 최적화할 수 있습니다.

3. **프로토타이핑**: 샘플 데이터는 프로토타입과 목업을 만드는 데 사용되어 사용자 요구사항을 이해하고 피드백을 받는 데 도움이 됩니다.

4. **데이터 분석**: 데이터 과학에서는 탐색적 데이터 분석, 모델 학습, 알고리즘 테스트에 샘플 데이터를 자주 사용합니다.

5. **보안**: 개발 및 테스트 환경에서 샘플 데이터를 사용하면 민감한 실제 데이터의 우발적 유출을 방지할 수 있습니다.

6. **학습**: 새로운 기술이나 도구를 배우는 경우, 샘플 데이터를 활용하면 배운 내용을 실습할 수 있는 좋은 방법이 됩니다.

샘플 데이터의 품질은 이러한 활동에 큰 영향을 미칠 수 있으므로, 구조와 변동성 면에서 실제 데이터와 최대한 유사해야 합니다.

### 샘플 데이터 생성
[Generate DataSet Script](./CreatingSampleData.md)

## 데이터셋

좋은 샘플 데이터셋의 예로는 [DBQ/Burberry.Product.prices.United.States dataset](https://huggingface.co/datasets/DBQ/Burberry.Product.prices.United.States) (Huggingface에서 제공)을 들 수 있습니다.  
이 샘플 데이터셋은 Burberry 제품과 제품 카테고리, 가격, 제목에 대한 메타데이터를 포함하며 총 3,040개의 행으로 구성되어 각 행이 고유한 제품을 나타냅니다. 이 데이터셋은 모델이 시각적 데이터를 이해하고 해석하는 능력을 테스트하며, 복잡한 시각적 세부사항과 브랜드 특성을 포착하는 설명 텍스트를 생성할 수 있게 합니다.

**Note:** 이미지가 포함된 모든 데이터셋을 사용할 수 있습니다.

## 복잡한 추론

모델은 이미지 만으로 가격과 명칭에 대해 추론해야 합니다. 이는 모델이 시각적 특징을 인식하는 것뿐만 아니라, 제품 가치와 브랜드 측면에서 그 의미를 이해해야 함을 요구합니다. 이미지를 통해 정확한 텍스트 설명을 합성함으로써, 이 프로젝트는 시각적 데이터를 통합하여 실제 응용에서 모델의 성능과 다재다능성을 향상시킬 수 있는 가능성을 보여줍니다.

## Phi-3 Vision 아키텍처

모델 아키텍처는 Phi-3의 멀티모달 버전입니다. 텍스트와 이미지 데이터를 모두 처리하며, 이 입력들을 통합된 시퀀스로 결합하여 포괄적인 이해와 생성 작업을 수행합니다. 텍스트와 이미지는 각각 별도의 임베딩 레이어를 사용합니다. 텍스트 토큰은 밀집 벡터로 변환되고, 이미지는 CLIP 비전 모델을 통해 특징 임베딩을 추출합니다. 이 이미지 임베딩은 텍스트 임베딩 차원에 맞게 투영되어 원활한 통합이 가능하도록 합니다.

## 텍스트와 이미지 임베딩의 통합

텍스트 시퀀스 내의 특수 토큰은 이미지 임베딩이 삽입될 위치를 나타냅니다. 처리 과정에서 이 특수 토큰들은 해당 이미지 임베딩으로 대체되어, 모델이 텍스트와 이미지를 하나의 시퀀스로 다룰 수 있게 합니다. 데이터셋의 프롬프트는 특수 <|image|> 토큰을 사용하여 다음과 같이 포맷됩니다:

```python
text = f"<|user|>\n<|image_1|>What is shown in this image?<|end|><|assistant|>\nProduct: {row['title']}, Category: {row['category3_code']}, Full Price: {row['full_price']}<|end|>"
```

## 샘플 코드
- [Phi-3-Vision Training Script](../../../../code/03.Finetuning/Phi-3-vision-Trainingscript.py)
- [Weights and Bias Example walkthrough](https://wandb.ai/byyoung3/mlnews3/reports/How-to-fine-tune-Phi-3-vision-on-a-custom-dataset--Vmlldzo4MTEzMTg3)

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있으나, 자동 번역에는 오류나 부정확한 부분이 있을 수 있음을 유의하시기 바랍니다. 원문은 해당 언어의 원본 문서가 권위 있는 출처로 간주되어야 합니다. 중요한 정보의 경우 전문적인 인간 번역을 권장합니다. 본 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.