<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:32:04+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "tr"
}
-->
# Olive kullanarak Phi3'Ã¼ ince ayarlama

Bu Ã¶rnekte Olive'u kullanarak:

1. LoRA adaptÃ¶rÃ¼nÃ¼ ifadeleri ÃœzgÃ¼n, Mutlu, Korku, SÃ¼rpriz olarak sÄ±nÄ±flandÄ±rmak iÃ§in ince ayarlayacaksÄ±nÄ±z.  
1. AdaptÃ¶r aÄŸÄ±rlÄ±klarÄ±nÄ± temel modele birleÅŸtireceksiniz.  
1. Modeli `int4` formatÄ±nda optimize edip kuantize edeceksiniz.

AyrÄ±ca, ince ayarlanmÄ±ÅŸ modeli ONNX Runtime (ORT) Generate API ile nasÄ±l Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸiz.

> **âš ï¸ Ä°nce ayar iÃ§in uygun bir GPU'ya ihtiyacÄ±nÄ±z olacak - Ã¶rneÄŸin, A10, V100, A100 gibi.**

## ğŸ’¾ Kurulum

Yeni bir Python sanal ortamÄ± oluÅŸturun (Ã¶rneÄŸin, `conda` kullanarak):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Sonra, Olive ve ince ayar iÅŸ akÄ±ÅŸÄ± iÃ§in gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## ğŸ§ª Olive kullanarak Phi3'Ã¼ ince ayarlama
[Olive yapÄ±landÄ±rma dosyasÄ±](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) aÅŸaÄŸÄ±daki *iÅŸ akÄ±ÅŸÄ±* ve *adÄ±mlarÄ±* iÃ§erir:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

YÃ¼ksek seviyede, bu iÅŸ akÄ±ÅŸÄ± ÅŸunlarÄ± yapacak:

1. Phi3'Ã¼ [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) verisiyle (150 adÄ±m iÃ§in, deÄŸiÅŸtirilebilir) ince ayarlayacak.  
1. LoRA adaptÃ¶r aÄŸÄ±rlÄ±klarÄ±nÄ± temel modele birleÅŸtirecek. Bu size ONNX formatÄ±nda tek bir model dosyasÄ± verecek.  
1. Model Builder modeli ONNX runtime iÃ§in optimize edecek *ve* modeli `int4` formatÄ±nda kuantize edecek.

Ä°ÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
olive run --config phrase-classification.json
```

Olive tamamlandÄ±ÄŸÄ±nda, optimize edilmiÅŸ ve ince ayarlanmÄ±ÅŸ `int4` formatÄ±ndaki Phi3 modeliniz ÅŸu dizinde bulunacak: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## ğŸ§‘â€ğŸ’» Ä°nce ayarlanmÄ±ÅŸ Phi3'Ã¼ uygulamanÄ±za entegre edin

UygulamayÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Bu yanÄ±t, ifadenin tek kelimelik sÄ±nÄ±flandÄ±rmasÄ± olmalÄ±dÄ±r (Sad/Joy/Fear/Surprise).

**Feragatname**:  
Bu belge, AI Ã§eviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu oluÅŸabilecek yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.