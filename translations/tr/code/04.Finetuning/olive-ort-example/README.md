<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:45:07+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "tr"
}
-->
# Olive kullanarak Phi3'Ã¼ ince ayarlama

Bu Ã¶rnekte Olive'Ä± kullanarak:

1. LoRA adaptÃ¶rÃ¼nÃ¼ cÃ¼mleleri ÃœzgÃ¼n, NeÅŸeli, Korku, ÅaÅŸkÄ±n olarak sÄ±nÄ±flandÄ±rmak iÃ§in ince ayarlayacaksÄ±nÄ±z.  
1. AdaptÃ¶r aÄŸÄ±rlÄ±klarÄ±nÄ± temel modele birleÅŸtireceksiniz.  
1. Modeli `int4` formatÄ±nda optimize edip kuantize edeceksiniz.  

AyrÄ±ca, ONNX Runtime (ORT) Generate API kullanarak ince ayarlanmÄ±ÅŸ modeli nasÄ±l Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸiz.

> **âš ï¸ Ä°nce ayar iÃ§in uygun bir GPUâ€™ya ihtiyacÄ±nÄ±z olacak - Ã¶rneÄŸin, A10, V100, A100.**

## ğŸ’¾ Kurulum

Yeni bir Python sanal ortamÄ± oluÅŸturun (Ã¶rneÄŸin, `conda` kullanarak):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Sonra, Olive ve ince ayar iÅŸ akÄ±ÅŸÄ± iÃ§in gereken baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## ğŸ§ª Olive kullanarak Phi3'Ã¼ ince ayarlama  
[Olive yapÄ±landÄ±rma dosyasÄ±](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) ÅŸu *iÅŸ akÄ±ÅŸÄ±* ve *adÄ±mlarÄ±* iÃ§erir:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

YÃ¼ksek seviyede, bu iÅŸ akÄ±ÅŸÄ± ÅŸunlarÄ± yapacak:

1. Phi3'Ã¼ (150 adÄ±m boyunca, deÄŸiÅŸtirilebilir) [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json) verisiyle ince ayarlayacak.  
1. LoRA adaptÃ¶r aÄŸÄ±rlÄ±klarÄ±nÄ± temel modele birleÅŸtirecek. BÃ¶ylece ONNX formatÄ±nda tek bir model dosyanÄ±z olacak.  
1. Model Builder, modeli ONNX runtime iÃ§in optimize edecek *ve* modeli `int4` formatÄ±nda kuantize edecek.  

Ä°ÅŸ akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
olive run --config phrase-classification.json
```

Olive tamamlandÄ±ÄŸÄ±nda, optimize edilmiÅŸ `int4` formatÄ±ndaki ince ayarlÄ± Phi3 modeliniz ÅŸu dizinde hazÄ±r olacak: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## ğŸ§‘â€ğŸ’» Ä°nce ayarlÄ± Phi3'Ã¼ uygulamanÄ±za entegre edin

UygulamayÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Bu yanÄ±t, cÃ¼mlenin tek kelimelik sÄ±nÄ±flandÄ±rmasÄ± olmalÄ±dÄ±r (Sad/Joy/Fear/Surprise).

**Feragatname**:  
Bu belge, AI Ã§eviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba sarf etsek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, kendi ana dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucunda oluÅŸabilecek yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.