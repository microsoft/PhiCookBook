<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-07-16T17:47:52+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "tr"
}
-->
# Phi modelleri için Yapay Zeka güvenliği  
Phi model ailesi, [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) doğrultusunda geliştirilmiştir. Bu standart, şirket genelinde geçerli olan ve hesap verebilirlik, şeffaflık, adalet, güvenilirlik ve güvenlik, gizlilik ve güvenlik ile kapsayıcılık olmak üzere altı temel ilkeye dayanan gereksinimlerden oluşur ve [Microsoft’un Sorumlu Yapay Zeka ilkelerini](https://www.microsoft.com/ai/responsible-ai) oluşturur.  

Önceki Phi modellerinde olduğu gibi, çok yönlü bir güvenlik değerlendirmesi ve eğitim sonrası güvenlik yaklaşımı benimsenmiş, bu sürümün çok dilli yetenekleri göz önünde bulundurularak ek önlemler alınmıştır. Çoklu dil ve risk kategorilerinde testleri içeren güvenlik eğitimi ve değerlendirme yaklaşımımız [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833) belgesinde özetlenmiştir. Phi modelleri bu yaklaşımdan faydalansa da, geliştiricilerin kendi kullanım senaryoları ile kültürel ve dilsel bağlamlarına özgü riskleri haritalandırmaları, ölçmeleri ve azaltmaları dahil olmak üzere sorumlu yapay zeka en iyi uygulamalarını uygulamaları gerekmektedir.  

## En İyi Uygulamalar  

Diğer modellerde olduğu gibi, Phi model ailesi de haksız, güvenilmez veya rahatsız edici davranışlar sergileyebilir.  

SLM ve LLM’nin farkında olunması gereken bazı sınırlayıcı davranışları şunlardır:  

- **Hizmet Kalitesi:** Phi modelleri öncelikle İngilizce metinler üzerinde eğitilmiştir. İngilizce dışındaki dillerde performans daha düşük olabilir. Eğitim verilerinde daha az temsil edilen İngilizce dil çeşitleri, standart Amerikan İngilizcesine kıyasla daha kötü performans gösterebilir.  
- **Zararların Temsili ve Stereotiplerin Sürdürülmesi:** Bu modeller bazı insan gruplarını aşırı veya yetersiz temsil edebilir, bazı grupların temsilini yok sayabilir veya aşağılayıcı ya da olumsuz stereotipleri pekiştirebilir. Güvenlik sonrası eğitim yapılmış olsa da, farklı grupların temsil düzeylerindeki farklılıklar veya eğitim verilerindeki olumsuz stereotip örneklerinin gerçek dünya kalıplarını ve toplumsal önyargıları yansıtması nedeniyle bu sınırlamalar devam edebilir.  
- **Uygunsuz veya Rahatsız Edici İçerik:** Bu modeller, kullanım senaryosuna özgü ek önlemler olmadan hassas bağlamlarda kullanımı uygun olmayan başka tür uygunsuz veya rahatsız edici içerikler üretebilir.  
- **Bilgi Güvenilirliği:** Dil modelleri anlamsız içerik oluşturabilir veya mantıklı gibi görünen ancak yanlış ya da güncel olmayan içerikler uydurabilir.  
- **Kod İçin Sınırlı Kapsam:** Phi-3 eğitim verilerinin çoğunluğu Python tabanlıdır ve "typing, math, random, collections, datetime, itertools" gibi yaygın paketleri kullanır. Model, başka paketler kullanan Python betikleri veya diğer dillerde betikler oluşturursa, kullanıcıların tüm API kullanımlarını manuel olarak doğrulamalarını şiddetle tavsiye ederiz.  

Geliştiriciler sorumlu yapay zeka en iyi uygulamalarını uygulamalı ve belirli kullanım senaryosunun ilgili yasa ve düzenlemelere (örneğin gizlilik, ticaret vb.) uygunluğunu sağlamaktan sorumludur.  

## Sorumlu Yapay Zeka Dikkat Edilmesi Gerekenler  

Diğer dil modellerinde olduğu gibi, Phi serisi modeller de haksız, güvenilmez veya rahatsız edici davranışlar sergileyebilir. Dikkat edilmesi gereken bazı sınırlayıcı davranışlar şunlardır:  

**Hizmet Kalitesi:** Phi modelleri öncelikle İngilizce metinler üzerinde eğitilmiştir. İngilizce dışındaki dillerde performans daha düşük olabilir. Eğitim verilerinde daha az temsil edilen İngilizce dil çeşitleri, standart Amerikan İngilizcesine kıyasla daha kötü performans gösterebilir.  

**Zararların Temsili ve Stereotiplerin Sürdürülmesi:** Bu modeller bazı insan gruplarını aşırı veya yetersiz temsil edebilir, bazı grupların temsilini yok sayabilir veya aşağılayıcı ya da olumsuz stereotipleri pekiştirebilir. Güvenlik sonrası eğitim yapılmış olsa da, farklı grupların temsil düzeylerindeki farklılıklar veya eğitim verilerindeki olumsuz stereotip örneklerinin gerçek dünya kalıplarını ve toplumsal önyargıları yansıtması nedeniyle bu sınırlamalar devam edebilir.  

**Uygunsuz veya Rahatsız Edici İçerik:** Bu modeller, kullanım senaryosuna özgü ek önlemler olmadan hassas bağlamlarda kullanımı uygun olmayan başka tür uygunsuz veya rahatsız edici içerikler üretebilir.  
Bilgi Güvenilirliği: Dil modelleri anlamsız içerik oluşturabilir veya mantıklı gibi görünen ancak yanlış ya da güncel olmayan içerikler uydurabilir.  

**Kod İçin Sınırlı Kapsam:** Phi-3 eğitim verilerinin çoğunluğu Python tabanlıdır ve "typing, math, random, collections, datetime, itertools" gibi yaygın paketleri kullanır. Model, başka paketler kullanan Python betikleri veya diğer dillerde betikler oluşturursa, kullanıcıların tüm API kullanımlarını manuel olarak doğrulamalarını şiddetle tavsiye ederiz.  

Geliştiriciler sorumlu yapay zeka en iyi uygulamalarını uygulamalı ve belirli kullanım senaryosunun ilgili yasa ve düzenlemelere (örneğin gizlilik, ticaret vb.) uygunluğunu sağlamaktan sorumludur. Dikkat edilmesi gereken önemli alanlar şunlardır:  

**Tahsis:** Modeller, yasal statü veya kaynakların ya da yaşam fırsatlarının tahsisi üzerinde önemli etkisi olabilecek senaryolar için uygun olmayabilir (örneğin: konut, istihdam, kredi vb.) ve bu tür durumlarda ek değerlendirmeler ve önyargı azaltma teknikleri gereklidir.  

**Yüksek Riskli Senaryolar:** Geliştiriciler, haksız, güvenilmez veya rahatsız edici çıktılarının çok maliyetli veya zararlı olabileceği yüksek riskli senaryolarda modellerin kullanım uygunluğunu değerlendirmelidir. Bu, doğruluk ve güvenilirliğin kritik olduğu hassas veya uzman alanlarda (örneğin: hukuki veya sağlık danışmanlığı) tavsiye verilmesini içerir. Uygulama düzeyinde, dağıtım bağlamına göre ek güvenlik önlemleri uygulanmalıdır.  

**Yanlış Bilgi:** Modeller yanlış bilgi üretebilir. Geliştiriciler şeffaflık en iyi uygulamalarını takip etmeli ve son kullanıcıları bir yapay zeka sistemiyle etkileşimde oldukları konusunda bilgilendirmelidir. Uygulama düzeyinde, geliştiriciler geri bildirim mekanizmaları ve yanıtları kullanım senaryosuna özgü, bağlamsal bilgilerle destekleyen boru hatları oluşturabilir; bu teknik Retrieval Augmented Generation (RAG) olarak bilinir.  

**Zararlı İçerik Üretimi:** Geliştiriciler, çıktıları bağlamlarına göre değerlendirmeli ve kullanım senaryolarına uygun mevcut güvenlik sınıflandırıcıları veya özel çözümleri kullanmalıdır.  

**Kötüye Kullanım:** Dolandırıcılık, spam veya kötü amaçlı yazılım üretimi gibi diğer kötüye kullanım biçimleri mümkün olabilir ve geliştiriciler uygulamalarının geçerli yasa ve düzenlemelere aykırı olmadığından emin olmalıdır.  

### İnce Ayar ve Yapay Zeka İçerik Güvenliği  

Bir modeli ince ayar yaptıktan sonra, modeller tarafından oluşturulan içeriği izlemek, potansiyel riskleri, tehditleri ve kalite sorunlarını tespit etmek ve engellemek için [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) önlemlerini kullanmanızı şiddetle tavsiye ederiz.  

![Phi3AISafety](../../../../../translated_images/01.phi3aisafety.c0d7fc42f5a5c40507c5e8be556615b8377a63b8764865d057d4faac3757a478.tr.png)  

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) hem metin hem de görsel içerikleri destekler. Bulutta, bağlantısız konteynerlerde ve uç/gömülü cihazlarda dağıtılabilir.  

## Azure AI Content Safety Genel Bakış  

Azure AI Content Safety tek tip bir çözüm değildir; işletmelerin özel politikalarına uyacak şekilde özelleştirilebilir. Ayrıca, çok dilli modelleri sayesinde birden fazla dili aynı anda anlayabilir.  

![AIContentSafety](../../../../../translated_images/01.AIcontentsafety.a288819b8ce8da1a56cf708aff010a541799d002ae7ae84bb819b19ab8950591.tr.png)  

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5 video**  

Azure AI Content Safety servisi, uygulamalarda ve hizmetlerde zararlı kullanıcı ve yapay zeka tarafından oluşturulan içerikleri tespit eder. Zararlı veya uygunsuz materyalleri tespit etmeye olanak tanıyan metin ve görsel API’lerini içerir.  

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**Feragatname**:  
Bu belge, AI çeviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hatalar veya yanlışlıklar içerebileceğini lütfen unutmayınız. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımı sonucu oluşabilecek yanlış anlamalar veya yorum hatalarından sorumlu değiliz.