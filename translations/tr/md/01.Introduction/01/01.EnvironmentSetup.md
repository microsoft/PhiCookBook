<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:07:57+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "tr"
}
-->
# Phi-3 ile Yerel Başlangıç

Bu rehber, Phi-3 modelini Ollama kullanarak çalıştırmak için yerel ortamınızı kurmanıza yardımcı olacak. Modeli GitHub Codespaces, VS Code Dev Containers veya yerel ortamınızda çalıştırmanın birkaç farklı yolu vardır.

## Ortam Kurulumu

### GitHub Codespaces

Bu şablonu GitHub Codespaces kullanarak sanal olarak çalıştırabilirsiniz. Buton, tarayıcınızda web tabanlı bir VS Code örneği açacaktır:

1. Şablonu açın (bu birkaç dakika sürebilir):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Bir terminal penceresi açın

### VS Code Dev Containers

⚠️ Bu seçenek, Docker Desktop'unuzda en az 16 GB RAM ayrılmışsa çalışır. 16 GB'den az RAM'iniz varsa, [GitHub Codespaces seçeneğini](../../../../../md/01.Introduction/01) deneyebilir veya [yerel olarak kurabilirsiniz](../../../../../md/01.Introduction/01).

İlgili bir seçenek de VS Code Dev Containers'dır; bu, projeyi yerel VS Code'unuzda [Dev Containers uzantısı](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) kullanarak açacaktır:

1. Docker Desktop'u başlatın (yüklü değilse kurun)
2. Projeyi açın:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Açılan VS Code penceresinde, proje dosyaları göründüğünde (bu birkaç dakika sürebilir) bir terminal penceresi açın.
4. [Dağıtım adımları](../../../../../md/01.Introduction/01) ile devam edin

### Yerel Ortam

1. Aşağıdaki araçların yüklü olduğundan emin olun:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Modeli Test Etme

1. Ollama'dan phi3:mini modelini indirip çalıştırmasını isteyin:

    ```shell
    ollama run phi3:mini
    ```

    Modelin indirilmesi birkaç dakika sürecektir.

2. Çıktıda "success" gördüğünüzde, prompt'tan bu modele mesaj gönderebilirsiniz.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Birkaç saniye sonra modelden bir yanıt akışı görmelisiniz.

4. Dil modelleriyle kullanılan farklı teknikleri öğrenmek için Python defterini [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) açın ve her hücreyi çalıştırın. 'phi3:mini' dışındaki bir modeli kullandıysanız, dosyanın en üstündeki `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` değerini gerektiği şekilde değiştirin; ayrıca sistem mesajını değiştirebilir veya isterseniz few-shot örnekleri ekleyebilirsiniz.

**Feragatname**:  
Bu belge, AI çeviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba gösterilse de, otomatik çevirilerin hatalar veya yanlışlıklar içerebileceğini lütfen unutmayınız. Orijinal belge, kendi ana dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımı sonucu oluşabilecek yanlış anlamalar veya yorumlamalardan dolayı sorumluluk kabul edilmemektedir.