# Phi-3 ile yerel olarak başlayın

Bu rehber, Phi-3 modelini Ollama kullanarak çalıştırmak için yerel ortamınızı nasıl kuracağınızı gösterecek. Modeli GitHub Codespaces, VS Code Dev Containers veya yerel ortamınızda olmak üzere birkaç farklı şekilde çalıştırabilirsiniz.

## Ortam kurulumu

### GitHub Codespaces

Bu şablonu GitHub Codespaces kullanarak sanal olarak çalıştırabilirsiniz. Buton, tarayıcınızda web tabanlı bir VS Code örneği açacaktır:

1. Şablonu açın (bu birkaç dakika sürebilir):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Bir terminal penceresi açın

### VS Code Dev Containers

⚠️ Bu seçenek, Docker Desktop’unuzda en az 16 GB RAM ayrılmışsa çalışır. Eğer 16 GB’dan az RAM’iniz varsa, [GitHub Codespaces seçeneğini](../../../../../md/01.Introduction/01) deneyebilir veya [yerel ortamda kurulum yapabilirsiniz](../../../../../md/01.Introduction/01).

İlgili bir seçenek de VS Code Dev Containers’dır; bu, projeyi yerel VS Code’unuzda [Dev Containers eklentisi](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) ile açar:

1. Docker Desktop’u başlatın (henüz kurulu değilse kurun)
2. Projeyi açın:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Açılan VS Code penceresinde, proje dosyaları göründüğünde (bu birkaç dakika sürebilir) bir terminal penceresi açın.
4. [Dağıtım adımlarıyla](../../../../../md/01.Introduction/01) devam edin

### Yerel Ortam

1. Aşağıdaki araçların kurulu olduğundan emin olun:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Modeli test edin

1. Ollama’dan phi3:mini modelini indirip çalıştırmasını isteyin:

    ```shell
    ollama run phi3:mini
    ```

    Modelin indirilmesi birkaç dakika sürecektir.

2. Çıktıda "success" gördüğünüzde, o modelle prompt üzerinden mesaj gönderebilirsiniz.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Birkaç saniye sonra modelden bir yanıt akışı görmelisiniz.

4. Dil modelleriyle kullanılan farklı teknikleri öğrenmek için Python not defteri [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) dosyasını açın ve her hücreyi çalıştırın. 'phi3:mini' dışında bir model kullandıysanız, ilk hücredeki `MODEL_NAME` değerini değiştirin.

5. Python’dan phi3:mini modeliyle sohbet etmek için Python dosyası [chat.py](../../../../../code/01.Introduce/chat.py) dosyasını açın ve çalıştırın. Dosyanın en üstündeki `MODEL_NAME` değerini ihtiyacınıza göre değiştirebilir, sistem mesajını veya few-shot örneklerini de ekleyebilirsiniz.

**Feragatname**:  
Bu belge, AI çeviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hatalar veya yanlışlıklar içerebileceğini lütfen unutmayın. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımı sonucu ortaya çıkabilecek yanlış anlamalar veya yorum hatalarından sorumlu değiliz.