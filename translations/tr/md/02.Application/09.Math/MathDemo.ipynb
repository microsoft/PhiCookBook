{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e7ac41",
   "metadata": {},
   "source": [
    "## Gerekli Kütüphaneleri İçe Aktar  \n",
    "Phi-4 modelini yüklemek ve kullanmak için gereken PyTorch ve transformers kütüphanelerini içe aktarın.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6caaf7",
   "metadata": {},
   "source": [
    "## Rastgele Tohum Ayarla\n",
    "Farklı çalışmalarda tekrarlanabilir sonuçlar elde etmek için rastgele tohumu ayarlayın.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ce6d9",
   "metadata": {},
   "source": [
    "## Phi-4-mini-flash-reasoning Model ve Tokenizer'ı Yükleme\n",
    "Microsoft Phi-4-mini-flash-reasoning modelini ve buna karşılık gelen tokenizer'ı Hugging Face'den yükleyin. Model, daha hızlı çıkarım için CUDA üzerinde yüklenecek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-4-mini-flash-reasoning\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"cuda\",\n",
    "   torch_dtype=\"auto\",\n",
    "   trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8789ea8",
   "metadata": {},
   "source": [
    "## Giriş Mesajını Hazırlayın\n",
    "Model için sohbet şablonunu kullanarak bir ikinci dereceden denklem matematik problemi içeren bir konuşma mesajı oluşturun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "   \"role\": \"user\",\n",
    "   \"content\": \"How to solve 3*x^2+4*x+5=1?\"\n",
    "}]   \n",
    "inputs = tokenizer.apply_chat_template(\n",
    "   messages,\n",
    "   add_generation_prompt=True,\n",
    "   return_dict=True,\n",
    "   return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b87bf8",
   "metadata": {},
   "source": [
    "## Yanıt Oluşturma\n",
    "Modelden, çıktının rastgeleliğini kontrol etmek için sıcaklık ve top_p gibi belirli parametreler kullanılarak bir yanıt oluşturun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "   **inputs.to(model.device),\n",
    "   max_new_tokens=32768,\n",
    "   temperature=0.6,\n",
    "   top_p=0.95,\n",
    "   do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088f0d",
   "metadata": {},
   "source": [
    "## Çıktıyı Metne Çevir\n",
    "Oluşturulan token dizilerini insan tarafından okunabilir metne geri çevirin, yalnızca modelin yanıtını göstermek için orijinal giriş tokenlerini hariç tutun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Feragatname**:  \nBu belge, AI çeviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hata veya yanlışlık içerebileceğini lütfen unutmayın. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından kaynaklanan yanlış anlamalar veya yanlış yorumlamalar için sorumluluk kabul etmiyoruz.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "93d4d22a7a9ec7e7e668474526477813",
   "translation_date": "2025-09-12T18:51:11+00:00",
   "source_file": "md/02.Application/09.Math/MathDemo.ipynb",
   "language_code": "tr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}