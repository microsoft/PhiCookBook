<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c4fe7f589d179be96a5577b0b8cba6aa",
  "translation_date": "2025-05-09T18:48:42+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md",
  "language_code": "tr"
}
-->
# **Microsoft Phi-3.5 tflite kullanarak Android uygulamasÄ± oluÅŸturma**

Bu, Microsoft Phi-3.5 tflite modellerini kullanan bir Android Ã¶rneÄŸidir.

## **ğŸ“š Bilgi**

Android LLM Inference API, Android uygulamalarÄ± iÃ§in bÃ¼yÃ¼k dil modellerini (LLM) tamamen cihaz Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r. Bu sayede metin oluÅŸturma, doÄŸal dil biÃ§iminde bilgi alma ve belgeleri Ã¶zetleme gibi Ã§eÅŸitli gÃ¶revleri gerÃ§ekleÅŸtirebilirsiniz. Bu gÃ¶rev, birden fazla metin-temelli bÃ¼yÃ¼k dil modelini destekler, bÃ¶ylece en yeni cihaz Ã¼zeri Ã¼retken yapay zeka modellerini Android uygulamalarÄ±nÄ±za uygulayabilirsiniz.

Googld AI Edge Torch, PyTorch modellerini .tflite formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmeyi destekleyen bir Python kÃ¼tÃ¼phanesidir ve bu modeller TensorFlow Lite ve MediaPipe ile Ã§alÄ±ÅŸtÄ±rÄ±labilir. Bu sayede Android, iOS ve IoT uygulamalarÄ± iÃ§in modeller tamamen cihaz Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±labilir. AI Edge Torch geniÅŸ CPU desteÄŸi sunar ve baÅŸlangÄ±Ã§ta GPU ile NPU desteÄŸi saÄŸlar. AI Edge Torch, torch.export() Ã¼zerine inÅŸa edilerek PyTorch ile sÄ±kÄ± entegrasyon hedefler ve Core ATen operatÃ¶rlerinin iyi bir kapsamÄ±nÄ± saÄŸlar.

## **ğŸª¬ KÄ±lavuz**

### **ğŸ”¥ Microsoft Phi-3.5â€™i tflite formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme**

0. Bu Ã¶rnek Android 14+ iÃ§indir.

1. Python 3.10.12 yÃ¼kleyin

***Ã–neri:*** Python ortamÄ±nÄ±zÄ± kurmak iÃ§in conda kullanÄ±n

2. Ubuntu 20.04 / 22.04 (lÃ¼tfen [google ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch) projesine odaklanÄ±n)

***Ã–neri:*** OrtamÄ±nÄ±zÄ± oluÅŸturmak iÃ§in Azure Linux VM veya 3. taraf bulut VM kullanÄ±n

3. Linux bashâ€™inize gidin ve Python kÃ¼tÃ¼phanesini yÃ¼kleyin

```bash

git clone https://github.com/google-ai-edge/ai-edge-torch.git

cd ai-edge-torch

pip install -r requirements.txt -U 

pip install tensorflow-cpu -U

pip install -e .

```

4. Hugging faceâ€™den Microsoft-3.5-Instruct modelini indirin

```bash

git lfs install

git clone  https://huggingface.co/microsoft/Phi-3.5-mini-instruct

```

5. Microsoft Phi-3.5â€™i tflite formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n

```bash

python ai-edge-torch/ai_edge_torch/generative/examples/phi/convert_phi3_to_tflite.py --checkpoint_path  Your Microsoft Phi-3.5-mini-instruct path --tflite_path Your Microsoft Phi-3.5-mini-instruct tflite path  --prefill_seq_len 1024 --kv_cache_max_len 1280 --quantize True

```

### **ğŸ”¥ Microsoft Phi-3.5â€™i Android Mediapipe Paketine dÃ¶nÃ¼ÅŸtÃ¼rme**

LÃ¼tfen Ã¶ncelikle mediapipeâ€™i kurun

```bash

pip install mediapipe

```

Bu kodu [notebookâ€™unuzda](../../../../../../code/09.UpdateSamples/Aug/Android/convert/convert_phi.ipynb) Ã§alÄ±ÅŸtÄ±rÄ±n

```python

import mediapipe as mp
from mediapipe.tasks.python.genai import bundler

config = bundler.BundleConfig(
    tflite_model='Your Phi-3.5 tflite model path',
    tokenizer_model='Your Phi-3.5 tokenizer model path',
    start_token='start_token',
    stop_tokens=[STOP_TOKENS],
    output_filename='Your Phi-3.5 task model path',
    enable_bytes_to_unicode_mapping=True or Flase,
)
bundler.create_bundle(config)

```

### **ğŸ”¥ adb push ile model dosyasÄ±nÄ± Android cihazÄ±nÄ±zÄ±n yoluna gÃ¶nderme**

```bash

adb shell rm -r /data/local/tmp/llm/ # Remove any previously loaded models

adb shell mkdir -p /data/local/tmp/llm/

adb push 'Your Phi-3.5 task model path' /data/local/tmp/llm/phi3.task

```

### **ğŸ”¥ Android kodunuzu Ã§alÄ±ÅŸtÄ±rma**

![demo](../../../../../../translated_images/demo.8981711efb5a9cee5dcd835f66b3b31b94b4f3e527300e15a98a0d48863b9fbd.tr.png)

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba sarf etsek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, kendi ana dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu oluÅŸabilecek yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.