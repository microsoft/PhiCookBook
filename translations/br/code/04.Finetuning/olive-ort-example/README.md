<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:44:45+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "br"
}
-->
# Fine-tune Phi3 use Olive

En este ejemplo usar√°s Olive para:

1. Ajustar un adaptador LoRA para clasificar frases en Tristeza, Alegr√≠a, Miedo, Sorpresa.  
1. Fusionar los pesos del adaptador en el modelo base.  
1. Optimizar y cuantizar el modelo en `int4`.

Tambi√©n te mostraremos c√≥mo inferir el modelo ajustado usando la API Generate de ONNX Runtime (ORT).

> **‚ö†Ô∏è Para el ajuste fino, necesitar√°s una GPU adecuada disponible, por ejemplo, una A10, V100, A100.**

## üíæ Instalaci√≥n

Crea un nuevo entorno virtual de Python (por ejemplo, usando `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Luego, instala Olive y las dependencias para un flujo de trabajo de ajuste fino:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Ajustar Phi3 usando Olive
El [archivo de configuraci√≥n de Olive](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) contiene un *workflow* con las siguientes *pasadas*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

A grandes rasgos, este workflow har√°:

1. Ajustar Phi3 (por 150 pasos, que puedes modificar) usando los datos de [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).  
1. Fusionar los pesos del adaptador LoRA en el modelo base. Esto te dar√° un √∫nico artefacto de modelo en formato ONNX.  
1. Model Builder optimizar√° el modelo para ONNX Runtime *y* cuantizar√° el modelo en `int4`.

Para ejecutar el workflow, corre:

```bash
olive run --config phrase-classification.json
```

Cuando Olive termine, tu modelo ajustado optimizado `int4` estar√° disponible en: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Integra Phi3 ajustado en tu aplicaci√≥n

Para ejecutar la app:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

La respuesta debe ser una clasificaci√≥n de una sola palabra para la frase (Sad/Joy/Fear/Surprise).

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, por favor, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.