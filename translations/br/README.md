<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a73c59eecd7ad4ec494fd4333a29e208",
  "translation_date": "2025-10-11T10:52:52+00:00",
  "source_file": "README.md",
  "language_code": "br"
}
-->
# Phi Cookbook: Exemplos Pr√°ticos com os Modelos Phi da Microsoft

[![Abrir e usar os exemplos no GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phicookbook)
[![Abrir em Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook)

[![Contribuidores do GitHub](https://img.shields.io/github/contributors/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)
[![Problemas no GitHub](https://img.shields.io/github/issues/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)
[![Pull Requests no GitHub](https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)
[![PRs Bem-vindos](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![Observadores no GitHub](https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)
[![Forks no GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
[![Estrelas no GitHub](https://img.shields.io/github/stars/microsoft/phicookbook?style=social&label=Star)](https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Phi √© uma s√©rie de modelos de IA de c√≥digo aberto desenvolvidos pela Microsoft.

Atualmente, Phi √© o modelo de linguagem pequeno (SLM) mais poderoso e econ√¥mico, com benchmarks excelentes em cen√°rios de m√∫ltiplos idiomas, racioc√≠nio, gera√ß√£o de texto/chat, codifica√ß√£o, imagens, √°udio e outros.

Voc√™ pode implantar Phi na nuvem ou em dispositivos de borda e construir facilmente aplica√ß√µes de IA generativa com poder computacional limitado.

Siga estas etapas para come√ßar a usar este recurso:
1. **Fa√ßa um Fork do Reposit√≥rio**: Clique [![Forks no GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
2. **Clone o Reposit√≥rio**: `git clone https://github.com/microsoft/PhiCookBook.git`
3. [**Junte-se √† Comunidade Microsoft AI Discord e conhe√ßa especialistas e outros desenvolvedores**](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

![capa](../../imgs/cover.png)

### üåê Suporte a M√∫ltiplos Idiomas

#### Suporte via GitHub Action (Automatizado e Sempre Atualizado)

<!-- CO-OP TRANSLATOR LANGUAGES TABLE START -->
[√Årabe](../ar/README.md) | [Bengali](../bn/README.md) | [B√∫lgaro](../bg/README.md) | [Birman√™s (Myanmar)](../my/README.md) | [Chin√™s (Simplificado)](../zh/README.md) | [Chin√™s (Tradicional, Hong Kong)](../hk/README.md) | [Chin√™s (Tradicional, Macau)](../mo/README.md) | [Chin√™s (Tradicional, Taiwan)](../tw/README.md) | [Croata](../hr/README.md) | [Tcheco](../cs/README.md) | [Dinamarqu√™s](../da/README.md) | [Holand√™s](../nl/README.md) | [Estoniano](../et/README.md) | [Finland√™s](../fi/README.md) | [Franc√™s](../fr/README.md) | [Alem√£o](../de/README.md) | [Grego](../el/README.md) | [Hebraico](../he/README.md) | [Hindi](../hi/README.md) | [H√∫ngaro](../hu/README.md) | [Indon√©sio](../id/README.md) | [Italiano](../it/README.md) | [Japon√™s](../ja/README.md) | [Coreano](../ko/README.md) | [Lituano](../lt/README.md) | [Malaio](../ms/README.md) | [Marathi](../mr/README.md) | [Nepal√™s](../ne/README.md) | [Noruegu√™s](../no/README.md) | [Persa (Farsi)](../fa/README.md) | [Polon√™s](../pl/README.md) | [Portugu√™s (Brasil)](./README.md) | [Portugu√™s (Portugal)](../pt/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Romeno](../ro/README.md) | [Russo](../ru/README.md) | [S√©rvio (Cir√≠lico)](../sr/README.md) | [Eslovaco](../sk/README.md) | [Esloveno](../sl/README.md) | [Espanhol](../es/README.md) | [Sua√≠li](../sw/README.md) | [Sueco](../sv/README.md) | [Tagalo (Filipino)](../tl/README.md) | [T√¢mil](../ta/README.md) | [Tailand√™s](../th/README.md) | [Turco](../tr/README.md) | [Ucraniano](../uk/README.md) | [Urdu](../ur/README.md) | [Vietnamita](../vi/README.md)
<!-- CO-OP TRANSLATOR LANGUAGES TABLE END -->

## √çndice

- Introdu√ß√£o
  - [Bem-vindo √† Fam√≠lia Phi](./md/01.Introduction/01/01.PhiFamily.md)
  - [Configurando seu ambiente](./md/01.Introduction/01/01.EnvironmentSetup.md)
  - [Entendendo as Tecnologias Principais](./md/01.Introduction/01/01.Understandingtech.md)
  - [Seguran√ßa em IA para Modelos Phi](./md/01.Introduction/01/01.AISafety.md)
  - [Suporte de Hardware para Phi](./md/01.Introduction/01/01.Hardwaresupport.md)
  - [Modelos Phi e Disponibilidade em Plataformas](./md/01.Introduction/01/01.Edgeandcloud.md)
  - [Usando Guidance-ai e Phi](./md/01.Introduction/01/01.Guidance.md)
  - [Modelos no GitHub Marketplace](https://github.com/marketplace/models)
  - [Cat√°logo de Modelos Azure AI](https://ai.azure.com)

- Infer√™ncia Phi em diferentes ambientes
    - [Hugging Face](./md/01.Introduction/02/01.HF.md)
    - [Modelos do GitHub](./md/01.Introduction/02/02.GitHubModel.md)
    - [Cat√°logo de Modelos Azure AI Foundry](./md/01.Introduction/02/03.AzureAIFoundry.md)
    - [Ollama](./md/01.Introduction/02/04.Ollama.md)
    - [AI Toolkit VSCode (AITK)](./md/01.Introduction/02/05.AITK.md)
    - [NVIDIA NIM](./md/01.Introduction/02/06.NVIDIA.md)
    - [Foundry Local](./md/01.Introduction/02/07.FoundryLocal.md)

- Infer√™ncia Fam√≠lia Phi
    - [Infer√™ncia Phi no iOS](./md/01.Introduction/03/iOS_Inference.md)
    - [Infer√™ncia Phi no Android](./md/01.Introduction/03/Android_Inference.md)
    - [Infer√™ncia Phi no Jetson](./md/01.Introduction/03/Jetson_Inference.md)
    - [Infer√™ncia Phi em PC de IA](./md/01.Introduction/03/AIPC_Inference.md)
    - [Infer√™ncia Phi com Apple MLX Framework](./md/01.Introduction/03/MLX_Inference.md)
    - [Infer√™ncia Phi em Servidor Local](./md/01.Introduction/03/Local_Server_Inference.md)
    - [Infer√™ncia Phi em Servidor Remoto usando AI Toolkit](./md/01.Introduction/03/Remote_Interence.md)
    - [Infer√™ncia Phi com Rust](./md/01.Introduction/03/Rust_Inference.md)
    - [Infer√™ncia Phi--Vision Localmente](./md/01.Introduction/03/Vision_Inference.md)
    - [Infer√™ncia Phi com Kaito AKS, Azure Containers (suporte oficial)](./md/01.Introduction/03/Kaito_Inference.md)
- [Quantificando Fam√≠lia Phi](./md/01.Introduction/04/QuantifyingPhi.md)
    - [Quantificando Phi-3.5 / 4 usando llama.cpp](./md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md)
    - [Quantificando Phi-3.5 / 4 usando extens√µes de IA generativa para onnxruntime](./md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md)
    - [Quantificando Phi-3.5 / 4 usando Intel OpenVINO](./md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md)
    - [Quantificando Phi-3.5 / 4 usando Apple MLX Framework](./md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md)

- Avalia√ß√£o Phi
    - [IA Respons√°vel](./md/01.Introduction/05/ResponsibleAI.md)
    - [Azure AI Foundry para Avalia√ß√£o](./md/01.Introduction/05/AIFoundry.md)
    - [Usando Promptflow para Avalia√ß√£o](./md/01.Introduction/05/Promptflow.md)

- RAG com Azure AI Search
    - [Como usar Phi-4-mini e Phi-4-multimodal (RAG) com Azure AI Search](https://github.com/microsoft/PhiCookBook/blob/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb)

- Exemplos de desenvolvimento de aplica√ß√µes Phi
  - Aplica√ß√µes de Texto e Chat
    - Exemplos Phi-4 üÜï
      - [üìì] [Chat com o Modelo Phi-4-mini ONNX](./md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md)
      - [Chat com o Modelo Phi-4 local ONNX .NET](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime)
      - [Aplicativo de Console .NET com Phi-4 ONNX usando Semantic Kernel](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK)
    - Exemplos Phi-3 / 3.5
      - [Chatbot Local no navegador usando Phi3, ONNX Runtime Web e WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)
      - [Chat OpenVino](./md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md)
      - [Multi Modelo - Interativo Phi-3-mini e OpenAI Whisper](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md)
      - [MLFlow - Construindo um wrapper e usando Phi-3 com MLFlow](./md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md)
      - [Otimiza√ß√£o de Modelo - Como otimizar o modelo Phi-3-min para ONNX Runtime Web com Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)
- [WinUI3 App com Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)
- [WinUI3 App de Notas com IA Multi Model](https://github.com/microsoft/ai-powered-notes-winui3-sample)
- [Ajuste fino e integra√ß√£o de modelos personalizados Phi-3 com Prompt flow](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)
- [Ajuste fino e integra√ß√£o de modelos personalizados Phi-3 com Prompt flow no Azure AI Foundry](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md)
- [Avalia√ß√£o do modelo ajustado Phi-3 / Phi-3.5 no Azure AI Foundry com foco nos Princ√≠pios de IA Respons√°vel da Microsoft](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md)
- [üìì] [Exemplo de previs√£o de linguagem com Phi-3.5-mini-instruct (Chin√™s/Ingl√™s)](../../md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb)
- [Chatbot RAG com Phi-3.5-Instruct WebGPU](./md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md)
- [Usando GPU do Windows para criar solu√ß√£o Prompt flow com Phi-3.5-Instruct ONNX](./md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md)
- [Usando Microsoft Phi-3.5 tflite para criar aplicativo Android](./md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md)
- [Exemplo de Q&A .NET usando modelo local ONNX Phi-3 com Microsoft.ML.OnnxRuntime](../../md/04.HOL/dotnet/src/LabsPhi301)
- [Aplicativo de chat .NET com Semantic Kernel e Phi-3](../../md/04.HOL/dotnet/src/LabsPhi302)

- Exemplos de C√≥digo com Azure AI Inference SDK  
  - Exemplos Phi-4 üÜï  
    - [üìì] [Gerar c√≥digo de projeto usando Phi-4-multimodal](./md/02.Application/02.Code/Phi4/GenProjectCode/README.md)  
  - Exemplos Phi-3 / 3.5  
    - [Crie seu pr√≥prio Chat Copilot no Visual Studio Code com a fam√≠lia Phi-3 da Microsoft](./md/02.Application/02.Code/Phi3/VSCodeExt/README.md)  
    - [Crie seu pr√≥prio Agente Chat Copilot no Visual Studio Code com Phi-3.5 usando modelos do GitHub](/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md)  

- Exemplos de Racioc√≠nio Avan√ßado  
  - Exemplos Phi-4 üÜï  
    - [üìì] [Exemplos de Phi-4-mini-reasoning ou Phi-4-reasoning](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md)  
    - [üìì] [Ajuste fino de Phi-4-mini-reasoning com Microsoft Olive](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb)  
    - [üìì] [Ajuste fino de Phi-4-mini-reasoning com Apple MLX](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/mlx_ft_phi_4_reasoning_with_medicaldata.ipynb)  
    - [üìì] [Phi-4-mini-reasoning com modelos do GitHub](../../md/02.Application/02.Code/Phi4r/github_models_inference.ipynb)  
    - [üìì] [Phi-4-mini-reasoning com modelos do Azure AI Foundry](../../md/02.Application/02.Code/Phi4r/azure_models_inference.ipynb)  
- Demos  
    - [Demos de Phi-4-mini hospedadas no Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo)  
    - [Demos de Phi-4-multimodal hospedadas no Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo)  
- Exemplos de Vis√£o  
  - Exemplos Phi-4 üÜï  
    - [üìì] [Usar Phi-4-multimodal para ler imagens e gerar c√≥digo](./md/02.Application/04.Vision/Phi4/CreateFrontend/README.md)  
  - Exemplos Phi-3 / 3.5  
    - [üìì][Phi-3-vision - Texto de imagem para texto](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)  
    - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)  
    - [üìì][Phi-3-vision CLIP Embedding](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)  
    - [DEMO: Phi-3 Reciclagem](https://github.com/jennifermarsman/PhiRecycling/)  
    - [Phi-3-vision - Assistente visual de linguagem - com Phi3-Vision e OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)  
    - [Phi-3 Vision Nvidia NIM](./md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md)  
    - [Phi-3 Vision OpenVino](./md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md)  
    - [üìì][Exemplo de multi-frame ou multi-imagem com Phi-3.5 Vision](../../md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb)  
    - [Phi-3 Vision Modelo Local ONNX usando Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi303)  
    - [Modelo Local ONNX Phi-3 Vision baseado em menu usando Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi304)  

- Exemplos de Matem√°tica  
  - Exemplos Phi-4-Mini-Flash-Reasoning-Instruct üÜï [Demo de Matem√°tica com Phi-4-Mini-Flash-Reasoning-Instruct](../../md/02.Application/09.Math/MathDemo.ipynb)  

- Exemplos de √Åudio  
  - Exemplos Phi-4 üÜï  
    - [üìì] [Extraindo transcri√ß√µes de √°udio usando Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Transciption/README.md)  
    - [üìì] [Exemplo de √Åudio com Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Siri/demo.ipynb)  
    - [üìì] [Exemplo de Tradu√ß√£o de Fala com Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Translate/demo.ipynb)  
    - [Aplicativo de console .NET usando Phi-4-multimodal √Åudio para analisar um arquivo de √°udio e gerar transcri√ß√£o](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio)  

- Exemplos MOE  
  - Exemplos Phi-3 / 3.5  
    - [üìì] [Exemplo de Modelos Mixture of Experts (MoEs) Phi-3.5 para M√≠dias Sociais](../../md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb)  
    - [üìì] [Construindo um Pipeline de Gera√ß√£o-Aumentada por Recupera√ß√£o (RAG) com NVIDIA NIM Phi-3 MOE, Azure AI Search e LlamaIndex](../../md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb)  

- Exemplos de Chamadas de Fun√ß√£o  
  - Exemplos Phi-4 üÜï  
    - [üìì] [Usando Chamadas de Fun√ß√£o com Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md)  
    - [üìì] [Usando Chamadas de Fun√ß√£o para criar multi-agentes com Phi-4-mini](../../md/02.Application/07.FunctionCalling/Phi4/Multiagents/Phi_4_mini_multiagent.ipynb)  
    - [üìì] [Usando Chamadas de Fun√ß√£o com Ollama](../../md/02.Application/07.FunctionCalling/Phi4/Ollama/ollama_functioncalling.ipynb)  
    - [üìì] [Usando Chamadas de Fun√ß√£o com ONNX](../../md/02.Application/07.FunctionCalling/Phi4/ONNX/onnx_parallel_functioncalling.ipynb)  

- Exemplos de Mistura Multimodal  
  - Exemplos Phi-4 üÜï  
    - [üìì] [Usando Phi-4-multimodal como jornalista de tecnologia](../../md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb)  
    - [Aplicativo de console .NET usando Phi-4-multimodal para analisar imagens](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images)  

- Exemplos de Ajuste Fino Phi  
  - [Cen√°rios de Ajuste Fino](./md/03.FineTuning/FineTuning_Scenarios.md)  
  - [Ajuste Fino vs RAG](./md/03.FineTuning/FineTuning_vs_RAG.md)  
  - [Ajuste Fino: Deixe Phi-3 se tornar um especialista na ind√∫stria](./md/03.FineTuning/LetPhi3gotoIndustriy.md)  
  - [Ajuste Fino de Phi-3 com AI Toolkit para VS Code](./md/03.FineTuning/Finetuning_VSCodeaitoolkit.md)  
  - [Ajuste Fino de Phi-3 com Azure Machine Learning Service](./md/03.FineTuning/Introduce_AzureML.md)  
  - [Ajuste Fino de Phi-3 com Lora](./md/03.FineTuning/FineTuning_Lora.md)  
  - [Ajuste Fino de Phi-3 com QLora](./md/03.FineTuning/FineTuning_Qlora.md)  
  - [Ajuste Fino de Phi-3 com Azure AI Foundry](./md/03.FineTuning/FineTuning_AIFoundry.md)  
  - [Ajuste Fino de Phi-3 com Azure ML CLI/SDK](./md/03.FineTuning/FineTuning_MLSDK.md)  
  - [Ajuste Fino com Microsoft Olive](./md/03.FineTuning/FineTuning_MicrosoftOlive.md)  
  - [Laborat√≥rio Pr√°tico de Ajuste Fino com Microsoft Olive](./md/03.FineTuning/olive-lab/readme.md)  
  - [Ajuste Fino de Phi-3-vision com Weights and Bias](./md/03.FineTuning/FineTuning_Phi-3-visionWandB.md)  
  - [Ajuste Fino de Phi-3 com Apple MLX Framework](./md/03.FineTuning/FineTuning_MLX.md)  
  - [Ajuste Fino de Phi-3-vision (suporte oficial)](./md/03.FineTuning/FineTuning_Vision.md)  
  - [Ajuste Fino de Phi-3 com Kaito AKS, Azure Containers (suporte oficial)](./md/03.FineTuning/FineTuning_Kaito.md)  
  - [Ajuste Fino de Phi-3 e 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)  

- Laborat√≥rio Pr√°tico  
  - [Explorando modelos de ponta: LLMs, SLMs, desenvolvimento local e mais](https://github.com/microsoft/aitour-exploring-cutting-edge-models)  
  - [Desbloqueando o Potencial de NLP: Ajuste Fino com Microsoft Olive](https://github.com/azure/Ignite_FineTuning_workshop)  

- Artigos de Pesquisa Acad√™mica e Publica√ß√µes  
  - [Textbooks Are All You Need II: relat√≥rio t√©cnico phi-1.5](https://arxiv.org/abs/2309.05463)  
  - [Relat√≥rio T√©cnico Phi-3: Um modelo de linguagem altamente capaz localmente no seu telefone](https://arxiv.org/abs/2404.14219)  
  - [Relat√≥rio T√©cnico Phi-4](https://arxiv.org/abs/2412.08905)  
  - [Relat√≥rio T√©cnico Phi-4-Mini: Modelos de linguagem multimodal compactos e poderosos via Mixture-of-LoRAs](https://arxiv.org/abs/2503.01743)  
  - [Otimizando Modelos de Linguagem Pequenos para Chamadas de Fun√ß√µes em Ve√≠culos](https://arxiv.org/abs/2501.02342)
  - [(WhyPHI) Ajustando PHI-3 para Respostas de Perguntas de M√∫ltipla Escolha: Metodologia, Resultados e Desafios](https://arxiv.org/abs/2501.01588)
  - [Relat√≥rio T√©cnico Phi-4-reasoning](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf)
  - [Relat√≥rio T√©cnico Phi-4-mini-reasoning](https://huggingface.co/microsoft/Phi-4-mini-reasoning/blob/main/Phi-4-Mini-Reasoning.pdf)

## Usando Modelos Phi

### Phi no Azure AI Foundry

Voc√™ pode aprender como usar o Microsoft Phi e como construir solu√ß√µes de ponta a ponta (E2E) em seus diferentes dispositivos de hardware. Para experimentar o Phi, comece explorando os modelos e personalizando o Phi para seus cen√°rios usando o‚ÄØ[Cat√°logo de Modelos do Azure AI Foundry](https://aka.ms/phi3-azure-ai). Voc√™ pode saber mais em Introdu√ß√£o ao [Azure AI Foundry](/md/02.QuickStart/AzureAIFoundry_QuickStart.md).

**Playground**  
Cada modelo tem um playground dedicado para testar o modelo [Azure AI Playground](https://aka.ms/try-phi3).

### Phi no GitHub Models

Voc√™ pode aprender como usar o Microsoft Phi e como construir solu√ß√µes de ponta a ponta (E2E) em seus diferentes dispositivos de hardware. Para experimentar o Phi, comece explorando o modelo e personalizando o Phi para seus cen√°rios usando o‚ÄØ[Cat√°logo de Modelos do GitHub](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo). Voc√™ pode saber mais em Introdu√ß√£o ao [Cat√°logo de Modelos do GitHub](/md/02.QuickStart/GitHubModel_QuickStart.md).

**Playground**  
Cada modelo tem um [playground dedicado para testar o modelo](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi no Hugging Face

Voc√™ tamb√©m pode encontrar o modelo no [Hugging Face](https://huggingface.co/microsoft).

**Playground**  
[Playground do Hugging Chat](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct).

## IA Respons√°vel

A Microsoft est√° comprometida em ajudar nossos clientes a usar nossos produtos de IA de forma respons√°vel, compartilhando nossos aprendizados e construindo parcerias baseadas em confian√ßa por meio de ferramentas como Notas de Transpar√™ncia e Avalia√ß√µes de Impacto. Muitos desses recursos podem ser encontrados em [https://aka.ms/RAI](https://aka.ms/RAI).  
A abordagem da Microsoft para IA respons√°vel est√° fundamentada em nossos princ√≠pios de IA: justi√ßa, confiabilidade e seguran√ßa, privacidade e seguran√ßa, inclus√£o, transpar√™ncia e responsabilidade.

Modelos de linguagem natural, imagem e fala em larga escala - como os usados neste exemplo - podem potencialmente se comportar de maneiras injustas, pouco confi√°veis ou ofensivas, causando danos. Consulte a [Nota de Transpar√™ncia do servi√ßo Azure OpenAI](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) para se informar sobre riscos e limita√ß√µes.

A abordagem recomendada para mitigar esses riscos √© incluir um sistema de seguran√ßa em sua arquitetura que possa detectar e prevenir comportamentos prejudiciais. O [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) fornece uma camada independente de prote√ß√£o, capaz de detectar conte√∫do prejudicial gerado por usu√°rios e por IA em aplicativos e servi√ßos. O Azure AI Content Safety inclui APIs de texto e imagem que permitem detectar material prejudicial. Dentro do Azure AI Foundry, o servi√ßo Content Safety permite visualizar, explorar e testar c√≥digos de exemplo para detectar conte√∫do prejudicial em diferentes modalidades. A seguinte [documenta√ß√£o de in√≠cio r√°pido](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) orienta voc√™ sobre como fazer solicita√ß√µes ao servi√ßo.

Outro aspecto a ser considerado √© o desempenho geral do aplicativo. Em aplicativos multimodais e com m√∫ltiplos modelos, consideramos desempenho como a capacidade do sistema de atender √†s expectativas suas e de seus usu√°rios, incluindo n√£o gerar sa√≠das prejudiciais. √â importante avaliar o desempenho geral do seu aplicativo usando [avaliadores de Desempenho e Qualidade e de Risco e Seguran√ßa](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in). Voc√™ tamb√©m tem a capacidade de criar e avaliar com [avaliadores personalizados](https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators).

Voc√™ pode avaliar seu aplicativo de IA em seu ambiente de desenvolvimento usando o [Azure AI Evaluation SDK](https://microsoft.github.io/promptflow/index.html). Dado um conjunto de dados de teste ou um alvo, as gera√ß√µes do seu aplicativo de IA generativa s√£o medidas quantitativamente com avaliadores integrados ou avaliadores personalizados de sua escolha. Para come√ßar com o Azure AI Evaluation SDK e avaliar seu sistema, voc√™ pode seguir o [guia de in√≠cio r√°pido](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk). Ap√≥s executar uma avalia√ß√£o, voc√™ pode [visualizar os resultados no Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results).

## Marcas Registradas

Este projeto pode conter marcas registradas ou logotipos de projetos, produtos ou servi√ßos. O uso autorizado de marcas registradas ou logotipos da Microsoft est√° sujeito e deve seguir as [Diretrizes de Marca e Logotipo da Microsoft](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).  
O uso de marcas registradas ou logotipos da Microsoft em vers√µes modificadas deste projeto n√£o deve causar confus√£o ou implicar patroc√≠nio da Microsoft. Qualquer uso de marcas registradas ou logotipos de terceiros est√° sujeito √†s pol√≠ticas desses terceiros.

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.