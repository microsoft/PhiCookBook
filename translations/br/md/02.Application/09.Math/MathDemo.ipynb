{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e7ac41",
   "metadata": {},
   "source": [
    "## Importar Bibliotecas Necessárias\n",
    "Importe as bibliotecas PyTorch e transformers necessárias para carregar e usar o modelo Phi-4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6caaf7",
   "metadata": {},
   "source": [
    "## Definir Semente Aleatória\n",
    "Defina a semente aleatória para garantir resultados reproduzíveis em diferentes execuções.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ce6d9",
   "metadata": {},
   "source": [
    "## Carregar o Modelo e Tokenizador Phi-4-mini-flash-reasoning\n",
    "Carregue o modelo Microsoft Phi-4-mini-flash-reasoning e seu tokenizador correspondente do Hugging Face. O modelo será carregado em CUDA para inferência mais rápida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-4-mini-flash-reasoning\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"cuda\",\n",
    "   torch_dtype=\"auto\",\n",
    "   trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8789ea8",
   "metadata": {},
   "source": [
    "## Preparar Mensagem de Entrada\n",
    "Crie uma mensagem de conversa com um problema matemático de equação quadrática e formate-a usando o modelo de chat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "   \"role\": \"user\",\n",
    "   \"content\": \"How to solve 3*x^2+4*x+5=1?\"\n",
    "}]   \n",
    "inputs = tokenizer.apply_chat_template(\n",
    "   messages,\n",
    "   add_generation_prompt=True,\n",
    "   return_dict=True,\n",
    "   return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b87bf8",
   "metadata": {},
   "source": [
    "## Gerar Resposta\n",
    "Gere uma resposta do modelo usando parâmetros especificados, como temperatura e top_p, para controlar a aleatoriedade na saída.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "   **inputs.to(model.device),\n",
    "   max_new_tokens=32768,\n",
    "   temperature=0.6,\n",
    "   top_p=0.95,\n",
    "   do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088f0d",
   "metadata": {},
   "source": [
    "## Decodificar Saída para Texto\n",
    "Converta as sequências de tokens geradas de volta para texto legível por humanos, excluindo os tokens de entrada originais para mostrar apenas a resposta do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automatizadas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações equivocadas decorrentes do uso desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "93d4d22a7a9ec7e7e668474526477813",
   "translation_date": "2025-09-12T18:50:46+00:00",
   "source_file": "md/02.Application/09.Math/MathDemo.ipynb",
   "language_code": "br"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}