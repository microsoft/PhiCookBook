<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e0a07fd2a30fe2af30b1373df207a5bf",
  "translation_date": "2025-07-17T08:05:09+00:00",
  "source_file": "md/03.FineTuning/FineTuning_Phi-3-visionWandB.md",
  "language_code": "ru"
}
-->
# Обзор проекта Phi-3-Vision-128K-Instruct

## Модель

Phi-3-Vision-128K-Instruct — это легкая, современная мультимодальная модель, лежащая в основе данного проекта. Она принадлежит к семейству моделей Phi-3 и поддерживает контекст длиной до 128 000 токенов. Модель обучалась на разнообразном наборе данных, включающем синтетические данные и тщательно отфильтрованные общедоступные веб-сайты, с акцентом на высококачественный контент, требующий глубокого анализа. В процессе обучения использовалась как контролируемая донастройка, так и оптимизация предпочтений для точного следования инструкциям, а также внедрены надежные меры безопасности.

## Почему создание примерных данных так важно:

1. **Тестирование**: Примерные данные позволяют проверять ваше приложение в различных сценариях без риска повлиять на реальные данные. Это особенно важно на этапах разработки и тестирования.

2. **Оптимизация производительности**: Используя примерные данные, которые имитируют масштаб и сложность реальных, можно выявить узкие места в производительности и оптимизировать приложение.

3. **Прототипирование**: Примерные данные помогают создавать прототипы и макеты, что облегчает понимание требований пользователей и получение обратной связи.

4. **Анализ данных**: В области науки о данных примерные данные часто применяются для разведочного анализа, обучения моделей и тестирования алгоритмов.

5. **Безопасность**: Использование примерных данных в средах разработки и тестирования помогает избежать случайных утечек конфиденциальной информации.

6. **Обучение**: Если вы осваиваете новую технологию или инструмент, работа с примерными данными предоставляет практическую возможность применить полученные знания.

Помните, что качество примерных данных существенно влияет на эффективность всех этих процессов. Они должны максимально соответствовать реальным данным по структуре и разнообразию.

### Создание примерных данных
[Generate DataSet Script](./CreatingSampleData.md)

## Набор данных

Хорошим примером примерного набора данных является [DBQ/Burberry.Product.prices.United.States dataset](https://huggingface.co/datasets/DBQ/Burberry.Product.prices.United.States) (доступен на Huggingface).  
Этот набор содержит данные о продуктах Burberry вместе с метаданными о категории, цене и названии товара, всего 3 040 строк, каждая из которых представляет уникальный продукт. Этот набор позволяет проверить способность модели понимать и интерпретировать визуальные данные, генерируя описательный текст, отражающий тонкие визуальные детали и особенности бренда.

**Note:** Вы можете использовать любой набор данных, включающий изображения.

## Сложное рассуждение

Модель должна делать выводы о ценах и названиях, имея только изображение. Это требует не только распознавания визуальных особенностей, но и понимания их значения с точки зрения ценности продукта и брендинга. Создавая точные текстовые описания на основе изображений, проект демонстрирует потенциал интеграции визуальных данных для повышения эффективности и универсальности моделей в реальных приложениях.

## Архитектура Phi-3 Vision

Архитектура модели — мультимодальная версия Phi-3. Она обрабатывает как текстовые, так и визуальные данные, объединяя их в единую последовательность для комплексного понимания и генерации. Модель использует отдельные слои эмбеддингов для текста и изображений. Текстовые токены преобразуются в плотные векторы, а изображения проходят через модель CLIP vision для извлечения признаков. Эти эмбеддинги изображений затем проецируются так, чтобы соответствовать размерности текстовых эмбеддингов, что обеспечивает их бесшовную интеграцию.

## Интеграция текстовых и визуальных эмбеддингов

Специальные токены в текстовой последовательности указывают места вставки эмбеддингов изображений. Во время обработки эти специальные токены заменяются соответствующими эмбеддингами изображений, позволяя модели воспринимать текст и изображения как единую последовательность. Промпт для нашего набора данных форматируется с использованием специального токена <|image|> следующим образом:

```python
text = f"<|user|>\n<|image_1|>What is shown in this image?<|end|><|assistant|>\nProduct: {row['title']}, Category: {row['category3_code']}, Full Price: {row['full_price']}<|end|>"
```

## Пример кода
- [Phi-3-Vision Training Script](../../../../code/03.Finetuning/Phi-3-vision-Trainingscript.py)
- [Weights and Bias Example walkthrough](https://wandb.ai/byyoung3/mlnews3/reports/How-to-fine-tune-Phi-3-vision-on-a-custom-dataset--Vmlldzo4MTEzMTg3)

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия по обеспечению точности, просим учитывать, что автоматический перевод может содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется обращаться к профессиональному человеческому переводу. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.