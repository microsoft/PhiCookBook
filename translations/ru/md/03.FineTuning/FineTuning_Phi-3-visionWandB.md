<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e0a07fd2a30fe2af30b1373df207a5bf",
  "translation_date": "2025-03-27T15:02:49+00:00",
  "source_file": "md\\03.FineTuning\\FineTuning_Phi-3-visionWandB.md",
  "language_code": "ru"
}
-->
# Обзор проекта Phi-3-Vision-128K-Instruct

## Модель

Phi-3-Vision-128K-Instruct — это легковесная, современная мультимодальная модель, которая является ядром данного проекта. Она входит в семейство моделей Phi-3 и поддерживает длину контекста до 128,000 токенов. Модель обучена на разнообразном наборе данных, включающем синтетические данные и тщательно отфильтрованные общедоступные веб-сайты, с акцентом на качественный контент, требующий глубокого анализа. Процесс обучения включал в себя тонкую настройку под контролем и оптимизацию предпочтений для точного выполнения инструкций, а также надежные меры безопасности.

## Создание примеров данных важно по нескольким причинам:

1. **Тестирование**: Примерные данные позволяют тестировать ваше приложение в различных сценариях, не затрагивая реальные данные. Это особенно важно на этапах разработки и тестирования.

2. **Оптимизация производительности**: Используя примерные данные, которые имитируют масштаб и сложность реальных данных, вы можете выявить узкие места в производительности и оптимизировать приложение.

3. **Прототипирование**: Примерные данные могут использоваться для создания прототипов и макетов, что помогает лучше понять требования пользователей и получить обратную связь.

4. **Анализ данных**: В области анализа данных примерные данные часто применяются для исследования данных, обучения моделей и тестирования алгоритмов.

5. **Безопасность**: Использование примерных данных в средах разработки и тестирования помогает предотвратить случайные утечки конфиденциальных реальных данных.

6. **Обучение**: Если вы изучаете новую технологию или инструмент, работа с примерными данными предоставляет практическую возможность применить полученные знания.

Помните, что качество ваших примерных данных может существенно повлиять на эти процессы. Они должны быть максимально приближены к реальным данным по структуре и вариативности.

### Создание примерных данных
[Скрипт для генерации набора данных](./CreatingSampleData.md)

## Набор данных

Хорошим примером примерного набора данных является [DBQ/Burberry.Product.prices.United.States dataset](https://huggingface.co/datasets/DBQ/Burberry.Product.prices.United.States) (доступен на Huggingface).  
Примерный набор данных содержит информацию о продуктах Burberry вместе с метаданными, такими как категория продукта, цена и название. Всего в наборе 3,040 строк, каждая из которых представляет уникальный продукт. Этот набор данных позволяет протестировать способность модели понимать и интерпретировать визуальные данные, генерируя описательный текст, который передает сложные визуальные детали и характеристики бренда.

**Примечание:** Вы можете использовать любой набор данных, включающий изображения.

## Сложное рассуждение

Модель должна делать выводы о ценах и названиях, имея только изображение. Это требует от модели не только распознавания визуальных характеристик, но и понимания их значения с точки зрения стоимости продукта и брендинга. Генерируя точные текстовые описания на основе изображений, проект демонстрирует потенциал интеграции визуальных данных для повышения производительности и универсальности моделей в реальных приложениях.

## Архитектура Phi-3 Vision

Архитектура модели представляет собой мультимодальную версию Phi-3. Она обрабатывает как текстовые, так и визуальные данные, интегрируя их в единую последовательность для выполнения задач по пониманию и генерации. Модель использует отдельные слои эмбеддинга для текста и изображений. Текстовые токены преобразуются в плотные векторы, а изображения обрабатываются с помощью модели CLIP vision для извлечения эмбеддингов признаков. Затем эти эмбеддинги изображений проецируются, чтобы соответствовать размерности текстовых эмбеддингов, что обеспечивает их бесшовную интеграцию.

## Интеграция текстовых и визуальных эмбеддингов

Специальные токены внутри текстовой последовательности указывают, где должны быть вставлены эмбеддинги изображений. Во время обработки эти специальные токены заменяются соответствующими эмбеддингами изображений, что позволяет модели обрабатывать текст и изображения как единую последовательность. Формат подсказки для нашего набора данных использует специальный токен <|image|>, как показано ниже:

```python
text = f"<|user|>\n<|image_1|>What is shown in this image?<|end|><|assistant|>\nProduct: {row['title']}, Category: {row['category3_code']}, Full Price: {row['full_price']}<|end|>"
```

## Пример кода
- [Скрипт для обучения Phi-3-Vision](../../../../code/03.Finetuning/Phi-3-vision-Trainingscript.py)
- [Пример использования Weights and Bias](https://wandb.ai/byyoung3/mlnews3/reports/How-to-fine-tune-Phi-3-vision-on-a-custom-dataset--Vmlldzo4MTEzMTg3)

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за недоразумения или неправильное толкование, возникающие в результате использования данного перевода.