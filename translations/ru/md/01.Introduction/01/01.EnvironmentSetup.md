<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-03-27T05:41:04+00:00",
  "source_file": "md\\01.Introduction\\01\\01.EnvironmentSetup.md",
  "language_code": "ru"
}
-->
# Начало работы с Phi-3 локально

Этот гид поможет вам настроить локальную среду для запуска модели Phi-3 с использованием Ollama. Вы можете запустить модель несколькими способами, включая GitHub Codespaces, Dev Containers в VS Code или вашу локальную среду.

## Настройка среды

### GitHub Codespaces

Вы можете запустить этот шаблон виртуально, используя GitHub Codespaces. Кнопка откроет веб-версию VS Code прямо в вашем браузере:

1. Откройте шаблон (это может занять несколько минут):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Откройте окно терминала.

### Dev Containers в VS Code

⚠️ Этот вариант будет работать только в том случае, если вашему Docker Desktop выделено как минимум 16 ГБ оперативной памяти. Если у вас меньше 16 ГБ, вы можете попробовать [вариант с GitHub Codespaces](../../../../../md/01.Introduction/01) или [настроить локальную среду](../../../../../md/01.Introduction/01).

Альтернативный вариант — Dev Containers в VS Code, который откроет проект в вашем локальном VS Code с использованием [расширения Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Запустите Docker Desktop (установите его, если он еще не установлен).
2. Откройте проект:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. В окне VS Code, которое откроется, после того как файлы проекта появятся (это может занять несколько минут), откройте окно терминала.
4. Продолжайте с [шагов развертывания](../../../../../md/01.Introduction/01).

### Локальная среда

1. Убедитесь, что установлены следующие инструменты:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Тестирование модели

1. Попросите Ollama скачать и запустить модель phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Это займет несколько минут для загрузки модели.

2. После того как в выводе появится "success", вы можете отправить сообщение этой модели через командную строку.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Через несколько секунд вы должны увидеть поток ответа от модели.

4. Чтобы узнать о различных техниках работы с языковыми моделями, откройте Python-ноутбук [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) и выполните каждую ячейку. Если вы использовали модель, отличную от 'phi3:mini', измените `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` в верхней части файла по необходимости, а также можете модифицировать системное сообщение или добавить примеры few-shot, если это требуется.

**Отказ от ответственности**:  
Данный документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несём ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.