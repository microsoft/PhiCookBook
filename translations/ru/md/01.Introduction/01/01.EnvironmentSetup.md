<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:06:40+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "ru"
}
-->
# Начало работы с Phi-3 локально

Это руководство поможет вам настроить локальную среду для запуска модели Phi-3 с помощью Ollama. Модель можно запускать разными способами, включая GitHub Codespaces, VS Code Dev Containers или вашу локальную среду.

## Настройка окружения

### GitHub Codespaces

Вы можете запустить этот шаблон виртуально, используя GitHub Codespaces. Кнопка откроет веб-версию VS Code прямо в вашем браузере:

1. Откройте шаблон (это может занять несколько минут):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Откройте окно терминала

### VS Code Dev Containers

⚠️ Этот вариант будет работать только если Docker Desktop выделено не менее 16 ГБ оперативной памяти. Если у вас меньше 16 ГБ, попробуйте [вариант с GitHub Codespaces](../../../../../md/01.Introduction/01) или [настройку локально](../../../../../md/01.Introduction/01).

Связанный вариант — VS Code Dev Containers, который откроет проект в вашем локальном VS Code с помощью [расширения Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Запустите Docker Desktop (установите, если он ещё не установлен)
2. Откройте проект:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. В открывшемся окне VS Code, когда появятся файлы проекта (это может занять несколько минут), откройте окно терминала.
4. Продолжайте с [шагами развертывания](../../../../../md/01.Introduction/01)

### Локальная среда

1. Убедитесь, что установлены следующие инструменты:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Тестирование модели

1. Попросите Ollama скачать и запустить модель phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Загрузка модели займет несколько минут.

2. Как только в выводе появится "success", вы можете отправлять сообщения этой модели через командную строку.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Через несколько секунд вы увидите поток ответов от модели.

4. Чтобы узнать о различных техниках работы с языковыми моделями, откройте Python-ноутбук [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) и выполните каждую ячейку. Если вы использовали модель, отличную от 'phi3:mini', измените значение `MODEL_NAME` в первой ячейке.

5. Чтобы вести диалог с моделью phi3:mini из Python, откройте файл [chat.py](../../../../../code/01.Introduce/chat.py) и запустите его. При необходимости вы можете изменить `MODEL_NAME` в начале файла, а также изменить системное сообщение или добавить примеры few-shot.

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия по обеспечению точности, просим учитывать, что автоматический перевод может содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется обращаться к профессиональному переводу, выполненному человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.