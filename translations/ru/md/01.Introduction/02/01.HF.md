<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-07-16T18:49:55+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "ru"
}
-->
# **Использование Phi Family в Hugging Face**

[Hugging Face](https://huggingface.co/) — это очень популярное сообщество в области ИИ с большим количеством данных и открытых моделей. Разные производители выпускают открытые LLM и SLM через Hugging Face, такие как Microsoft, Meta, Mistral, Apple, Google и другие.

Семейство Microsoft Phi уже доступно на Hugging Face. Разработчики могут скачать соответствующую модель Phi Family в зависимости от сценариев и бизнес-задач. Помимо развертывания моделей Phi Pytorch на Hugging Face, мы также выпустили квантизированные модели в форматах GGUF и ONNX, чтобы предоставить пользователям выбор.

## **Скачивание моделей на Hugging Face**

Вы можете скачать модели Phi Family по этой ссылке

[Microsoft Models на Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Вы можете скачать модель разными способами, например, установив ***Hugging face CLI SDK*** или используя ***git clone***.

### **Использование Hugging face CLI для скачивания моделей Phi Family**

- Установите Hugging face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Войдите в систему с помощью huggingface-cli

Авторизуйтесь на Hugging Face с помощью [User Access Token](https://huggingface.co/docs/hub/security-tokens) на вашей странице [Settings](https://huggingface.co/settings/tokens)

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Скачивание

Вы можете скачать модель и сохранить её в кэш

```bash

huggingface-cli download microsoft/phi-4

```

Можно указать путь для сохранения в нужное место

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **Использование git clone для скачивания моделей Phi Family**

Вы также можете скачать модель с помощью ***git clone***

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Примеры — инференс Microsoft Phi-4**

- **Установка библиотеки transformers**

```bash

pip install transformers -U

```

- **Запуск этого кода в VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия по обеспечению точности, просим учитывать, что автоматический перевод может содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется обращаться к профессиональному переводу, выполненному человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.