<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bcf5dd7031db0031abdb9dd0c05ba118",
  "translation_date": "2025-07-16T20:55:04+00:00",
  "source_file": "md/01.Introduction/03/Local_Server_Inference.md",
  "language_code": "ru"
}
-->
# **Инференс Phi-3 на локальном сервере**

Мы можем развернуть Phi-3 на локальном сервере. Пользователи могут выбрать решения [Ollama](https://ollama.com) или [LM Studio](https://llamaedge.com), либо написать собственный код. Вы можете подключить локальные сервисы Phi-3 через [Semantic Kernel](https://github.com/microsoft/semantic-kernel?WT.mc_id=aiml-138114-kinfeylo) или [Langchain](https://www.langchain.com/) для создания приложений Copilot.

## **Использование Semantic Kernel для доступа к Phi-3-mini**

В приложении Copilot мы создаём приложения через Semantic Kernel / LangChain. Такая архитектура приложений обычно совместима с Azure OpenAI Service / моделями OpenAI, а также может поддерживать open source модели на Hugging Face и локальные модели. Что делать, если мы хотим использовать Semantic Kernel для доступа к Phi-3-mini? На примере .NET можно объединить его с Hugging Face Connector в Semantic Kernel. По умолчанию он соответствует id модели на Hugging Face (при первом использовании модель скачивается с Hugging Face, что занимает много времени). Также можно подключиться к локальному сервису, который вы создали самостоятельно. Из двух вариантов мы рекомендуем второй, так как он обеспечивает большую автономность, особенно в корпоративных приложениях.

![sk](../../../../../translated_images/ru/sk.d03785c25edc6d44.png)

На рисунке показано, что доступ к локальным сервисам через Semantic Kernel позволяет легко подключиться к самостоятельно созданному серверу модели Phi-3-mini. Вот результат работы:

![skrun](../../../../../translated_images/ru/skrun.5aafc1e7197dca20.png)

***Пример кода*** https://github.com/kinfey/Phi3MiniSamples/tree/main/semantickernel

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия по обеспечению точности, просим учитывать, что автоматический перевод может содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется обращаться к профессиональному переводу, выполненному человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.