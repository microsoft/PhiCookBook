<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "92e7dac1e5af0dd7c94170fdaf6860fe",
  "translation_date": "2025-03-27T11:12:16+00:00",
  "source_file": "md\\02.Application\\01.TextAndChat\\Phi3\\UsingPromptFlowWithONNX.md",
  "language_code": "ru"
}
-->
# Использование Windows GPU для создания решения Prompt Flow с Phi-3.5-Instruct ONNX

Этот документ представляет собой пример использования PromptFlow с ONNX (Open Neural Network Exchange) для разработки AI-приложений на основе моделей Phi-3.

PromptFlow — это набор инструментов для разработки, предназначенный для упрощения полного цикла разработки AI-приложений на основе LLM (Large Language Model), начиная от идеи и прототипирования до тестирования и оценки.

Интеграция PromptFlow с ONNX позволяет разработчикам:

- **Оптимизировать производительность модели:** Использовать ONNX для эффективного вывода и развертывания моделей.
- **Упростить разработку:** Управлять рабочим процессом и автоматизировать повторяющиеся задачи с помощью PromptFlow.
- **Улучшить сотрудничество:** Обеспечить более тесное взаимодействие между членами команды за счет единой среды разработки.

**Prompt flow** — это набор инструментов для разработки, который упрощает полный цикл разработки AI-приложений на основе LLM: от идеи, прототипирования, тестирования и оценки до развертывания в производстве и мониторинга. Он значительно облегчает работу с инженерией запросов и позволяет создавать приложения LLM производственного качества.

Prompt flow может подключаться к OpenAI, Azure OpenAI Service и настраиваемым моделям (Huggingface, локальные LLM/SLM). Мы надеемся развернуть квантованную модель ONNX Phi-3.5 для локальных приложений. Prompt flow может помочь нам лучше спланировать наш бизнес и реализовать локальные решения на основе Phi-3.5. В этом примере мы будем использовать библиотеку ONNX Runtime GenAI для создания решения Prompt flow на основе Windows GPU.

## **Установка**

### **ONNX Runtime GenAI для Windows GPU**

Ознакомьтесь с этим руководством для настройки ONNX Runtime GenAI для Windows GPU [нажмите здесь](./ORTWindowGPUGuideline.md).

### **Настройка Prompt flow в VSCode**

1. Установите расширение Prompt flow для VS Code.

![pfvscode](../../../../../../translated_images/pfvscode.79f42ae5dd93ed35c19d6d978ae75831fef40e0b8440ee48b893b5a0597d2260.ru.png)

2. После установки расширения Prompt flow для VS Code нажмите на расширение и выберите **Installation dependencies**, следуя этому руководству, чтобы установить SDK Prompt flow в вашу среду.

![pfsetup](../../../../../../translated_images/pfsetup.0c82d99c7760aac29833b37faf4329e67e22279b1c5f37a73724dfa9ebaa32ee.ru.png)

3. Скачайте [Пример кода](../../../../../../code/09.UpdateSamples/Aug/pf/onnx_inference_pf) и откройте его в VS Code.

![pfsample](../../../../../../translated_images/pfsample.7bf40b133a558d86356dd6bc0e480bad2659d9c5364823dae9b3e6784e6f2d25.ru.png)

4. Откройте **flow.dag.yaml**, чтобы выбрать вашу Python-среду.

![pfdag](../../../../../../translated_images/pfdag.c5eb356fa3a96178cd594de9a5da921c4bbe646a9946f32aa20d344ccbeb51a0.ru.png)

   Откройте **chat_phi3_ort.py**, чтобы указать местоположение вашей модели Phi-3.5-Instruct ONNX.

![pfphi](../../../../../../translated_images/pfphi.fff4b0afea47c92c8481174dbf3092823906fca5b717fc642f78947c3e5bbb39.ru.png)

5. Запустите ваш Prompt flow для тестирования.

Откройте **flow.dag.yaml** и нажмите на визуальный редактор.

![pfv](../../../../../../translated_images/pfv.7af6ecd65784a98558b344ba69b5ba6233876823fb435f163e916a632394fc1e.ru.png)

После этого нажмите "Run", чтобы протестировать.

![pfflow](../../../../../../translated_images/pfflow.9697e0fda67794bb0cf4b78d52e6f5a42002eec935bc2519933064afbbdd34f0.ru.png)

1. Вы можете запустить пакет в терминале, чтобы проверить больше результатов.

```bash

pf run create --file batch_run.yaml --stream --name 'Your eval qa name'    

```

Вы можете просмотреть результаты в вашем браузере по умолчанию.

![pfresult](../../../../../../translated_images/pfresult.972eb57dd5bec646e1aa01148991ba8959897efea396e42cf9d7df259444878d.ru.png)

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования данного перевода.