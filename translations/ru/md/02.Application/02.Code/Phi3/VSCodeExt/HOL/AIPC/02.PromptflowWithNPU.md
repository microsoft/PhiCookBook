<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-03-27T11:55:18+00:00",
  "source_file": "md\\02.Application\\02.Code\\Phi3\\VSCodeExt\\HOL\\AIPC\\02.PromptflowWithNPU.md",
  "language_code": "ru"
}
-->
# **Лабораторная работа 2 - Запуск Prompt flow с Phi-3-mini на AIPC**

## **Что такое Prompt flow**

Prompt flow — это набор инструментов для разработки, предназначенный для упрощения полного цикла разработки AI-приложений на основе LLM, начиная от генерации идей, прототипирования, тестирования, оценки и заканчивая развертыванием в продакшн и мониторингом. Этот инструмент значительно упрощает работу с prompt engineering и позволяет создавать LLM-приложения с качеством, соответствующим требованиям продакшн-среды.

С помощью Prompt flow вы сможете:

- Создавать потоки, связывающие LLM, подсказки (prompts), Python-код и другие инструменты в исполняемый рабочий процесс.

- Удобно отлаживать и итеративно улучшать свои потоки, особенно взаимодействие с LLM.

- Оценивать свои потоки, рассчитывать метрики качества и производительности на больших наборах данных.

- Интегрировать тестирование и оценку в вашу систему CI/CD для обеспечения качества вашего потока.

- Развёртывать свои потоки на выбранной вами платформе или легко интегрировать их в кодовую базу приложения.

- (Необязательно, но настоятельно рекомендуется) Работать в команде, используя облачную версию Prompt flow в Azure AI.

## **Что такое AIPC**

AI PC — это компьютер, оснащённый процессором (CPU), графическим процессором (GPU) и нейронным процессором (NPU), каждый из которых имеет свои специфические возможности ускорения AI. NPU, или нейронный процессор, — это специализированный ускоритель, обрабатывающий задачи искусственного интеллекта (AI) и машинного обучения (ML) непосредственно на вашем компьютере, вместо отправки данных для обработки в облако. Хотя GPU и CPU также могут выполнять эти задачи, NPU особенно эффективен при низкопотребляемых AI-вычислениях. AI PC представляет собой фундаментальный сдвиг в том, как работают наши компьютеры. Это не решение для проблемы, которая ранее не существовала. Скорее, это значительное улучшение для повседневного использования компьютеров.

Как это работает? В отличие от генеративного AI и массивных больших языковых моделей (LLM), обученных на огромных объёмах публичных данных, AI, работающий на вашем компьютере, становится более доступным практически на всех уровнях. Концепция проще для понимания, а благодаря тому, что обучение происходит на ваших данных без необходимости обращаться к облаку, преимущества становятся более очевидными для широкой аудитории.

В ближайшем будущем мир AI PC будет включать в себя персональных ассистентов и небольшие AI-модели, работающие непосредственно на вашем компьютере, используя ваши данные для предоставления персонализированных, приватных и более безопасных AI-улучшений для повседневных задач — от создания протоколов встреч, организации фэнтези-футбольной лиги, автоматизации улучшений для редактирования фото и видео до составления идеального маршрута для семейного воссоединения с учётом времени прибытия и отъезда всех участников.

## **Создание потоков генерации кода на AIPC**

***Примечание***: Если вы ещё не завершили установку среды, посетите [Лабораторная работа 0 - Установка](./01.Installations.md)

1. Откройте расширение Prompt flow в Visual Studio Code и создайте пустой проект потока.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.ru.png)

2. Добавьте параметры Входа и Выхода, а также добавьте Python-код в качестве нового потока.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.ru.png)

Вы можете использовать эту структуру (flow.dag.yaml) для построения вашего потока:

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Добавьте код в файл ***Chat_With_Phi3.py***.

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Вы можете протестировать поток, запустив отладку или выполнение, чтобы проверить, правильно ли генерируется код.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.ru.png)

5. Запустите поток как API для разработки в терминале.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Вы можете протестировать его с помощью Postman или Thunder Client.

### **Примечания**

1. Первый запуск занимает много времени. Рекомендуется загрузить модель phi-3 через Hugging Face CLI.

2. Учитывая ограниченные вычислительные возможности Intel NPU, рекомендуется использовать Phi-3-mini-4k-instruct.

3. Мы используем ускорение Intel NPU для квантования и конверсии в INT4, но если вы перезапускаете сервис, необходимо удалить кэш и папки nc_workshop.

## **Ресурсы**

1. Изучите Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Узнайте больше об ускорении Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Пример кода, скачайте [Пример кода локального NPU-агента](../../../../../../../../../code/07.Lab/01/AIPC)

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, имейте в виду, что автоматический перевод может содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется использовать профессиональный перевод, выполненный человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.