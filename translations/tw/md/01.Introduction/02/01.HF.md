<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-08T06:24:22+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "tw"
}
-->
# **在 Hugging Face 使用 Phi Family**


[Hugging Face](https://huggingface.co/) 是一個非常受歡迎的 AI 社群，擁有豐富的資料和開源模型資源。不同廠商會透過 Hugging Face 發佈開源的 LLM 和 SLM，例如 Microsoft、Meta、Mistral、Apple、Google 等。

Microsoft Phi Family 已經在 Hugging Face 上釋出。開發者可以根據場景和業務需求下載對應的 Phi Family 模型。除了在 Hugging Face 部署 Phi Pytorch 模型外，我們也釋出了量化模型，採用 GGUF 和 ONNX 格式，讓終端使用者有更多選擇。


## **在 Hugging Face 下載模型**

你可以透過以下連結下載 Phi family 模型

[Microsoft Modelson Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

你可以用不同方式下載模型，例如安裝 ***Hugging face CLI SDK*** 或使用 ***git clone***。

### **使用 Hugging face CLI 下載 Phi Family 模型**

- 安裝 Hugging face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- 使用 huggingface-cli 登入

使用你在 [設定頁面](https://huggingface.co/settings/tokens) 取得的 [User Access Token](https://huggingface.co/docs/hub/security-tokens) 登入 Hugging face


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- 下載


你可以下載模型並儲存到快取中

```bash

huggingface-cli download microsoft/phi-4

```

你也可以設定下載到你指定的位置


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **使用 git clone 下載 Phi Family 模型**

你也可以用 ***git clone*** 下載模型

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **範例 - 推論 Microsoft Phi-4**

- **安裝 transformers 函式庫**

```bash

pip install transformers -U

```

- **在 VSCode 執行此程式碼**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**免責聲明**：  
本文件係使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於翻譯的準確性，但請注意自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於重要資訊，建議採用專業人工翻譯。我們不對因使用本翻譯而產生的任何誤解或誤譯負責。