<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:45:35+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "da"
}
-->
# Finjuster Phi3 med Olive

I dette eksempel bruger du Olive til:

1. At finjustere en LoRA-adapter til at klassificere s√¶tninger som Sad, Joy, Fear, Surprise.
1. At sl√• adapterv√¶gtningerne sammen med basismodellen.
1. At optimere og kvantisere modellen til `int4`.

Vi viser dig ogs√•, hvordan du kan k√∏re inference p√• den finjusterede model ved hj√¶lp af ONNX Runtime (ORT) Generate API.

> **‚ö†Ô∏è Til finjustering skal du have en passende GPU tilg√¶ngelig - for eksempel en A10, V100, A100.**

## üíæ Installation

Opret et nyt Python virtuelt milj√∏ (for eksempel med `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Installer derefter Olive og afh√¶ngighederne til en finjusteringsworkflow:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Finjuster Phi3 med Olive
[Olive konfigurationsfilen](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) indeholder et *workflow* med f√∏lgende *passes*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

Overordnet vil dette workflow:

1. Finjustere Phi3 (i 150 trin, som du kan √¶ndre) ved hj√¶lp af dataene fra [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. Flette LoRA-adapterv√¶gtningerne ind i basismodellen. Det giver dig en enkelt modelartefakt i ONNX-format.
1. Model Builder optimerer modellen til ONNX runtime *og* kvantiserer modellen til `int4`.

For at k√∏re workflowet, k√∏r:

```bash
olive run --config phrase-classification.json
```

N√•r Olive er f√¶rdig, finder du din optimerede `int4` finjusterede Phi3-model i: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Integrer den finjusterede Phi3 i din applikation

For at k√∏re appen:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Svaret skal v√¶re en enkeltordsklassifikation af s√¶tningen (Sad/Joy/Fear/Surprise).

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets modersm√•l b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.