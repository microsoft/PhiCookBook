<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-05-09T19:40:34+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/Apple/02.PromptflowWithMLX.md",
  "language_code": "id"
}
-->
# **Lab 2 - Menjalankan Prompt flow dengan Phi-3-mini di AIPC**

## **Apa itu Prompt flow**

Prompt flow adalah rangkaian alat pengembangan yang dirancang untuk mempermudah siklus pengembangan aplikasi AI berbasis LLM secara menyeluruh, mulai dari ideasi, prototyping, pengujian, evaluasi hingga penerapan produksi dan pemantauan. Ini membuat rekayasa prompt jauh lebih mudah dan memungkinkan Anda membangun aplikasi LLM dengan kualitas produksi.

Dengan prompt flow, Anda akan dapat:

- Membuat alur yang menghubungkan LLM, prompt, kode Python, dan alat lain dalam sebuah workflow yang dapat dijalankan.

- Debug dan iterasi alur Anda, terutama interaksi dengan LLM dengan mudah.

- Mengevaluasi alur Anda, menghitung metrik kualitas dan performa dengan dataset yang lebih besar.

- Mengintegrasikan pengujian dan evaluasi ke dalam sistem CI/CD Anda untuk memastikan kualitas alur.

- Menyebarkan alur Anda ke platform penyajian yang Anda pilih atau mengintegrasikannya ke basis kode aplikasi Anda dengan mudah.

- (Opsional tapi sangat disarankan) Bekerja sama dengan tim Anda dengan memanfaatkan versi cloud dari Prompt flow di Azure AI.

## **Membangun alur kode generasi di Apple Silicon**

***Note*** ï¼šJika Anda belum menyelesaikan instalasi lingkungan, silakan kunjungi [Lab 0 -Installations](./01.Installations.md)

1. Buka Ekstensi Prompt flow di Visual Studio Code dan buat proyek alur kosong

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.id.png)

2. Tambahkan parameter Inputs dan Outputs serta Tambahkan Kode Python sebagai alur baru

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.id.png)

Anda dapat merujuk pada struktur ini (flow.dag.yaml) untuk membangun alur Anda

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. Kuantisasi phi-3-mini

Kami berharap dapat menjalankan SLM dengan lebih baik di perangkat lokal. Secara umum, kami mengkuantisasi model (INT4, FP16, FP32)

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Note:** folder default adalah mlx_model

4. Tambahkan Kode di ***Chat_With_Phi3.py***

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. Anda dapat menguji alur dari Debug atau Run untuk memeriksa apakah kode generasi berjalan dengan baik atau tidak

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.id.png)

5. Jalankan alur sebagai API pengembangan di terminal

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Anda dapat mengujinya di Postman / Thunder Client

### **Note**

1. Jalankan pertama kali membutuhkan waktu lama. Disarankan untuk mengunduh model phi-3 dari Hugging face CLI.

2. Mengingat keterbatasan daya komputasi Intel NPU, disarankan menggunakan Phi-3-mini-4k-instruct

3. Kami menggunakan Akselerasi Intel NPU untuk mengkuantisasi konversi INT4, tetapi jika Anda menjalankan ulang layanan, Anda perlu menghapus folder cache dan nc_workshop.

## **Sumber daya**

1. Pelajari Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Pelajari Akselerasi Intel NPU [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Kode Contoh, unduh [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk akurasi, harap diketahui bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sah. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau salah tafsir yang timbul dari penggunaan terjemahan ini.