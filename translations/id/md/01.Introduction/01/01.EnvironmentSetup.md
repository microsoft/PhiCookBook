<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:13:56+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "id"
}
-->
# Memulai dengan Phi-3 secara lokal

Panduan ini akan membantu Anda menyiapkan lingkungan lokal untuk menjalankan model Phi-3 menggunakan Ollama. Anda dapat menjalankan model ini dengan beberapa cara berbeda, termasuk menggunakan GitHub Codespaces, VS Code Dev Containers, atau lingkungan lokal Anda.

## Pengaturan lingkungan

### GitHub Codespaces

Anda dapat menjalankan template ini secara virtual dengan menggunakan GitHub Codespaces. Tombol ini akan membuka instance VS Code berbasis web di browser Anda:

1. Buka template (ini mungkin memakan waktu beberapa menit):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buka jendela terminal

### VS Code Dev Containers

⚠️ Opsi ini hanya akan berfungsi jika Docker Desktop Anda dialokasikan minimal 16 GB RAM. Jika Anda memiliki kurang dari 16 GB RAM, Anda bisa mencoba [opsi GitHub Codespaces](../../../../../md/01.Introduction/01) atau [menyiapkannya secara lokal](../../../../../md/01.Introduction/01).

Opsi terkait adalah VS Code Dev Containers, yang akan membuka proyek di VS Code lokal Anda menggunakan [ekstensi Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Mulai Docker Desktop (pasang jika belum terpasang)
2. Buka proyek:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Di jendela VS Code yang terbuka, setelah file proyek muncul (ini mungkin memakan waktu beberapa menit), buka jendela terminal.
4. Lanjutkan dengan [langkah-langkah deployment](../../../../../md/01.Introduction/01)

### Lingkungan Lokal

1. Pastikan alat-alat berikut sudah terpasang:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Uji model

1. Minta Ollama untuk mengunduh dan menjalankan model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Ini akan memakan beberapa menit untuk mengunduh model.

2. Setelah Anda melihat "success" di output, Anda bisa mengirim pesan ke model tersebut dari prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Setelah beberapa detik, Anda akan melihat aliran respons dari model.

4. Untuk mempelajari berbagai teknik yang digunakan dengan model bahasa, buka notebook Python [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) dan jalankan setiap sel. Jika Anda menggunakan model selain 'phi3:mini', ubah `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` di bagian atas file sesuai kebutuhan, dan Anda juga dapat memodifikasi pesan sistem atau menambahkan contoh few-shot jika diinginkan.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk akurasi, harap diperhatikan bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang otoritatif. Untuk informasi yang penting, disarankan menggunakan terjemahan manusia profesional. Kami tidak bertanggung jawab atas kesalahpahaman atau salah tafsir yang timbul dari penggunaan terjemahan ini.