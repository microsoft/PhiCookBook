<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:11:15+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "id"
}
-->
# Memulai dengan Phi-3 secara lokal

Panduan ini akan membantu Anda menyiapkan lingkungan lokal untuk menjalankan model Phi-3 menggunakan Ollama. Anda dapat menjalankan model ini dengan beberapa cara berbeda, termasuk menggunakan GitHub Codespaces, VS Code Dev Containers, atau lingkungan lokal Anda.

## Penyiapan lingkungan

### GitHub Codespaces

Anda dapat menjalankan template ini secara virtual dengan menggunakan GitHub Codespaces. Tombol ini akan membuka instance VS Code berbasis web di browser Anda:

1. Buka template (ini mungkin memakan waktu beberapa menit):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buka jendela terminal

### VS Code Dev Containers

⚠️ Opsi ini hanya akan berfungsi jika Docker Desktop Anda dialokasikan minimal 16 GB RAM. Jika Anda memiliki kurang dari 16 GB RAM, Anda bisa mencoba opsi [GitHub Codespaces](../../../../../md/01.Introduction/01) atau [menyiapkannya secara lokal](../../../../../md/01.Introduction/01).

Opsi terkait adalah VS Code Dev Containers, yang akan membuka proyek di VS Code lokal Anda menggunakan [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Mulai Docker Desktop (instal jika belum terpasang)
2. Buka proyek:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Di jendela VS Code yang terbuka, setelah file proyek muncul (ini mungkin memakan waktu beberapa menit), buka jendela terminal.
4. Lanjutkan dengan [langkah deployment](../../../../../md/01.Introduction/01)

### Lingkungan Lokal

1. Pastikan alat-alat berikut sudah terpasang:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Uji model

1. Minta Ollama untuk mengunduh dan menjalankan model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Ini akan memakan waktu beberapa menit untuk mengunduh model.

2. Setelah Anda melihat "success" di output, Anda dapat mengirim pesan ke model tersebut dari prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Setelah beberapa detik, Anda akan melihat aliran respons dari model.

4. Untuk mempelajari berbagai teknik yang digunakan dengan model bahasa, buka notebook Python [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) dan jalankan setiap sel. Jika Anda menggunakan model selain 'phi3:mini', ubah `MODEL_NAME` di sel pertama.

5. Untuk melakukan percakapan dengan model phi3:mini dari Python, buka file Python [chat.py](../../../../../code/01.Introduce/chat.py) dan jalankan. Anda dapat mengubah `MODEL_NAME` di bagian atas file sesuai kebutuhan, dan juga dapat memodifikasi pesan sistem atau menambahkan contoh few-shot jika diinginkan.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk mencapai akurasi, harap diketahui bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sahih. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.