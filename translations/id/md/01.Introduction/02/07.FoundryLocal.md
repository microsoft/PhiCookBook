<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-07-16T19:49:05+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "id"
}
-->
## Memulai dengan Model Phi-Family di Foundry Local

### Pengenalan Foundry Local

Foundry Local adalah solusi inferensi AI yang berjalan langsung di perangkat, menghadirkan kemampuan AI kelas perusahaan langsung ke perangkat keras lokal Anda. Tutorial ini akan memandu Anda dalam mengatur dan menggunakan model Phi-Family dengan Foundry Local, memberikan kendali penuh atas beban kerja AI Anda sambil menjaga privasi dan mengurangi biaya.

Foundry Local menawarkan keunggulan performa, privasi, kustomisasi, dan efisiensi biaya dengan menjalankan model AI secara lokal di perangkat Anda. Solusi ini terintegrasi dengan mulus ke dalam alur kerja dan aplikasi Anda melalui CLI, SDK, dan REST API yang intuitif.


![arch](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7d68815ddb0153503587142ff32e6997041c7cf0c9df24b49.id.png)

### Mengapa Memilih Foundry Local?

Memahami manfaat Foundry Local akan membantu Anda membuat keputusan yang tepat terkait strategi penerapan AI Anda:

- **Inferensi di Perangkat:** Jalankan model secara lokal di perangkat Anda sendiri, mengurangi biaya sekaligus menjaga semua data tetap di perangkat Anda.

- **Kustomisasi Model:** Pilih dari model yang sudah disiapkan atau gunakan model Anda sendiri untuk memenuhi kebutuhan dan kasus penggunaan spesifik.

- **Efisiensi Biaya:** Hilangkan biaya berulang layanan cloud dengan memanfaatkan perangkat keras yang sudah Anda miliki, membuat AI lebih terjangkau.

- **Integrasi Mulus:** Hubungkan dengan aplikasi Anda melalui SDK, endpoint API, atau CLI, dengan kemudahan skala ke Azure AI Foundry saat kebutuhan Anda berkembang.

> **Catatan Memulai:** Tutorial ini fokus pada penggunaan Foundry Local melalui antarmuka CLI dan SDK. Anda akan mempelajari kedua cara tersebut untuk membantu memilih metode terbaik sesuai kebutuhan Anda.

## Bagian 1: Menyiapkan Foundry Local CLI

### Langkah 1: Instalasi

Foundry Local CLI adalah pintu gerbang Anda untuk mengelola dan menjalankan model AI secara lokal. Mari mulai dengan menginstalnya di sistem Anda.

**Platform yang Didukung:** Windows dan macOS

Untuk petunjuk instalasi lengkap, silakan lihat [dokumentasi resmi Foundry Local](https://github.com/microsoft/Foundry-Local/blob/main/README.md).

### Langkah 2: Menjelajahi Model yang Tersedia

Setelah Foundry Local CLI terpasang, Anda dapat melihat model apa saja yang tersedia untuk kebutuhan Anda. Perintah ini akan menampilkan semua model yang didukung:


```bash
foundry model list
```

### Langkah 3: Memahami Model Phi Family

Phi Family menawarkan berbagai model yang dioptimalkan untuk berbagai kasus penggunaan dan konfigurasi perangkat keras. Berikut adalah model Phi yang tersedia di Foundry Local:

**Model Phi yang Tersedia:** 

- **phi-3.5-mini** - Model ringkas untuk tugas dasar
- **phi-3-mini-128k** - Versi konteks diperpanjang untuk percakapan lebih panjang
- **phi-3-mini-4k** - Model konteks standar untuk penggunaan umum
- **phi-4** - Model canggih dengan kemampuan yang ditingkatkan
- **phi-4-mini** - Versi ringan dari Phi-4
- **phi-4-mini-reasoning** - Spesialis untuk tugas penalaran kompleks

> **Kompatibilitas Perangkat Keras:** Setiap model dapat dikonfigurasi untuk akselerasi perangkat keras yang berbeda (CPU, GPU) sesuai kemampuan sistem Anda.

### Langkah 4: Menjalankan Model Phi Pertama Anda

Mari mulai dengan contoh praktis. Kita akan menjalankan model `phi-4-mini-reasoning`, yang unggul dalam menyelesaikan masalah kompleks secara bertahap.


**Perintah untuk menjalankan model:**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **Pengaturan Pertama Kali:** Saat menjalankan model untuk pertama kali, Foundry Local akan mengunduh model tersebut ke perangkat lokal Anda secara otomatis. Waktu unduh tergantung kecepatan jaringan Anda, jadi harap bersabar selama proses awal ini.

### Langkah 5: Menguji Model dengan Masalah Nyata

Sekarang mari kita uji model dengan masalah logika klasik untuk melihat bagaimana model melakukan penalaran langkah demi langkah:

**Contoh Masalah:**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**Perilaku yang Diharapkan:** Model harus memecah masalah ini menjadi langkah-langkah logis, menggunakan fakta bahwa burung pegar memiliki 2 kaki dan kelinci memiliki 4 kaki untuk menyelesaikan sistem persamaan.

**Hasil:**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d916093866d4df99190150d4198fd33ab79e586f9d6f5403089.id.png)

## Bagian 2: Membangun Aplikasi dengan Foundry Local SDK

### Mengapa Menggunakan SDK?

Sementara CLI sangat cocok untuk pengujian dan interaksi cepat, SDK memungkinkan Anda mengintegrasikan Foundry Local ke dalam aplikasi secara programatik. Ini membuka kemungkinan untuk:

- Membangun aplikasi bertenaga AI yang kustom
- Membuat alur kerja otomatis
- Mengintegrasikan kemampuan AI ke dalam sistem yang sudah ada
- Mengembangkan chatbot dan alat interaktif

### Bahasa Pemrograman yang Didukung

Foundry Local menyediakan dukungan SDK untuk berbagai bahasa pemrograman sesuai preferensi pengembangan Anda:

**ðŸ“¦ SDK yang Tersedia:**

- **C# (.NET):** [Dokumentasi & Contoh SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)
- **Python:** [Dokumentasi & Contoh SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **JavaScript:** [Dokumentasi & Contoh SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)
- **Rust:** [Dokumentasi & Contoh SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### Langkah Selanjutnya

1. **Pilih SDK yang Anda sukai** berdasarkan lingkungan pengembangan Anda
2. **Ikuti dokumentasi khusus SDK** untuk panduan implementasi yang detail
3. **Mulai dengan contoh sederhana** sebelum membangun aplikasi yang kompleks
4. **Jelajahi kode contoh** yang disediakan di setiap repositori SDK

## Kesimpulan

Sekarang Anda telah mempelajari cara untuk:
- âœ… Menginstal dan menyiapkan Foundry Local CLI
- âœ… Menemukan dan menjalankan model Phi Family
- âœ… Menguji model dengan masalah dunia nyata
- âœ… Memahami opsi SDK untuk pengembangan aplikasi

Foundry Local memberikan fondasi yang kuat untuk menghadirkan kemampuan AI langsung ke lingkungan lokal Anda, memberi Anda kendali atas performa, privasi, dan biaya sekaligus tetap fleksibel untuk skala ke solusi cloud saat diperlukan.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk mencapai akurasi, harap diketahui bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sahih. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.