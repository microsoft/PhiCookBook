<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-05-09T09:58:32+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "id"
}
-->
## Keluarga Phi di NVIDIA NIM

NVIDIA NIM adalah kumpulan microservices yang mudah digunakan, dirancang untuk mempercepat penerapan model AI generatif di cloud, pusat data, dan workstation. NIM dikategorikan berdasarkan keluarga model dan per model. Misalnya, NVIDIA NIM untuk large language models (LLMs) menghadirkan kekuatan LLM terkini ke aplikasi perusahaan, memberikan kemampuan pemrosesan dan pemahaman bahasa alami yang tak tertandingi.

NIM memudahkan tim IT dan DevOps untuk meng-host sendiri large language models (LLMs) dalam lingkungan yang mereka kelola, sambil tetap menyediakan API standar industri bagi pengembang untuk membangun copilots, chatbot, dan asisten AI yang kuat yang dapat mengubah bisnis mereka. Dengan memanfaatkan akselerasi GPU mutakhir dari NVIDIA dan penerapan yang dapat diskalakan, NIM menawarkan jalur tercepat untuk inferensi dengan performa luar biasa.

Anda dapat menggunakan NVIDIA NIM untuk melakukan inferensi pada Model Keluarga Phi

![nim](../../../../../translated_images/Phi-NIM.45af94d89220fbbbc85f8da0379150a29cc88c3dd8ec417b1d3b7237bbe1c58a.id.png)

### **Contoh - Phi-3-Vision di NVIDIA NIM**

Bayangkan Anda memiliki sebuah gambar (`demo.png`) dan ingin menghasilkan kode Python yang memproses gambar ini serta menyimpan versi barunya (`phi-3-vision.jpg`).

Kode di atas mengotomatiskan proses ini dengan cara:

1. Menyiapkan lingkungan dan konfigurasi yang diperlukan.
2. Membuat prompt yang menginstruksikan model untuk menghasilkan kode Python yang dibutuhkan.
3. Mengirim prompt ke model dan mengumpulkan kode yang dihasilkan.
4. Mengekstrak dan menjalankan kode yang dihasilkan.
5. Menampilkan gambar asli dan gambar yang sudah diproses.

Pendekatan ini memanfaatkan kekuatan AI untuk mengotomatiskan tugas pemrosesan gambar, membuatnya lebih mudah dan cepat untuk mencapai tujuan Anda.

[Sample Code Solution](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

Mari kita uraikan apa yang dilakukan seluruh kode langkah demi langkah:

1. **Pasang Paket yang Dibutuhkan**:  
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```  
    Perintah ini memasang paket `langchain_nvidia_ai_endpoints`, memastikan versinya yang terbaru.

2. **Impor Modul yang Diperlukan**:  
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```  
    Impor ini membawa modul yang dibutuhkan untuk berinteraksi dengan NVIDIA AI endpoints, menangani password dengan aman, berinteraksi dengan sistem operasi, dan melakukan encoding/decoding data dalam format base64.

3. **Siapkan API Key**:  
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```  
    Kode ini memeriksa apakah variabel lingkungan `NVIDIA_API_KEY` sudah diset. Jika belum, pengguna diminta untuk memasukkan API key secara aman.

4. **Tentukan Model dan Jalur Gambar**:  
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```  
    Ini mengatur model yang akan digunakan, membuat instance `ChatNVIDIA` dengan model tersebut, dan menentukan jalur file gambar.

5. **Buat Prompt Teks**:  
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```  
    Mendefinisikan prompt teks yang menginstruksikan model untuk menghasilkan kode Python untuk memproses gambar.

6. **Encode Gambar ke Base64**:  
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```  
    Kode ini membaca file gambar, meng-encode-nya ke base64, dan membuat tag gambar HTML dengan data yang sudah diencode.

7. **Gabungkan Teks dan Gambar ke Dalam Prompt**:  
    ```python
    prompt = f"{text} {image}"
    ```  
    Menggabungkan prompt teks dan tag gambar HTML menjadi satu string.

8. **Hasilkan Kode Menggunakan ChatNVIDIA**:  
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```  
    Kode ini mengirim prompt ke `ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code` string.

9. **Ekstrak Kode Python dari Konten yang Dihasilkan**:  
    ```python
    begin = code.index('```python') + 9  
    code = code[begin:]  
    end = code.index('```')
    code = code[:end]
    ```  
    Ini mengekstrak kode Python sebenarnya dari konten yang dihasilkan dengan menghilangkan format markdown.

10. **Jalankan Kode yang Dihasilkan**:  
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```  
    Menjalankan kode Python yang sudah diekstrak sebagai subprocess dan menangkap outputnya.

11. **Tampilkan Gambar**:  
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```  
    Baris-baris ini menampilkan gambar menggunakan modul `IPython.display`.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berusaha untuk akurasi, harap diperhatikan bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sahih. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.