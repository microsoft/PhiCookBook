<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4951d458c0b60c02cd1e751b40903877",
  "translation_date": "2025-05-09T09:40:29+00:00",
  "source_file": "md/01.Introduction/02/05.AITK.md",
  "language_code": "id"
}
-->
# Keluarga Phi di AITK

[AI Toolkit untuk VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) mempermudah pengembangan aplikasi AI generatif dengan menggabungkan alat dan model AI terkini dari Azure AI Foundry Catalog dan katalog lain seperti Hugging Face. Anda dapat menjelajahi katalog model AI yang didukung oleh GitHub Models dan Azure AI Foundry Model Catalogs, mengunduhnya secara lokal atau jarak jauh, melakukan fine-tune, menguji, dan menggunakannya dalam aplikasi Anda.

AI Toolkit Preview akan berjalan secara lokal. Inferensi lokal atau fine-tune, tergantung pada model yang Anda pilih, Anda mungkin memerlukan GPU seperti NVIDIA CUDA GPU. Anda juga dapat menjalankan GitHub Models langsung dengan AITK.

## Memulai

[Pelajari lebih lanjut cara menginstal Windows subsystem untuk Linux](https://learn.microsoft.com/windows/wsl/install?WT.mc_id=aiml-137032-kinfeylo)

dan [mengubah distribusi default](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

[Repositori GitHub AI Toolkit](https://github.com/microsoft/vscode-ai-toolkit/)

- Windows, Linux, macOS
  
- Untuk fine-tuning di Windows dan Linux, Anda memerlukan GPU Nvidia. Selain itu, **Windows** membutuhkan subsystem untuk Linux dengan distro Ubuntu 18.4 atau lebih baru. [Pelajari lebih lanjut cara menginstal Windows subsystem untuk Linux](https://learn.microsoft.com/windows/wsl/install) dan [mengubah distribusi default](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

### Instal AI Toolkit

AI Toolkit dikirim sebagai [Ekstensi Visual Studio Code](https://code.visualstudio.com/docs/setup/additional-components#_vs-code-extensions), jadi Anda perlu menginstal [VS Code](https://code.visualstudio.com/docs/setup/windows?WT.mc_id=aiml-137032-kinfeylo) terlebih dahulu, lalu unduh AI Toolkit dari [VS Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio).
[AI Toolkit tersedia di Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) dan dapat diinstal seperti ekstensi VS Code lainnya.

Jika Anda belum familiar dengan pemasangan ekstensi VS Code, ikuti langkah-langkah berikut:

### Masuk

1. Di Activity Bar di VS Code, pilih **Extensions**
2. Di bilah pencarian Extensions, ketik "AI Toolkit"
3. Pilih "AI Toolkit for Visual Studio code"
4. Pilih **Install**

Sekarang, Anda siap menggunakan ekstensi ini!

Anda akan diminta untuk masuk ke GitHub, jadi klik "Allow" untuk melanjutkan. Anda akan diarahkan ke halaman masuk GitHub.

Silakan masuk dan ikuti langkah-langkah prosesnya. Setelah berhasil, Anda akan diarahkan kembali ke VS Code.

Setelah ekstensi terpasang, ikon AI Toolkit akan muncul di Activity Bar Anda.

Mari jelajahi aksi yang tersedia!

### Aksi yang Tersedia

Sidebar utama AI Toolkit diorganisasi menjadi  

- **Models**
- **Resources**
- **Playground**  
- **Fine-tuning**
- **Evaluation**

Tersedia di bagian Resources. Untuk memulai, pilih **Model Catalog**.

### Unduh model dari katalog

Saat meluncurkan AI Toolkit dari sidebar VS Code, Anda dapat memilih opsi berikut:

![AI toolkit model catalog](../../../../../translated_images/AItoolkitmodel_catalog.eee6b38a71f628501d730ffe9c2ae69b8f18706e7492ac2371423b045485996e.id.png)

- Cari model yang didukung dari **Model Catalog** dan unduh secara lokal
- Uji inferensi model di **Model Playground**
- Fine-tune model secara lokal atau jarak jauh di **Model Fine-tuning**
- Deploy model yang sudah di-fine-tune ke cloud melalui command palette untuk AI Toolkit
- Evaluasi model

> [!NOTE]
>
> **GPU Vs CPU**
>
> Anda akan melihat bahwa kartu model menunjukkan ukuran model, platform, dan jenis akselerator (CPU, GPU). Untuk performa optimal pada **perangkat Windows yang memiliki setidaknya satu GPU**, pilih versi model yang hanya ditargetkan untuk Windows.
>
> Ini memastikan Anda memiliki model yang dioptimalkan untuk akselerator DirectML.
>
> Nama model memiliki format
>
> - `{model_name}-{accelerator}-{quantization}-{format}`.
>
>Untuk memeriksa apakah Anda memiliki GPU pada perangkat Windows Anda, buka **Task Manager** lalu pilih tab **Performance**. Jika Anda memiliki GPU, akan terdaftar dengan nama seperti "GPU 0" atau "GPU 1".

### Jalankan model di playground

Setelah semua parameter diatur, klik **Generate Project**.

Setelah model Anda selesai diunduh, pilih **Load in Playground** pada kartu model di katalog:

- Mulai pengunduhan model
- Instal semua prasyarat dan dependensi
- Buat workspace VS Code

![Load model in playground](../../../../../translated_images/AItoolkitload_model_into_playground.e442d8013c65406e69471fb4f8e4e3800505255fe1bd7aa9422f02ee715bad57.id.png)

### Gunakan REST API dalam aplikasi Anda

AI Toolkit dilengkapi dengan server web REST API lokal **di port 5272** yang menggunakan format [OpenAI chat completions](https://platform.openai.com/docs/api-reference/chat/create).

Ini memungkinkan Anda menguji aplikasi secara lokal tanpa harus bergantung pada layanan model AI cloud. Contohnya, file JSON berikut menunjukkan cara mengonfigurasi body request:

```json
{
    "model": "Phi-4",
    "messages": [
        {
            "role": "user",
            "content": "what is the golden ratio?"
        }
    ],
    "temperature": 0.7,
    "top_p": 1,
    "top_k": 10,
    "max_tokens": 100,
    "stream": true
}
```

Anda dapat menguji REST API menggunakan (misalnya) [Postman](https://www.postman.com/) atau utilitas CURL (Client URL):

```bash
curl -vX POST http://127.0.0.1:5272/v1/chat/completions -H 'Content-Type: application/json' -d @body.json
```

### Menggunakan library klien OpenAI untuk Python

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:5272/v1/", 
    api_key="x" # required for the API but not used
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "what is the golden ratio?",
        }
    ],
    model="Phi-4",
)

print(chat_completion.choices[0].message.content)
```

### Menggunakan library klien Azure OpenAI untuk .NET

Tambahkan [library klien Azure OpenAI untuk .NET](https://www.nuget.org/packages/Azure.AI.OpenAI/) ke proyek Anda menggunakan NuGet:

```bash
dotnet add {project_name} package Azure.AI.OpenAI --version 1.0.0-beta.17
```

Tambahkan file C# bernama **OverridePolicy.cs** ke proyek Anda dan tempel kode berikut:

```csharp
// OverridePolicy.cs
using Azure.Core.Pipeline;
using Azure.Core;

internal partial class OverrideRequestUriPolicy(Uri overrideUri)
    : HttpPipelineSynchronousPolicy
{
    private readonly Uri _overrideUri = overrideUri;

    public override void OnSendingRequest(HttpMessage message)
    {
        message.Request.Uri.Reset(_overrideUri);
    }
}
```

Selanjutnya, tempel kode berikut ke file **Program.cs** Anda:

```csharp
// Program.cs
using Azure.AI.OpenAI;

Uri localhostUri = new("http://localhost:5272/v1/chat/completions");

OpenAIClientOptions clientOptions = new();
clientOptions.AddPolicy(
    new OverrideRequestUriPolicy(localhostUri),
    Azure.Core.HttpPipelinePosition.BeforeTransport);
OpenAIClient client = new(openAIApiKey: "unused", clientOptions);

ChatCompletionsOptions options = new()
{
    DeploymentName = "Phi-4",
    Messages =
    {
        new ChatRequestSystemMessage("You are a helpful assistant. Be brief and succinct."),
        new ChatRequestUserMessage("What is the golden ratio?"),
    }
};

StreamingResponse<StreamingChatCompletionsUpdate> streamingChatResponse
    = await client.GetChatCompletionsStreamingAsync(options);

await foreach (StreamingChatCompletionsUpdate chatChunk in streamingChatResponse)
{
    Console.Write(chatChunk.ContentUpdate);
}
```


## Fine Tuning dengan AI Toolkit

- Mulai dengan penemuan model dan playground.
- Fine-tuning dan inferensi model menggunakan sumber daya komputasi lokal.
- Fine-tuning dan inferensi jarak jauh menggunakan sumber daya Azure

[Fine Tuning dengan AI Toolkit](../../03.FineTuning/Finetuning_VSCodeaitoolkit.md)

## Sumber Daya Tanya Jawab AI Toolkit

Silakan merujuk ke [halaman Q&A kami](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/QA.md) untuk masalah umum dan solusi

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berusaha untuk akurasi, harap diperhatikan bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sahih. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang salah yang timbul dari penggunaan terjemahan ini.