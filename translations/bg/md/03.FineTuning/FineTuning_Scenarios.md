<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cb5648935f63edc17e95ce38f23adc32",
  "translation_date": "2025-05-09T21:57:58+00:00",
  "source_file": "md/03.FineTuning/FineTuning_Scenarios.md",
  "language_code": "bg"
}
-->
## Сценарии за фино настройване

![FineTuning with MS Services](../../../../translated_images/FinetuningwithMS.25759a0154a97ad90e43a6cace37d6bea87f0ac0236ada3ad5d4a1fbacc3bdf7.bg.png)

**Платформа** Това включва различни технологии като Azure AI Foundry, Azure Machine Learning, AI Tools, Kaito и ONNX Runtime.

**Инфраструктура** Това включва CPU и FPGA, които са от съществено значение за процеса на фино настройване. Нека ви покажа иконите за всяка от тези технологии.

**Инструменти и рамки** Това включва ONNX Runtime и ONNX Runtime. Нека ви покажа иконите за всяка от тези технологии.  
[Вмъкнете икони за ONNX Runtime и ONNX Runtime]

Процесът на фино настройване с технологиите на Microsoft включва различни компоненти и инструменти. Чрез разбирането и използването на тези технологии можем ефективно да фино настройваме нашите приложения и да създаваме по-добри решения.

## Модел като услуга

Фино настройте модела, използвайки хоствано фино настройване, без необходимост да създавате и управлявате изчислителни ресурси.

![MaaS Fine Tuning](../../../../translated_images/MaaSfinetune.6184d80a336ea9d7bb67a581e9e5d0b021cafdffff7ba257c2012e2123e0d77e.bg.png)

Безсървърното фино настройване е налично за моделите Phi-3-mini и Phi-3-medium, което позволява на разработчиците бързо и лесно да персонализират моделите за облачни и крайни сценарии без да се налага да осигуряват изчислителни ресурси. Също така обявихме, че Phi-3-small вече е достъпен чрез нашето предложение Models-as-a-Service, така че разработчиците могат бързо и лесно да започнат с AI разработката без да се налага да управляват подлежащата инфраструктура.

## Модел като платформа

Потребителите управляват собствените си изчислителни ресурси, за да фино настройват моделите си.

![Maap Fine Tuning](../../../../translated_images/MaaPFinetune.cf8b08ef05bf57f362da90834be87562502f4370de4a7325a9fb03b8c008e5e7.bg.png)

[Fine Tuning Sample](https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/system/finetune/chat-completion/chat-completion.ipynb)

## Сценарии за фино настройване

| | | | | | | |
|-|-|-|-|-|-|-|
|Сценарий|LoRA|QLoRA|PEFT|DeepSpeed|ZeRO|DORA|
|Адаптиране на предварително обучени LLM към конкретни задачи или области|Да|Да|Да|Да|Да|Да|
|Фино настройване за NLP задачи като класификация на текст, разпознаване на именувани обекти и машинен превод|Да|Да|Да|Да|Да|Да|
|Фино настройване за задачи по въпроси и отговори|Да|Да|Да|Да|Да|Да|
|Фино настройване за генериране на човешки отговори в чатботове|Да|Да|Да|Да|Да|Да|
|Фино настройване за генериране на музика, изкуство или други форми на творчество|Да|Да|Да|Да|Да|Да|
|Намаляване на изчислителните и финансови разходи|Да|Да|Не|Да|Да|Не|
|Намаляване на използването на памет|Не|Да|Не|Да|Да|Да|
|Използване на по-малко параметри за ефективно фино настройване|Не|Да|Да|Не|Не|Да|
|Паметно ефективна форма на паралелизъм на данни, която дава достъп до общата GPU памет на всички налични GPU устройства|Не|Не|Не|Да|Да|Да|

## Примери за производителност при фино настройване

![Finetuning Performance](../../../../translated_images/Finetuningexamples.9dbf84557eef43e011eb7cadf51f51686f9245f7953e2712a27095ab7d18a6d1.bg.png)

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI преводаческа услуга [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи могат да съдържат грешки или неточности. Оригиналният документ на неговия оригинален език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или неправилни тълкувания, възникнали от използването на този превод.