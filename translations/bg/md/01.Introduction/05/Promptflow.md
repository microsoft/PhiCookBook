<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3cbe7629d254f1043193b7fe22524d55",
  "translation_date": "2025-05-09T15:22:28+00:00",
  "source_file": "md/01.Introduction/05/Promptflow.md",
  "language_code": "bg"
}
-->
# **Представяне на Promptflow**

[Microsoft Prompt Flow](https://microsoft.github.io/promptflow/index.html?WT.mc_id=aiml-138114-kinfeylo) е визуален инструмент за автоматизация на работни процеси, който позволява на потребителите да създават автоматизирани работни потоци, използвайки предварително създадени шаблони и персонализирани конектори. Той е създаден, за да даде възможност на разработчици и бизнес анализатори бързо да изграждат автоматизирани процеси за задачи като управление на данни, сътрудничество и оптимизация на процеси. С Prompt Flow потребителите лесно свързват различни услуги, приложения и системи и автоматизират сложни бизнес процеси.

Microsoft Prompt Flow е проектиран да оптимизира целия цикъл на разработка на AI приложения, базирани на големи езикови модели (LLMs). Независимо дали разработвате идеи, прототипирате, тествате, оценявате или внедрявате приложения, базирани на LLM, Prompt Flow опростява процеса и ви позволява да създавате LLM приложения с качество за продукция.

## Основни характеристики и предимства на Microsoft Prompt Flow:

**Интерактивно създаване**

Prompt Flow предоставя визуално представяне на структурата на вашия поток, което улеснява разбирането и навигацията в проектите.
Предлага опит, подобен на бележник, за ефективно разработване и отстраняване на грешки в потокa.

**Варианти и настройка на подканите**

Създавайте и сравнявайте множество варианти на подканите, за да улесните итеративния процес на усъвършенстване. Оценявайте представянето на различни подканите и избирайте най-ефективните.

**Вградени оценъчни потоци**

Оценявайте качеството и ефективността на вашите подканите и потоци с помощта на вградени инструменти за оценка.
Разберете колко добре се представят вашите приложения, базирани на LLM.

**Обширни ресурси**

Prompt Flow включва библиотека с вградени инструменти, примери и шаблони. Тези ресурси служат като отправна точка за разработка, вдъхновяват креативност и ускоряват процеса.

**Сътрудничество и готовност за корпоративна среда**

Поддържа екипна работа, позволявайки на множество потребители да работят заедно по проекти за инженеринг на подканите.
Поддържайте контрол на версиите и споделяйте знания ефективно. Оптимизирайте целия процес на инженеринг на подканите – от разработка и оценка до внедряване и мониторинг.

## Оценка в Prompt Flow

В Microsoft Prompt Flow оценката играе ключова роля при преценката на представянето на вашите AI модели. Нека разгледаме как можете да персонализирате оценъчните потоци и метрики в Prompt Flow:

![PFVizualise](../../../../../translated_images/pfvisualize.93c453890f4088830217fa7308b1a589058ed499bbfff160c85676066b5cbf2d.bg.png)

**Разбиране на оценката в Prompt Flow**

В Prompt Flow потокът представлява последователност от възли, които обработват вход и генерират изход. Оценъчните потоци са специални видове потоци, предназначени да оценят представянето на дадено изпълнение въз основа на конкретни критерии и цели.

**Основни характеристики на оценъчните потоци**

Обикновено се изпълняват след тествания поток, използвайки неговите изходи. Изчисляват оценки или метрики, за да измерят представянето на тествания поток. Метриките могат да включват точност, оценки за релевантност или други подходящи показатели.

### Персонализиране на оценъчните потоци

**Определяне на входове**

Оценъчните потоци трябва да приемат изходите от тестваното изпълнение. Определете входовете по подобен начин като при стандартните потоци.
Например, ако оценявате QnA поток, наименувайте вход като "answer". Ако оценявате поток за класификация, наименувайте вход като "category". Може да са необходими и входове с истински стойности (например реални етикети).

**Изходи и метрики**

Оценъчните потоци генерират резултати, които измерват представянето на тествания поток. Метриките могат да се изчисляват с Python или LLM. Използвайте функцията log_metric() за записване на съответните метрики.

**Използване на персонализирани оценъчни потоци**

Разработете собствен оценъчен поток, съобразен с конкретните ви задачи и цели. Персонализирайте метриките според вашите цели за оценка.
Прилагайте този персонализиран оценъчен поток за пакетни изпълнения при мащабно тестване.

## Вградени методи за оценка

Prompt Flow предлага и вградени методи за оценка.
Можете да изпращате пакетни изпълнения и да използвате тези методи, за да оцените колко добре се представя вашият поток с големи набори от данни.
Преглеждайте резултатите от оценката, сравнявайте метриките и правете нужните корекции.
Запомнете, че оценката е важна за гарантиране, че вашите AI модели отговарят на желаните критерии и цели. Разгледайте официалната документация за подробни инструкции за разработване и използване на оценъчни потоци в Microsoft Prompt Flow.

В обобщение, Microsoft Prompt Flow дава възможност на разработчиците да създават висококачествени LLM приложения чрез опростяване на инженерингa на подканите и предоставяне на стабилна среда за разработка. Ако работите с LLM, Prompt Flow е ценен инструмент, който си заслужава да изследвате. Разгледайте [Prompt Flow Evaluation Documents](https://learn.microsoft.com/azure/machine-learning/prompt-flow/how-to-develop-an-evaluation-flow?view=azureml-api-2?WT.mc_id=aiml-138114-kinfeylo) за подробни инструкции за разработване и използване на оценъчни потоци в Microsoft Prompt Flow.

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI преводаческа услуга [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи могат да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или неправилни тълкувания, произтичащи от използването на този превод.