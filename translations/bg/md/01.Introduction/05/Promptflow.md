<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3cbe7629d254f1043193b7fe22524d55",
  "translation_date": "2025-07-16T22:44:49+00:00",
  "source_file": "md/01.Introduction/05/Promptflow.md",
  "language_code": "bg"
}
-->
# **Въведение в Promptflow**

[Microsoft Prompt Flow](https://microsoft.github.io/promptflow/index.html?WT.mc_id=aiml-138114-kinfeylo) е визуален инструмент за автоматизация на работни потоци, който позволява на потребителите да създават автоматизирани процеси, използвайки предварително изградени шаблони и персонализирани конектори. Той е създаден, за да даде възможност на разработчици и бизнес анализатори бързо да изграждат автоматизирани процеси за задачи като управление на данни, сътрудничество и оптимизация на процеси. С Prompt Flow потребителите могат лесно да свързват различни услуги, приложения и системи и да автоматизират сложни бизнес процеси.

Microsoft Prompt Flow е проектиран да опрости целия цикъл на разработка на AI приложения, базирани на големи езикови модели (LLMs). Независимо дали създавате идеи, прототипирате, тествате, оценявате или внедрявате приложения, базирани на LLM, Prompt Flow улеснява процеса и ви позволява да изграждате LLM приложения с производствено качество.

## Основни характеристики и предимства на Microsoft Prompt Flow:

**Интерактивно създаване**

Prompt Flow предоставя визуално представяне на структурата на вашия поток, което улеснява разбирането и навигацията в проектите ви.  
Предлага опит, подобен на тетрадка, за ефективно разработване и отстраняване на грешки в потоците.

**Варианти и настройка на подсказки**

Създавайте и сравнявайте множество варианти на подсказки, за да улесните итеративния процес на усъвършенстване. Оценявайте представянето на различни подсказки и избирайте най-ефективните.

**Вградени оценъчни потоци**  
Оценявайте качеството и ефективността на вашите подсказки и потоци с помощта на вградени инструменти за оценка.  
Разберете колко добре се представят вашите приложения, базирани на LLM.

**Обширни ресурси**

Prompt Flow включва библиотека с вградени инструменти, примери и шаблони. Тези ресурси служат като отправна точка за разработка, вдъхновяват креативността и ускоряват процеса.

**Сътрудничество и готовност за корпоративна употреба**

Поддържа екипна работа, позволявайки на множество потребители да работят заедно по проекти за инженеринг на подсказки.  
Поддържа контрол на версиите и ефективно споделяне на знания. Оптимизира целия процес на инженеринг на подсказки – от разработка и оценка до внедряване и мониторинг.

## Оценка в Prompt Flow

В Microsoft Prompt Flow оценката играе ключова роля за преценяване на представянето на вашите AI модели. Нека разгледаме как можете да персонализирате оценъчните потоци и метрики в Prompt Flow:

![PFVizualise](../../../../../translated_images/pfvisualize.c1d9ca75baa2a2221667124fa82ba2307f74a34620b9c1eff2cfc1fa2972909b.bg.png)

**Разбиране на оценката в Prompt Flow**

В Prompt Flow потокът представлява последователност от възли, които обработват входни данни и генерират изход. Оценъчните потоци са специален тип потоци, предназначени да оценят представянето на изпълнението според конкретни критерии и цели.

**Основни характеристики на оценъчните потоци**

Обикновено се изпълняват след тествания поток, използвайки неговите изходи. Изчисляват резултати или метрики, за да измерят представянето на тествания поток. Метриките могат да включват точност, оценки за релевантност или други подходящи показатели.

### Персонализиране на оценъчни потоци

**Дефиниране на входове**

Оценъчните потоци трябва да приемат изходите от тестваното изпълнение. Дефинирайте входовете по същия начин като при стандартните потоци.  
Например, ако оценявате QnA поток, наименувайте входа „answer“. Ако оценявате поток за класификация, наименувайте входа „category“. Може да са необходими и входове с истински стойности (например реални етикети).

**Изходи и метрики**

Оценъчните потоци генерират резултати, които измерват представянето на тествания поток. Метриките могат да се изчисляват с Python или LLM. Използвайте функцията log_metric(), за да записвате съответните метрики.

**Използване на персонализирани оценъчни потоци**

Разработете собствен оценъчен поток, съобразен с вашите конкретни задачи и цели. Персонализирайте метриките според вашите нужди за оценка.  
Прилагайте този персонализиран оценъчен поток за пакетни изпълнения при мащабно тестване.

## Вградени методи за оценка

Prompt Flow предлага и вградени методи за оценка.  
Можете да изпращате пакетни изпълнения и да използвате тези методи, за да оцените колко добре се представя вашият поток с големи набори от данни.  
Преглеждайте резултатите от оценката, сравнявайте метриките и правете необходимите итерации.  
Не забравяйте, че оценката е от съществено значение за гарантиране, че вашите AI модели отговарят на желаните критерии и цели. Разгледайте официалната документация за подробни инструкции за разработване и използване на оценъчни потоци в Microsoft Prompt Flow.

В обобщение, Microsoft Prompt Flow дава възможност на разработчиците да създават висококачествени LLM приложения, като опростява инженерството на подсказки и предоставя стабилна среда за разработка. Ако работите с LLM, Prompt Flow е ценен инструмент за изследване. Разгледайте [Prompt Flow Evaluation Documents](https://learn.microsoft.com/azure/machine-learning/prompt-flow/how-to-develop-an-evaluation-flow?view=azureml-api-2?WT.mc_id=aiml-138114-kinfeylo) за подробни инструкции за разработване и използване на оценъчни потоци в Microsoft Prompt Flow.

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI преводаческа услуга [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи могат да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или неправилни тълкувания, произтичащи от използването на този превод.