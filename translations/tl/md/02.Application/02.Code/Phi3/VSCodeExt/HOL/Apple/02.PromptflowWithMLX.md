<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3dbbf568625b1ee04b354c2dc81d3248",
  "translation_date": "2025-05-09T19:40:50+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/Apple/02.PromptflowWithMLX.md",
  "language_code": "tl"
}
-->
# **Lab 2 - Patakbuhin ang Prompt flow gamit ang Phi-3-mini sa AIPC**

## **Ano ang Prompt flow**

Ang Prompt flow ay isang hanay ng mga development tools na idinisenyo upang gawing mas madali ang buong proseso ng pagbuo ng mga LLM-based AI application, mula sa ideya, prototyping, testing, pagsusuri, hanggang sa deployment at monitoring sa production. Pinapadali nito ang prompt engineering at nagbibigay-daan upang makagawa ka ng LLM apps na may kalidad pang-production.

Sa Prompt flow, magagawa mong:

- Gumawa ng mga flow na nag-uugnay ng LLMs, prompts, Python code, at iba pang tools sa isang executable na workflow.

- I-debug at i-iterate ang iyong mga flow, lalo na ang pakikipag-ugnayan sa LLMs nang madali.

- Suriin ang iyong mga flow, kalkulahin ang kalidad at performance gamit ang mas malalaking dataset.

- Isama ang testing at evaluation sa iyong CI/CD system para matiyak ang kalidad ng iyong flow.

- I-deploy ang iyong mga flow sa platform na gusto mo o isama ito sa code base ng iyong app nang madali.

- (Opsyonal pero lubos na inirerekomenda) Makipagtulungan sa iyong team gamit ang cloud version ng Prompt flow sa Azure AI.

## **Pagbuo ng generation code flows sa Apple Silicon**

***Note*** ï¼šKung hindi mo pa natapos ang pag-install ng environment, bisitahin ang [Lab 0 -Installations](./01.Installations.md)

1. Buksan ang Prompt flow Extension sa Visual Studio Code at gumawa ng isang empty flow project

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.tl.png)

2. Magdagdag ng Inputs at Outputs na parameters at magdagdag ng Python Code bilang bagong flow

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.tl.png)

Maaari mong sundan ang istrukturang ito (flow.dag.yaml) para buuin ang iyong flow

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. I-quantify ang phi-3-mini

Nais naming mas mapatakbo nang maayos ang SLM sa lokal na mga device. Karaniwan, ini-quantify namin ang modelo (INT4, FP16, FP32)

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Note:** ang default folder ay mlx_model

4. Magdagdag ng Code sa ***Chat_With_Phi3.py***

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. Maaari mong subukan ang flow mula sa Debug o Run upang tingnan kung maayos ang generation code

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.tl.png)

5. Patakbuhin ang flow bilang development API sa terminal

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Maaari mo itong subukan sa Postman / Thunder Client

### **Note**

1. Ang unang pagtakbo ay tumatagal ng matagal. Inirerekomenda na i-download ang phi-3 model mula sa Hugging face CLI.

2. Dahil sa limitadong computing power ng Intel NPU, inirerekomenda gamitin ang Phi-3-mini-4k-instruct

3. Ginagamit namin ang Intel NPU Acceleration para i-quantize sa INT4 conversion, pero kung uulitin mong patakbuhin ang serbisyo, kailangan mong burahin ang cache at nc_workshop folders.

## **Resources**

1. Matutunan ang Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Matutunan ang Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Sample Code, i-download ang [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kaming maging tumpak, pakatandaan na ang mga awtomatikong salin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na opisyal na sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng salin na ito.