<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-07-17T04:00:39+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "tl"
}
-->
# **Lab 2 - Patakbuhin ang Prompt flow gamit ang Phi-3-mini sa AIPC**

## **Ano ang Prompt flow**

Ang Prompt flow ay isang hanay ng mga kasangkapan sa pag-develop na idinisenyo upang gawing mas madali ang buong proseso ng pagbuo ng mga AI application na batay sa LLM, mula sa pag-iisip ng ideya, paggawa ng prototype, pagsubok, pagsusuri hanggang sa deployment at pagmamanman sa produksyon. Pinapadali nito ang prompt engineering at nagbibigay-daan sa iyo na makabuo ng mga LLM app na may kalidad para sa produksyon.

Sa pamamagitan ng prompt flow, magagawa mong:

- Gumawa ng mga flow na nag-uugnay sa LLMs, prompts, Python code, at iba pang mga kasangkapan sa isang executable na workflow.

- I-debug at ulitin ang iyong mga flow, lalo na ang pakikipag-ugnayan sa LLMs nang madali.

- Suriin ang iyong mga flow, kalkulahin ang kalidad at mga performance metrics gamit ang mas malalaking dataset.

- Isama ang pagsubok at pagsusuri sa iyong CI/CD system upang matiyak ang kalidad ng iyong flow.

- I-deploy ang iyong mga flow sa platform na iyong pinili o isama ito sa code base ng iyong app nang madali.

- (Opsyonal ngunit lubos na inirerekomenda) Makipagtulungan sa iyong koponan gamit ang cloud version ng Prompt flow sa Azure AI.

## **Ano ang AIPC**

Ang AI PC ay may CPU, GPU, at NPU, bawat isa ay may partikular na kakayahan sa AI acceleration. Ang NPU, o neural processing unit, ay isang espesyal na accelerator na humahawak ng mga gawain sa artificial intelligence (AI) at machine learning (ML) nang direkta sa iyong PC sa halip na ipadala ang data para iproseso sa cloud. Maaari ring iproseso ng GPU at CPU ang mga trabahong ito, ngunit ang NPU ay partikular na mahusay sa mga low-power AI calculations. Ang AI PC ay kumakatawan sa isang pangunahing pagbabago sa paraan ng pagpapatakbo ng ating mga computer. Hindi ito solusyon sa isang problemang dati ay wala, kundi isang malaking pag-unlad para sa pang-araw-araw na paggamit ng PC.

Paano ito gumagana? Kung ikukumpara sa generative AI at sa malalaking language models (LLMs) na sinanay gamit ang napakaraming pampublikong data, ang AI na tatakbo sa iyong PC ay mas madaling ma-access sa halos lahat ng antas. Mas madaling maintindihan ang konsepto, at dahil ito ay sinanay gamit ang iyong data, nang hindi na kailangang kumonekta sa cloud, mas agad na kapaki-pakinabang ito sa mas malawak na populasyon.

Sa malapit na hinaharap, ang mundo ng AI PC ay kinabibilangan ng mga personal assistant at mas maliliit na AI model na tumatakbo nang direkta sa iyong PC, gamit ang iyong data upang magbigay ng personal, pribado, at mas ligtas na AI na mga pagpapahusay para sa mga bagay na ginagawa mo araw-araw – tulad ng pagkuha ng tala sa mga pulong, pag-aayos ng fantasy football league, pag-automate ng mga pagpapahusay sa pag-edit ng larawan at video, o paggawa ng perpektong itinerary para sa isang family reunion base sa oras ng pagdating at pag-alis ng bawat isa.

## **Pagbuo ng generation code flows sa AIPC**

***Note*** ：Kung hindi mo pa natatapos ang pag-install ng environment, bisitahin ang [Lab 0 -Installations](./01.Installations.md)

1. Buksan ang Prompt flow Extension sa Visual Studio Code at gumawa ng isang empty flow project

![create](../../../../../../../../../translated_images/pf_create.bde888dc83502eba082a058175bbf1eee6791219795393a386b06fd3043ec54d.tl.png)

2. Magdagdag ng Inputs at Outputs na mga parameter at magdagdag ng Python Code bilang bagong flow

![flow](../../../../../../../../../translated_images/pf_flow.520824c0969f2a94f17e947f86bdc4b4c6c88a2efa394fe3bcfb58c0dbc578a7.tl.png)

Maaari mong sundan ang istrukturang ito (flow.dag.yaml) para buuin ang iyong flow

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Magdagdag ng Code sa ***Chat_With_Phi3.py***

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Maaari mong subukan ang flow mula sa Debug o Run upang tingnan kung maayos ang generation code

![RUN](../../../../../../../../../translated_images/pf_run.4239e8a0b420a58284edf6ee1471c1697c345670313c8e7beac0edaee15b9a9d.tl.png)

5. Patakbuhin ang flow bilang development API sa terminal

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Maaari mo itong subukan sa Postman / Thunder Client

### **Note**

1. Ang unang pagtakbo ay tumatagal ng matagal. Inirerekomenda na i-download ang phi-3 model mula sa Hugging face CLI.

2. Dahil sa limitadong computing power ng Intel NPU, inirerekomenda ang paggamit ng Phi-3-mini-4k-instruct

3. Ginagamit namin ang Intel NPU Acceleration para sa INT4 quantization conversion, ngunit kung uulitin mong patakbuhin ang serbisyo, kailangan mong tanggalin ang cache at nc_workshop na mga folder.

## **Mga Resources**

1. Matutunan ang Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Matutunan ang Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Sample Code, i-download ang [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o di-tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.