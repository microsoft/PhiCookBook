<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd049872f37c3079c87d4fe17109cea0",
  "translation_date": "2025-07-16T18:20:05+00:00",
  "source_file": "md/01.Introduction/01/01.Guidance.md",
  "language_code": "tl"
}
-->
### Guidance-AI at Phi Models bilang Serbisyo (MaaS)
Inilalapit namin ang [Guidance](https://github.com/guidance-ai/guidance) sa Phi-3.5-mini serverless endpoint na inaalok sa Azure AI Foundry upang gawing mas predictable ang mga output sa pamamagitan ng pagtukoy ng istruktura na angkop sa isang aplikasyon. Sa Guidance, maiiwasan mo ang magastos na mga retry, at maaari mong, halimbawa, limitahan ang modelo na pumili mula sa mga pre-defined na listahan (hal., mga medical code), higpitan ang mga output sa mga direktang sipi mula sa ibinigay na konteksto, o sundan ang anumang regex. Pinapatnubayan ng Guidance ang modelo token-by-token sa inference stack, na nagpapababa ng gastos at latency ng 30-50%, kaya ito ay isang natatangi at mahalagang dagdag sa [Phi-3-mini serverless endpoint](https://aka.ms/try-phi3.5mini).

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) ay isang framework na idinisenyo upang tulungan ang mga developer na gumawa at mag-deploy ng mga AI model nang mas epektibo. Nakatuon ito sa pagbibigay ng mga kasangkapan at pinakamahusay na mga pamamaraan para sa pagbuo ng matibay na AI na aplikasyon.

Kapag pinagsama sa **Phi Models bilang Serbisyo (MaaS)**, nag-aalok ito ng makapangyarihang solusyon para sa pag-deploy ng maliliit na language model (SLMs) na parehong cost-effective at mataas ang performance.

**Guidance-AI** ay isang programming framework na idinisenyo upang tulungan ang mga developer na kontrolin at patnubayan ang malalaking language model (LLMs) nang mas epektibo. Pinapayagan nito ang tumpak na pag-istruktura ng mga output, na nagpapababa ng latency at gastos kumpara sa tradisyunal na prompting o fine-tuning na mga pamamaraan.

### Pangunahing Tampok ng Guidance-AI:
- **Epektibong Kontrol**: Pinapahintulutan ang mga developer na kontrolin kung paano bumubuo ng teksto ang language model, na tinitiyak ang mataas na kalidad at may kaugnayang mga output.
- **Pagbawas ng Gastos at Latency**: Ina-optimize ang proseso ng pagbuo upang maging mas mura at mas mabilis.
- **Flexible na Integrasyon**: Gumagana sa iba't ibang backend, kabilang ang Transformers, llama.cpp, AzureAI, VertexAI, at OpenAI.
- **Mayamang Istruktura ng Output**: Sinusuportahan ang komplikadong istruktura ng output tulad ng conditionals, loops, at paggamit ng mga tool, na nagpapadali sa pagbuo ng malinaw at madaling i-parse na mga resulta.
- **Kompatibilidad**: Pinapayagan ang isang Guidance program na patakbuhin sa maraming backend, na nagpapalawak ng flexibility at kadalian ng paggamit.

### Mga Halimbawa ng Paggamit:
- **Constrained Generation**: Paggamit ng regular expressions at context-free grammars upang gabayan ang output ng modelo.
- **Tool Integration**: Awtomatikong pinagsasama ang kontrol at pagbuo, tulad ng paggamit ng calculator sa loob ng isang text generation na gawain.

Para sa mas detalyadong impormasyon at mga halimbawa, maaari mong bisitahin ang [Guidance-AI GitHub repository](https://github.com/guidance-ai/guidance).

[Tingnan ang Phi-3.5 Sample](../../../../../code/01.Introduce/guidance.ipynb)

### Pangunahing Tampok ng Phi Models:
1. **Cost-Effective**: Dinisenyo upang maging abot-kaya habang pinapanatili ang mataas na performance.
2. **Mababang Latency**: Perpekto para sa mga real-time na aplikasyon na nangangailangan ng mabilis na tugon.
3. **Flexibility**: Maaaring i-deploy sa iba't ibang kapaligiran, kabilang ang cloud, edge, at offline na mga sitwasyon.
4. **Customization**: Maaaring i-fine-tune ang mga modelo gamit ang domain-specific na data upang mapabuti ang performance.
5. **Seguridad at Pagsunod**: Binubuo ayon sa mga prinsipyo ng AI ng Microsoft, na tinitiyak ang pananagutan, transparency, katarungan, pagiging maaasahan, kaligtasan, privacy, at pagiging inklusibo.

### Phi Models bilang Serbisyo (MaaS):
Ang mga Phi model ay available sa pamamagitan ng pay-as-you-go na sistema ng pagsingil gamit ang inference APIs, na nagpapadali sa pag-integrate nito sa iyong mga aplikasyon nang walang malaking paunang gastos.

### Pagsisimula sa Phi-3:
Para magsimula gamit ang Phi models, maaari mong tuklasin ang [Azure AI model catalog](https://ai.azure.com/explore/models) o ang [GitHub Marketplace Models](https://github.com/marketplace/models) na nag-aalok ng mga prebuilt at customizable na mga modelo. Bukod dito, maaari kang gumamit ng mga kasangkapan tulad ng [Azure AI Foundry](https://ai.azure.com) upang bumuo at mag-deploy ng iyong mga AI na aplikasyon.

### Mga Sanggunian
[Sample Notebook sa pagsisimula gamit ang Guidance](../../../../../code/01.Introduce/guidance.ipynb)

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o di-tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.