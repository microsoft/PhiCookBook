<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd049872f37c3079c87d4fe17109cea0",
  "translation_date": "2025-05-09T07:39:13+00:00",
  "source_file": "md/01.Introduction/01/01.Guidance.md",
  "language_code": "tl"
}
-->
### Guidance-AI at Phi Models bilang Serbisyo (MaaS)
Ipinapakilala namin ang [Guidance](https://github.com/guidance-ai/guidance) sa Phi-3.5-mini serverless endpoint sa Azure AI Foundry upang gawing mas predictable ang mga output sa pamamagitan ng pagdedetalye ng istruktura na angkop sa isang aplikasyon. Sa Guidance, maiiwasan mo ang magastos na pag-ulit, at halimbawa, maaari mong limitahan ang modelo na pumili mula sa mga pre-defined na listahan (hal., mga medical code), pigilan ang output na lumabas lamang bilang direktang sipi mula sa ibinigay na konteksto, o sundan ang anumang regex. Pinapatnubayan ng Guidance ang modelo token-by-token sa inference stack, na nagpapababa ng gastos at latency ng 30-50%, kaya't ito ay isang natatangi at mahalagang dagdag sa [Phi-3-mini serverless endpoint](https://aka.ms/try-phi3.5mini).

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) ay isang framework na idinisenyo upang tulungan ang mga developer na lumikha at mag-deploy ng AI models nang mas epektibo. Nakatuon ito sa pagbibigay ng mga tools at best practices para makabuo ng matibay na AI applications.

Kapag pinagsama sa **Phi Models bilang Serbisyo (MaaS)**, nag-aalok ito ng malakas na solusyon para sa pag-deploy ng maliliit na language models (SLMs) na parehong cost-effective at mataas ang performance.

**Guidance-AI** ay isang programming framework na ginawa upang tulungan ang mga developer na mas kontrolin at gabayan ang malalaking language models (LLMs) nang mas epektibo. Pinapayagan nito ang tumpak na pag-istruktura ng mga output, na nagpapababa ng latency at gastos kumpara sa tradisyunal na prompting o fine-tuning na mga paraan.

### Pangunahing Tampok ng Guidance-AI:
- **Mabisang Kontrol**: Pinapahintulutan ang mga developer na kontrolin kung paano gagawa ng teksto ang language model, upang matiyak ang mataas na kalidad at kaugnay na mga output.
- **Pagbawas ng Gastos at Latency**: Ina-optimize ang proseso ng pagbuo upang maging mas mura at mabilis.
- **Flexible na Integrasyon**: Gumagana sa iba't ibang backends, kabilang ang Transformers, llama.cpp, AzureAI, VertexAI, at OpenAI.
- **Masalimuot na Istruktura ng Output**: Sinusuportahan ang mga komplikadong istruktura ng output tulad ng conditionals, loops, at paggamit ng mga tools, na nagpapadali sa paggawa ng malinaw at madaling i-parse na resulta.
- **Compatibility**: Pinapayagan ang isang Guidance program na tumakbo sa iba't ibang backends, na nagpapalawak ng flexibility at kadalian ng paggamit.

### Halimbawa ng mga Paggamit:
- **Pinigilang Pagbuo**: Paggamit ng regular expressions at context-free grammars upang gabayan ang output ng modelo.
- **Integrasyon ng Tool**: Awtomatikong pinagsasama ang kontrol at pagbuo, tulad ng paggamit ng calculator sa loob ng gawain ng text generation.

Para sa mas detalyadong impormasyon at mga halimbawa, bisitahin ang [Guidance-AI GitHub repository](https://github.com/guidance-ai/guidance).

[Tingnan ang Phi-3.5 Sample](../../../../../code/01.Introduce/guidance.ipynb)

### Pangunahing Tampok ng Phi Models:
1. **Abot-kaya**: Dinisenyo upang maging mura habang pinapanatili ang mataas na performance.
2. **Mababang Latency**: Perpekto para sa mga real-time na aplikasyon na nangangailangan ng mabilis na tugon.
3. **Flexible**: Maaaring i-deploy sa iba't ibang kapaligiran, kabilang ang cloud, edge, at offline na mga sitwasyon.
4. **Pasadyang Pag-aayos**: Maaaring i-fine-tune ang mga modelo gamit ang domain-specific na data upang mapabuti ang performance.
5. **Seguridad at Pagsunod**: Ginawa alinsunod sa mga prinsipyo ng AI ng Microsoft, na tinitiyak ang pananagutan, transparency, katarungan, pagiging maaasahan, kaligtasan, privacy, at inklusibidad.

### Phi Models bilang Serbisyo (MaaS):
Ang mga Phi models ay available sa pamamagitan ng pay-as-you-go na sistema ng pagbabayad gamit ang inference APIs, kaya madali itong maisama sa iyong mga aplikasyon nang walang malaking paunang gastos.

### Pagsisimula sa Phi-3:
Para magsimula sa paggamit ng Phi models, maaari mong tingnan ang [Azure AI model catalog](https://ai.azure.com/explore/models) o ang [GitHub Marketplace Models](https://github.com/marketplace/models) na nag-aalok ng mga prebuilt at customizable na mga modelo. Bukod dito, maaari mong gamitin ang mga tools tulad ng [Azure AI Foundry](https://ai.azure.com) para bumuo at mag-deploy ng iyong mga AI application.

### Mga Resources
[Sample Notebook sa pagsisimula gamit ang Guidance](../../../../../code/01.Introduce/guidance.ipynb)

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang serbisyong AI na pagsasalin [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o di-tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.