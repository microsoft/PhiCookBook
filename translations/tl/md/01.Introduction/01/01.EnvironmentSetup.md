# Magsimula sa Phi-3 nang lokal

Tutulungan ka ng gabay na ito na i-setup ang iyong lokal na kapaligiran para patakbuhin ang Phi-3 model gamit ang Ollama. Maaari mong patakbuhin ang model sa ilang paraan, kabilang ang paggamit ng GitHub Codespaces, VS Code Dev Containers, o ang iyong lokal na kapaligiran.

## Pag-setup ng Kapaligiran

### GitHub Codespaces

Maaari mong patakbuhin ang template na ito nang virtual gamit ang GitHub Codespaces. Ang button ay magbubukas ng web-based na VS Code instance sa iyong browser:

1. Buksan ang template (maaari itong tumagal ng ilang minuto):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buksan ang terminal window

### VS Code Dev Containers

⚠️ Ang opsyong ito ay gagana lamang kung ang Docker Desktop mo ay naka-allocate ng hindi bababa sa 16 GB ng RAM. Kung mas mababa sa 16 GB ang RAM mo, maaari mong subukan ang [GitHub Codespaces option](../../../../../md/01.Introduction/01) o [i-setup ito nang lokal](../../../../../md/01.Introduction/01).

Isang kaugnay na opsyon ang VS Code Dev Containers, na magbubukas ng proyekto sa iyong lokal na VS Code gamit ang [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Simulan ang Docker Desktop (i-install ito kung hindi pa naka-install)
2. Buksan ang proyekto:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Sa VS Code window na magbubukas, kapag lumabas na ang mga file ng proyekto (maaari itong tumagal ng ilang minuto), buksan ang terminal window.
4. Ipagpatuloy ang [deployment steps](../../../../../md/01.Introduction/01)

### Lokal na Kapaligiran

1. Siguraduhing naka-install ang mga sumusunod na tools:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Subukan ang model

1. Hilingin sa Ollama na i-download at patakbuhin ang phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Aabutin ng ilang minuto para ma-download ang model.

2. Kapag nakita mo na ang "success" sa output, maaari ka nang magpadala ng mensahe sa model mula sa prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Pagkalipas ng ilang segundo, makikita mo ang response stream mula sa model.

4. Para matutunan ang iba't ibang teknik na ginagamit sa mga language model, buksan ang Python notebook na [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) at patakbuhin ang bawat cell. Kung gumamit ka ng model na iba sa 'phi3:mini', palitan ang `MODEL_NAME` sa unang cell.

5. Para makipag-usap sa phi3:mini model mula sa Python, buksan ang Python file na [chat.py](../../../../../code/01.Introduce/chat.py) at patakbuhin ito. Maaari mong baguhin ang `MODEL_NAME` sa itaas ng file kung kinakailangan, at maaari mo ring i-modify ang system message o magdagdag ng few-shot examples kung nais mo.

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o di-tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.