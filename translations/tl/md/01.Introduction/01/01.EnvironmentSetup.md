<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:15:04+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "tl"
}
-->
# Magsimula sa Phi-3 nang lokal

Tutulungan ka ng gabay na ito na i-setup ang iyong lokal na kapaligiran para patakbuhin ang Phi-3 model gamit ang Ollama. Maaari mong patakbuhin ang model sa ilang paraan, kabilang ang paggamit ng GitHub Codespaces, VS Code Dev Containers, o ang iyong lokal na kapaligiran.

## Pagsasaayos ng Kapaligiran

### GitHub Codespaces

Maaari mong patakbuhin ang template na ito nang virtual gamit ang GitHub Codespaces. Bubuksan ng button ang isang web-based na VS Code instance sa iyong browser:

1. Buksan ang template (maaari itong tumagal ng ilang minuto):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buksan ang terminal window

### VS Code Dev Containers

⚠️ Gagana lang ang opsyong ito kung ang Docker Desktop mo ay may nakalaan na hindi bababa sa 16 GB na RAM. Kung kulang ka sa 16 GB RAM, maaari mong subukan ang [GitHub Codespaces option](../../../../../md/01.Introduction/01) o [i-setup ito nang lokal](../../../../../md/01.Introduction/01).

Isang kaugnay na opsyon ay ang VS Code Dev Containers, na magbubukas ng proyekto sa iyong lokal na VS Code gamit ang [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Simulan ang Docker Desktop (i-install ito kung hindi pa naka-install)
2. Buksan ang proyekto:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Sa VS Code window na magbubukas, kapag lumabas na ang mga file ng proyekto (maaari itong tumagal ng ilang minuto), buksan ang terminal window.
4. Magpatuloy sa mga [deployment steps](../../../../../md/01.Introduction/01)

### Lokal na Kapaligiran

1. Siguraduhing naka-install ang mga sumusunod na tools:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Subukan ang model

1. Hilingin sa Ollama na i-download at patakbuhin ang phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Tatagal ng ilang minuto bago ma-download ang model.

2. Kapag nakita mo na ang "success" sa output, maaari ka nang magpadala ng mensahe sa model mula sa prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Pagkalipas ng ilang segundo, makikita mo ang stream ng sagot mula sa model.

4. Para matutunan ang iba't ibang teknik na ginagamit sa mga language model, buksan ang Python notebook na [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) at patakbuhin ang bawat cell. Kung gumamit ka ng model na iba sa 'phi3:mini', palitan ang `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` sa taas ng file ayon sa kailangan, at maaari mo ring baguhin ang system message o magdagdag ng few-shot examples kung nais.

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kaming maging tumpak, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pinagmumulan ng katotohanan. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.