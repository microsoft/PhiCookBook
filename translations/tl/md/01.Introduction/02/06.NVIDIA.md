<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-07-16T19:38:47+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "tl"
}
-->
## Phi Family sa NVIDIA NIM

Ang NVIDIA NIM ay isang hanay ng madaling gamitin na microservices na idinisenyo upang pabilisin ang deployment ng mga generative AI models sa cloud, data center, at mga workstation. Ang mga NIM ay naka-kategorya ayon sa pamilya ng modelo at bawat modelo. Halimbawa, ang NVIDIA NIM para sa malalaking language models (LLMs) ay nagdadala ng kapangyarihan ng mga makabagong LLM sa mga enterprise application, na nagbibigay ng walang kapantay na kakayahan sa natural language processing at pag-unawa.

Pinapadali ng NIM para sa mga IT at DevOps team na mag-self-host ng malalaking language models (LLMs) sa kanilang sariling managed na kapaligiran habang nagbibigay pa rin sa mga developer ng industry standard na APIs na nagpapahintulot sa kanila na bumuo ng makapangyarihang copilots, chatbots, at AI assistants na kayang baguhin ang kanilang negosyo. Sa paggamit ng cutting-edge GPU acceleration ng NVIDIA at scalable deployment, nag-aalok ang NIM ng pinakamabilis na daan patungo sa inference na may walang kapantay na performance.

Maaari mong gamitin ang NVIDIA NIM para mag-inference ng Phi Family Models

![nim](../../../../../translated_images/Phi-NIM.09bebb743387ee4a5028d7d4f8fed55e619711b26c8937526b43a2af980f7dcf.tl.png)

### **Mga Halimbawa - Phi-3-Vision sa NVIDIA NIM**

Isipin na mayroon kang isang larawan (`demo.png`) at nais mong gumawa ng Python code na magpoproseso sa larawang ito at magsa-save ng bagong bersyon nito (`phi-3-vision.jpg`).

Ang code sa itaas ay awtomatikong ginagawa ang prosesong ito sa pamamagitan ng:

1. Pagsasaayos ng environment at mga kinakailangang configuration.
2. Paglikha ng prompt na nag-uutos sa modelo na gumawa ng kinakailangang Python code.
3. Pagpapadala ng prompt sa modelo at pagkolekta ng nagawang code.
4. Pagkuha at pagpapatakbo ng nagawang code.
5. Pagpapakita ng orihinal at na-prosesong mga larawan.

Ginagamit ng pamamaraang ito ang kapangyarihan ng AI upang i-automate ang mga gawain sa pagproseso ng larawan, na nagpapadali at nagpapabilis sa pag-abot ng iyong mga layunin.

[Sample Code Solution](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

Hatiin natin ang ginagawa ng buong code nang hakbang-hakbang:

1. **I-install ang Kinakailangang Package**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    Ini-install ng utos na ito ang `langchain_nvidia_ai_endpoints` package, tinitiyak na ito ay ang pinakabagong bersyon.

2. **I-import ang Mga Kinakailangang Module**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    Ang mga import na ito ay nagdadala ng mga kinakailangang module para makipag-ugnayan sa NVIDIA AI endpoints, ligtas na paghawak ng mga password, pakikipag-ugnayan sa operating system, at pag-encode/decode ng data sa base64 na format.

3. **I-set Up ang API Key**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    Tinitingnan ng code na ito kung naka-set ang `NVIDIA_API_KEY` environment variable. Kung wala, hinihikayat nito ang user na ligtas na ilagay ang kanilang API key.

4. **Itakda ang Modelo at Path ng Larawan**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    Itinatakda nito ang modelong gagamitin, lumilikha ng instance ng `ChatNVIDIA` gamit ang tinukoy na modelo, at tinutukoy ang path ng file ng larawan.

5. **Gumawa ng Text Prompt**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    Itinatakda nito ang text prompt na nag-uutos sa modelo na gumawa ng Python code para sa pagproseso ng larawan.

6. **I-encode ang Larawan sa Base64**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    Binabasa ng code na ito ang file ng larawan, ini-encode ito sa base64, at lumilikha ng HTML image tag gamit ang naka-encode na data.

7. **Pagsamahin ang Text at Larawan sa Prompt**:
    ```python
    prompt = f"{text} {image}"
    ```
    Pinagsasama nito ang text prompt at ang HTML image tag sa isang string.

8. **Gumawa ng Code Gamit ang ChatNVIDIA**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    Pinapadala ng code na ito ang prompt sa `ChatNVIDIA` model at kinokolekta ang nagawang code nang paunti-unti, ipinapakita at idinadagdag ang bawat bahagi sa string na `code`.

9. **Kunin ang Python Code mula sa Nagawang Nilalaman**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    Kinukuha nito ang aktwal na Python code mula sa nagawang nilalaman sa pamamagitan ng pagtanggal ng markdown formatting.

10. **Patakbuhin ang Nagawang Code**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    Pinapatakbo nito ang nakuha na Python code bilang subprocess at kinukuha ang output nito.

11. **Ipakita ang mga Larawan**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    Ipinapakita ng mga linyang ito ang mga larawan gamit ang `IPython.display` module.

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o di-tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.