<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4951d458c0b60c02cd1e751b40903877",
  "translation_date": "2025-05-09T09:41:52+00:00",
  "source_file": "md/01.Introduction/02/05.AITK.md",
  "language_code": "tl"
}
-->
# Phi Family sa AITK

[AI Toolkit para sa VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) ay nagpapadali ng paggawa ng generative AI apps sa pamamagitan ng pagsasama-sama ng mga makabagong AI development tools at mga modelo mula sa Azure AI Foundry Catalog at iba pang mga katalogo tulad ng Hugging Face. Maaari mong tingnan ang AI models catalog na pinapagana ng GitHub Models at Azure AI Foundry Model Catalogs, i-download ito locally o remote, i-fine-tune, subukan, at gamitin sa iyong aplikasyon.

Ang AI Toolkit Preview ay tatakbo locally. Local inference o fine-tune, depende sa modelong pinili mo, maaaring kailanganin mong magkaroon ng GPU tulad ng NVIDIA CUDA GPU. Maaari mo ring patakbuhin ang GitHub Models nang direkta gamit ang AITK.

## Pagsisimula

[Alamin kung paano mag-install ng Windows subsystem para sa Linux](https://learn.microsoft.com/windows/wsl/install?WT.mc_id=aiml-137032-kinfeylo)

at [pagpalit ng default na distribusyon](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

[AI Tooklit GitHub Repo](https://github.com/microsoft/vscode-ai-toolkit/)

- Windows, Linux, macOS
  
- Para sa finetuning sa parehong Windows at Linux, kailangan mo ng Nvidia GPU. Bukod dito, **Windows** ay nangangailangan ng subsystem para sa Linux na may Ubuntu distro 18.4 pataas. [Alamin kung paano mag-install ng Windows subsystem para sa Linux](https://learn.microsoft.com/windows/wsl/install) at [pagpalit ng default na distribusyon](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

### Pag-install ng AI Toolkit

Ang AI Toolkit ay ipinapadala bilang isang [Visual Studio Code Extension](https://code.visualstudio.com/docs/setup/additional-components#_vs-code-extensions), kaya kailangan mo munang mag-install ng [VS Code](https://code.visualstudio.com/docs/setup/windows?WT.mc_id=aiml-137032-kinfeylo), at i-download ang AI Toolkit mula sa [VS Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio).
Ang [AI Toolkit ay available sa Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) at maaaring i-install tulad ng ibang VS Code extension.

Kung hindi ka pamilyar sa pag-install ng VS Code extensions, sundin ang mga hakbang na ito:

### Mag-sign In

1. Sa Activity Bar ng VS Code, piliin ang **Extensions**
1. Sa Extensions Search bar, i-type ang "AI Toolkit"
1. Piliin ang "AI Toolkit for Visual Studio code"
1. Piliin ang **Install**

Handa ka na ngayong gamitin ang extension!

Hihilingin kang mag-sign in sa GitHub, kaya i-click ang "Allow" para magpatuloy. Ire-redirect ka sa GitHub signing page.

Mag-sign in at sundin ang mga hakbang. Pagkatapos ng matagumpay na proseso, ire-redirect ka pabalik sa VS Code.

Kapag na-install na ang extension, makikita mo ang AI Toolkit icon sa iyong Activity Bar.

Tuklasin natin ang mga available na aksyon!

### Mga Available na Aksyon

Ang pangunahing sidebar ng AI Toolkit ay nakaayos sa  

- **Models**
- **Resources**
- **Playground**  
- **Fine-tuning**
- **Evaluation**

Makikita ito sa Resources section. Para makapagsimula, piliin ang **Model Catalog**.

### Mag-download ng modelo mula sa katalogo

Pagkatapos ilunsad ang AI Toolkit mula sa VS Code sidebar, maaari kang pumili mula sa mga sumusunod na opsyon:

![AI toolkit model catalog](../../../../../translated_images/AItoolkitmodel_catalog.eee6b38a71f628501d730ffe9c2ae69b8f18706e7492ac2371423b045485996e.tl.png)

- Hanapin ang suportadong modelo sa **Model Catalog** at i-download ito locally
- Subukan ang model inference sa **Model Playground**
- Fine-tune ang modelo locally o remotely sa **Model Fine-tuning**
- I-deploy ang fine-tuned models sa cloud gamit ang command palette para sa AI Toolkit
- Evaluation ng mga modelo

> [!NOTE]
>
> **GPU Vs CPU**
>
> Mapapansin mo na ipinapakita sa mga model card ang laki ng modelo, platform, at uri ng accelerator (CPU, GPU). Para sa optimized na performance sa **Windows devices na may kahit isang GPU**, piliin ang mga model version na target lang ang Windows.
>
> Tinitiyak nito na may model kang optimized para sa DirectML accelerator.
>
> Ang mga pangalan ng modelo ay nasa format ng
>
> - `{model_name}-{accelerator}-{quantization}-{format}`.
>
>Para makita kung may GPU ang Windows device mo, buksan ang **Task Manager** at piliin ang tab na **Performance**. Kung may GPU(s), makikita ito sa ilalim ng mga pangalang tulad ng "GPU 0" o "GPU 1".

### Patakbuhin ang modelo sa playground

Kapag na-set na lahat ng mga parameter, i-click ang **Generate Project**.

Kapag na-download na ang modelo, piliin ang **Load in Playground** sa model card sa katalogo:

- Simulan ang pag-download ng modelo
- I-install ang lahat ng prerequisites at dependencies
- Gumawa ng VS Code workspace

![Load model in playground](../../../../../translated_images/AItoolkitload_model_into_playground.e442d8013c65406e69471fb4f8e4e3800505255fe1bd7aa9422f02ee715bad57.tl.png)

### Gamitin ang REST API sa iyong aplikasyon

Ang AI Toolkit ay may kasamang local REST API web server **sa port 5272** na gumagamit ng [OpenAI chat completions format](https://platform.openai.com/docs/api-reference/chat/create).

Pinapahintulutan ka nitong subukan ang iyong aplikasyon locally nang hindi kailangan umasa sa cloud AI model service. Halimbawa, ipinapakita ng sumusunod na JSON file kung paano i-configure ang body ng request:

```json
{
    "model": "Phi-4",
    "messages": [
        {
            "role": "user",
            "content": "what is the golden ratio?"
        }
    ],
    "temperature": 0.7,
    "top_p": 1,
    "top_k": 10,
    "max_tokens": 100,
    "stream": true
}
```

Maaari mong subukan ang REST API gamit ang (halimbawa) [Postman](https://www.postman.com/) o ang CURL (Client URL) utility:

```bash
curl -vX POST http://127.0.0.1:5272/v1/chat/completions -H 'Content-Type: application/json' -d @body.json
```

### Paggamit ng OpenAI client library para sa Python

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:5272/v1/", 
    api_key="x" # required for the API but not used
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "what is the golden ratio?",
        }
    ],
    model="Phi-4",
)

print(chat_completion.choices[0].message.content)
```

### Paggamit ng Azure OpenAI client library para sa .NET

Idagdag ang [Azure OpenAI client library para sa .NET](https://www.nuget.org/packages/Azure.AI.OpenAI/) sa iyong proyekto gamit ang NuGet:

```bash
dotnet add {project_name} package Azure.AI.OpenAI --version 1.0.0-beta.17
```

Magdagdag ng C# file na tinatawag na **OverridePolicy.cs** sa iyong proyekto at i-paste ang sumusunod na code:

```csharp
// OverridePolicy.cs
using Azure.Core.Pipeline;
using Azure.Core;

internal partial class OverrideRequestUriPolicy(Uri overrideUri)
    : HttpPipelineSynchronousPolicy
{
    private readonly Uri _overrideUri = overrideUri;

    public override void OnSendingRequest(HttpMessage message)
    {
        message.Request.Uri.Reset(_overrideUri);
    }
}
```

Sunod, i-paste ang sumusunod na code sa iyong **Program.cs** file:

```csharp
// Program.cs
using Azure.AI.OpenAI;

Uri localhostUri = new("http://localhost:5272/v1/chat/completions");

OpenAIClientOptions clientOptions = new();
clientOptions.AddPolicy(
    new OverrideRequestUriPolicy(localhostUri),
    Azure.Core.HttpPipelinePosition.BeforeTransport);
OpenAIClient client = new(openAIApiKey: "unused", clientOptions);

ChatCompletionsOptions options = new()
{
    DeploymentName = "Phi-4",
    Messages =
    {
        new ChatRequestSystemMessage("You are a helpful assistant. Be brief and succinct."),
        new ChatRequestUserMessage("What is the golden ratio?"),
    }
};

StreamingResponse<StreamingChatCompletionsUpdate> streamingChatResponse
    = await client.GetChatCompletionsStreamingAsync(options);

await foreach (StreamingChatCompletionsUpdate chatChunk in streamingChatResponse)
{
    Console.Write(chatChunk.ContentUpdate);
}
```


## Fine Tuning gamit ang AI Toolkit

- Magsimula sa model discovery at playground.
- Model fine-tuning at inference gamit ang local computing resources.
- Remote fine-tuning at inference gamit ang Azure resources

[Fine Tuning gamit ang AI Toolkit](../../03.FineTuning/Finetuning_VSCodeaitoolkit.md)

## AI Toolkit Q&A Resources

Mangyaring tingnan ang aming [Q&A page](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/QA.md) para sa mga karaniwang isyu at solusyon

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.