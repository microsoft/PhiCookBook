<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:46:33+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "tl"
}
-->
# Fine-tune Phi3 gamit ang Olive

Sa halimbawang ito, gagamitin mo ang Olive para:

1. I-fine-tune ang LoRA adapter upang iklasipika ang mga parirala bilang Sad, Joy, Fear, Surprise.
1. Pagsamahin ang mga timbang ng adapter sa base model.
1. I-optimize at i-quantize ang modelo sa `int4`.

Ipapakita rin namin kung paano i-inference ang fine-tuned na modelo gamit ang ONNX Runtime (ORT) Generate API.

> **‚ö†Ô∏è Para sa Fine-tuning, kailangan mong magkaroon ng angkop na GPU - halimbawa, A10, V100, A100.**

## üíæ Install

Gumawa ng bagong Python virtual environment (halimbawa, gamit ang `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Sunod, i-install ang Olive at mga dependencies para sa fine-tuning workflow:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Fine-tune Phi3 gamit ang Olive
Ang [Olive configuration file](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) ay naglalaman ng *workflow* na may mga sumusunod na *passes*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

Sa pangkalahatan, ang workflow na ito ay:

1. I-fine-tune ang Phi3 (sa loob ng 150 na hakbang, na maaari mong baguhin) gamit ang data mula sa [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. Pagsamahin ang mga timbang ng LoRA adapter sa base model. Magkakaroon ka ng isang model artifact sa ONNX format.
1. I-o-optimize ng Model Builder ang modelo para sa ONNX runtime *at* i-quantize ang modelo sa `int4`.

Para patakbuhin ang workflow, gamitin ang:

```bash
olive run --config phrase-classification.json
```

Kapag natapos na ang Olive, ang optimized `int4` fine-tuned Phi3 model ay makikita sa: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Isama ang fine-tuned na Phi3 sa iyong aplikasyon

Para patakbuhin ang app:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Ang sagot ay dapat isang salita na klasipikasyon ng parirala (Sad/Joy/Fear/Surprise).

**Paalala**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.