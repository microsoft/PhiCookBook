<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8cdc17ce0f10535da30b53d23fe1a795",
  "translation_date": "2025-05-09T07:51:08+00:00",
  "source_file": "md/01.Introduction/01/01.Hardwaresupport.md",
  "language_code": "nl"
}
-->
# Phi Hardware Ondersteuning

Microsoft Phi is geoptimaliseerd voor ONNX Runtime en ondersteunt Windows DirectML. Het werkt goed op verschillende soorten hardware, waaronder GPU's, CPU's en zelfs mobiele apparaten.

## Apparaathardware  
Specifiek wordt de volgende hardware ondersteund:

- GPU SKU: RTX 4090 (DirectML)  
- GPU SKU: 1 A100 80GB (CUDA)  
- CPU SKU: Standard F64s v2 (64 vCPU's, 128 GiB geheugen)  

## Mobiele SKU

- Android - Samsung Galaxy S21  
- Apple iPhone 14 of hoger met A16/A17-processor  

## Phi Hardware Specificaties

- Minimale vereiste configuratie.  
- Windows: DirectX 12-compatibele GPU en minimaal 4GB gecombineerd RAM  

CUDA: NVIDIA GPU met Compute Capability >= 7.02  

![HardwareSupport](../../../../../translated_images/01.phihardware.925db5699da7752cf486314e6db087580583cfbcd548970f8a257e31a8aa862c.nl.png)

## onnxruntime draaien op meerdere GPU's

De momenteel beschikbare Phi ONNX-modellen zijn alleen voor 1 GPU. Multi-GPU ondersteuning voor Phi-modellen is mogelijk, maar ORT met 2 GPU's garandeert niet dat het meer doorvoer oplevert dan 2 instanties van ORT. Zie [ONNX Runtime](https://onnxruntime.ai/) voor de laatste updates.

Tijdens [Build 2024 kondigde het GenAI ONNX Team](https://youtu.be/WLW4SE8M9i8?si=EtG04UwDvcjunyfC) aan dat ze multi-instance in plaats van multi-GPU hadden ingeschakeld voor Phi-modellen.

Op dit moment kun je zo één onnxruntime- of onnxruntime-genai-instantie draaien met de CUDA_VISIBLE_DEVICES-omgevingvariabele, bijvoorbeeld zo:

```Python
CUDA_VISIBLE_DEVICES=0 python infer.py
CUDA_VISIBLE_DEVICES=1 python infer.py
```

Voel je vrij om Phi verder te verkennen in [Azure AI Foundry](https://ai.azure.com)

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsdienst [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u er rekening mee te houden dat automatische vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het originele document in de oorspronkelijke taal moet als de gezaghebbende bron worden beschouwd. Voor cruciale informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor eventuele misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.