<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-09T08:39:53+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "nl"
}
-->
# **Phi Family gebruiken in Hugging Face**


[Hugging Face](https://huggingface.co/) is een zeer populaire AI-gemeenschap met uitgebreide data en open source modelbronnen. Verschillende fabrikanten brengen open source LLM- en SLM-modellen uit via Hugging Face, zoals Microsoft, Meta, Mistral, Apple, Google, enzovoort.

De Microsoft Phi Family is uitgebracht op Hugging Face. Ontwikkelaars kunnen het bijbehorende Phi Family-model downloaden op basis van scenarioâ€™s en bedrijfsbehoeften. Naast het inzetten van Phi Pytorch-modellen op Hugging Face, hebben we ook gekwantiseerde modellen uitgebracht, met GGUF- en ONNX-formaten, zodat eindgebruikers keuzevrijheid hebben.


## **Modellen downloaden op Hugging Face**

Je kunt het Phi Family-model downloaden via deze link

[Microsoft Modellen op Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Je kunt het model op verschillende manieren downloaden, bijvoorbeeld door de ***Hugging Face CLI SDK*** te installeren of met ***git clone***.


### **Phi Family model downloaden met Hugging Face CLI**

- Installeer Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Inloggen met huggingface-cli

Log in bij Hugging Face met een [User Access Token](https://huggingface.co/docs/hub/security-tokens) via je [Instellingenpagina](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Downloaden


Je kunt het model downloaden en opslaan in de cache

```bash

huggingface-cli download microsoft/phi-4

```

Je kunt ook een specifieke locatie instellen


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Phi Family model downloaden met git clone**

Je kunt ook ***git clone*** gebruiken om het model te downloaden

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Voorbeelden - Microsoft Phi-4 inferentie**

- **Transformers bibliotheek installeren**

```bash

pip install transformers -U

```

- **Deze code uitvoeren in VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsservice [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u er rekening mee te houden dat geautomatiseerde vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het oorspronkelijke document in de oorspronkelijke taal moet als de gezaghebbende bron worden beschouwd. Voor cruciale informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor eventuele misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.