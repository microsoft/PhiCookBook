<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-05-09T09:57:00+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "nl"
}
-->
## Phi Family in NVIDIA NIM

NVIDIA NIM is een verzameling gebruiksvriendelijke microservices die zijn ontworpen om de uitrol van generatieve AI-modellen te versnellen in de cloud, datacenters en werkstations. NIMs worden ingedeeld op modelfamilie en per model. Bijvoorbeeld, NVIDIA NIM voor grote taalmodellen (LLM’s) brengt de kracht van geavanceerde LLM’s naar bedrijfsapplicaties, en biedt ongeëvenaarde mogelijkheden voor natuurlijke taalverwerking en begrip.

NIM maakt het IT- en DevOps-teams eenvoudig om grote taalmodellen (LLM’s) zelf te hosten in hun eigen beheerde omgevingen, terwijl het ontwikkelaars toch industrieel gestandaardiseerde API’s biedt waarmee ze krachtige copiloten, chatbots en AI-assistenten kunnen bouwen die hun bedrijf kunnen transformeren. Door gebruik te maken van NVIDIA’s geavanceerde GPU-versnelling en schaalbare uitrol, biedt NIM de snelste weg naar inferentie met ongeëvenaarde prestaties.

Je kunt NVIDIA NIM gebruiken om Phi Family-modellen te infereren

![nim](../../../../../translated_images/Phi-NIM.45af94d89220fbbbc85f8da0379150a29cc88c3dd8ec417b1d3b7237bbe1c58a.nl.png)

### **Voorbeelden - Phi-3-Vision in NVIDIA NIM**

Stel je hebt een afbeelding (`demo.png`) en je wilt Python-code genereren die deze afbeelding verwerkt en een nieuwe versie opslaat (`phi-3-vision.jpg`).

De bovenstaande code automatiseert dit proces door:

1. De omgeving en benodigde configuraties op te zetten.
2. Een prompt te maken die het model instrueert om de benodigde Python-code te genereren.
3. De prompt naar het model te sturen en de gegenereerde code te verzamelen.
4. De gegenereerde code te extraheren en uit te voeren.
5. De originele en verwerkte afbeeldingen weer te geven.

Deze aanpak benut de kracht van AI om beeldverwerkingstaken te automatiseren, waardoor het makkelijker en sneller wordt om je doelen te bereiken.

[Voorbeeldcode Oplossing](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

Laten we stap voor stap bekijken wat de hele code doet:

1. **Installeer Vereist Pakket**:  
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```  
    Dit commando installeert het pakket `langchain_nvidia_ai_endpoints` en zorgt dat het de nieuwste versie is.

2. **Importeer Benodigde Modules**:  
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```  
    Deze imports halen de benodigde modules binnen om te communiceren met de NVIDIA AI endpoints, wachtwoorden veilig te verwerken, het besturingssysteem aan te spreken en data te coderen/decoderen in base64-formaat.

3. **Stel API-sleutel in**:  
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```  
    Deze code controleert of de omgevingsvariabele `NVIDIA_API_KEY` is ingesteld. Zo niet, wordt de gebruiker gevraagd om de API-sleutel veilig in te voeren.

4. **Definieer Model en Afbeeldingspad**:  
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```  
    Dit stelt het te gebruiken model in, maakt een instantie van `ChatNVIDIA` met het opgegeven model, en definieert het pad naar het afbeeldingsbestand.

5. **Maak Tekstprompt**:  
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```  
    Dit definieert een tekstprompt die het model instrueert om Python-code te genereren voor het verwerken van een afbeelding.

6. **Encodeer Afbeelding in Base64**:  
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```  
    Deze code leest het afbeeldingsbestand, codeert het in base64 en maakt een HTML-afbeeldingstag met de gecodeerde data.

7. **Combineer Tekst en Afbeelding in Prompt**:  
    ```python
    prompt = f"{text} {image}"
    ```  
    Dit combineert de tekstprompt en de HTML-afbeeldingstag tot één string.

8. **Genereer Code met ChatNVIDIA**:  
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```  
    Deze code stuurt de prompt naar `ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code` string.

9. **Extraheer Python-code uit de gegenereerde inhoud**:  
    ```python
    begin = code.index('```python') + 9  
    code = code[begin:]  
    end = code.index('```')
    code = code[:end]
    ```  
    Dit haalt de daadwerkelijke Python-code uit de gegenereerde inhoud door de markdown-opmaak te verwijderen.

10. **Voer de gegenereerde code uit**:  
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```  
    Dit voert de geëxtraheerde Python-code uit als een subprocess en vangt de uitvoer op.

11. **Toon Afbeeldingen**:  
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```  
    Deze regels tonen de afbeeldingen met behulp van de `IPython.display` module.

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsdienst [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u er rekening mee te houden dat geautomatiseerde vertalingen fouten of onjuistheden kunnen bevatten. Het oorspronkelijke document in de oorspronkelijke taal dient als de gezaghebbende bron te worden beschouwd. Voor kritieke informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor eventuele misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.