<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fb67a08b9fc911a10ed58081fadef416",
  "translation_date": "2025-05-09T08:53:44+00:00",
  "source_file": "md/01.Introduction/02/02.GitHubModel.md",
  "language_code": "nl"
}
-->
## Phi-familie in GitHub Models

Welkom bij [GitHub Models](https://github.com/marketplace/models)! We hebben alles klaargezet zodat je AI-modellen die gehost worden op Azure AI kunt ontdekken.

![GitHubModel](../../../../../translated_images/GitHub_ModelCatalog.4fc858ab26afe64c43f5e423ad0c5c733878bb536fdb027a5bcf1f80c41b0633.nl.png)

Voor meer informatie over de beschikbare modellen op GitHub Models, bekijk de [GitHub Model Marketplace](https://github.com/marketplace/models)

## Beschikbare modellen

Elk model heeft een eigen playground en voorbeeldcode

![Phi-4Model_Github](../../../../../translated_images/GitHub_ModelPlay.998e294f6ee69c3ca174c880b32af9feec4221d0d787de899ad9bb2da3b58981.nl.png)

### Phi-familie in GitHub Model Catalogus

- [Phi-4](https://github.com/marketplace/models/azureml/Phi-4)

- [Phi-3.5-MoE instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-MoE-instruct)

- [Phi-3.5-vision instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-vision-instruct)

- [Phi-3.5-mini instruct (128k)](https://github.com/marketplace/models/azureml/Phi-3-5-mini-instruct)

- [Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

- [Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

- [Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

- [Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

- [Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

- [Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## Aan de slag

Er zijn een paar basisvoorbeelden die klaarstaan om te draaien. Je vindt ze in de samples directory. Wil je direct naar je favoriete programmeertaal, dan vind je de voorbeelden in de volgende talen:

- Python
- JavaScript
- C#
- Java
- cURL

Er is ook een speciale Codespaces-omgeving beschikbaar om de samples en modellen uit te voeren.

![Getting Started](../../../../../translated_images/GitHub_ModelGetStarted.b4b839a081583da39bc976c2f0d8ac4603d3b8c23194b16cc9e0a1014f5611d0.nl.png)

## Voorbeeldcode

Hieronder vind je voorbeeldcode voor een aantal gebruiksscenario’s. Voor meer informatie over de Azure AI Inference SDK, zie de volledige documentatie en voorbeelden.

## Setup

1. Maak een personal access token aan  
Je hoeft geen permissies toe te kennen aan het token. Let op: het token wordt verzonden naar een Microsoft-service.

Om de onderstaande codevoorbeelden te gebruiken, maak je een omgevingsvariabele aan waarin je token wordt ingesteld als sleutel voor de clientcode.

Als je bash gebruikt:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
Als je powershell gebruikt:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```

Als je de Windows command prompt gebruikt:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```

## Python voorbeeld

### Installeer dependencies  
Installeer de Azure AI Inference SDK via pip (vereist: Python >=3.8):

```
pip install azure-ai-inference
```  
### Draai een basisvoorbeeld

Dit voorbeeld laat zien hoe je een eenvoudige oproep doet naar de chat completion API. Het maakt gebruik van het GitHub AI model inference endpoint en je GitHub token. De oproep is synchroon.

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
model_name = "Phi-4"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        UserMessage(content="I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"),
    ],
    temperature=0.4,
    top_p=1.0,
    max_tokens=2048,
    model=model_name
)

print(response.choices[0].message.content)
```

### Draai een multi-turn conversatie

Dit voorbeeld toont een meerstapsgesprek met de chat completion API. Bij gebruik van het model voor een chatapplicatie moet je de gespreksgeschiedenis beheren en de laatste berichten naar het model sturen.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

### Stream de output

Voor een betere gebruikerservaring wil je de reactie van het model streamen, zodat het eerste token snel verschijnt en je niet lang hoeft te wachten op een reactie.

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-4"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```

## GRATIS gebruik en limieten voor GitHub Models

![Model Catalog](../../../../../translated_images/GitHub_Model.0c2abb992151c5407046e2b763af51505ff709f04c0950785e0300fdc8c55a0c.nl.png)

De [rate limits voor de playground en gratis API-gebruik](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) zijn bedoeld om je te helpen experimenteren met modellen en je AI-applicatie te prototypen. Voor gebruik boven deze limieten moet je resources via een Azure-account provisioneren en daar authenticeren in plaats van met je GitHub personal access token. Je hoeft verder niets in je code aan te passen. Gebruik deze link om te ontdekken hoe je de gratis limieten in Azure AI kunt overstijgen.

### Kennisgevingen

Houd er rekening mee dat je bij interactie met een model experimenteert met AI, dus inhoudelijke fouten kunnen voorkomen.

De functie is onderhevig aan diverse limieten (zoals verzoeken per minuut, verzoeken per dag, tokens per verzoek en gelijktijdige verzoeken) en is niet bedoeld voor productieomgevingen.

GitHub Models gebruikt Azure AI Content Safety. Deze filters kunnen niet worden uitgeschakeld als onderdeel van de GitHub Models-ervaring. Als je besluit modellen via een betaalde dienst te gebruiken, configureer dan je contentfilters zodat ze aan je eisen voldoen.

Deze service valt onder GitHub’s Pre-release Terms.

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsdienst [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u er rekening mee te houden dat automatische vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het originele document in de oorspronkelijke taal moet als de gezaghebbende bron worden beschouwd. Voor cruciale informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.