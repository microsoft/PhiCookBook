<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-07-16T16:25:44+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "pt"
}
-->
# Ajustar finamente o Phi3 usando Olive

Neste exemplo, vais usar o Olive para:

1. Ajustar finamente um adaptador LoRA para classificar frases em Triste, Alegria, Medo, Surpresa.  
1. Fundir os pesos do adaptador no modelo base.  
1. Otimizar e quantizar o modelo para `int4`.  

Tamb√©m te mostramos como fazer infer√™ncia com o modelo ajustado usando a API ONNX Runtime (ORT) Generate.

> **‚ö†Ô∏è Para o ajuste fino, precisas de ter uma GPU adequada dispon√≠vel - por exemplo, uma A10, V100, A100.**

## üíæ Instalar

Cria um novo ambiente virtual Python (por exemplo, usando `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

De seguida, instala o Olive e as depend√™ncias para o fluxo de trabalho de ajuste fino:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Ajustar finamente o Phi3 usando Olive  
O [ficheiro de configura√ß√£o do Olive](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) cont√©m um *workflow* com as seguintes *etapas*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

De forma geral, este workflow ir√°:

1. Ajustar finamente o Phi3 (durante 150 passos, que podes modificar) usando os dados de [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).  
1. Fundir os pesos do adaptador LoRA no modelo base. Isto vai gerar um √∫nico artefacto de modelo no formato ONNX.  
1. O Model Builder vai otimizar o modelo para o runtime ONNX *e* quantizar o modelo para `int4`.  

Para executar o workflow, corre:

```bash
olive run --config phrase-classification.json
```

Quando o Olive terminar, o teu modelo Phi3 ajustado e otimizado em `int4` estar√° dispon√≠vel em: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Integrar o Phi3 ajustado na tua aplica√ß√£o

Para correr a aplica√ß√£o:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

A resposta dever√° ser uma classifica√ß√£o de uma √∫nica palavra da frase (Triste/Alegria/Medo/Surpresa).

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, por favor tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes da utiliza√ß√£o desta tradu√ß√£o.