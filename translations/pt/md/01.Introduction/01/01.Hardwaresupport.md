<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8cdc17ce0f10535da30b53d23fe1a795",
  "translation_date": "2025-07-16T18:24:42+00:00",
  "source_file": "md/01.Introduction/01/01.Hardwaresupport.md",
  "language_code": "pt"
}
-->
# Suporte de Hardware Phi

O Microsoft Phi foi otimizado para ONNX Runtime e suporta Windows DirectML. Funciona bem em vários tipos de hardware, incluindo GPUs, CPUs e até dispositivos móveis.

## Hardware do Dispositivo  
Especificamente, o hardware suportado inclui:

- GPU SKU: RTX 4090 (DirectML)
- GPU SKU: 1 A100 80GB (CUDA)
- CPU SKU: Standard F64s v2 (64 vCPUs, 128 GiB de memória)

## SKU Móvel

- Android - Samsung Galaxy S21
- Apple iPhone 14 ou superior com processador A16/A17

## Especificações do Hardware Phi

- Configuração mínima necessária.
- Windows: GPU compatível com DirectX 12 e pelo menos 4GB de RAM combinada

CUDA: GPU NVIDIA com Compute Capability >= 7.02

![HardwareSupport](../../../../../translated_images/01.phihardware.5d51b2377cba18afc6949074542f290c56bb278dac3f4f86302aca6d80fffeb9.pt.png)

## Executar onnxruntime em múltiplas GPUs

Atualmente, os modelos Phi ONNX disponíveis são apenas para 1 GPU. É possível suportar multi-GPU para o modelo Phi, mas o ORT com 2 GPUs não garante que terá maior rendimento comparado a 2 instâncias do ort. Por favor, consulte [ONNX Runtime](https://onnxruntime.ai/) para as atualizações mais recentes.

Na [Build 2024 a equipa GenAI ONNX](https://youtu.be/WLW4SE8M9i8?si=EtG04UwDvcjunyfC) anunciou que ativaram multi-instância em vez de multi-GPU para os modelos Phi.

Atualmente, isto permite executar uma instância onnxruntime ou onnxruntime-genai com a variável de ambiente CUDA_VISIBLE_DEVICES assim.

```Python
CUDA_VISIBLE_DEVICES=0 python infer.py
CUDA_VISIBLE_DEVICES=1 python infer.py
```

Sinta-se à vontade para explorar o Phi mais a fundo em [Azure AI Foundry](https://ai.azure.com)

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução automática [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precisão, por favor tenha em atenção que traduções automáticas podem conter erros ou imprecisões. O documento original na sua língua nativa deve ser considerado a fonte autorizada. Para informações críticas, recomenda-se tradução profissional humana. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes da utilização desta tradução.