<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3139a6a82f357a9f90f1fe51c4caf65a",
  "translation_date": "2025-07-16T22:01:00+00:00",
  "source_file": "md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "pt"
}
-->
# **Quantiza√ß√£o do Phi-3.5 usando Intel OpenVINO**

A Intel √© o fabricante de CPUs mais tradicional, com muitos utilizadores. Com o crescimento do machine learning e deep learning, a Intel tamb√©m entrou na corrida pela acelera√ß√£o de IA. Para a infer√™ncia de modelos, a Intel n√£o utiliza apenas GPUs e CPUs, mas tamb√©m NPUs.

Pretendemos implementar a fam√≠lia Phi-3.x no lado do utilizador final, esperando que se torne a parte mais importante do PC de IA e do PC Copilot. O carregamento do modelo no lado do utilizador final depende da colabora√ß√£o entre diferentes fabricantes de hardware. Este cap√≠tulo foca-se principalmente no cen√°rio de aplica√ß√£o do Intel OpenVINO como modelo quantitativo.

## **O que √© o OpenVINO**

O OpenVINO √© um toolkit open-source para otimizar e implementar modelos de deep learning desde a cloud at√© ao edge. Acelera a infer√™ncia de deep learning em v√°rios casos de uso, como IA generativa, v√≠deo, √°udio e linguagem, com modelos de frameworks populares como PyTorch, TensorFlow, ONNX, entre outros. Permite converter e otimizar modelos, e implement√°-los numa combina√ß√£o de hardware e ambientes Intel¬Æ, localmente ou em dispositivos, no browser ou na cloud.

Com o OpenVINO, pode quantizar rapidamente o modelo GenAI em hardware Intel e acelerar a refer√™ncia do modelo.

Atualmente, o OpenVINO suporta a convers√£o de quantiza√ß√£o do Phi-3.5-Vision e do Phi-3.5 Instruct.

### **Configura√ß√£o do Ambiente**

Por favor, assegure que as seguintes depend√™ncias do ambiente est√£o instaladas, este √© o requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Quantiza√ß√£o do Phi-3.5-Instruct usando OpenVINO**

No Terminal, execute este script

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Quantiza√ß√£o do Phi-3.5-Vision usando OpenVINO**

Execute este script em Python ou Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ü§ñ Exemplos para Phi-3.5 com Intel OpenVINO**

| Labs    | Introdu√ß√£o | Ir |
| -------- | ------- |  ------- |
| üöÄ Lab-Introdu√ß√£o Phi-3.5 Instruct  | Aprenda a usar o Phi-3.5 Instruct no seu PC de IA    |  [Ir](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| üöÄ Lab-Introdu√ß√£o Phi-3.5 Vision (imagem) | Aprenda a usar o Phi-3.5 Vision para analisar imagens no seu PC de IA      |  [Ir](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| üöÄ Lab-Introdu√ß√£o Phi-3.5 Vision (v√≠deo)   | Aprenda a usar o Phi-3.5 Vision para analisar v√≠deo no seu PC de IA    |  [Ir](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Recursos**

1. Saiba mais sobre Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Reposit√≥rio Intel OpenVINO no GitHub [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, por favor tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes da utiliza√ß√£o desta tradu√ß√£o.