<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2e4b490f4bd424b095f21e38c6af33b",
  "translation_date": "2026-01-05T02:44:13+00:00",
  "source_file": "README.md",
  "language_code": "pt"
}
-->
# Phi Cookbook: Exemplos Pr√°ticos com os Modelos Phi da Microsoft

[![Abra e use os exemplos no GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phicookbook)
[![Abrir em Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook)

[![Contribuidores do GitHub](https://img.shields.io/github/contributors/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)
[![Issues do GitHub](https://img.shields.io/github/issues/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)
[![Pull requests do GitHub](https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)
[![PRs Bem-vindos](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![Observadores do GitHub](https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)
[![Forks do GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
[![Estrelas do GitHub](https://img.shields.io/github/stars/microsoft/phicookbook?style=social&label=Star)](https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)

[![Discord da Microsoft Azure AI Foundry](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Phi √© uma s√©rie de modelos de IA open source desenvolvidos pela Microsoft. 

Atualmente, o Phi √© o modelo de linguagem pequena (SLM) mais poderoso e rent√°vel, com benchmarks muito bons em multilinguismo, racioc√≠nio, gera√ß√£o de texto/chat, codifica√ß√£o, imagens, √°udio e outros cen√°rios. 

Pode implementar o Phi na cloud ou em dispositivos edge, e pode construir facilmente aplica√ß√µes de IA generativa com poder de computa√ß√£o limitado.

Siga estes passos para come√ßar a usar estes recursos :
1. **Fazer fork do Reposit√≥rio**: Clique [![Forks do GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
2. **Clonar o Reposit√≥rio**:   `git clone https://github.com/microsoft/PhiCookBook.git`
3. [**Junte-se √† Comunidade Microsoft AI no Discord e conhe√ßa especialistas e outros desenvolvedores**](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

![capa](../../translated_images/cover.eb18d1b9605d754b.pt.png)

### üåê Suporte Multilingue

#### Suportado via GitHub Action (Automatizado e Sempre Atualizado)

<!-- CO-OP TRANSLATOR LANGUAGES TABLE START -->
[√Årabe](../ar/README.md) | [Bengal√™s](../bn/README.md) | [B√∫lgaro](../bg/README.md) | [Birman√™s (Myanmar)](../my/README.md) | [Chin√™s (Simplificado)](../zh/README.md) | [Chin√™s (Tradicional, Hong Kong)](../hk/README.md) | [Chin√™s (Tradicional, Macau)](../mo/README.md) | [Chin√™s (Tradicional, Taiwan)](../tw/README.md) | [Croata](../hr/README.md) | [Checo](../cs/README.md) | [Dinamarqu√™s](../da/README.md) | [Neerland√™s](../nl/README.md) | [Est√≥nio](../et/README.md) | [Finland√™s](../fi/README.md) | [Franc√™s](../fr/README.md) | [Alem√£o](../de/README.md) | [Grego](../el/README.md) | [Hebraico](../he/README.md) | [Hindi](../hi/README.md) | [H√∫ngaro](../hu/README.md) | [Indon√©sio](../id/README.md) | [Italiano](../it/README.md) | [Japon√™s](../ja/README.md) | [Canar√™s](../kn/README.md) | [Coreano](../ko/README.md) | [Lituano](../lt/README.md) | [Malaio](../ms/README.md) | [Malayalam](../ml/README.md) | [Marathi](../mr/README.md) | [Nepali](../ne/README.md) | [Pidgin Nigeriano](../pcm/README.md) | [Noruegu√™s](../no/README.md) | [Persa (Farsi)](../fa/README.md) | [Polaco](../pl/README.md) | [Portugu√™s (Brasil)](../br/README.md) | [Portugu√™s (Portugal)](./README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Romeno](../ro/README.md) | [Russo](../ru/README.md) | [S√©rvio (Cir√≠lico)](../sr/README.md) | [Eslovaco](../sk/README.md) | [Esloveno](../sl/README.md) | [Espanhol](../es/README.md) | [Sua√≠li](../sw/README.md) | [Sueco](../sv/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Tamil](../ta/README.md) | [Telugu](../te/README.md) | [Tailand√™s](../th/README.md) | [Turco](../tr/README.md) | [Ucraniano](../uk/README.md) | [Urdu](../ur/README.md) | [Vietnamita](../vi/README.md)

> **Prefere clonar localmente?**

> Este reposit√≥rio inclui mais de 50 tradu√ß√µes de idiomas, o que aumenta significativamente o tamanho do download. Para clonar sem tradu√ß√µes, utilize sparse checkout:
> ```bash
> git clone --filter=blob:none --sparse https://github.com/microsoft/PhiCookBook.git
> cd PhiCookBook
> git sparse-checkout set --no-cone '/*' '!translations' '!translated_images'
> ```
> Isto d√°-lhe tudo o que precisa para completar o curso com um download muito mais r√°pido.
<!-- CO-OP TRANSLATOR LANGUAGES TABLE END -->

## √çndice

- Introdu√ß√£o
  - [Bem-vindo √† Fam√≠lia Phi](./md/01.Introduction/01/01.PhiFamily.md)
  - [Configurar o seu ambiente](./md/01.Introduction/01/01.EnvironmentSetup.md)
  - [Compreender Tecnologias Chave](./md/01.Introduction/01/01.Understandingtech.md)
  - [Seguran√ßa de IA para Modelos Phi](./md/01.Introduction/01/01.AISafety.md)
  - [Suporte de Hardware para Phi](./md/01.Introduction/01/01.Hardwaresupport.md)
  - [Modelos Phi e Disponibilidade atrav√©s de plataformas](./md/01.Introduction/01/01.Edgeandcloud.md)
  - [A utilizar Guidance-ai e Phi](./md/01.Introduction/01/01.Guidance.md)
  - [Modelos do GitHub Marketplace](https://github.com/marketplace/models)
  - [Cat√°logo de Modelos Azure AI](https://ai.azure.com)

- Infer√™ncia Phi em diferentes ambientes
    -  [Hugging face](./md/01.Introduction/02/01.HF.md)
    -  [GitHub Models](./md/01.Introduction/02/02.GitHubModel.md)
    -  [Azure AI Foundry Model Catalog](./md/01.Introduction/02/03.AzureAIFoundry.md)
    -  [Ollama](./md/01.Introduction/02/04.Ollama.md)
    -  [AI Toolkit VSCode (AITK)](./md/01.Introduction/02/05.AITK.md)
    -  [NVIDIA NIM](./md/01.Introduction/02/06.NVIDIA.md)
    -  [Foundry Local](./md/01.Introduction/02/07.FoundryLocal.md)

- Fam√≠lia de Infer√™ncia Phi
    - [Infer√™ncia Phi em iOS](./md/01.Introduction/03/iOS_Inference.md)
    - [Infer√™ncia Phi em Android](./md/01.Introduction/03/Android_Inference.md)
    - [Infer√™ncia Phi em Jetson](./md/01.Introduction/03/Jetson_Inference.md)
    - [Infer√™ncia Phi em AI PC](./md/01.Introduction/03/AIPC_Inference.md)
    - [Infer√™ncia Phi com Apple MLX Framework](./md/01.Introduction/03/MLX_Inference.md)
    - [Infer√™ncia Phi em Servidor Local](./md/01.Introduction/03/Local_Server_Inference.md)
    - [Infer√™ncia Phi em Servidor Remoto usando AI Toolkit](./md/01.Introduction/03/Remote_Interence.md)
    - [Infer√™ncia Phi com Rust](./md/01.Introduction/03/Rust_Inference.md)
    - [Infer√™ncia Phi ‚Äî Vis√£o em Local](./md/01.Introduction/03/Vision_Inference.md)
    - [Infer√™ncia Phi com Kaito AKS, Azure Containers (suporte oficial)](./md/01.Introduction/03/Kaito_Inference.md)
-  [Quantifica√ß√£o da Fam√≠lia Phi](./md/01.Introduction/04/QuantifyingPhi.md)
    - [Quantiza√ß√£o de Phi-3.5 / 4 usando llama.cpp](./md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md)
    - [Quantiza√ß√£o de Phi-3.5 / 4 usando Generative AI extensions for onnxruntime](./md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md)
    - [Quantiza√ß√£o de Phi-3.5 / 4 usando Intel OpenVINO](./md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md)
    - [Quantiza√ß√£o de Phi-3.5 / 4 usando Apple MLX Framework](./md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md)

-  Avalia√ß√£o Phi
    - [IA Respons√°vel](./md/01.Introduction/05/ResponsibleAI.md)
    - [Azure AI Foundry para Avalia√ß√£o](./md/01.Introduction/05/AIFoundry.md)
    - [Utilizar Promptflow para Avalia√ß√£o](./md/01.Introduction/05/Promptflow.md)
 
- RAG com Azure AI Search
    - [Como usar Phi-4-mini e Phi-4-multimodal(RAG) com Azure AI Search](https://github.com/microsoft/PhiCookBook/blob/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb)

- Exemplos de desenvolvimento de aplica√ß√µes Phi
  - Aplica√ß√µes de Texto e Chat
    - Exemplos Phi-4 üÜï
      - [üìì] [Chat com o Modelo Phi-4-mini ONNX](./md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md)
      - [Chat com Modelo ONNX local Phi-4 .NET](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime)
      - [Aplica√ß√£o de Consola .NET com Phi-4 ONNX usando Sementic Kernel](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK)
    - Exemplos Phi-3 / 3.5
      - [Chatbot local no navegador usando Phi3, ONNX Runtime Web e WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)
      - [Chat OpenVino](./md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md)
      - [Multi Model - Phi-3-mini Interactivo e OpenAI Whisper](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md)
      - [MLFlow - Construir um wrapper e usar Phi-3 com MLFlow](./md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md)
      - [Model Optimization - Como otimizar o modelo Phi-3-min para ONNX Runtime Web com Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)
      - [Aplica√ß√£o WinUI3 com Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)
      -[Exemplo de aplica√ß√£o WinUI3 Multi Model AI Powered Notes](https://github.com/microsoft/ai-powered-notes-winui3-sample)
      - [Ajuste fino e Integra√ß√£o de modelos Phi-3 personalizados com Prompt flow](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)
      - [Ajuste fino e Integra√ß√£o de modelos Phi-3 personalizados com Prompt flow no Azure AI Foundry](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md)
      - [Avaliar o modelo Phi-3 / Phi-3.5 afinado no Azure AI Foundry com foco nos Princ√≠pios de IA Respons√°vel da Microsoft](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md)
      - [üìì] [Exemplo de previs√£o de linguagem Phi-3.5-mini-instruct (Chin√™s/Ingl√™s)](./md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb)
      - [Chatbot RAG Phi-3.5-Instruct WebGPU](./md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md)
      - [Usar GPU Windows para criar solu√ß√£o Prompt flow com Phi-3.5-Instruct ONNX](./md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md)
      - [Usar Microsoft Phi-3.5 tflite para criar app Android](./md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md)
      - [Exemplo Q&A .NET usando o modelo ONNX Phi-3 local com Microsoft.ML.OnnxRuntime](../../md/04.HOL/dotnet/src/LabsPhi301)
      - [Aplica√ß√£o de chat de consola .NET com Semantic Kernel e Phi-3](../../md/04.HOL/dotnet/src/LabsPhi302)

  - Azure AI Inference SDK Code Based Samples 
    - Phi-4 Samples üÜï
      - [üìì] [Gerar c√≥digo de projeto usando Phi-4-multimodal](./md/02.Application/02.Code/Phi4/GenProjectCode/README.md)
    - Phi-3 / 3.5 Samples
      - [Construa o seu pr√≥prio Visual Studio Code GitHub Copilot Chat com Microsoft Phi-3 Family](./md/02.Application/02.Code/Phi3/VSCodeExt/README.md)
      - [Crie o seu pr√≥prio Visual Studio Code Chat Copilot Agent com Phi-3.5 pelos GitHub Models](/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md)

  - Amostras de Racioc√≠nio Avan√ßado
    - Phi-4 Samples üÜï
      - [üìì] [Amostras Phi-4-mini-reasoning ou Phi-4-reasoning](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md)
      - [üìì] [Ajuste fino Phi-4-mini-reasoning com Microsoft Olive](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb)
      - [üìì] [Ajuste fino Phi-4-mini-reasoning com Apple MLX](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/mlx_ft_phi_4_reasoning_with_medicaldata.ipynb)
      - [üìì] [Phi-4-mini-reasoning com GitHub Models](./md/02.Application/02.Code/Phi4r/github_models_inference.ipynb)
      - [üìì] [Phi-4-mini-reasoning com modelos Azure AI Foundry](./md/02.Application/02.Code/Phi4r/azure_models_inference.ipynb)
  - Demonstra√ß√µes
      - [Demos Phi-4-mini alojados no Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo)
      - [Demos Phi-4-multimodal alojados no Hugginge Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo)
  - Amostras de Vis√£o
    - Phi-4 Samples üÜï
      - [üìì] [Usar Phi-4-multimodal para ler imagens e gerar c√≥digo](./md/02.Application/04.Vision/Phi4/CreateFrontend/README.md) 
    - Phi-3 / 3.5 Samples
      -  [üìì][Phi-3-vision-Imagem texto para texto](./md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)
      - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)
      - [üìì][Phi-3-vision CLIP Embedding](./md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)
      - [DEMO: Phi-3 Recycling](https://github.com/jennifermarsman/PhiRecycling/)
      - [Phi-3-vision - Assistente de linguagem visual - com Phi3-Vision e OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)
      - [Phi-3 Vision Nvidia NIM](./md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md)
      - [Phi-3 Vision OpenVino](./md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md)
      - [üìì][Exemplo Phi-3.5 Vision multi-frame ou multi-image](./md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb)
      - [Phi-3 Vision Local ONNX Model using the Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi303)
      - [Menu based Phi-3 Vision Local ONNX Model using the Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi304)

  - Amostras de Matem√°tica
    -  Phi-4-Mini-Flash-Reasoning-Instruct Samples üÜï [Demonstra√ß√£o de Matem√°tica com Phi-4-Mini-Flash-Reasoning-Instruct](./md/02.Application/09.Math/MathDemo.ipynb)

  - Amostras de √Åudio
    - Phi-4 Samples üÜï
      - [üìì] [Extrair transcri√ß√µes de √°udio usando Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Transciption/README.md)
      - [üìì] [Exemplo de √°udio Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Siri/demo.ipynb)
      - [üìì] [Exemplo de Tradu√ß√£o de Fala Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Translate/demo.ipynb)
      - [.NET console application using Phi-4-multimodal Audio to analyze an audio file and generate transcript](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio)

  - Amostras MOE
    - Phi-3 / 3.5 Samples
      - [üìì] [Exemplo Phi-3.5 Mixture of Experts Models (MoEs) para Redes Sociais](./md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb)
      - [üìì] [Construir uma pipeline Retrieval-Augmented Generation (RAG) com NVIDIA NIM Phi-3 MOE, Azure AI Search, e LlamaIndex](./md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb)
      - 
  - Amostras de Function Calling
    - Phi-4 Samples üÜï
      -  [üìì] [Usar Function Calling With Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md)
      -  [üìì] [Usar Function Calling para criar multi-agentes With Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/Multiagents/Phi_4_mini_multiagent.ipynb)
      -  [üìì] [Usar Function Calling com Ollama](./md/02.Application/07.FunctionCalling/Phi4/Ollama/ollama_functioncalling.ipynb)
      -  [üìì] [Usar Function Calling com ONNX](./md/02.Application/07.FunctionCalling/Phi4/ONNX/onnx_parallel_functioncalling_ipynb.ipynb)
  - Amostras de Mistura Multimodal
    - Phi-4 Samples üÜï
      -  [üìì] [Usar Phi-4-multimodal como jornalista de Tecnologia](./md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb)
      - [.NET console application using Phi-4-multimodal to analyze images](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images)

- Exemplos de Fine-tuning Phi
  - [Cen√°rios de Fine-tuning](./md/03.FineTuning/FineTuning_Scenarios.md)
  - [Fine-tuning vs RAG](./md/03.FineTuning/FineTuning_vs_RAG.md)
  - [Fine-tuning: Deixe o Phi-3 tornar-se um especialista da ind√∫stria](./md/03.FineTuning/LetPhi3gotoIndustriy.md)
  - [Fine-tuning Phi-3 com AI Toolkit para VS Code](./md/03.FineTuning/Finetuning_VSCodeaitoolkit.md)
  - [Fine-tuning Phi-3 com Azure Machine Learning Service](./md/03.FineTuning/Introduce_AzureML.md)
  - [Fine-tuning Phi-3 com Lora](./md/03.FineTuning/FineTuning_Lora.md)
  - [Fine-tuning Phi-3 com QLora](./md/03.FineTuning/FineTuning_Qlora.md)
  - [Fine-tuning Phi-3 com Azure AI Foundry](./md/03.FineTuning/FineTuning_AIFoundry.md)
  - [Fine-tuning Phi-3 com Azure ML CLI/SDK](./md/03.FineTuning/FineTuning_MLSDK.md)
  - [Fine-tuning com Microsoft Olive](./md/03.FineTuning/FineTuning_MicrosoftOlive.md)
  - [Fine-tuning com Microsoft Olive Hands-On Lab](./md/03.FineTuning/olive-lab/readme.md)
  - [Fine-tuning Phi-3-vision com Weights and Bias](./md/03.FineTuning/FineTuning_Phi-3-visionWandB.md)
  - [Fine-tuning Phi-3 com Apple MLX Framework](./md/03.FineTuning/FineTuning_MLX.md)
  - [Fine-tuning Phi-3-vision (suporte oficial)](./md/03.FineTuning/FineTuning_Vision.md)
  - [Fine-Tuning Phi-3 com Kaito AKS , Azure Containers(official Support)](./md/03.FineTuning/FineTuning_Kaito.md)
  - [Fine-Tuning Phi-3 and 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)

- Laborat√≥rio Pr√°tico
  - [Explorar modelos de ponta: LLMs, SLMs, desenvolvimento local e mais](https://github.com/microsoft/aitour-exploring-cutting-edge-models)
  - [Desbloquear o potencial da PNL: Fine-Tuning com Microsoft Olive](https://github.com/azure/Ignite_FineTuning_workshop)

- Artigos e Publica√ß√µes de Investiga√ß√£o Acad√©mica
  - [Textbooks Are All You Need II: relat√≥rio t√©cnico phi-1.5](https://arxiv.org/abs/2309.05463)
  - [Relat√≥rio T√©cnico Phi-3: Um Modelo de Linguagem Altamente Capaz Localmente no Seu Telem√≥vel](https://arxiv.org/abs/2404.14219)
  - [Relat√≥rio T√©cnico Phi-4](https://arxiv.org/abs/2412.08905)
  - [Relat√≥rio T√©cnico Phi-4-Mini: Modelos de Linguagem Multimodais Compactos mas Poderosos via Mistura-de-LoRAs](https://arxiv.org/abs/2503.01743)
  - [Otimiza√ß√£o de Modelos de Linguagem Pequenos para Chamada de Fun√ß√µes em Ve√≠culos](https://arxiv.org/abs/2501.02342)
  - [(WhyPHI) Ajuste Fino do PHI-3 para Responder a Quest√µes de Escolha M√∫ltipla: Metodologia, Resultados e Desafios](https://arxiv.org/abs/2501.01588)
  - [Relat√≥rio T√©cnico Phi-4-racioc√≠nio](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf)
  - [Relat√≥rio T√©cnico Phi-4-mini-racioc√≠nio](https://huggingface.co/microsoft/Phi-4-mini-reasoning/blob/main/Phi-4-Mini-Reasoning.pdf)

## Usar Modelos Phi

### Phi no Azure AI Foundry

Pode aprender como usar o Microsoft Phi e como construir solu√ß√µes E2E nos seus diferentes dispositivos de hardware. Para experimentar o Phi por si pr√≥prio, comece por testar os modelos e personalizar o Phi para os seus cen√°rios usando o‚ÄØ[Azure AI Foundry Azure AI Model Catalog](https://aka.ms/phi3-azure-ai) pode saber mais em Como Come√ßar com [Azure AI Foundry](/md/02.QuickStart/AzureAIFoundry_QuickStart.md)

**Ambiente de Testes**
Cada modelo tem um playground dedicado para testar o modelo [Azure AI Playground](https://aka.ms/try-phi3).

### Phi nos Modelos do GitHub

Pode aprender como usar o Microsoft Phi e como construir solu√ß√µes E2E nos seus diferentes dispositivos de hardware. Para experimentar o Phi por si pr√≥prio, comece por testar o modelo e personalizar o Phi para os seus cen√°rios usando o‚ÄØ[GitHub Model Catalog](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo) pode saber mais em Como Come√ßar com [GitHub Model Catalog](/md/02.QuickStart/GitHubModel_QuickStart.md)

**Ambiente de Testes**
Cada modelo tem um [playground dedicado para testar o modelo](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi no Hugging Face

Tamb√©m pode encontrar o modelo no [Hugging Face](https://huggingface.co/microsoft)

**Ambiente de Testes**
 [Playground do Hugging Chat](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

 ## üéí Outros Cursos

A nossa equipa produz outros cursos! Confira:

<!-- CO-OP TRANSLATOR OTHER COURSES START -->
### LangChain
[![LangChain4j para Iniciantes](https://img.shields.io/badge/LangChain4j%20for%20Beginners-22C55E?style=for-the-badge&&labelColor=E5E7EB&color=0553D6)](https://aka.ms/langchain4j-for-beginners)
[![LangChain.js para Iniciantes](https://img.shields.io/badge/LangChain.js%20for%20Beginners-22C55E?style=for-the-badge&labelColor=E5E7EB&color=0553D6)](https://aka.ms/langchainjs-for-beginners?WT.mc_id=m365-94501-dwahlin)

---

### Azure / Edge / MCP / Agentes
[![AZD para Iniciantes](https://img.shields.io/badge/AZD%20for%20Beginners-0078D4?style=for-the-badge&labelColor=E5E7EB&color=0078D4)](https://github.com/microsoft/AZD-for-beginners?WT.mc_id=academic-105485-koreyst)
[![Edge AI para Iniciantes](https://img.shields.io/badge/Edge%20AI%20for%20Beginners-00B8E4?style=for-the-badge&labelColor=E5E7EB&color=00B8E4)](https://github.com/microsoft/edgeai-for-beginners?WT.mc_id=academic-105485-koreyst)
[![MCP para Iniciantes](https://img.shields.io/badge/MCP%20for%20Beginners-009688?style=for-the-badge&labelColor=E5E7EB&color=009688)](https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst)
[![Agentes de IA para Iniciantes](https://img.shields.io/badge/AI%20Agents%20for%20Beginners-00C49A?style=for-the-badge&labelColor=E5E7EB&color=00C49A)](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)

---
 
### S√©rie de IA Generativa
[![IA Generativa para Iniciantes](https://img.shields.io/badge/Generative%20AI%20for%20Beginners-8B5CF6?style=for-the-badge&labelColor=E5E7EB&color=8B5CF6)](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
[![IA Generativa (.NET)](https://img.shields.io/badge/Generative%20AI%20(.NET)-9333EA?style=for-the-badge&labelColor=E5E7EB&color=9333EA)](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
[![IA Generativa (Java)](https://img.shields.io/badge/Generative%20AI%20(Java)-C084FC?style=for-the-badge&labelColor=E5E7EB&color=C084FC)](https://github.com/microsoft/generative-ai-for-beginners-java?WT.mc_id=academic-105485-koreyst)
[![IA Generativa (JavaScript)](https://img.shields.io/badge/Generative%20AI%20(JavaScript)-E879F9?style=for-the-badge&labelColor=E5E7EB&color=E879F9)](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)

---
 
### Aprendizagem B√°sica
[![ML para Iniciantes](https://img.shields.io/badge/ML%20for%20Beginners-22C55E?style=for-the-badge&labelColor=E5E7EB&color=22C55E)](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
[![Ci√™ncia de Dados para Iniciantes](https://img.shields.io/badge/Data%20Science%20for%20Beginners-84CC16?style=for-the-badge&labelColor=E5E7EB&color=84CC16)](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
[![IA para Iniciantes](https://img.shields.io/badge/AI%20for%20Beginners-A3E635?style=for-the-badge&labelColor=E5E7EB&color=A3E635)](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
[![Ciberseguran√ßa para Iniciantes](https://img.shields.io/badge/Cybersecurity%20for%20Beginners-F97316?style=for-the-badge&labelColor=E5E7EB&color=F97316)](https://github.com/microsoft/Security-101?WT.mc_id=academic-96948-sayoung)
[![Desenvolvimento Web para Iniciantes](https://img.shields.io/badge/Web%20Dev%20for%20Beginners-EC4899?style=for-the-badge&labelColor=E5E7EB&color=EC4899)](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
[![IoT para Iniciantes](https://img.shields.io/badge/IoT%20for%20Beginners-14B8A6?style=for-the-badge&labelColor=E5E7EB&color=14B8A6)](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)
[![Desenvolvimento XR para Iniciantes](https://img.shields.io/badge/XR%20Development%20for%20Beginners-38BDF8?style=for-the-badge&labelColor=E5E7EB&color=38BDF8)](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)

---
 
### S√©rie Copilot
[![Copilot para Programa√ß√£o Emparelhada com IA](https://img.shields.io/badge/Copilot%20for%20AI%20Paired%20Programming-FACC15?style=for-the-badge&labelColor=E5E7EB&color=FACC15)](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)
[![Copilot para C#/.NET](https://img.shields.io/badge/Copilot%20for%20C%23/.NET-FBBF24?style=for-the-badge&labelColor=E5E7EB&color=FBBF24)](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)
[![Aventura Copilot](https://img.shields.io/badge/Copilot%20Adventure-FDE68A?style=for-the-badge&labelColor=E5E7EB&color=FDE68A)](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)
<!-- CO-OP TRANSLATOR OTHER COURSES END -->

## IA Respons√°vel 

A Microsoft est√° empenhada em ajudar os nossos clientes a utilizar os nossos produtos de IA de forma respons√°vel, partilhando as nossas aprendizagens e construindo parcerias baseadas na confian√ßa atrav√©s de ferramentas como Transparency Notes e Impact Assessments. Muitos destes recursos podem ser encontrados em [https://aka.ms/RAI](https://aka.ms/RAI).
A abordagem da Microsoft √† IA respons√°vel assenta nos nossos princ√≠pios de IA: equidade, fiabilidade e seguran√ßa, privacidade e seguran√ßa, inclus√£o, transpar√™ncia e responsabilidade.

Modelos de grande escala para linguagem natural, imagem e voz - como os utilizados neste exemplo - podem potencialmente comportar-se de formas que sejam injustas, pouco fi√°veis ou ofensivas, causando danos. Por favor consulte a [nota de transpar√™ncia do servi√ßo Azure OpenAI](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) para se informar sobre riscos e limita√ß√µes.

A abordagem recomendada para mitigar estes riscos √© incluir um sistema de seguran√ßa na sua arquitetura que consiga detetar e prevenir comportamentos nocivos. [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) fornece uma camada independente de prote√ß√£o, capaz de detetar conte√∫dos nocivos gerados por utilizadores e por IA em aplica√ß√µes e servi√ßos. O Azure AI Content Safety inclui APIs de texto e imagem que lhe permitem detetar material que seja prejudicial. Dentro do Azure AI Foundry, o servi√ßo Content Safety permite-lhe ver, explorar e experimentar c√≥digo de exemplo para detetar conte√∫do nocivo atrav√©s de diferentes modalidades. A seguinte [documenta√ß√£o de in√≠cio r√°pido](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) orienta-o sobre como efetuar pedidos ao servi√ßo.

Outro aspeto a ter em conta √© o desempenho global da aplica√ß√£o. Em aplica√ß√µes multimodais e com m√∫ltiplos modelos, consideramos desempenho que o sistema funcione conforme voc√™ e os seus utilizadores esperam, incluindo n√£o gerar sa√≠das prejudiciais. √â importante avaliar o desempenho da sua aplica√ß√£o global utilizando os [avaliadores de Performance and Quality and Risk and Safety](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in). Tamb√©m tem a capacidade de criar e avaliar com [avaliadores personalizados](https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators).
Pode avaliar a sua aplica√ß√£o de IA no seu ambiente de desenvolvimento utilizando o [Azure AI Evaluation SDK](https://microsoft.github.io/promptflow/index.html). Dado um conjunto de dados de teste ou um objetivo, as gera√ß√µes da sua aplica√ß√£o de IA generativa s√£o medidas quantitativamente com avaliadores incorporados ou avaliadores personalizados √† sua escolha. Para come√ßar a usar o Azure AI Evaluation SDK para avaliar o seu sistema, pode seguir o [guia de in√≠cio r√°pido](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk). Uma vez que execute uma execu√ß√£o de avalia√ß√£o, pode [visualizar os resultados no Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results). 

## Marcas registadas

Este projeto pode conter marcas registadas ou log√≥tipos de projetos, produtos ou servi√ßos. A utiliza√ß√£o autorizada de marcas registadas ou log√≥tipos da Microsoft est√° sujeita e deve seguir as [Diretrizes de Marcas e Identidade da Microsoft](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
A utiliza√ß√£o de marcas registadas ou log√≥tipos da Microsoft em vers√µes modificadas deste projeto n√£o deve causar confus√£o nem implicar patroc√≠nio por parte da Microsoft. Qualquer utiliza√ß√£o de marcas registadas ou log√≥tipos de terceiros est√° sujeita √†s pol√≠ticas desses terceiros.

## Obter Ajuda

Se ficar bloqueado ou tiver alguma d√∫vida sobre a cria√ß√£o de aplica√ß√µes de IA, junte-se a:

[![Discord da Azure AI Foundry](https://img.shields.io/badge/Discord-Azure_AI_Foundry_Community_Discord-blue?style=for-the-badge&logo=discord&color=5865f2&logoColor=fff)](https://aka.ms/foundry/discord)

Se tiver coment√°rios sobre o produto ou encontrar erros durante o desenvolvimento, visite:

[![F√≥rum de Desenvolvedores da Azure AI Foundry](https://img.shields.io/badge/GitHub-Azure_AI_Foundry_Developer_Forum-blue?style=for-the-badge&logo=github&color=000000&logoColor=fff)](https://aka.ms/foundry/forum)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Aviso legal:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original, na sua l√≠ngua de origem, deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional por um tradutor humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->