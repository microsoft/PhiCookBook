<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4951d458c0b60c02cd1e751b40903877",
  "translation_date": "2025-05-07T15:05:16+00:00",
  "source_file": "md/01.Introduction/02/05.AITK.md",
  "language_code": "ur"
}
-->
# Phi Family in AITK

[AI Toolkit for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) ترقی یافتہ AI ایپلیکیشن کی ترقی کو آسان بناتا ہے، Azure AI Foundry Catalog اور دیگر کیٹلاگز جیسے Hugging Face سے جدید AI ترقی کے اوزار اور ماڈلز کو یکجا کر کے۔ آپ GitHub Models اور Azure AI Foundry Model Catalogs کی طاقت سے چلنے والے AI ماڈلز کا کیٹلاگ براؤز کر سکیں گے، انہیں لوکل یا ریموٹ طور پر ڈاؤن لوڈ کر کے، فائن ٹیون کر کے، ٹیسٹ کر کے اور اپنی ایپلیکیشن میں استعمال کر سکیں گے۔

AI Toolkit Preview لوکل چلائی جائے گی۔ لوکل انفرنس یا فائن ٹیون، منتخب کردہ ماڈل پر منحصر ہے، آپ کو NVIDIA CUDA GPU جیسا GPU درکار ہو سکتا ہے۔ آپ GitHub Models کو براہ راست AITK کے ساتھ بھی چلا سکتے ہیں۔

## Getting Started

[Learn more how to install Windows subsystem for Linux](https://learn.microsoft.com/windows/wsl/install?WT.mc_id=aiml-137032-kinfeylo)

اور [changing default distribution](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

[AI Tooklit GitHub Repo](https://github.com/microsoft/vscode-ai-toolkit/)

- Windows, Linux, macOS

- ونڈوز اور لینکس دونوں پر فائن ٹیوننگ کے لیے، آپ کو Nvidia GPU کی ضرورت ہوگی۔ مزید برآں، **Windows** کو Ubuntu ڈسٹری 18.4 یا اس سے زیادہ کے ساتھ Linux سب سسٹم کی ضرورت ہے۔ [Learn more how to install Windows subsystem for Linux](https://learn.microsoft.com/windows/wsl/install) اور [changing default distribution](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed)۔

### Install AI Toolkit

AI Toolkit [Visual Studio Code Extension](https://code.visualstudio.com/docs/setup/additional-components#_vs-code-extensions) کے طور پر دستیاب ہے، لہٰذا پہلے آپ کو [VS Code](https://code.visualstudio.com/docs/setup/windows?WT.mc_id=aiml-137032-kinfeylo) انسٹال کرنا ہوگا، اور AI Toolkit کو [VS Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) سے ڈاؤن لوڈ کریں۔  
[AI Toolkit Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) میں دستیاب ہے اور کسی بھی دوسرے VS Code ایکسٹینشن کی طرح انسٹال کیا جا سکتا ہے۔

اگر آپ VS Code ایکسٹینشن انسٹال کرنے سے ناواقف ہیں تو یہ مراحل فالو کریں:

### Sign In

1. VS Code میں Activity Bar میں **Extensions** منتخب کریں  
1. Extensions سرچ بار میں "AI Toolkit" ٹائپ کریں  
1. "AI Toolkit for Visual Studio code" منتخب کریں  
1. **Install** منتخب کریں  

اب آپ ایکسٹینشن استعمال کرنے کے لیے تیار ہیں!

آپ کو GitHub میں سائن ان کرنے کا کہا جائے گا، براہ کرم جاری رکھنے کے لیے "Allow" پر کلک کریں۔ آپ کو GitHub سائن ان پیج پر ری ڈائریکٹ کیا جائے گا۔

براہ کرم سائن ان کریں اور عمل کے مراحل پر عمل کریں۔ کامیاب مکمل ہونے کے بعد، آپ VS Code پر واپس آ جائیں گے۔

ایک بار ایکسٹینشن انسٹال ہونے کے بعد آپ کو Activity Bar میں AI Toolkit کا آئیکن نظر آئے گا۔

آئیے دستیاب ایکشنز کو دریافت کرتے ہیں!

### Available Actions

AI Toolkit کی پرائمری سائیڈبار مندرجہ ذیل حصوں میں منظم ہے  

- **Models**  
- **Resources**  
- **Playground**  
- **Fine-tuning**  
- **Evaluation**

Resources سیکشن میں دستیاب ہیں۔ شروع کرنے کے لیے **Model Catalog** منتخب کریں۔

### Download a model from the catalog

جب آپ VS Code سائیڈ بار سے AI Toolkit لانچ کریں گے، تو آپ درج ذیل اختیارات میں سے انتخاب کر سکتے ہیں:

![AI toolkit model catalog](../../../../../translated_images/AItoolkitmodel_catalog.7a7be6a7d8468d310ae1dc2cdb2d42add99d7607b5e0e838db7924d4d25e8475.ur.png)

- **Model Catalog** سے سپورٹ شدہ ماڈل تلاش کریں اور لوکل ڈاؤن لوڈ کریں  
- **Model Playground** میں ماڈل انفرنس ٹیسٹ کریں  
- **Model Fine-tuning** میں ماڈل کو لوکل یا ریموٹ طور پر فائن ٹیون کریں  
- فائن ٹیون شدہ ماڈلز کو AI Toolkit کے کمانڈ پیلیٹ کے ذریعے کلاؤڈ پر تعینات کریں  
- ماڈلز کا جائزہ لیں  

> [!NOTE]  
>  
> **GPU Vs CPU**  
>  
> آپ نوٹس کریں گے کہ ماڈل کارڈز میں ماڈل کا سائز، پلیٹ فارم اور ایکسلریٹر کی قسم (CPU, GPU) دکھائی جاتی ہے۔ **Windows ڈیوائسز جن میں کم از کم ایک GPU ہوتا ہے**، ان پر بہترین کارکردگی کے لیے، صرف Windows کو ہدف بنانے والے ماڈل ورژنز منتخب کریں۔  
>  
> یہ یقینی بناتا ہے کہ آپ کے پاس DirectML ایکسلریٹر کے لیے بہتر بنایا گیا ماڈل ہے۔  
>  
> ماڈل کے نام اس فارمیٹ میں ہوتے ہیں:  
>  
> - `{model_name}-{accelerator}-{quantization}-{format}`۔  
>  
> یہ چیک کرنے کے لیے کہ آپ کے Windows ڈیوائس پر GPU موجود ہے یا نہیں، **Task Manager** کھولیں اور پھر **Performance** ٹیب منتخب کریں۔ اگر آپ کے پاس GPU(s) ہیں، تو وہ "GPU 0" یا "GPU 1" جیسے ناموں کے تحت فہرست میں ہوں گے۔

### Run the model in the playground

تمام پیرامیٹرز سیٹ کرنے کے بعد، **Generate Project** پر کلک کریں۔

جب آپ کا ماڈل ڈاؤن لوڈ ہو جائے، تو کیٹلاگ میں ماڈل کارڈ پر **Load in Playground** منتخب کریں:

- ماڈل ڈاؤن لوڈ شروع کریں  
- تمام prerequisites اور dependencies انسٹال کریں  
- VS Code ورک اسپیس بنائیں  

![Load model in playground](../../../../../translated_images/AItoolkitload_model_into_playground.dcef5355b1653b52e1f675d80cd429100cfe0c5d6a316ff331f3ae10923bca38.ur.png)

### Use the REST API in your application

AI Toolkit کے ساتھ لوکل REST API ویب سرور **پورٹ 5272 پر** آتا ہے جو [OpenAI chat completions format](https://platform.openai.com/docs/api-reference/chat/create) استعمال کرتا ہے۔

یہ آپ کو اپنی ایپلیکیشن کو لوکل ٹیسٹ کرنے کی سہولت دیتا ہے بغیر کلاؤڈ AI ماڈل سروس پر انحصار کیے۔ مثال کے طور پر، درج ذیل JSON فائل درخواست کے باڈی کو کنفیگر کرنے کا طریقہ دکھاتی ہے:

```json
{
    "model": "Phi-4",
    "messages": [
        {
            "role": "user",
            "content": "what is the golden ratio?"
        }
    ],
    "temperature": 0.7,
    "top_p": 1,
    "top_k": 10,
    "max_tokens": 100,
    "stream": true
}
```

آپ REST API کو (مثلاً) [Postman](https://www.postman.com/) یا CURL (Client URL) یوٹیلٹی کے ذریعے ٹیسٹ کر سکتے ہیں:

```bash
curl -vX POST http://127.0.0.1:5272/v1/chat/completions -H 'Content-Type: application/json' -d @body.json
```

### Using the OpenAI client library for Python

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:5272/v1/", 
    api_key="x" # required for the API but not used
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "what is the golden ratio?",
        }
    ],
    model="Phi-4",
)

print(chat_completion.choices[0].message.content)
```

### Using Azure OpenAI client library for .NET

NuGet کے ذریعے اپنے پروجیکٹ میں [Azure OpenAI client library for .NET](https://www.nuget.org/packages/Azure.AI.OpenAI/) شامل کریں:

```bash
dotnet add {project_name} package Azure.AI.OpenAI --version 1.0.0-beta.17
```

اپنے پروجیکٹ میں **OverridePolicy.cs** نامی C# فائل شامل کریں اور درج ذیل کوڈ پیسٹ کریں:

```csharp
// OverridePolicy.cs
using Azure.Core.Pipeline;
using Azure.Core;

internal partial class OverrideRequestUriPolicy(Uri overrideUri)
    : HttpPipelineSynchronousPolicy
{
    private readonly Uri _overrideUri = overrideUri;

    public override void OnSendingRequest(HttpMessage message)
    {
        message.Request.Uri.Reset(_overrideUri);
    }
}
```

پھر اپنے **Program.cs** فائل میں درج ذیل کوڈ پیسٹ کریں:

```csharp
// Program.cs
using Azure.AI.OpenAI;

Uri localhostUri = new("http://localhost:5272/v1/chat/completions");

OpenAIClientOptions clientOptions = new();
clientOptions.AddPolicy(
    new OverrideRequestUriPolicy(localhostUri),
    Azure.Core.HttpPipelinePosition.BeforeTransport);
OpenAIClient client = new(openAIApiKey: "unused", clientOptions);

ChatCompletionsOptions options = new()
{
    DeploymentName = "Phi-4",
    Messages =
    {
        new ChatRequestSystemMessage("You are a helpful assistant. Be brief and succinct."),
        new ChatRequestUserMessage("What is the golden ratio?"),
    }
};

StreamingResponse<StreamingChatCompletionsUpdate> streamingChatResponse
    = await client.GetChatCompletionsStreamingAsync(options);

await foreach (StreamingChatCompletionsUpdate chatChunk in streamingChatResponse)
{
    Console.Write(chatChunk.ContentUpdate);
}
```

## Fine Tuning with AI Toolkit

- ماڈل دریافت اور playground سے شروع کریں۔  
- لوکل کمپیوٹنگ وسائل کا استعمال کرتے ہوئے ماڈل کی فائن ٹیوننگ اور انفرنس۔  
- Azure وسائل کا استعمال کرتے ہوئے ریموٹ فائن ٹیوننگ اور انفرنس۔  

[Fine Tuning with AI Toolkit](../../03.FineTuning/Finetuning_VSCodeaitoolkit.md)

## AI Toolkit Q&A Resources

زیادہ تر عام مسائل اور حل کے لیے براہ کرم ہماری [Q&A page](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/QA.md) ملاحظہ کریں۔

**ڈس کلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجموں میں غلطیاں یا نقائص ہو سکتے ہیں۔ اصل دستاویز اپنی مادری زبان میں ہی معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ورانہ انسانی ترجمہ تجویز کیا جاتا ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔