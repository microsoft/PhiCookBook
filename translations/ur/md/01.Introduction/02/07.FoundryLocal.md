<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "52973a5680a65a810aa80b7036afd31f",
  "translation_date": "2025-06-27T13:33:38+00:00",
  "source_file": "md/01.Introduction/02/07.FoundryLocal.md",
  "language_code": "ur"
}
-->
## Foundry Local میں Phi-Family ماڈلز کے ساتھ شروعات

### Foundry Local کا تعارف

Foundry Local ایک طاقتور آن-ڈیوائس AI انفرنس حل ہے جو انٹرپرائز معیار کی AI صلاحیتیں براہ راست آپ کے مقامی ہارڈویئر پر فراہم کرتا ہے۔ یہ ٹیوٹوریل آپ کو Foundry Local کے ساتھ Phi-Family ماڈلز کو سیٹ اپ اور استعمال کرنے کا طریقہ سکھائے گا، جس سے آپ کو اپنے AI ورک لوڈز پر مکمل کنٹرول ملے گا، ساتھ ہی پرائیویسی برقرار رکھتے ہوئے اور اخراجات کو کم کرتے ہوئے۔

Foundry Local آپ کے ڈیوائس پر AI ماڈلز کو مقامی طور پر چلانے کے ذریعے کارکردگی، پرائیویسی، تخصیص اور لاگت کے فوائد فراہم کرتا ہے۔ یہ ایک آسان CLI، SDK، اور REST API کے ذریعے آپ کے موجودہ ورک فلو اور ایپلیکیشنز میں بخوبی ضم ہو جاتا ہے۔

![arch](../../../../../translated_images/foundry-local-arch.8823e321dd8258d7d68815ddb0153503587142ff32e6997041c7cf0c9df24b49.ur.png)

### Foundry Local کیوں منتخب کریں؟

Foundry Local کے فوائد کو سمجھنا آپ کو اپنی AI تعیناتی کی حکمت عملی کے بارے میں بہتر فیصلے کرنے میں مدد دے گا:

- **آن-ڈیوائس انفرنس:** ماڈلز کو اپنے ہارڈویئر پر مقامی طور پر چلائیں، اپنے اخراجات کم کریں اور تمام ڈیٹا اپنے ڈیوائس پر رکھیں۔

- **ماڈل کی تخصیص:** پہلے سے موجود ماڈلز میں سے انتخاب کریں یا اپنی ضروریات اور استعمال کے کیسز کے مطابق اپنا ماڈل استعمال کریں۔

- **لاگت کی بچت:** موجودہ ہارڈویئر استعمال کر کے بار بار آنے والی کلاؤڈ سروس کی لاگت کو ختم کریں، اور AI کو مزید قابل رسائی بنائیں۔

- **بلا رکاوٹ انضمام:** SDK، API اینڈ پوائنٹس، یا CLI کے ذریعے اپنی ایپلیکیشنز سے جڑیں، اور جیسے جیسے آپ کی ضروریات بڑھیں Azure AI Foundry کی طرف آسانی سے اسکیل کریں۔

> **Getting Started Note:** یہ ٹیوٹوریل Foundry Local کو CLI اور SDK انٹرفیس کے ذریعے استعمال کرنے پر مرکوز ہے۔ آپ دونوں طریقے سیکھیں گے تاکہ اپنے استعمال کے کیس کے لیے بہترین طریقہ منتخب کر سکیں۔

## حصہ 1: Foundry Local CLI کی سیٹ اپ

### مرحلہ 1: انسٹالیشن

Foundry Local CLI آپ کا ذریعہ ہے AI ماڈلز کو مقامی طور پر مینیج اور چلانے کے لیے۔ آئیے اسے اپنے سسٹم پر انسٹال کرتے ہیں۔

**مدد یافتہ پلیٹ فارمز:** Windows اور macOS

تفصیلی انسٹالیشن ہدایات کے لیے براہ کرم [official Foundry Local documentation](https://github.com/microsoft/Foundry-Local/blob/main/README.md) ملاحظہ کریں۔

### مرحلہ 2: دستیاب ماڈلز کی دریافت

جب آپ نے Foundry Local CLI انسٹال کر لیا، تو آپ دیکھ سکتے ہیں کہ آپ کے استعمال کے لیے کون سے ماڈلز دستیاب ہیں۔ یہ کمانڈ تمام سپورٹڈ ماڈلز دکھائے گی:

```bash
foundry model list
```

### مرحلہ 3: Phi Family ماڈلز کو سمجھنا

Phi Family مختلف استعمال کے کیسز اور ہارڈویئر کنفیگریشنز کے لیے بہتر بنائے گئے متعدد ماڈلز پیش کرتی ہے۔ یہاں Foundry Local میں دستیاب Phi ماڈلز ہیں:

**دستیاب Phi ماڈلز:**

- **phi-3.5-mini** - بنیادی کاموں کے لیے کمپیکٹ ماڈل  
- **phi-3-mini-128k** - طویل گفتگو کے لیے توسیع شدہ کانٹیکسٹ ورژن  
- **phi-3-mini-4k** - عام استعمال کے لیے معیاری کانٹیکسٹ ماڈل  
- **phi-4** - بہتر صلاحیتوں کے ساتھ جدید ماڈل  
- **phi-4-mini** - Phi-4 کا ہلکا ورژن  
- **phi-4-mini-reasoning** - پیچیدہ استدلالی کاموں کے لیے خاص

> **ہارڈویئر مطابقت:** ہر ماڈل کو آپ کے سسٹم کی صلاحیتوں کے مطابق مختلف ہارڈویئر ایکسیلیریشن (CPU، GPU) کے لیے کنفیگر کیا جا سکتا ہے۔

### مرحلہ 4: اپنا پہلا Phi ماڈل چلانا

آئیے ایک عملی مثال سے شروع کرتے ہیں۔ ہم `phi-4-mini-reasoning` ماڈل چلائیں گے، جو پیچیدہ مسائل کو قدم بہ قدم حل کرنے میں ماہر ہے۔

**ماڈل چلانے کی کمانڈ:**

```bash
foundry model run Phi-4-mini-reasoning-generic-cpu
```

> **پہلی بار سیٹ اپ:** جب آپ پہلی بار کوئی ماڈل چلائیں گے، تو Foundry Local اسے خودکار طریقے سے آپ کے مقامی ڈیوائس پر ڈاؤن لوڈ کرے گا۔ نیٹ ورک کی رفتار کے مطابق ڈاؤن لوڈ کا وقت مختلف ہو سکتا ہے، اس لیے ابتدائی سیٹ اپ کے دوران صبر کریں۔

### مرحلہ 5: ماڈل کو حقیقی مسئلے کے ساتھ آزمانا

اب آئیے اپنے ماڈل کو ایک کلاسک منطق کے مسئلے کے ساتھ ٹیسٹ کریں تاکہ دیکھیں یہ قدم بہ قدم استدلال کیسے کرتا ہے:

**مثال کا مسئلہ:**

```txt
Please calculate the following step by step: Now there are pheasants and rabbits in the same cage, there are thirty-five heads on top and ninety-four legs on the bottom, how many pheasants and rabbits are there?
```

**متوقع رویہ:** ماڈل کو چاہیے کہ یہ مسئلہ منطقی مراحل میں تقسیم کرے، اس بات کو استعمال کرتے ہوئے کہ فیزنٹس کے 2 پیر ہوتے ہیں اور خرگوشوں کے 4 پیر، تاکہ مساوات کا نظام حل کیا جا سکے۔

**نتائج:**

![cli](../../../../../translated_images/cli.862ec6b55c2b5d916093866d4df99190150d4198fd33ab79e586f9d6f5403089.ur.png)

## حصہ 2: Foundry Local SDK کے ساتھ ایپلیکیشنز بنانا

### SDK کیوں استعمال کریں؟

جبکہ CLI ٹیسٹنگ اور فوری تعاملات کے لیے بہترین ہے، SDK آپ کو Foundry Local کو پروگراماتی طور پر اپنی ایپلیکیشنز میں ضم کرنے کی سہولت دیتا ہے۔ اس سے یہ امکانات کھلتے ہیں:

- کسٹم AI پاورڈ ایپلیکیشنز بنانا  
- خودکار ورک فلو تخلیق کرنا  
- موجودہ سسٹمز میں AI صلاحیتوں کا انضمام  
- چیٹ بوٹس اور انٹرایکٹو ٹولز تیار کرنا

### مدد یافتہ پروگرامنگ زبانیں

Foundry Local مختلف پروگرامنگ زبانوں کے لیے SDK سپورٹ فراہم کرتا ہے تاکہ آپ کی ترقی کی ترجیحات کے مطابق ہو:

**📦 دستیاب SDKs:**

- **C# (.NET):** [SDK Documentation & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/cs)  
- **Python:** [SDK Documentation & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)  
- **JavaScript:** [SDK Documentation & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/js)  
- **Rust:** [SDK Documentation & Examples](https://github.com/microsoft/Foundry-Local/tree/main/sdk/rust)

### اگلے اقدامات

1. اپنی ترقیاتی ماحول کے مطابق **اپنا پسندیدہ SDK منتخب کریں**  
2. تفصیلی نفاذ کے لیے **SDK مخصوص دستاویزات پر عمل کریں**  
3. پیچیدہ ایپلیکیشنز بنانے سے پہلے **سادہ مثالوں سے آغاز کریں**  
4. ہر SDK ریپوزیٹری میں موجود **نمونہ کوڈ کو دریافت کریں**

## نتیجہ

اب آپ نے سیکھ لیا ہے کہ کیسے:

- ✅ Foundry Local CLI انسٹال اور سیٹ اپ کریں  
- ✅ Phi Family ماڈلز دریافت اور چلائیں  
- ✅ حقیقی مسائل کے ساتھ ماڈلز کو ٹیسٹ کریں  
- ✅ ایپلیکیشن ڈیولپمنٹ کے لیے SDK کے اختیارات کو سمجھیں

Foundry Local آپ کے مقامی ماحول میں AI صلاحیتیں براہ راست لانے کے لیے ایک مضبوط بنیاد فراہم کرتا ہے، جس سے آپ کو کارکردگی، پرائیویسی، اور لاگت پر کنٹرول ملتا ہے، اور ضرورت پڑنے پر کلاؤڈ حل کی طرف اسکیل کرنے کی لچک بھی حاصل ہوتی ہے۔

**ڈس کلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر نہیں ہوگی۔