<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b08e277df2a9307f861ae54bc30c772",
  "translation_date": "2025-05-07T15:08:12+00:00",
  "source_file": "md/01.Introduction/02/06.NVIDIA.md",
  "language_code": "ur"
}
-->
## NVIDIA NIM میں Phi فیملی

NVIDIA NIM ایک آسان مائیکروسروسز کا مجموعہ ہے جو کلاؤڈ، ڈیٹا سینٹر، اور ورک سٹیشنز میں جنریٹو AI ماڈلز کی تعیناتی کو تیز کرنے کے لیے ڈیزائن کیا گیا ہے۔ NIMs کو ماڈل فیملی اور ہر ماڈل کی بنیاد پر درجہ بندی کیا گیا ہے۔ مثال کے طور پر، بڑے زبان کے ماڈلز (LLMs) کے لیے NVIDIA NIM جدید ترین LLMs کی طاقت کو انٹرپرائز ایپلیکیشنز تک پہنچاتا ہے، جو بے مثال قدرتی زبان کی پروسیسنگ اور سمجھنے کی صلاحیتیں فراہم کرتا ہے۔

NIM IT اور DevOps ٹیموں کے لیے اپنے منظم ماحول میں بڑے زبان کے ماڈلز (LLMs) کو خود ہوسٹ کرنا آسان بناتا ہے جبکہ ڈیولپرز کو صنعت کے معیاری APIs مہیا کرتا ہے جو انہیں طاقتور کوپائلٹس، چیٹ بوٹس، اور AI اسسٹنٹس بنانے کی اجازت دیتے ہیں جو ان کے کاروبار کو تبدیل کر سکتے ہیں۔ NVIDIA کی جدید GPU ایکسیلیریشن اور اسکیل ایبل تعیناتی کا فائدہ اٹھاتے ہوئے، NIM بے مثال کارکردگی کے ساتھ انفرنس کا سب سے تیز راستہ پیش کرتا ہے۔

آپ NVIDIA NIM کو Phi فیملی ماڈلز کی انفرنس کے لیے استعمال کر سکتے ہیں

![nim](../../../../../translated_images/Phi-NIM.09bebb743387ee4a5028d7d4f8fed55e619711b26c8937526b43a2af980f7dcf.ur.png)

### **نمونے - NVIDIA NIM میں Phi-3-Vision**

فرض کریں آپ کے پاس ایک تصویر (`demo.png`) ہے اور آپ Python کوڈ جنریٹ کرنا چاہتے ہیں جو اس تصویر کو پروسیس کرے اور اس کی ایک نئی ورژن محفوظ کرے (`phi-3-vision.jpg`)۔

اوپر دیا گیا کوڈ اس عمل کو خودکار بناتا ہے:

1. ماحول اور ضروری کنفیگریشنز سیٹ کرنا۔
2. ایک پرامپٹ تیار کرنا جو ماڈل کو مطلوبہ Python کوڈ جنریٹ کرنے کی ہدایت دے۔
3. پرامپٹ کو ماڈل کو بھیجنا اور جنریٹ کیے گئے کوڈ کو جمع کرنا۔
4. جنریٹ کیے گئے کوڈ کو نکالنا اور چلانا۔
5. اصل اور پروسیس کی گئی تصاویر دکھانا۔

یہ طریقہ کار AI کی طاقت کو استعمال کرتے ہوئے تصویر پروسیسنگ کے کاموں کو خودکار بناتا ہے، جس سے آپ کے مقاصد کو حاصل کرنا آسان اور تیز ہو جاتا ہے۔

[Sample Code Solution](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

آئیے پورے کوڈ کو قدم بہ قدم سمجھتے ہیں:

1. **ضروری پیکج انسٹال کریں**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    یہ کمانڈ `langchain_nvidia_ai_endpoints` پیکج انسٹال کرتی ہے اور یقینی بناتی ہے کہ یہ تازہ ترین ورژن ہو۔

2. **ضروری ماڈیولز امپورٹ کریں**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    یہ امپورٹس NVIDIA AI endpoints کے ساتھ تعامل، پاس ورڈز کو محفوظ طریقے سے ہینڈل کرنے، آپریٹنگ سسٹم کے ساتھ کام کرنے، اور base64 فارمیٹ میں ڈیٹا انکوڈ/ڈیکوڈ کرنے کے لیے ضروری ماڈیولز لاتے ہیں۔

3. **API کلید سیٹ کریں**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    یہ کوڈ چیک کرتا ہے کہ `NVIDIA_API_KEY` انوائرمنٹ ویریبل سیٹ ہے یا نہیں۔ اگر نہیں، تو صارف سے محفوظ طریقے سے API کلید مانگی جاتی ہے۔

4. **ماڈل اور تصویر کا راستہ تعین کریں**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    یہ ماڈل کو منتخب کرتا ہے، `ChatNVIDIA` کی ایک مثال بناتا ہے اور تصویر کی فائل کا راستہ متعین کرتا ہے۔

5. **ٹیکسٹ پرامپٹ بنائیں**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    یہ ایک ٹیکسٹ پرامپٹ ڈیفائن کرتا ہے جو ماڈل کو تصویر پروسیس کرنے کے لیے Python کوڈ بنانے کی ہدایت دیتا ہے۔

6. **تصویر کو base64 میں انکوڈ کریں**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    یہ کوڈ تصویر کی فائل پڑھتا ہے، اسے base64 میں انکوڈ کرتا ہے، اور انکوڈ کیے گئے ڈیٹا کے ساتھ ایک HTML امیج ٹیگ بناتا ہے۔

7. **ٹیکسٹ اور تصویر کو پرامپٹ میں ملائیں**:
    ```python
    prompt = f"{text} {image}"
    ```
    یہ ٹیکسٹ پرامپٹ اور HTML امیج ٹیگ کو ایک سٹرنگ میں جوڑتا ہے۔

8. **ChatNVIDIA کے ذریعے کوڈ جنریٹ کریں**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    یہ کوڈ پرامپٹ کو `ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code` سٹرنگ کو بھیجتا ہے۔

9. **جنریٹ کیے گئے مواد سے Python کوڈ نکالیں**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    یہ مارک ڈاؤن فارمیٹنگ ہٹا کر جنریٹ کیے گئے مواد سے اصل Python کوڈ نکالتا ہے۔

10. **جنریٹ کیے گئے کوڈ کو چلائیں**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    یہ نکالا گیا Python کوڈ subprocess کے طور پر چلاتا ہے اور اس کا آؤٹ پٹ حاصل کرتا ہے۔

11. **تصاویر دکھائیں**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    یہ لائنز `IPython.display` ماڈیول کا استعمال کرتے ہوئے تصاویر کو دکھاتی ہیں۔

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم آگاہ رہیں کہ خودکار تراجم میں غلطیاں یا بے ضابطگیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں ہی معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ورانہ انسانی ترجمہ تجویز کیا جاتا ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔