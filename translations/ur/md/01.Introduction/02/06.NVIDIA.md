<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b028cdc5b33b99efb0f061bcff71023",
  "translation_date": "2025-04-03T06:46:06+00:00",
  "source_file": "md\\01.Introduction\\02\\06.NVIDIA.md",
  "language_code": "ur"
}
-->
## NVIDIA NIM میں Phi فیملی

NVIDIA NIM ایک آسان استعمال مائیکرو سروسز کا سیٹ ہے جو جنریٹو AI ماڈلز کو کلاؤڈ، ڈیٹا سینٹر، اور ورک اسٹیشنز پر تیزی سے نافذ کرنے کے لیے بنایا گیا ہے۔ NIM ماڈلز کو فیملی اور انفرادی ماڈل کی بنیاد پر تقسیم کرتا ہے۔ مثال کے طور پر، بڑے لینگویج ماڈلز (LLMs) کے لیے NVIDIA NIM جدید ترین LLMs کی طاقت کو انٹرپرائز ایپلیکیشنز میں لاتا ہے، جو بے مثال قدرتی زبان کی پروسیسنگ اور سمجھنے کی صلاحیتیں فراہم کرتا ہے۔

NIM IT اور DevOps ٹیمز کو اپنی خود کی مینیجڈ ماحول میں بڑے لینگویج ماڈلز (LLMs) کو ہوسٹ کرنے میں آسانی فراہم کرتا ہے، جبکہ ڈیولپرز کو انڈسٹری اسٹینڈرڈ APIs فراہم کرتا ہے تاکہ وہ طاقتور کوپائلٹس، چیٹ بوٹس، اور AI اسسٹنٹس بنا سکیں جو ان کے کاروبار کو بدل سکتے ہیں۔ NVIDIA کی جدید ترین GPU ایکسیلریشن اور اسکیل ایبل ڈیپلائمنٹ کا فائدہ اٹھاتے ہوئے، NIM بے مثال کارکردگی کے ساتھ تیزی سے انفرنس کا راستہ فراہم کرتا ہے۔

آپ NVIDIA NIM کو Phi فیملی ماڈلز کے انفرنس کے لیے استعمال کر سکتے ہیں۔

![nim](../../../../../translated_images/Phi-NIM.45af94d89220fbbbc85f8da0379150a29cc88c3dd8ec417b1d3b7237bbe1c58a.ur.png)

### **نمونے - NVIDIA NIM میں Phi-3-Vision**

فرض کریں کہ آپ کے پاس ایک تصویر (`demo.png`) ہے اور آپ اس تصویر کو پروسیس کرنے اور اس کا نیا ورژن محفوظ کرنے کے لیے Python کوڈ بنانا چاہتے ہیں (`phi-3-vision.jpg`)۔

اوپر دیا گیا کوڈ اس عمل کو خودکار بناتا ہے:

1. ماحول اور ضروری کنفیگریشنز کو سیٹ کرنا۔
2. ایک پرومپٹ بنانا جو ماڈل کو مطلوبہ Python کوڈ تیار کرنے کی ہدایت دیتا ہے۔
3. پرومپٹ کو ماڈل کو بھیجنا اور تیار کردہ کوڈ کو جمع کرنا۔
4. تیار کردہ کوڈ کو نکالنا اور چلانا۔
5. اصل اور پروسیس شدہ تصاویر کو دکھانا۔

یہ طریقہ AI کی طاقت کو استعمال کرتے ہوئے امیج پروسیسنگ کے کاموں کو خودکار بناتا ہے، جس سے آپ کے اہداف کو حاصل کرنا آسان اور تیز ہو جاتا ہے۔

[نمونہ کوڈ حل](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

آئیے پورے کوڈ کو قدم بہ قدم سمجھتے ہیں:

1. **ضروری پیکج انسٹال کریں**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    یہ کمانڈ `langchain_nvidia_ai_endpoints` پیکج کو انسٹال کرتی ہے، یہ یقینی بناتے ہوئے کہ یہ تازہ ترین ورژن ہے۔

2. **ضروری ماڈیولز درآمد کریں**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    یہ درآمدات NVIDIA AI اینڈپوائنٹس کے ساتھ تعامل، پاسورڈز کو محفوظ طریقے سے ہینڈل کرنے، آپریٹنگ سسٹم کے ساتھ تعامل، اور بیس64 فارمیٹ میں ڈیٹا کو انکوڈ/ڈیکوڈ کرنے کے لیے ضروری ماڈیولز لاتے ہیں۔

3. **API کلید سیٹ کریں**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    یہ کوڈ چیک کرتا ہے کہ آیا `NVIDIA_API_KEY` ماحولیات متغیر سیٹ ہے۔ اگر نہیں، تو یہ صارف کو اپنی API کلید محفوظ طریقے سے درج کرنے کا اشارہ دیتا ہے۔

4. **ماڈل اور تصویر کا راستہ متعین کریں**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    یہ استعمال ہونے والے ماڈل کو سیٹ کرتا ہے، `ChatNVIDIA` کی ایک انسٹینس کو مخصوص ماڈل کے ساتھ بناتا ہے، اور تصویر فائل کے راستے کو متعین کرتا ہے۔

5. **ٹیکسٹ پرومپٹ بنائیں**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    یہ ایک ٹیکسٹ پرومپٹ متعین کرتا ہے جو ماڈل کو تصویر پروسیسنگ کے لیے Python کوڈ تیار کرنے کی ہدایت دیتا ہے۔

6. **تصویر کو بیس64 میں انکوڈ کریں**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    یہ کوڈ تصویر فائل کو پڑھتا ہے، اسے بیس64 میں انکوڈ کرتا ہے، اور انکوڈ شدہ ڈیٹا کے ساتھ ایک HTML تصویر ٹیگ بناتا ہے۔

7. **ٹیکسٹ اور تصویر کو پرومپٹ میں یکجا کریں**:
    ```python
    prompt = f"{text} {image}"
    ```
    یہ ٹیکسٹ پرومپٹ اور HTML تصویر ٹیگ کو ایک سنگل اسٹرنگ میں یکجا کرتا ہے۔

8. **ChatNVIDIA کا استعمال کرتے ہوئے کوڈ تیار کریں**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    یہ کوڈ پرومپٹ کو `ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code` اسٹرنگ کو بھیجتا ہے۔

9. **تیار کردہ مواد سے Python کوڈ نکالیں**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    یہ تیار کردہ مواد سے اصل Python کوڈ کو نکالتا ہے، مارک ڈاؤن فارمیٹنگ کو ہٹاتے ہوئے۔

10. **تیار کردہ کوڈ چلائیں**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    یہ تیار کردہ Python کوڈ کو ایک سب پروسیس کے طور پر چلاتا ہے اور اس کے آؤٹ پٹ کو کیپچر کرتا ہے۔

11. **تصاویر دکھائیں**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    یہ لائنز `IPython.display` ماڈیول کا استعمال کرتے ہوئے تصاویر کو دکھاتی ہیں۔

**ڈسکلوزر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستیاں ہوسکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔