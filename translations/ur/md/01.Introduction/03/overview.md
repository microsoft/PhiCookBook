<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d570fac7029d6697ad8ab1c963b43811",
  "translation_date": "2025-04-03T06:56:38+00:00",
  "source_file": "md\\01.Introduction\\03\\overview.md",
  "language_code": "ur"
}
-->
فی-3-منی میں، "انفرنس" کا مطلب ہے ماڈل کا استعمال کرتے ہوئے پیشگوئی کرنا یا ان پٹ ڈیٹا کی بنیاد پر نتائج پیدا کرنا۔ آئیے آپ کو فی-3-منی اور اس کی انفرنس صلاحیتوں کے بارے میں مزید تفصیلات فراہم کرتے ہیں۔

فی-3-منی، مائیکروسافٹ کی جانب سے جاری کردہ فی-3 ماڈلز کی سیریز کا حصہ ہے۔ یہ ماڈلز چھوٹے لینگویج ماڈلز (SLMs) کے ساتھ ممکنات کو نئے انداز میں پیش کرنے کے لیے ڈیزائن کیے گئے ہیں۔

یہاں فی-3-منی اور اس کی انفرنس صلاحیتوں کے بارے میں کچھ اہم نکات ہیں:

## **فی-3-منی کا تعارف:**
- فی-3-منی کے پیرامیٹرز کا سائز 3.8 بلین ہے۔
- یہ نہ صرف روایتی کمپیوٹنگ ڈیوائسز پر چل سکتا ہے بلکہ موبائل ڈیوائسز اور آئی او ٹی ڈیوائسز جیسے ایج ڈیوائسز پر بھی چلنے کی صلاحیت رکھتا ہے۔
- فی-3-منی کی ریلیز افراد اور اداروں کو مختلف ہارڈویئر ڈیوائسز پر SLMs کو ڈیپلائے کرنے کی سہولت فراہم کرتی ہے، خاص طور پر وسائل محدود ماحول میں۔
- یہ مختلف ماڈل فارمیٹس کو سپورٹ کرتا ہے، جن میں روایتی پائی ٹارچ فارمیٹ، gguf فارمیٹ کا کوانٹائزڈ ورژن، اور ONNX پر مبنی کوانٹائزڈ ورژن شامل ہیں۔

## **فی-3-منی تک رسائی:**
فی-3-منی تک رسائی کے لیے آپ [Semantic Kernel](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) کو ایک کوپائلٹ ایپلیکیشن میں استعمال کر سکتے ہیں۔ سیمینٹک کرنل عام طور پر Azure OpenAI Service، Hugging Face پر موجود اوپن سورس ماڈلز، اور لوکل ماڈلز کے ساتھ مطابقت رکھتا ہے۔  
آپ [Ollama](https://ollama.com) یا [LlamaEdge](https://llamaedge.com) کو کوانٹائزڈ ماڈلز کال کرنے کے لیے بھی استعمال کر سکتے ہیں۔ Ollama انفرادی صارفین کو مختلف کوانٹائزڈ ماڈلز کال کرنے کی سہولت فراہم کرتا ہے، جبکہ LlamaEdge GGUF ماڈلز کے لیے کراس پلیٹ فارم دستیابی فراہم کرتا ہے۔

## **کوانٹائزڈ ماڈلز:**
بہت سے صارفین لوکل انفرنس کے لیے کوانٹائزڈ ماڈلز کو ترجیح دیتے ہیں۔ مثال کے طور پر، آپ Ollama پر براہ راست فی-3 چلانے یا اسے آف لائن موڈ فائل کے ذریعے کنفیگر کر سکتے ہیں۔ موڈ فائل GGUF فائل کے راستے اور پرامپٹ فارمیٹ کی وضاحت کرتی ہے۔

## **جنریٹو AI کی ممکنات:**
ایسے SLMs کو فی-3-منی جیسے ماڈلز کے ساتھ ملا کر جنریٹو AI کے لیے نئی ممکنات پیدا کی جا سکتی ہیں۔ انفرنس صرف پہلا قدم ہے؛ یہ ماڈلز مختلف ٹاسکس کے لیے وسائل محدود، لیٹنسی پر مبنی، اور لاگت محدود منظرناموں میں استعمال کیے جا سکتے ہیں۔

## **فی-3-منی کے ذریعے جنریٹو AI کو انلاک کرنا: انفرنس اور ڈیپلائمنٹ کی رہنمائی**
سیمینٹک کرنل، Ollama/LlamaEdge، اور ONNX Runtime کو استعمال کرتے ہوئے فی-3-منی ماڈلز تک رسائی حاصل کرنے اور انفرنس کرنے کا طریقہ سیکھیں، اور مختلف ایپلیکیشن منظرناموں میں جنریٹو AI کی ممکنات کو دریافت کریں۔

**خصوصیات**  
فی-3-منی ماڈل کی انفرنس درج ذیل میں کریں:

- [Semantic Kernel](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo)
- [Ollama](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)
- [LlamaEdge WASM](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo)
- [ONNX Runtime](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/onnx?WT.mc_id=aiml-138114-kinfeylo)
- [iOS](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ios?WT.mc_id=aiml-138114-kinfeylo)

خلاصہ یہ کہ فی-3-منی ڈویلپرز کو مختلف ماڈل فارمیٹس کو دریافت کرنے اور مختلف ایپلیکیشن منظرناموں میں جنریٹو AI کو استعمال کرنے کی سہولت فراہم کرتا ہے۔

**ڈس کلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے بھرپور کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔