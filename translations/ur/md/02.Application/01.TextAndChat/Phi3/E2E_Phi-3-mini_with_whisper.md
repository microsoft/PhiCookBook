<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f72d7981ed3640865700f51ae407da4",
  "translation_date": "2026-01-14T15:10:41+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md",
  "language_code": "ur"
}
-->
# انٹرایکٹو فی ۳ منی ۴ کے انسٹرکٹ چیٹ بوٹ ود وسپر

## جائزہ

انٹرایکٹو فی ۳ منی ۴ کے انسٹرکٹ چیٹ بوٹ ایک ایسا آلہ ہے جو صارفین کو مائیکروسافٹ فی ۳ منی ۴ کے انسٹرکٹ ڈیمو کے ساتھ متن یا آڈیو ان پٹ کے ذریعے تعامل کرنے کی اجازت دیتا ہے۔ اس چیٹ بوٹ کو مختلف کاموں کے لیے استعمال کیا جا سکتا ہے، جیسے ترجمہ، موسم کی تازہ کاری، اور عمومی معلومات حاصل کرنا۔

### شروعات

اس چیٹ بوٹ کو استعمال کرنے کے لیے، بس ان ہدایات پر عمل کریں:

1. ایک نیا [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) کھولیں
2. نوٹ بک کی مرکزی ونڈو میں، آپ کو ایک چیٹ باکس انٹرفیس نظر آئے گا جس میں ایک متن ان پٹ باکس اور "Send" بٹن ہوگا۔
3. متن پر مبنی چیٹ بوٹ استعمال کرنے کے لیے، بس اپنا پیغام متن ان پٹ باکس میں ٹائپ کریں اور "Send" بٹن پر کلک کریں۔ چیٹ بوٹ آڈیو فائل کے ساتھ جواب دے گا جسے براہ راست نوٹ بک کے اندر چلایا جا سکتا ہے۔

**نوٹ**: اس آلے کے لیے جی پی یو اور مائیکروسافٹ فی-۳ اور اوپن اے آئی وسپر ماڈلز تک رسائی درکار ہے، جو تقریر کی پہچان اور ترجمے کے لیے استعمال ہوتے ہیں۔

### جی پی یو کی ضروریات

اس ڈیمو کو چلانے کے لیے آپ کو 12GB جی پی یو میموری کی ضرورت ہے۔

**مائیکروسافٹ-فی-3-منی-4K انسٹرکٹ** ڈیمو کو جی پی یو پر چلانے کے لیے میموری کی ضروریات کئی عوامل پر منحصر ہوتی ہیں، جیسے ان پٹ ڈیٹا (آڈیو یا متن) کا سائز، ترجمے کے لیے زبان، ماڈل کی رفتار، اور جی پی یو پر دستیاب میموری۔

عمومی طور پر، وسپر ماڈل جی پی یوز پر چلانے کے لیے ڈیزائن کیا گیا ہے۔ وسپر ماڈل چلانے کے لیے سفارش کردہ کم از کم جی پی یو میموری 8 جی بی ہے، لیکن یہ ضرورت پڑنے پر بڑی مقدار کی میموری بھی سنبھال سکتا ہے۔

یہ بات اہم ہے کہ زیادہ مقدار میں ڈیٹا یا درخواستوں کی بڑی تعداد ماڈل پر چلانا جی پی یو میموری کی زیادہ ضرورت پیدا کر سکتا ہے اور/یا کارکردگی کے مسائل پیدا کر سکتا ہے۔ اپنی مخصوص ضروریات کے لیے بہترین ترتیبات معلوم کرنے کے لیے مختلف کنفیگریشنز کے ساتھ ٹیسٹ کرنا اور میموری کا استعمال مانیٹر کرنا تجویز کیا جاتا ہے۔

## انٹرایکٹو فی ۳ منی ۴ کے انسٹرکٹ چیٹ بوٹ ود وسپر کے لیے E2E نمونہ

جہاں جیوپیٹر نوٹ بک کا عنوان [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) ہے، وہ مائیکروسافٹ فی ۳ منی ۴ کے انسٹرکٹ ڈیمو کو آڈیو یا تحریری متن سے متن تیار کرنے کے لیے استعمال کرنے کا طریقہ دکھاتا ہے۔ نوٹ بک میں چند فنکشنز کی تعریف کی گئی ہے:

1. `tts_file_name(text)`: یہ فنکشن جنریٹ شدہ آڈیو فائل محفوظ کرنے کے لیے ان پٹ متن کی بنیاد پر فائل کا نام تیار کرتا ہے۔
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: یہ فنکشن ایج ٹی ٹی ایس API استعمال کرتے ہوئے ان پٹ متن کے چنکس کی فہرست سے آڈیو فائل تیار کرتا ہے۔ ان پٹ پیرامیٹرز چنکس کی فہرست، تقریر کی رفتار، آواز کا نام، اور جنریٹ شدہ آڈیو فائل محفوظ کرنے کا راستہ ہیں۔
1. `talk(input_text)`: یہ فنکشن ایج ٹی ٹی ایس API استعمال کرتے ہوئے آڈیو فائل تیار کرتا ہے اور اسے /content/audio ڈائرکٹری میں ایک تصادفی فائل نام کے ساتھ محفوظ کرتا ہے۔ ان پٹ پیرامیٹر وہ متن ہے جسے تقریر میں تبدیل کرنا ہوتا ہے۔
1. `run_text_prompt(message, chat_history)`: یہ فنکشن مائیکروسافٹ فی ۳ منی ۴ کے انسٹرکٹ ڈیمو کا استعمال کرتے ہوئے میسج ان پٹ سے آڈیو فائل تیار کرتا ہے اور اسے چیٹ ہسٹری میں شامل کرتا ہے۔
1. `run_audio_prompt(audio, chat_history)`: یہ فنکشن آڈیو فائل کو وسپر ماڈل API کے ذریعے متن میں تبدیل کرتا ہے اور اسے `run_text_prompt()` فنکشن کو دیتا ہے۔
1. کوڈ ایک گرادیو ایپ لانچ کرتا ہے جو صارفین کو میسجز ٹائپ کرنے یا آڈیو فائلز اپلوڈ کرنے کے ذریعے فی ۳ منی ۴ کے انسٹرکٹ ڈیمو کے ساتھ تعامل کی اجازت دیتا ہے۔ آؤٹ پٹ ایپ میں ایک متن کے پیغام کے طور پر دکھایا جاتا ہے۔

## مسئلے کا حل

Cuda GPU ڈرائیورز کی تنصیب

1. یقینی بنائیں کہ آپ کے لینکس ایپلیکیشنز تازہ ترین ہیں

    ```bash
    sudo apt update
    ```

1. Cuda ڈرائیورز انسٹال کریں

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. cuda ڈرائیور کی جگہ رجسٹر کریں

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Nvidia GPU میموری کا سائز چیک کریں (درکار 12GB جی پی یو میموری)

    ```bash
    nvidia-smi
    ```

1. کیشے خالی کریں: اگر آپ پائی ٹارچ استعمال کر رہے ہیں، تو torch.cuda.empty_cache() کال کرکے تمام غیر استعمال شدہ کیش شدہ میموری جاری کریں تاکہ دوسری GPU ایپلیکیشنز استعمال کر سکیں

    ```python
    torch.cuda.empty_cache() 
    ```

1. Nvidia Cuda چیک کریں

    ```bash
    nvcc --version
    ```

1. Hugging Face ٹوکن بنانے کے لیے درج ذیل کام کریں۔

    - [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo) پر جائیں۔
    - **New token** منتخب کریں۔
    - وہ منصوبہ کا **Name** درج کریں جسے آپ استعمال کرنا چاہتے ہیں۔
    - **Type** کو **Write** منتخب کریں۔

> [!NOTE]
>
> اگر آپ کو درج ذیل غلطی کا سامنا ہو:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> اس کا حل کرنے کے لیے، اپنے ٹرمینل میں درج ذیل کمانڈ ٹائپ کریں۔
>
> ```bash
> sudo ldconfig
> ```

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**دستخطی عبارت**:  
اس دستاویز کا ترجمہ AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے کیا گیا ہے۔ ہم درستگی کے لیے کوشاں ہیں، مگر براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا نادقتیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں ہی معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ تجویز کیا جاتا ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تفسیر کی ذمہ داری ہم پر عائد نہیں ہوتی۔
<!-- CO-OP TRANSLATOR DISCLAIMER END -->