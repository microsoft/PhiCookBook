<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cb5648935f63edc17e95ce38f23adc32",
  "translation_date": "2025-07-17T08:31:39+00:00",
  "source_file": "md/03.FineTuning/FineTuning_Scenarios.md",
  "language_code": "uk"
}
-->
## Сценарії тонкого налаштування

![FineTuning with MS Services](../../../../translated_images/uk/FinetuningwithMS.3d0cec8ae693e094.png)

**Платформа** Включає різні технології, такі як Azure AI Foundry, Azure Machine Learning, AI Tools, Kaito та ONNX Runtime.

**Інфраструктура** Включає CPU та FPGA, які є ключовими для процесу тонкого налаштування. Дозвольте показати вам іконки для кожної з цих технологій.

**Інструменти та фреймворки** Включає ONNX Runtime та ONNX Runtime. Дозвольте показати вам іконки для кожної з цих технологій.  
[Вставте іконки для ONNX Runtime та ONNX Runtime]

Процес тонкого налаштування з використанням технологій Microsoft включає різні компоненти та інструменти. Розуміючи та використовуючи ці технології, ми можемо ефективно налаштовувати наші додатки та створювати кращі рішення.

## Модель як сервіс

Тонке налаштування моделі за допомогою хостингового тонкого налаштування, без необхідності створювати та керувати обчислювальними ресурсами.

![MaaS Fine Tuning](../../../../translated_images/uk/MaaSfinetune.3eee4630607aff0d.png)

Безсерверне тонке налаштування доступне для моделей Phi-3-mini та Phi-3-medium, що дозволяє розробникам швидко та легко налаштовувати моделі для хмарних та edge-сценаріїв без необхідності організовувати обчислення. Ми також оголосили, що Phi-3-small тепер доступна через нашу пропозицію Models-as-a-Service, щоб розробники могли швидко та просто почати розробку AI без необхідності керувати базовою інфраструктурою.

## Модель як платформа

Користувачі керують власними обчислювальними ресурсами для тонкого налаштування своїх моделей.

![Maap Fine Tuning](../../../../translated_images/uk/MaaPFinetune.fd3829c1122f5d1c.png)

[Приклад тонкого налаштування](https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/system/finetune/chat-completion/chat-completion.ipynb)

## Сценарії тонкого налаштування

| | | | | | | |
|-|-|-|-|-|-|-|
|Сценарій|LoRA|QLoRA|PEFT|DeepSpeed|ZeRO|DORA|
|Адаптація попередньо навчених LLM до конкретних завдань або доменів|Так|Так|Так|Так|Так|Так|
|Тонке налаштування для NLP-завдань, таких як класифікація тексту, розпізнавання іменованих сутностей та машинний переклад|Так|Так|Так|Так|Так|Так|
|Тонке налаштування для завдань QA|Так|Так|Так|Так|Так|Так|
|Тонке налаштування для генерації відповідей, схожих на людські, у чат-ботах|Так|Так|Так|Так|Так|Так|
|Тонке налаштування для створення музики, мистецтва або інших форм творчості|Так|Так|Так|Так|Так|Так|
|Зменшення обчислювальних та фінансових витрат|Так|Так|Ні|Так|Так|Ні|
|Зменшення використання пам’яті|Ні|Так|Ні|Так|Так|Так|
|Використання меншої кількості параметрів для ефективного тонкого налаштування|Ні|Так|Так|Ні|Ні|Так|
|Ефективна за пам’яттю форма паралелізму даних, що дає доступ до сумарної пам’яті GPU всіх доступних пристроїв|Ні|Ні|Ні|Так|Так|Так|

## Приклади продуктивності тонкого налаштування

![Finetuning Performance](../../../../translated_images/uk/Finetuningexamples.a9a41214f8f5afc1.png)

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується звертатися до професійного людського перекладу. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.