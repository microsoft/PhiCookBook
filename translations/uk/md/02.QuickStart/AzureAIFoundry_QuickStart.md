<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3a1e48b628022485aac989c9f733e792",
  "translation_date": "2025-07-09T20:08:01+00:00",
  "source_file": "md/02.QuickStart/AzureAIFoundry_QuickStart.md",
  "language_code": "uk"
}
-->
# **Використання Phi-3 в Azure AI Foundry**

З розвитком генеративного ШІ ми прагнемо використовувати єдину платформу для керування різними LLM та SLM, інтеграції корпоративних даних, операцій тонкого налаштування/RAG, а також оцінки різних бізнес-процесів після інтеграції LLM та SLM, щоб генеративний ШІ міг краще реалізовувати розумні додатки. [Azure AI Foundry](https://ai.azure.com) — це корпоративна платформа для застосування генеративного ШІ.

![aistudo](../../../../imgs/01/02/03/aifoundry_home.png)

За допомогою Azure AI Foundry ви можете оцінювати відповіді великих мовних моделей (LLM) та організовувати компоненти застосунків із підказками за допомогою prompt flow для покращення продуктивності. Платформа забезпечує масштабованість, що дозволяє легко перетворювати прототипи в повноцінне виробництво. Безперервний моніторинг і вдосконалення підтримують довгостроковий успіх.

Ми можемо швидко розгорнути модель Phi-3 на Azure AI Foundry за допомогою простих кроків, а потім використовувати Azure AI Foundry для виконання Playground/Chat, тонкого налаштування, оцінки та інших пов’язаних завдань з Phi-3.

## **1. Підготовка**

Якщо у вас вже встановлено [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/overview?WT.mc_id=aiml-138114-kinfeylo) на вашому комп’ютері, використання цього шаблону зводиться до запуску цієї команди в новій директорії.

## Ручне створення

Створення проекту та хаба в Microsoft Azure AI Foundry — це чудовий спосіб організувати та керувати вашою роботою зі ШІ. Ось покрокова інструкція, щоб почати:

### Створення проекту в Azure AI Foundry

1. **Перейдіть до Azure AI Foundry**: Увійдіть у портал Azure AI Foundry.
2. **Створіть проект**:
   - Якщо ви перебуваєте в проекті, виберіть "Azure AI Foundry" у верхньому лівому куті сторінки, щоб перейти на головну сторінку.
   - Виберіть "+ Create project".
   - Введіть назву проекту.
   - Якщо у вас є хаб, він буде вибраний за замовчуванням. Якщо у вас є доступ до кількох хабів, ви можете вибрати інший зі списку. Якщо хочете створити новий хаб, виберіть "Create new hub" і введіть назву.
   - Виберіть "Create".

### Створення хаба в Azure AI Foundry

1. **Перейдіть до Azure AI Foundry**: Увійдіть у свій обліковий запис Azure.
2. **Створіть хаб**:
   - Виберіть Центр керування в лівому меню.
   - Виберіть "All resources", потім стрілку вниз поруч із "+ New project" і виберіть "+ New hub".
   - У діалоговому вікні "Create a new hub" введіть назву хаба (наприклад, contoso-hub) і за бажанням змініть інші поля.
   - Виберіть "Next", перегляньте інформацію, а потім натисніть "Create".

Для детальніших інструкцій звертайтеся до офіційної [документації Microsoft](https://learn.microsoft.com/azure/ai-studio/how-to/create-projects).

Після успішного створення ви можете отримати доступ до створеного студіо через [ai.azure.com](https://ai.azure.com/)

В одному AI Foundry може бути кілька проектів. Створіть проект у AI Foundry для підготовки.

Створіть Azure AI Foundry [QuickStarts](https://learn.microsoft.com/azure/ai-studio/quickstarts/get-started-code)

## **2. Розгортання моделі Phi в Azure AI Foundry**

Натисніть опцію Explore у проекті, щоб перейти до Каталогу моделей, і виберіть Phi-3

Виберіть Phi-3-mini-4k-instruct

Натисніть 'Deploy', щоб розгорнути модель Phi-3-mini-4k-instruct

> [!NOTE]
>
> Під час розгортання можна вибрати обчислювальні ресурси

## **3. Playground Chat Phi в Azure AI Foundry**

Перейдіть на сторінку розгортання, виберіть Playground і спілкуйтеся з Phi-3 в Azure AI Foundry

## **4. Розгортання моделі з Azure AI Foundry**

Щоб розгорнути модель із каталогу моделей Azure, виконайте такі кроки:

- Увійдіть в Azure AI Foundry.
- Виберіть модель, яку хочете розгорнути, у каталозі моделей Azure AI Foundry.
- На сторінці деталей моделі виберіть Deploy, а потім Serverless API з Azure AI Content Safety.
- Виберіть проект, у якому хочете розгорнути модель. Для використання Serverless API ваш робочий простір має належати до регіону East US 2 або Sweden Central. Ви можете налаштувати назву розгортання.
- У майстрі розгортання виберіть Pricing and terms, щоб ознайомитися з цінами та умовами використання.
- Виберіть Deploy. Дочекайтеся готовності розгортання та автоматичного переходу на сторінку Deployments.
- Виберіть Open in playground, щоб почати взаємодію з моделлю.
- Ви можете повернутися на сторінку Deployments, вибрати розгортання та звернути увагу на Target URL кінцевої точки та Secret Key, які можна використовувати для виклику розгортання та генерації відповідей.
- Деталі кінцевої точки, URL та ключі доступу завжди можна знайти на вкладці Build у розділі Components, вибравши Deployments.

> [!NOTE]
> Зверніть увагу, що ваш обліковий запис повинен мати роль Azure AI Developer у Resource Group для виконання цих кроків.

## **5. Використання Phi API в Azure AI Foundry**

Ви можете отримати доступ до https://{Your project name}.region.inference.ml.azure.com/swagger.json через Postman GET і, поєднуючи з Key, ознайомитися з доступними інтерфейсами.

Ви дуже зручно отримаєте параметри запиту, а також параметри відповіді.

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується звертатися до професійного людського перекладу. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.