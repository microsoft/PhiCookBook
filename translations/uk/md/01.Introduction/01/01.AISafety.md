<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8273672cc57df2be675407a1383aaf0",
  "translation_date": "2025-07-09T19:43:13+00:00",
  "source_file": "md/01.Introduction/01/01.AISafety.md",
  "language_code": "uk"
}
-->
# Безпека ШІ для моделей Phi  
Сімейство моделей Phi було розроблено відповідно до [Microsoft Responsible AI Standard](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl) — загальнофірмових вимог, заснованих на шести принципах: підзвітність, прозорість, справедливість, надійність і безпека, конфіденційність і захист, а також інклюзивність, які формують [принципи відповідального ШІ Microsoft](https://www.microsoft.com/ai/responsible-ai).

Як і попередні моделі Phi, було застосовано багатогранну оцінку безпеки та підхід до безпеки після навчання, з додатковими заходами, що враховують багатомовні можливості цього релізу. Наш підхід до навчання безпеки та оцінок, включно з тестуванням кількома мовами та категоріями ризиків, викладено в [Phi Safety Post-Training Paper](https://arxiv.org/abs/2407.13833). Хоча моделі Phi отримують користь від цього підходу, розробники повинні застосовувати найкращі практики відповідального ШІ, включно з картографуванням, вимірюванням і пом’якшенням ризиків, пов’язаних із їхнім конкретним випадком використання та культурним і мовним контекстом.

## Найкращі практики

Як і інші моделі, сімейство Phi потенційно може поводитися несправедливо, ненадійно або образливо.

Деякі обмеження поведінки SLM і LLM, про які варто знати:

- **Якість обслуговування:** Моделі Phi в основному навчені на англомовних текстах. Мови, окрім англійської, можуть демонструвати гіршу продуктивність. Варіанти англійської мови з меншою представленістю в навчальних даних можуть працювати гірше, ніж стандартна американська англійська.  
- **Відображення шкоди та підтримка стереотипів:** Ці моделі можуть надмірно або недостатньо відображати певні групи людей, ігнорувати представлення деяких груп або посилювати принизливі чи негативні стереотипи. Незважаючи на безпеку після навчання, ці обмеження можуть залишатися через різний рівень представленості різних груп або поширеність прикладів негативних стереотипів у навчальних даних, що відображають реальні патерни та суспільні упередження.  
- **Неприйнятний або образливий контент:** Моделі можуть генерувати інші типи неприйнятного або образливого контенту, що може робити їх непридатними для використання в чутливих контекстах без додаткових заходів, специфічних для конкретного випадку.  
- **Надійність інформації:** Мовні моделі можуть створювати безглуздий контент або вигадувати інформацію, яка звучить переконливо, але є неточною або застарілою.  
- **Обмежена сфера застосування для коду:** Більшість навчальних даних Phi-3 базується на Python і використовує поширені пакети, такі як "typing, math, random, collections, datetime, itertools". Якщо модель генерує Python-скрипти з використанням інших пакетів або скрипти іншими мовами, ми настійно рекомендуємо користувачам вручну перевіряти всі виклики API.

Розробники повинні застосовувати найкращі практики відповідального ШІ та нести відповідальність за дотримання відповідних законів і нормативів (наприклад, щодо конфіденційності, торгівлі тощо) у конкретних випадках використання.

## Роздуми про відповідальний ШІ

Як і інші мовні моделі, серія Phi потенційно може поводитися несправедливо, ненадійно або образливо. Деякі обмеження, про які варто пам’ятати:

**Якість обслуговування:** Моделі Phi в основному навчені на англомовних текстах. Мови, окрім англійської, можуть демонструвати гіршу продуктивність. Варіанти англійської мови з меншою представленістю в навчальних даних можуть працювати гірше, ніж стандартна американська англійська.

**Відображення шкоди та підтримка стереотипів:** Ці моделі можуть надмірно або недостатньо відображати певні групи людей, ігнорувати представлення деяких груп або посилювати принизливі чи негативні стереотипи. Незважаючи на безпеку після навчання, ці обмеження можуть залишатися через різний рівень представленості різних груп або поширеність прикладів негативних стереотипів у навчальних даних, що відображають реальні патерни та суспільні упередження.

**Неприйнятний або образливий контент:** Моделі можуть генерувати інші типи неприйнятного або образливого контенту, що може робити їх непридатними для використання в чутливих контекстах без додаткових заходів, специфічних для конкретного випадку.  
Надійність інформації: Мовні моделі можуть створювати безглуздий контент або вигадувати інформацію, яка звучить переконливо, але є неточною або застарілою.

**Обмежена сфера застосування для коду:** Більшість навчальних даних Phi-3 базується на Python і використовує поширені пакети, такі як "typing, math, random, collections, datetime, itertools". Якщо модель генерує Python-скрипти з використанням інших пакетів або скрипти іншими мовами, ми настійно рекомендуємо користувачам вручну перевіряти всі виклики API.

Розробники повинні застосовувати найкращі практики відповідального ШІ та нести відповідальність за дотримання відповідних законів і нормативів (наприклад, щодо конфіденційності, торгівлі тощо). Важливі аспекти для розгляду включають:

**Розподіл:** Моделі можуть бути непридатними для сценаріїв, які можуть мати значний вплив на юридичний статус або розподіл ресурсів чи життєвих можливостей (наприклад, житло, працевлаштування, кредитування тощо) без додаткових оцінок і заходів з усунення упереджень.

**Високоризикові сценарії:** Розробники повинні оцінити доцільність використання моделей у високоризикових сценаріях, де несправедливі, ненадійні або образливі результати можуть бути надзвичайно дорогими або призвести до шкоди. Це включає надання порад у чутливих або експертних сферах, де точність і надійність критично важливі (наприклад, юридичні або медичні консультації). Додаткові заходи безпеки слід впроваджувати на рівні застосунку відповідно до контексту розгортання.

**Дезінформація:** Моделі можуть генерувати неточну інформацію. Розробники повинні дотримуватися найкращих практик прозорості та інформувати кінцевих користувачів про те, що вони взаємодіють із системою ШІ. На рівні застосунку розробники можуть створювати механізми зворотного зв’язку та канали для підкріплення відповідей контекстною інформацією, специфічною для випадку використання, що відоме як Retrieval Augmented Generation (RAG).

**Генерація шкідливого контенту:** Розробники повинні оцінювати результати з урахуванням контексту та використовувати доступні класифікатори безпеки або власні рішення, відповідні для їхнього випадку використання.

**Зловживання:** Можливі інші форми зловживань, такі як шахрайство, спам або створення шкідливого ПЗ, і розробники повинні забезпечити, щоб їхні застосунки не порушували чинні закони та нормативи.

### Тонке налаштування та безпека контенту ШІ

Після тонкого налаштування моделі ми настійно рекомендуємо використовувати заходи [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) для моніторингу контенту, що генерується моделями, виявлення та блокування потенційних ризиків, загроз і проблем якості.

![Phi3AISafety](../../../../../imgs/01/01/01.phi3aisafety.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) підтримує як текстовий, так і графічний контент. Його можна розгортати в хмарі, у відключених контейнерах та на периферійних/вбудованих пристроях.

## Огляд Azure AI Content Safety

Azure AI Content Safety — це не універсальне рішення; його можна налаштувати відповідно до політик конкретного бізнесу. Крім того, його багатомовні моделі дозволяють одночасно розуміти кілька мов.

![AIContentSafety](../../../../../imgs/01/01/01.AIcontentsafety.png)

- **Azure AI Content Safety**  
- **Microsoft Developer**  
- **5 відео**

Сервіс Azure AI Content Safety виявляє шкідливий контент, створений користувачами та ШІ, у застосунках і сервісах. Він включає API для тексту та зображень, які дозволяють виявляти шкідливі або неприйнятні матеріали.

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується звертатися до професійного людського перекладу. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.