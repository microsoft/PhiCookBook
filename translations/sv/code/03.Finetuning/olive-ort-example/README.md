<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:32:29+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "sv"
}
-->
# Fine-tune Phi3 med Olive

I det h√§r exemplet kommer du att anv√§nda Olive f√∂r att:

1. Finjustera en LoRA-adapter f√∂r att klassificera fraser i Sad, Joy, Fear, Surprise.
1. Sl√• samman adaptervikterna med basmodellen.
1. Optimera och kvantisera modellen till `int4`.

Vi visar ocks√• hur du kan inferera den finjusterade modellen med ONNX Runtime (ORT) Generate API.

> **‚ö†Ô∏è F√∂r finjustering beh√∂ver du en l√§mplig GPU tillg√§nglig ‚Äì till exempel en A10, V100, A100.**

## üíæ Installera

Skapa en ny Python-virtuell milj√∂ (till exempel med `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Installera sedan Olive och beroenden f√∂r ett finjusteringsfl√∂de:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Finjustera Phi3 med Olive  
[Olive-konfigurationsfilen](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) inneh√•ller ett *workflow* med f√∂ljande *steg*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

P√• en √∂vergripande niv√• kommer detta workflow att:

1. Finjustera Phi3 (i 150 steg, vilket du kan √§ndra) med data fr√•n [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. Sl√• samman LoRA-adaptervikterna med basmodellen. Det ger dig en enda modellartefakt i ONNX-format.
1. Model Builder optimerar modellen f√∂r ONNX runtime *och* kvantiserar modellen till `int4`.

F√∂r att k√∂ra workflow, k√∂r:

```bash
olive run --config phrase-classification.json
```

N√§r Olive √§r klar finns din optimerade och finjusterade `int4` Phi3-modell i: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Integrera finjusterad Phi3 i din applikation

F√∂r att k√∂ra appen:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Svaret ska vara en enkel ordklassificering av frasen (Sad/Joy/Fear/Surprise).

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, v√§nligen observera att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r viktig information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r till f√∂ljd av anv√§ndningen av denna √∂vers√§ttning.