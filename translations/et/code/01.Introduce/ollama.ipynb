{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama + OpenAI + Python\n",
    "\n",
    "## 1. Määrake mudeli nimi\n",
    "\n",
    "Kui laadisite teise mudeli kui \"phi3:mini\", muutke allolevas lahtris väärtust.\n",
    "See muutuja kasutatakse kogu töövihiku koodis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"phi3:mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Seadista Open AI klient\n",
    "\n",
    "Tavaliselt kasutatakse Open AI klienti OpenAI.com-i või Azure OpenAI-ga suurte keelemudelitega suhtlemiseks.\n",
    "Siiski saab seda kasutada ka Ollamaga, kuna Ollama pakub OpenAI-ühilduvat lõpp-punkti aadressil \"http://localhost:11434/v1\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"nokeyneeded\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Genereeri vestluse vastus\n",
    "\n",
    "Nüüd saame OpenAI SDK-d kasutada, et genereerida vastus vestlusele. See päring peaks genereerima haiku kassidest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about a hungry cat\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Promptide inseneritöö\n",
    "\n",
    "Esimene keelemudelile saadetav sõnum nimetatakse \"süsteemisõnumiks\" või \"süsteemipromptiks\" ja see määrab mudeli üldised juhised.  \n",
    "Sa võid esitada oma kohandatud süsteemiprompti, et juhendada keelemudelit väljundi genereerimisel teisel viisil.  \n",
    "Muuda allolevat `SYSTEM_MESSAGE`-i nii, et see vastaks nagu sinu lemmikkuulus filmi- või telesaate tegelane, või saa inspiratsiooni teiste süsteemipromptide jaoks lehelt [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts?tab=readme-ov-file#prompts).\n",
    "\n",
    "Kui oled süsteemisõnumi kohandanud, esita esimene kasutajaküsimus `USER_MESSAGE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "I want you to act like Elmo from Sesame Street.\n",
    "I want you to respond and answer like Elmo using the tone, manner and vocabulary that Elmo would use.\n",
    "Do not write any explanations. Only answer like Elmo.\n",
    "You must know all of the knowledge of Elmo, and nothing more.\n",
    "\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"\"\"\n",
    "Hi Elmo, how are you doing today?\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Few-shot näited\n",
    "\n",
    "Teine viis keelemudeli juhendamiseks on anda \"few shots\", järjestikune näidisküsimuste/‑vastuste seeria, mis demonstreerib, kuidas mudel peaks vastama.\n",
    "\n",
    "Allolev näide püüab panna keelemudeli käituma nagu õppeassistent, esitades mõned näited küsimustest ja vastustest, mida õppeassistent võiks anda, ning seejärel esitab mudelile küsimuse, mida üliõpilane võiks küsida.\n",
    "\n",
    "Proovige seda esmalt, ja seejärel muutke `SYSTEM_MESSAGE`, `EXAMPLES`, ja `USER_MESSAGE` uue stsenaariumi jaoks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that helps students with their homework.\n",
    "Instead of providing the full answer, you respond with a hint or a clue.\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLES = [\n",
    "    (\n",
    "        \"What is the capital of France?\",\n",
    "        \"Can you remember the name of the city that is known for the Eiffel Tower?\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the square root of 144?\",\n",
    "        \"What number multiplied by itself equals 144?\"\n",
    "    ),\n",
    "    (   \"What is the atomic number of oxygen?\",\n",
    "        \"How many protons does an oxygen atom have?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "USER_MESSAGE = \"What is the largest planet in our solar system?\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": EXAMPLES[0][0]},\n",
    "        {\"role\": \"assistant\", \"content\": EXAMPLES[0][1]},\n",
    "        {\"role\": \"user\", \"content\": EXAMPLES[1][0]},\n",
    "        {\"role\": \"assistant\", \"content\": EXAMPLES[1][1]},\n",
    "        {\"role\": \"user\", \"content\": EXAMPLES[2][0]},\n",
    "        {\"role\": \"assistant\", \"content\": EXAMPLES[2][1]},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Otsinguga rikastatud genereerimine\n",
    "\n",
    "RAG (Retrieval Augmented Generation) on tehnika, mille abil panna keelemudel vastama konkreetse valdkonna küsimustele täpselt, hankides esmalt asjakohast teavet teadmisteallikast ja seejärel genereerides vastuse selle teabe põhjal.\n",
    "\n",
    "Meil on olemas kohalik CSV-fail, mis sisaldab andmeid hübriidautode kohta. Allolev kood loeb CSV-faili, otsib vastavusi kasutaja küsimusele ja genereerib seejärel leitud teabe põhjal vastuse. Pane tähele, et see võtab kauem aega kui eelmised näited, kuna mudelile saadetakse rohkem andmeid. Kui märkad, et vastus ei põhine siiski andmetel, võid proovida süsteemiinsenerimist või katsetada teisi mudeleid. Üldiselt on RAG tõhusam kas suuremate mudelitega või peenhäälestatud versioonidega SLMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that answers questions about cars based off a hybrid car data set.\n",
    "You must use the data set to answer the questions, you should not provide any information that is not in the provided sources.\n",
    "\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"how fast is a prius?\"\n",
    "\n",
    "# Open the CSV and store in a list\n",
    "with open(\"hybrid.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Normalize the user question to replace punctuation and make lowercase\n",
    "normalized_message = USER_MESSAGE.lower().replace(\"?\", \"\").replace(\"(\", \" \").replace(\")\", \" \")\n",
    "\n",
    "# Search the CSV for user question using very naive search\n",
    "words = normalized_message.split()\n",
    "matches = []\n",
    "for row in rows[1:]:\n",
    "    # if the word matches any word in row, add the row to the matches\n",
    "    if any(word in row[0].lower().split() for word in words) or any(word in row[5].lower().split() for word in words):\n",
    "        matches.append(row)\n",
    "\n",
    "# Format as a markdown table, since language models understand markdown\n",
    "matches_table = \" | \".join(rows[0]) + \"\\n\" + \" | \".join(\" --- \" for _ in range(len(rows[0]))) + \"\\n\"\n",
    "matches_table += \"\\n\".join(\" | \".join(row) for row in matches)\n",
    "print(f\"Found {len(matches)} matches:\")\n",
    "print(matches_table)\n",
    "\n",
    "# Now we can use the matches to generate a response\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE + \"\\nSources: \" + matches_table},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\nVastutusest loobumine:\nSee dokument on tõlgitud tehisintellektil põhineva tõlketeenuse Co-op Translator (https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palun arvestage, et automatiseeritud tõlked võivad sisaldada vigu või ebatäpsusi. Originaaldokument tema emakeeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitatakse kasutada professionaalset inimtõlget. Me ei vastuta käesoleva tõlke kasutamisest tulenevate arusaamatuste või väärtõlgenduste eest.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "coopTranslator": {
   "original_hash": "6f9e40a7dbbd892aae50aff77da4b4be",
   "translation_date": "2025-12-22T04:06:41+00:00",
   "source_file": "code/01.Introduce/ollama.ipynb",
   "language_code": "et"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}