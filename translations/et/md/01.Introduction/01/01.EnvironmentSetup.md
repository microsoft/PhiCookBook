<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-10-11T12:14:37+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "et"
}
-->
# Alusta Phi-3 mudeli kasutamist kohalikus keskkonnas

See juhend aitab sul seadistada oma kohalikku keskkonda, et käivitada Phi-3 mudelit Ollama abil. Mudelit saab käivitada mitmel viisil, sealhulgas GitHub Codespaces, VS Code Dev Containers või kohalikus keskkonnas.

## Keskkonna seadistamine

### GitHub Codespaces

Seda malli saab virtuaalselt käivitada GitHub Codespaces abil. Nupp avab veebipõhise VS Code'i akna sinu brauseris:

1. Ava mall (see võib võtta mitu minutit):

    [![Ava GitHub Codespaces'is](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Ava terminali aken

### VS Code Dev Containers

⚠️ See valik töötab ainult siis, kui sinu Docker Desktopile on eraldatud vähemalt 16 GB RAM-i. Kui sul on vähem kui 16 GB RAM-i, võid proovida [GitHub Codespaces'i valikut](../../../../../md/01.Introduction/01) või [seadistada selle kohalikult](../../../../../md/01.Introduction/01).

Teine võimalus on VS Code Dev Containers, mis avab projekti sinu kohalikus VS Code'is, kasutades [Dev Containers laiendust](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Käivita Docker Desktop (paigalda see, kui see pole veel paigaldatud)
2. Ava projekt:

    [![Ava Dev Containers'is](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Kui VS Code'i aken avaneb ja projekti failid ilmuvad (see võib võtta mitu minutit), ava terminali aken.
4. Jätka [juurutamise sammudega](../../../../../md/01.Introduction/01)

### Kohalik keskkond

1. Veendu, et järgmised tööriistad on paigaldatud:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Mudeli testimine

1. Palu Ollamal alla laadida ja käivitada phi3:mini mudel:

    ```shell
    ollama run phi3:mini
    ```

    Mudeli allalaadimine võtab paar minutit.

2. Kui väljundis ilmub "success", saad mudelile sõnumi saata otse käsurealt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Mõne sekundi pärast peaks mudel hakkama vastust voogesitama.

4. Et õppida erinevaid tehnikaid, mida kasutatakse keelemudelitega, ava Python'i märkmik [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) ja käivita iga lahter. Kui kasutasid mõnda muud mudelit peale 'phi3:mini', muuda `MODEL_NAME` esimeses lahtris.

5. Et vestelda phi3:mini mudeliga Python'i kaudu, ava Python'i fail [chat.py](../../../../../code/01.Introduce/chat.py) ja käivita see. Saad muuta faili ülaosas `MODEL_NAME` vastavalt vajadusele ning samuti kohandada süsteemi sõnumit või lisada näiteid, kui soovid.

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valesti tõlgenduste eest.