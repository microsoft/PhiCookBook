<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bc29f7fe7fc16bed6932733eac8c81b8",
  "translation_date": "2025-10-11T11:56:25+00:00",
  "source_file": "md/02.Application/02.Code/Phi3/VSCodeExt/HOL/AIPC/02.PromptflowWithNPU.md",
  "language_code": "et"
}
-->
# **Lab 2 - Käivita Prompt flow Phi-3-mini abil AIPC-s**

## **Mis on Prompt flow**

Prompt flow on arendustööriistade komplekt, mis on loodud LLM-põhiste AI-rakenduste arendustsükli lihtsustamiseks alates ideest, prototüüpimisest, testimisest, hindamisest kuni tootmisse juurutamise ja jälgimiseni. See muudab promptide inseneeria palju lihtsamaks ja võimaldab luua tootmiskvaliteediga LLM-rakendusi.

Prompt flow abil saate:

- Luua vooge, mis ühendavad LLM-id, promptid, Python-koodi ja muud tööriistad täidetavaks töövooks.

- Siluda ja täiustada oma vooge, eriti LLM-idega suhtlemist, lihtsasti.

- Hinnata oma vooge, arvutada kvaliteedi- ja jõudlusmõõdikuid suuremate andmekogumite abil.

- Integreerida testimise ja hindamise oma CI/CD süsteemi, et tagada voogude kvaliteet.

- Juurutada oma vooge valitud teenindusplatvormile või integreerida need hõlpsasti oma rakenduse koodibaasi.

- (Valikuline, kuid väga soovitatav) Teha koostööd oma meeskonnaga, kasutades Azure AI pilveversiooni Prompt flow'st.

## **Mis on AIPC**

AI PC sisaldab protsessorit (CPU), graafikaprotsessorit (GPU) ja närvitöötlusüksust (NPU), millest igaühel on spetsiifilised AI kiirendamise võimed. NPU ehk närvitöötlusüksus on spetsiaalne kiirendi, mis tegeleb tehisintellekti (AI) ja masinõppe (ML) ülesannetega otse teie arvutis, selle asemel et saata andmeid pilves töötlemiseks. Kuigi GPU ja CPU suudavad samuti neid töökoormusi töödelda, on NPU eriti hea madala energiatarbega AI arvutuste puhul. AI PC esindab fundamentaalset muutust selles, kuidas meie arvutid töötavad. See ei ole lahendus probleemile, mida varem ei eksisteerinud, vaid lubab olla suur edasiminek igapäevases arvutikasutuses.

Kuidas see siis töötab? Võrreldes generatiivse AI ja massiivsete suurte keelemudelitega (LLM), mis on treenitud tohutul hulgal avalikel andmetel, on AI, mis toimub teie arvutis, palju kättesaadavam peaaegu igal tasandil. Kontseptsioon on lihtsamini mõistetav ja kuna see on treenitud teie andmetel, ilma pilvele juurdepääsuta, on selle eelised koheselt atraktiivsemad laiemale kasutajaskonnale.

Lühiajalises perspektiivis hõlmab AI PC maailm isiklikke assistente ja väiksemaid AI mudeleid, mis töötavad otse teie arvutis, kasutades teie andmeid, et pakkuda isiklikke, privaatseid ja turvalisemaid AI täiustusi igapäevaste tegevuste jaoks – näiteks koosolekute protokollide koostamine, fantaasia jalgpalliliiga organiseerimine, foto- ja videotöötluse automaatne täiustamine või ideaalse pere kokkutuleku ajakava koostamine, mis põhineb kõigi saabumis- ja lahkumisaegadel.

## **Generatsioonikoodi voogude loomine AIPC-s**

***Märkus***: Kui te pole keskkonna installimist lõpetanud, külastage [Lab 0 - Installatsioonid](./01.Installations.md)

1. Avage Visual Studio Code'is Prompt flow laiendus ja looge tühi vooguprojekt.

![create](../../../../../../../../../imgs/02/vscodeext/pf_create.png)

2. Lisage sisendi- ja väljundparameetrid ning lisage Python-kood uue voona.

![flow](../../../../../../../../../imgs/02/vscodeext/pf_flow.png)

Võite viidata sellele struktuurile (flow.dag.yaml), et oma voogu üles ehitada.

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Lisage kood ***Chat_With_Phi3.py*** faili.

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Voogu saab testida Debug või Run abil, et kontrollida, kas generatsioonikood töötab.

![RUN](../../../../../../../../../imgs/02/vscodeext/pf_run.png)

5. Käivitage voog arendus-API-na terminalis.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Seda saab testida Postmanis / Thunder Clientis.

### **Märkus**

1. Esimene käivitus võtab kaua aega. Soovitatav on alla laadida phi-3 mudel Hugging Face CLI kaudu.

2. Arvestades Intel NPU piiratud arvutusvõimsust, on soovitatav kasutada Phi-3-mini-4k-instruct mudelit.

3. Kasutame Intel NPU kiirendust INT4 konversiooni kvantiseerimiseks, kuid kui teenust uuesti käivitate, peate kustutama vahemälu ja nc_workshop kaustad.

## **Ressursid**

1. Õpi Promptflow'd [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Õpi Intel NPU kiirendust [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Näidiskood, laadige alla [Kohalik NPU agendi näidiskood](../../../../../../../../../code/07.Lab/01/AIPC)

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valesti tõlgenduste eest.