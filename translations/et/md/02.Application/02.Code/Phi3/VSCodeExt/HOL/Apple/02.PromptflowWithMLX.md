# **Lab 2 - Käivita Prompt flow Phi-3-mini abil AIPC-s**

## **Mis on Prompt flow**

Prompt flow on arendustööriistade komplekt, mis on loodud LLM-põhiste AI-rakenduste arendustsükli lihtsustamiseks alates ideest, prototüüpimisest, testimisest, hindamisest kuni tootmisse juurutamise ja jälgimiseni. See muudab promptide inseneeria palju lihtsamaks ja võimaldab luua tootmiskvaliteediga LLM-rakendusi.

Prompt flow abil saate:

- Luua voogusid, mis ühendavad LLM-e, prompte, Python-koodi ja muid tööriistu täidetavaks töövooguks.

- Siluda ja täiustada oma voogusid, eriti LLM-idega suhtlemist, lihtsasti.

- Hinnata oma voogusid, arvutada kvaliteedi- ja jõudlusmõõdikuid suuremate andmekogumite abil.

- Integreerida testimise ja hindamise oma CI/CD süsteemi, et tagada voogude kvaliteet.

- Juurutada oma voogusid valitud teenindusplatvormile või integreerida need hõlpsasti oma rakenduse koodibaasi.

- (Valikuline, kuid väga soovitatav) Teha koostööd oma meeskonnaga, kasutades Prompt flow pilveversiooni Azure AI-s.



## **Generatiivse koodivoo loomine Apple Siliconil**

***Märkus***: Kui te pole veel keskkonna installimist lõpetanud, külastage [Lab 0 - Installatsioonid](./01.Installations.md)

1. Avage Visual Studio Code'is Prompt flow laiendus ja looge tühi vooprojekt.

![create](../../../../../../../../../imgs/02/vscodeext/pf_create.png)

2. Lisage sisendi- ja väljundparameetrid ning lisage Python-kood uue voona.

![flow](../../../../../../../../../imgs/02/vscodeext/pf_flow.png)

Võite viidata sellele struktuurile (flow.dag.yaml), et oma voogu üles ehitada.

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. Kvantifitseerige phi-3-mini

Soovime SLM-i paremini kohalikul seadmel käivitada. Üldiselt kvantifitseerime mudeli (INT4, FP16, FP32).

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Märkus:** vaikimisi kaust on mlx_model.

4. Lisage kood ***Chat_With_Phi3.py*** faili.

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. Voogu saab testida Debug või Run abil, et kontrollida, kas generatiivne kood töötab.

![RUN](../../../../../../../../../imgs/02/vscodeext/pf_run.png)

5. Käivitage voog arendus-API-na terminalis.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Seda saab testida Postmanis / Thunder Clientis.


### **Märkus**

1. Esimene käivitus võtab kaua aega. Soovitatav on alla laadida phi-3 mudel Hugging Face CLI kaudu.

2. Arvestades Intel NPU piiratud arvutusvõimsust, on soovitatav kasutada Phi-3-mini-4k-instruct mudelit.

3. Kasutame Intel NPU kiirendust INT4 konversiooni kvantifitseerimiseks, kuid kui teenust uuesti käivitate, peate kustutama vahemälu ja nc_workshop kaustad.



## **Ressursid**

1. Õpi Promptflow'd [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Õpi Intel NPU kiirendust [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Näidiskood, laadige alla [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valesti tõlgenduste eest.