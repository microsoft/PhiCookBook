<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c4fe7f589d179be96a5577b0b8cba6aa",
  "translation_date": "2025-07-17T02:49:12+00:00",
  "source_file": "md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md",
  "language_code": "fr"
}
-->
# **Utilisation de Microsoft Phi-3.5 tflite pour cr√©er une application Android**

Ceci est un exemple Android utilisant les mod√®les Microsoft Phi-3.5 tflite.

## **üìö Connaissances**

L‚ÄôAPI d‚Äôinf√©rence LLM Android vous permet d‚Äôex√©cuter des mod√®les de langage de grande taille (LLM) enti√®rement sur l‚Äôappareil pour les applications Android, ce que vous pouvez utiliser pour r√©aliser une large gamme de t√¢ches, telles que g√©n√©rer du texte, r√©cup√©rer des informations en langage naturel, et r√©sumer des documents. La t√¢che offre un support int√©gr√© pour plusieurs mod√®les de langage de grande taille texte-√†-texte, vous permettant ainsi d‚Äôappliquer les derniers mod√®les d‚ÄôIA g√©n√©rative sur appareil √† vos applications Android.

Googld AI Edge Torch est une biblioth√®que Python qui permet de convertir des mod√®les PyTorch au format .tflite, pouvant ensuite √™tre ex√©cut√©s avec TensorFlow Lite et MediaPipe. Cela permet de cr√©er des applications pour Android, iOS et IoT capables d‚Äôex√©cuter les mod√®les enti√®rement sur l‚Äôappareil. AI Edge Torch offre une large couverture CPU, avec un support initial pour GPU et NPU. AI Edge Torch vise une int√©gration √©troite avec PyTorch, en s‚Äôappuyant sur torch.export() et en couvrant bien les op√©rateurs Core ATen.

## **ü™¨ Guide**

### **üî• Conversion de Microsoft Phi-3.5 au format tflite**

0. Cet exemple est destin√© √† Android 14+

1. Installez Python 3.10.12

***Suggestion :*** utilisez conda pour installer votre environnement Python

2. Ubuntu 20.04 / 22.04 (concentrez-vous sur [google ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch))

***Suggestion :*** utilisez une VM Linux Azure ou une VM cloud tierce pour cr√©er votre environnement

3. Ouvrez votre terminal Linux pour installer la biblioth√®que Python

```bash

git clone https://github.com/google-ai-edge/ai-edge-torch.git

cd ai-edge-torch

pip install -r requirements.txt -U 

pip install tensorflow-cpu -U

pip install -e .

```

4. T√©l√©chargez Microsoft-3.5-Instruct depuis Hugging Face

```bash

git lfs install

git clone  https://huggingface.co/microsoft/Phi-3.5-mini-instruct

```

5. Convertissez Microsoft Phi-3.5 en tflite

```bash

python ai-edge-torch/ai_edge_torch/generative/examples/phi/convert_phi3_to_tflite.py --checkpoint_path  Your Microsoft Phi-3.5-mini-instruct path --tflite_path Your Microsoft Phi-3.5-mini-instruct tflite path  --prefill_seq_len 1024 --kv_cache_max_len 1280 --quantize True

```

### **üî• Conversion de Microsoft Phi-3.5 en bundle Android Mediapipe**

Veuillez installer mediapipe en premier lieu

```bash

pip install mediapipe

```

Ex√©cutez ce code dans [votre notebook](../../../../../../code/09.UpdateSamples/Aug/Android/convert/convert_phi.ipynb)

```python

import mediapipe as mp
from mediapipe.tasks.python.genai import bundler

config = bundler.BundleConfig(
    tflite_model='Your Phi-3.5 tflite model path',
    tokenizer_model='Your Phi-3.5 tokenizer model path',
    start_token='start_token',
    stop_tokens=[STOP_TOKENS],
    output_filename='Your Phi-3.5 task model path',
    enable_bytes_to_unicode_mapping=True or Flase,
)
bundler.create_bundle(config)

```

### **üî• Utilisation de adb push pour transf√©rer le mod√®le task vers le chemin de votre appareil Android**

```bash

adb shell rm -r /data/local/tmp/llm/ # Remove any previously loaded models

adb shell mkdir -p /data/local/tmp/llm/

adb push 'Your Phi-3.5 task model path' /data/local/tmp/llm/phi3.task

```

### **üî• Ex√©cution de votre code Android**

![demo](../../../../../../translated_images/demo.06d5a4246f057d1be99ffad0cbf22f4ac0c41530774d51ff903cfaa1d3cd3c8e.fr.png)

**Avertissement** :  
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle r√©alis√©e par un humain est recommand√©e. Nous d√©clinons toute responsabilit√© en cas de malentendus ou de mauvaises interpr√©tations r√©sultant de l‚Äôutilisation de cette traduction.