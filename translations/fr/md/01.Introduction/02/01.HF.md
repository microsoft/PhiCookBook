<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a6b485d694cca1ce16096da1d6d03ff8",
  "translation_date": "2025-03-27T06:08:49+00:00",
  "source_file": "md\\01.Introduction\\02\\01.HF.md",
  "language_code": "fr"
}
-->
# **Utiliser la famille Phi dans Hugging Face**

[Hugging Face](https://huggingface.co/) est une communauté d'IA très populaire, offrant des données riches et des ressources de modèles open source. Différents fabricants publient des modèles LLM et SLM open source via Hugging Face, tels que Microsoft, Meta, Mistral, Apple, Google, etc.

La famille Phi de Microsoft a été mise à disposition sur Hugging Face. Les développeurs peuvent télécharger le modèle correspondant de la famille Phi en fonction des scénarios et des besoins commerciaux. En plus de déployer les modèles Phi Pytorch sur Hugging Face, nous avons également publié des modèles quantifiés, utilisant les formats GGUF et ONNX pour offrir un choix aux utilisateurs finaux.

## **Télécharger les modèles sur Hugging Face**

Vous pouvez télécharger les modèles de la famille Phi via ce lien :

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

Vous pouvez télécharger le modèle de différentes manières, comme en installant le ***SDK CLI Hugging Face*** ou en utilisant ***git clone***.

### **Utiliser le CLI Hugging Face pour télécharger les modèles de la famille Phi**

- Installer le CLI Hugging Face

```bash

pip install -U "huggingface_hub[cli]"

```

- Utiliser huggingface-cli pour se connecter

Connectez-vous à Hugging Face avec un [jeton d'accès utilisateur](https://huggingface.co/docs/hub/security-tokens) depuis votre [page de paramètres](https://huggingface.co/settings/tokens).

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Télécharger

Vous pouvez télécharger le modèle et l'enregistrer dans le cache.

```bash

huggingface-cli download microsoft/phi-4

```

Vous pouvez définir un emplacement spécifique pour le stockage.

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **Utiliser git clone pour télécharger les modèles de la famille Phi**

Vous pouvez également utiliser ***git clone*** pour télécharger le modèle.

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Exemples - Inférence avec Microsoft Phi-4**

- **Installer la bibliothèque transformers**

```bash

pip install transformers -U

```

- **Exécuter ce code dans VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Clause de non-responsabilité** :  
Ce document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des imprécisions. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de recourir à une traduction professionnelle réalisée par un humain. Nous déclinons toute responsabilité en cas de malentendus ou d'interprétations erronées résultant de l'utilisation de cette traduction.