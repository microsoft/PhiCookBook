<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-05-07T15:09:06+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "fr"
}
-->
# **Utiliser la famille Phi sur Hugging Face**


[Hugging Face](https://huggingface.co/) est une communauté d’IA très populaire, riche en données et en modèles open source. Différents fabricants publient des LLM et SLM open source via Hugging Face, comme Microsoft, Meta, Mistral, Apple, Google, etc.

La famille Microsoft Phi est disponible sur Hugging Face. Les développeurs peuvent télécharger le modèle Phi correspondant selon les scénarios et les besoins métier. En plus de déployer les modèles Phi Pytorch sur Hugging Face, nous avons également publié des modèles quantifiés, utilisant les formats GGUF et ONNX pour offrir plus de choix aux utilisateurs finaux.


## **Télécharger les modèles sur Hugging Face**

Vous pouvez télécharger les modèles de la famille Phi via ce lien

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Vous pouvez télécharger les modèles de différentes manières, par exemple en installant le ***Hugging Face CLI SDK*** ou en utilisant ***git clone***.

### **Utiliser le CLI Hugging Face pour télécharger les modèles Phi Family**

- Installer le CLI Hugging Face

```bash

pip install -U "huggingface_hub[cli]"

```

- Se connecter avec huggingface-cli

Connectez-vous à Hugging Face avec un [User Access Token](https://huggingface.co/docs/hub/security-tokens) depuis votre [page Paramètres](https://huggingface.co/settings/tokens)


```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Télécharger


Vous pouvez télécharger le modèle et le sauvegarder dans le cache

```bash

huggingface-cli download microsoft/phi-4

```

Vous pouvez définir un emplacement spécifique


```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```


### **Utiliser git clone pour télécharger les modèles Phi Family**

Vous pouvez aussi utiliser ***git clone*** pour télécharger les modèles

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Exemples - Inférence avec Microsoft Phi-4**

- **Installer la bibliothèque transformers**

```bash

pip install transformers -U

```

- **Exécuter ce code dans VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Avertissement** :  
Ce document a été traduit à l’aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d’assurer l’exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d’origine doit être considéré comme la source faisant foi. Pour des informations critiques, une traduction professionnelle réalisée par un humain est recommandée. Nous ne sommes pas responsables des malentendus ou interprétations erronées résultant de l’utilisation de cette traduction.