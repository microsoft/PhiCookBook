# **Utilisation de la famille Phi sur Hugging Face**

[Hugging Face](https://huggingface.co/) est une communauté d’IA très populaire, riche en données et en ressources de modèles open source. Différents fabricants publient des LLM et SLM open source via Hugging Face, tels que Microsoft, Meta, Mistral, Apple, Google, etc.

La famille Microsoft Phi a été publiée sur Hugging Face. Les développeurs peuvent télécharger le modèle correspondant de la famille Phi selon les scénarios et les besoins métiers. En plus de déployer les modèles Phi Pytorch sur Hugging Face, nous avons également publié des modèles quantifiés, utilisant les formats GGUF et ONNX pour offrir un choix aux utilisateurs finaux.

## **Télécharger les modèles sur Hugging Face**

Vous pouvez télécharger les modèles de la famille Phi via ce lien

[Microsoft Models on Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

Vous pouvez télécharger les modèles de différentes manières, comme en installant le ***Hugging Face CLI SDK*** ou en utilisant ***git clone***.

### **Utiliser Hugging Face CLI pour télécharger un modèle de la famille Phi**

- Installer Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Se connecter avec huggingface-cli

Connectez-vous à Hugging Face avec un [User Access Token](https://huggingface.co/docs/hub/security-tokens) depuis votre [page Paramètres](https://huggingface.co/settings/tokens)

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Télécharger

Vous pouvez télécharger le modèle et le sauvegarder dans le cache

```bash

huggingface-cli download microsoft/phi-4

```

Vous pouvez définir un emplacement spécifique

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **Utiliser git clone pour télécharger un modèle de la famille Phi**

Vous pouvez aussi utiliser ***git clone*** pour télécharger le modèle

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Exemples - Inférence avec Microsoft Phi-4**

- **Installation de la bibliothèque transformers**

```bash

pip install transformers -U

```

- **Exécution de ce code dans VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Avertissement** :  
Ce document a été traduit à l’aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d’assurer l’exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d’origine doit être considéré comme la source faisant foi. Pour les informations critiques, une traduction professionnelle réalisée par un humain est recommandée. Nous déclinons toute responsabilité en cas de malentendus ou de mauvaises interprétations résultant de l’utilisation de cette traduction.