<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd049872f37c3079c87d4fe17109cea0",
  "translation_date": "2025-03-27T05:44:08+00:00",
  "source_file": "md\\01.Introduction\\01\\01.Guidance.md",
  "language_code": "fr"
}
-->
### Guidance-AI et modèles Phi en tant que service (MaaS)
Nous introduisons [Guidance](https://github.com/guidance-ai/guidance) dans le point de terminaison sans serveur Phi-3.5-mini d'Azure AI Foundry pour rendre les résultats plus prévisibles en définissant une structure adaptée à une application. Avec Guidance, vous pouvez éviter les reprises coûteuses et, par exemple, contraindre le modèle à sélectionner parmi des listes pré-définies (par exemple, des codes médicaux), limiter les sorties à des citations directes du contexte fourni, ou respecter des expressions régulières. Guidance guide le modèle, jeton par jeton, dans la pile d'inférence, réduisant ainsi les coûts et la latence de 30 à 50 %, ce qui en fait un ajout unique et précieux au [point de terminaison sans serveur Phi-3-mini](https://aka.ms/try-phi3.5mini).

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) est un framework conçu pour aider les développeurs à créer et déployer des modèles d'IA efficacement. Il se concentre sur la fourniture d'outils et de bonnes pratiques pour construire des applications d'IA robustes.

Lorsqu'il est combiné avec **Phi Models as a Service (MaaS)**, il offre une solution puissante pour déployer des modèles de langage de petite taille (SLMs) à la fois rentables et performants.

**Guidance-AI** est un framework de programmation conçu pour aider les développeurs à mieux contrôler et orienter les grands modèles de langage (LLMs). Il permet une structuration précise des sorties, réduisant la latence et les coûts par rapport aux méthodes traditionnelles de "prompting" ou de "fine-tuning".

### Principales caractéristiques de Guidance-AI :
- **Contrôle efficace** : Permet aux développeurs de contrôler la manière dont le modèle génère du texte, garantissant des résultats de haute qualité et pertinents.
- **Réduction des coûts et de la latence** : Optimise le processus de génération pour le rendre plus économique et rapide.
- **Intégration flexible** : Fonctionne avec divers backends, y compris Transformers, llama.cpp, AzureAI, VertexAI et OpenAI.
- **Structures de sortie riches** : Prend en charge des structures de sortie complexes comme les conditionnels, les boucles et l'utilisation d'outils, facilitant la génération de résultats clairs et exploitables.
- **Compatibilité** : Permet à un programme Guidance unique d'être exécuté sur plusieurs backends, offrant flexibilité et facilité d'utilisation.

### Exemples d'utilisation :
- **Génération contrainte** : Utilisation d'expressions régulières et de grammaires sans contexte pour guider les sorties du modèle.
- **Intégration d'outils** : Intercalage automatique entre contrôle et génération, comme l'utilisation d'une calculatrice dans une tâche de génération de texte.

Pour des informations plus détaillées et des exemples, vous pouvez consulter le [dépôt GitHub de Guidance-AI](https://github.com/guidance-ai/guidance).

[Consultez l'exemple Phi-3.5](../../../../../code/01.Introduce/guidance.ipynb)

### Principales caractéristiques des modèles Phi :
1. **Rentabilité** : Conçus pour être abordables tout en maintenant des performances élevées.
2. **Faible latence** : Idéal pour les applications en temps réel nécessitant des réponses rapides.
3. **Flexibilité** : Peut être déployé dans divers environnements, y compris le cloud, l'edge et les scénarios hors ligne.
4. **Personnalisation** : Les modèles peuvent être ajustés avec des données spécifiques au domaine pour améliorer les performances.
5. **Sécurité et conformité** : Développés selon les principes d'IA de Microsoft, garantissant responsabilité, transparence, équité, fiabilité, sécurité, confidentialité et inclusion.

### Modèles Phi en tant que service (MaaS) :
Les modèles Phi sont disponibles via un système de facturation à l'utilisation grâce à des API d'inférence, ce qui facilite leur intégration dans vos applications sans coûts initiaux importants.

### Démarrage avec Phi-3 :
Pour commencer à utiliser les modèles Phi, vous pouvez explorer le [catalogue de modèles Azure AI](https://ai.azure.com/explore/models) ou les [modèles disponibles sur GitHub Marketplace](https://github.com/marketplace/models), qui proposent des modèles préconstruits et personnalisables. De plus, vous pouvez utiliser des outils comme [Azure AI Foundry](https://ai.azure.com) pour développer et déployer vos applications d'IA.

### Ressources
[Exemple de notebook pour commencer avec Guidance](../../../../../code/01.Introduce/guidance.ipynb)

**Avertissement** :  
Ce document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions de garantir l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de faire appel à une traduction humaine professionnelle. Nous déclinons toute responsabilité en cas de malentendus ou d'interprétations erronées résultant de l'utilisation de cette traduction.