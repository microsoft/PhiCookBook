<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-07T15:15:04+00:00",
  "source_file": "code/04.Finetuning/olive-ort-example/README.md",
  "language_code": "fr"
}
-->
# Affiner Phi3 avec Olive

Dans cet exemple, vous utiliserez Olive pour :

1. Affiner un adaptateur LoRA afin de classer des phrases en Tristesse, Joie, Peur, Surprise.
1. Fusionner les poids de l‚Äôadaptateur dans le mod√®le de base.
1. Optimiser et quantifier le mod√®le en `int4`.

Nous vous montrerons √©galement comment effectuer une inf√©rence avec le mod√®le affin√© en utilisant l‚ÄôAPI Generate d‚ÄôONNX Runtime (ORT).

> **‚ö†Ô∏è Pour l‚Äôaffinage, vous devez disposer d‚Äôun GPU adapt√© - par exemple, un A10, V100, A100.**

## üíæ Installation

Cr√©ez un nouvel environnement virtuel Python (par exemple, avec `conda`) :

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ensuite, installez Olive et les d√©pendances n√©cessaires pour un workflow d‚Äôaffinage :

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Affiner Phi3 avec Olive
Le [fichier de configuration Olive](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) contient un *workflow* avec les *√©tapes* suivantes :

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

De mani√®re g√©n√©rale, ce workflow va :

1. Affiner Phi3 (pendant 150 √©tapes, modifiables) en utilisant les donn√©es de [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. Fusionner les poids de l‚Äôadaptateur LoRA dans le mod√®le de base. Cela vous donnera un seul artefact mod√®le au format ONNX.
1. Model Builder optimisera le mod√®le pour l‚Äôex√©cution ONNX *et* quantifiera le mod√®le en `int4`.

Pour lancer le workflow, ex√©cutez :

```bash
olive run --config phrase-classification.json
```

Une fois Olive termin√©, votre mod√®le Phi3 affin√© optimis√© en `int4` est disponible dans : `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Int√©grer Phi3 affin√© dans votre application

Pour lancer l‚Äôapplication :

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

La r√©ponse doit √™tre une classification en un seul mot de la phrase (Tristesse/Joie/Peur/Surprise).

**Avertissement** :  
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source faisant foi. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou de mauvaises interpr√©tations r√©sultant de l‚Äôutilisation de cette traduction.