<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-03-27T03:57:48+00:00",
  "source_file": "code\\04.Finetuning\\olive-ort-example\\README.md",
  "language_code": "fr"
}
-->
# Affiner Phi3 avec Olive

Dans cet exemple, vous utiliserez Olive pour :

1. Affiner un adaptateur LoRA afin de classer des phrases en Sad, Joy, Fear, Surprise.
1. Fusionner les poids de l'adaptateur avec le mod√®le de base.
1. Optimiser et quantifier le mod√®le dans `int4`.

Nous vous montrerons √©galement comment effectuer des inf√©rences avec le mod√®le affin√© en utilisant l'API Generate de ONNX Runtime (ORT).

> **‚ö†Ô∏è Pour l'affinage, vous devrez disposer d'un GPU adapt√©, comme un A10, V100, ou A100.**

## üíæ Installation

Cr√©ez un nouvel environnement virtuel Python (par exemple, en utilisant `conda`) :

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ensuite, installez Olive et les d√©pendances n√©cessaires au workflow d'affinage :

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Affiner Phi3 avec Olive
Le [fichier de configuration Olive](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) contient un *workflow* avec les *passes* suivantes :

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

√Ä un niveau √©lev√©, ce workflow permet de :

1. Affiner Phi3 (pendant 150 √©tapes, modifiables) en utilisant les donn√©es du fichier [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. Fusionner les poids de l'adaptateur LoRA avec le mod√®le de base. Cela vous donnera un artefact de mod√®le unique au format ONNX.
1. Model Builder optimisera le mod√®le pour ONNX Runtime *et* le quantifiera dans `int4`.

Pour ex√©cuter le workflow, lancez :

```bash
olive run --config phrase-classification.json
```

Une fois Olive termin√©, votre mod√®le Phi3 affin√© et optimis√© `int4` sera disponible ici : `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Int√©grer Phi3 affin√© dans votre application 

Pour ex√©cuter l'application :

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

La r√©ponse devrait √™tre une classification en un mot de la phrase (Sad/Joy/Fear/Surprise).

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.