<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-07T15:17:44+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "fr"
}
-->
# Affiner Phi3 avec Olive

Dans cet exemple, vous allez utiliser Olive pour :

1. Affiner un adaptateur LoRA afin de classifier des phrases en Tristesse, Joie, Peur, Surprise.  
1. Fusionner les poids de l‚Äôadaptateur dans le mod√®le de base.  
1. Optimiser et quantifier le mod√®le en `int4`.

Nous vous montrerons √©galement comment effectuer une inf√©rence avec le mod√®le affin√© en utilisant l‚ÄôAPI Generate de ONNX Runtime (ORT).

> **‚ö†Ô∏è Pour l‚Äôaffinage, vous devez disposer d‚Äôun GPU adapt√© - par exemple, un A10, V100, A100.**

## üíæ Installation

Cr√©ez un nouvel environnement virtuel Python (par exemple, avec `conda`) :

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ensuite, installez Olive ainsi que les d√©pendances n√©cessaires pour un workflow d‚Äôaffinage :

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Affiner Phi3 avec Olive  
Le [fichier de configuration Olive](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) contient un *workflow* avec les *√©tapes* suivantes :

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

En r√©sum√©, ce workflow va :

1. Affiner Phi3 (pendant 150 it√©rations, modifiables) en utilisant les donn√©es de [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json).  
1. Fusionner les poids de l‚Äôadaptateur LoRA dans le mod√®le de base. Cela vous donnera un unique artefact mod√®le au format ONNX.  
1. Model Builder optimisera le mod√®le pour l‚Äôex√©cution ONNX *et* quantifiera le mod√®le en `int4`.

Pour lancer le workflow, ex√©cutez :

```bash
olive run --config phrase-classification.json
```

Lorsque Olive aura termin√©, votre mod√®le Phi3 affin√©, optimis√© et en `int4` sera disponible dans : `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Int√©grer Phi3 affin√© dans votre application

Pour lancer l‚Äôapplication :

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

La r√©ponse doit √™tre une classification simple en un mot de la phrase (Tristesse/Joie/Peur/Surprise).

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle r√©alis√©e par un humain est recommand√©e. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.