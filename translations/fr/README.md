<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2e042b12a63c59931dc121c2c638bc58",
  "translation_date": "2025-07-09T17:57:59+00:00",
  "source_file": "README.md",
  "language_code": "fr"
}
-->
# Phi Cookbook : Exemples pratiques avec les mod√®les Phi de Microsoft

[![Ouvrir et utiliser les exemples dans GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phicookbook)  
[![Ouvrir dans Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)  
[![Issues GitHub](https://img.shields.io/github/issues/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)  
[![Pull requests GitHub](https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)  
[![PRs Bienvenues](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)  
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)  
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/phicookbook?style=social&label=Star)](https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)

[![Communaut√© Azure AI Discord](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

Phi est une s√©rie de mod√®les d‚ÄôIA open source d√©velopp√©s par Microsoft.

Phi est actuellement le mod√®le de langage petit (SLM) le plus puissant et √©conomique, avec d‚Äôexcellents r√©sultats dans plusieurs langues, le raisonnement, la g√©n√©ration de texte/chat, le codage, les images, l‚Äôaudio et d‚Äôautres sc√©narios.

Vous pouvez d√©ployer Phi dans le cloud ou sur des appareils en p√©riph√©rie, et construire facilement des applications d‚ÄôIA g√©n√©rative avec une puissance de calcul limit√©e.

Suivez ces √©tapes pour commencer √† utiliser ces ressources :  
1. **Forkez le d√©p√¥t** : Cliquez sur [![Forks GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)  
2. **Clonez le d√©p√¥t** : `git clone https://github.com/microsoft/PhiCookBook.git`  
3. [**Rejoignez la communaut√© Microsoft AI Discord et rencontrez des experts et d√©veloppeurs**](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

![cover](../../imgs/cover.png)

## üåê Support multilingue

### Pris en charge via GitHub Action (Automatis√© & Toujours √† jour)

[Fran√ßais](./README.md) | [Espagnol](../es/README.md) | [Allemand](../de/README.md) | [Russe](../ru/README.md) | [Arabe](../ar/README.md) | [Persan (Farsi)](../fa/README.md) | [Ourdou](../ur/README.md) | [Chinois (Simplifi√©)](../zh/README.md) | [Chinois (Traditionnel, Macao)](../mo/README.md) | [Chinois (Traditionnel, Hong Kong)](../hk/README.md) | [Chinois (Traditionnel, Ta√Øwan)](../tw/README.md) | [Japonais](../ja/README.md) | [Cor√©en](../ko/README.md) | [Hindi](../hi/README.md)  
[Bengali](../bn/README.md) | [Marathi](../mr/README.md) | [N√©palais](../ne/README.md) | [Pendjabi (Gurmukhi)](../pa/README.md) | [Portugais (Portugal)](../pt/README.md) | [Portugais (Br√©sil)](../br/README.md) | [Italien](../it/README.md) | [Polonais](../pl/README.md) | [Turc](../tr/README.md) | [Grec](../el/README.md) | [Tha√Ø](../th/README.md) | [Su√©dois](../sv/README.md) | [Danois](../da/README.md) | [Norv√©gien](../no/README.md) | [Finnois](../fi/README.md) | [N√©erlandais](../nl/README.md) | [H√©breu](../he/README.md) | [Vietnamien](../vi/README.md) | [Indon√©sien](../id/README.md) | [Malais](../ms/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Swahili](../sw/README.md) | [Hongrois](../hu/README.md) | [Tch√®que](../cs/README.md) | [Slovaque](../sk/README.md) | [Roumain](../ro/README.md) | [Bulgare](../bg/README.md) | [Serbe (Cyrillique)](../sr/README.md) | [Croate](../hr/README.md) | [Slov√®ne](../sl/README.md)

## Table des mati√®res

- Introduction  
  - [Bienvenue dans la famille Phi](./md/01.Introduction/01/01.PhiFamily.md)  
  - [Configurer votre environnement](./md/01.Introduction/01/01.EnvironmentSetup.md)  
  - [Comprendre les technologies cl√©s](./md/01.Introduction/01/01.Understandingtech.md)  
  - [S√©curit√© IA pour les mod√®les Phi](./md/01.Introduction/01/01.AISafety.md)  
  - [Support mat√©riel Phi](./md/01.Introduction/01/01.Hardwaresupport.md)  
  - [Mod√®les Phi & disponibilit√© sur diff√©rentes plateformes](./md/01.Introduction/01/01.Edgeandcloud.md)  
  - [Utiliser Guidance-ai et Phi](./md/01.Introduction/01/01.Guidance.md)  
  - [Mod√®les sur GitHub Marketplace](https://github.com/marketplace/models)  
  - [Catalogue de mod√®les Azure AI](https://ai.azure.com)

- Inf√©rence Phi dans diff√©rents environnements  
    -  [Hugging face](./md/01.Introduction/02/01.HF.md)  
    -  [Mod√®les GitHub](./md/01.Introduction/02/02.GitHubModel.md)  
    -  [Catalogue Azure AI Foundry](./md/01.Introduction/02/03.AzureAIFoundry.md)  
    -  [Ollama](./md/01.Introduction/02/04.Ollama.md)  
    -  [AI Toolkit VSCode (AITK)](./md/01.Introduction/02/05.AITK.md)  
    -  [NVIDIA NIM](./md/01.Introduction/02/06.NVIDIA.md)  
    -  [Foundry Local](./md/01.Introduction/02/07.FoundryLocal.md)

- Inf√©rence Phi Family  
    - [Inf√©rence Phi sur iOS](./md/01.Introduction/03/iOS_Inference.md)  
    - [Inf√©rence Phi sur Android](./md/01.Introduction/03/Android_Inference.md)  
    - [Inf√©rence Phi sur Jetson](./md/01.Introduction/03/Jetson_Inference.md)  
    - [Inf√©rence Phi sur AI PC](./md/01.Introduction/03/AIPC_Inference.md)  
    - [Inf√©rence Phi avec le framework Apple MLX](./md/01.Introduction/03/MLX_Inference.md)  
    - [Inf√©rence Phi sur serveur local](./md/01.Introduction/03/Local_Server_Inference.md)  
    - [Inf√©rence Phi sur serveur distant avec AI Toolkit](./md/01.Introduction/03/Remote_Interence.md)  
    - [Inf√©rence Phi avec Rust](./md/01.Introduction/03/Rust_Inference.md)  
    - [Inf√©rence Phi--Vision en local](./md/01.Introduction/03/Vision_Inference.md)  
    - [Inf√©rence Phi avec Kaito AKS, Azure Containers (support officiel)](./md/01.Introduction/03/Kaito_Inference.md)  
-  [Quantification Phi Family](./md/01.Introduction/04/QuantifyingPhi.md)  
    - [Quantification Phi-3.5 / 4 avec llama.cpp](./md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md)  
    - [Quantification Phi-3.5 / 4 avec les extensions Generative AI pour onnxruntime](./md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md)  
    - [Quantification Phi-3.5 / 4 avec Intel OpenVINO](./md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md)  
    - [Quantification Phi-3.5 / 4 avec le framework Apple MLX](./md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md)

- √âvaluation Phi  
    - [IA responsable](./md/01.Introduction/05/ResponsibleAI.md)  
    - [Azure AI Foundry pour l‚Äô√©valuation](./md/01.Introduction/05/AIFoundry.md)  
    - [Utiliser Promptflow pour l‚Äô√©valuation](./md/01.Introduction/05/Promptflow.md)

- RAG avec Azure AI Search  
    - [Comment utiliser Phi-4-mini et Phi-4-multimodal (RAG) avec Azure AI Search](https://github.com/microsoft/PhiCookBook/blob/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb)

- Exemples de d√©veloppement d‚Äôapplications Phi  
  - Applications texte & chat  
    - Exemples Phi-4 üÜï  
      - [üìì] [Chat avec le mod√®le Phi-4-mini ONNX](./md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md)  
      - [Chat avec mod√®le local Phi-4 ONNX en .NET](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime)  
      - [Application console Chat .NET avec Phi-4 ONNX utilisant Semantic Kernel](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK)  
    - Exemples Phi-3 / 3.5  
      - [Chatbot local dans le navigateur avec Phi3, ONNX Runtime Web et WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)  
      - [Chat OpenVino](./md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md)  
      - [Multi-mod√®le - Phi-3-mini interactif et OpenAI Whisper](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md)  
      - [MLFlow - Cr√©ation d‚Äôun wrapper et utilisation de Phi-3 avec MLFlow](./md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md)  
      - [Optimisation de mod√®le - Comment optimiser Phi-3-mini pour ONNX Runtime Web avec Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)  
      - [Application WinUI3 avec Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)  
      - [Exemple d‚Äôapplication de notes multi-mod√®les aliment√©e par IA WinUI3](https://github.com/microsoft/ai-powered-notes-winui3-sample)
- [Affiner et int√©grer des mod√®les Phi-3 personnalis√©s avec Prompt flow](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)
- [Affiner et int√©grer des mod√®les Phi-3 personnalis√©s avec Prompt flow dans Azure AI Foundry](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md)
- [√âvaluer le mod√®le Phi-3 / Phi-3.5 affin√© dans Azure AI Foundry en se concentrant sur les principes d‚ÄôIA responsable de Microsoft](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md)
- [üìì] [Exemple de pr√©diction linguistique Phi-3.5-mini-instruct (chinois/anglais)](../../md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb)
- [Chatbot RAG Phi-3.5-Instruct WebGPU](./md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md)
- [Utiliser le GPU Windows pour cr√©er une solution Prompt flow avec Phi-3.5-Instruct ONNX](./md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md)
- [Utiliser Microsoft Phi-3.5 tflite pour cr√©er une application Android](./md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md)
- [Exemple Q&R .NET utilisant un mod√®le local ONNX Phi-3 avec Microsoft.ML.OnnxRuntime](../../md/04.HOL/dotnet/src/LabsPhi301)
- [Application console chat .NET avec Semantic Kernel et Phi-3](../../md/04.HOL/dotnet/src/LabsPhi302)

- √âchantillons de code Azure AI Inference SDK  
  - √âchantillons Phi-4 üÜï  
    - [üìì] [G√©n√©rer le code d‚Äôun projet avec Phi-4-multimodal](./md/02.Application/02.Code/Phi4/GenProjectCode/README.md)  
  - √âchantillons Phi-3 / 3.5  
    - [Construisez votre propre chat GitHub Copilot pour Visual Studio Code avec la famille Microsoft Phi-3](./md/02.Application/02.Code/Phi3/VSCodeExt/README.md)  
    - [Cr√©ez votre propre agent Chat Copilot pour Visual Studio Code avec Phi-3.5 via les mod√®les GitHub](/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md)  

- √âchantillons de raisonnement avanc√©  
  - √âchantillons Phi-4 üÜï  
    - [üìì] [Exemples Phi-4-mini-reasoning ou Phi-4-reasoning](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md)  
    - [üìì] [Affinage de Phi-4-mini-reasoning avec Microsoft Olive](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb)  
    - [üìì] [Affinage de Phi-4-mini-reasoning avec Apple MLX](../../md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/mlx_ft_phi_4_reasoning_with_medicaldata.ipynb)  
    - [üìì] [Phi-4-mini-reasoning avec les mod√®les GitHub](../../md/02.Application/02.Code/Phi4r/github_models_inference.ipynb)  
    - [üìì] [Phi-4-mini-reasoning avec les mod√®les Azure AI Foundry](../../md/02.Application/02.Code/Phi4r/azure_models_inference.ipynb)  
- D√©mos  
    - [D√©mos Phi-4-mini h√©berg√©es sur Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo)  
    - [D√©mos Phi-4-multimodal h√©berg√©es sur Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo)  
- √âchantillons Vision  
  - √âchantillons Phi-4 üÜï  
    - [üìì] [Utiliser Phi-4-multimodal pour lire des images et g√©n√©rer du code](./md/02.Application/04.Vision/Phi4/CreateFrontend/README.md)  
  - √âchantillons Phi-3 / 3.5  
    - [üìì][Phi-3-vision - Texte image vers texte](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)  
    - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)  
    - [üìì][Phi-3-vision CLIP Embedding](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)  
    - [D√âMO : Phi-3 Recycling](https://github.com/jennifermarsman/PhiRecycling/)  
    - [Phi-3-vision - Assistant visuel linguistique - avec Phi3-Vision et OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)  
    - [Phi-3 Vision Nvidia NIM](./md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md)  
    - [Phi-3 Vision OpenVino](./md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md)  
    - [üìì][Exemple Phi-3.5 Vision multi-frames ou multi-images](../../md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb)  
    - [Mod√®le local Phi-3 Vision ONNX utilisant Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi303)  
    - [Mod√®le local Phi-3 Vision ONNX avec menu utilisant Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi304)  

- √âchantillons Math√©matiques  
  - √âchantillons Phi-4-Mini-Flash-Reasoning-Instruct üÜï [D√©mo Math avec Phi-4-Mini-Flash-Reasoning-Instruct](../../md/02.Application/09.Math/MathDemo.ipynb)  

- √âchantillons Audio  
  - √âchantillons Phi-4 üÜï  
    - [üìì] [Extraction de transcriptions audio avec Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Transciption/README.md)  
    - [üìì] [Exemple audio Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Siri/demo.ipynb)  
    - [üìì] [Exemple de traduction vocale Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Translate/demo.ipynb)  
    - [Application console .NET utilisant Phi-4-multimodal Audio pour analyser un fichier audio et g√©n√©rer une transcription](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio)  

- √âchantillons MOE  
  - √âchantillons Phi-3 / 3.5  
    - [üìì] [Exemple Phi-3.5 Mixture of Experts Models (MoEs) sur les r√©seaux sociaux](../../md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb)  
    - [üìì] [Cr√©ation d‚Äôun pipeline Retrieval-Augmented Generation (RAG) avec NVIDIA NIM Phi-3 MOE, Azure AI Search et LlamaIndex](../../md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb)  

- √âchantillons d‚Äôappel de fonction  
  - √âchantillons Phi-4 üÜï  
    - [üìì] [Utiliser l‚Äôappel de fonction avec Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md)  
    - [üìì] [Utiliser l‚Äôappel de fonction pour cr√©er des multi-agents avec Phi-4-mini](../../md/02.Application/07.FunctionCalling/Phi4/Multiagents/Phi_4_mini_multiagent.ipynb)  
    - [üìì] [Utiliser l‚Äôappel de fonction avec Ollama](../../md/02.Application/07.FunctionCalling/Phi4/Ollama/ollama_functioncalling.ipynb)  
    - [üìì] [Utiliser l‚Äôappel de fonction avec ONNX](../../md/02.Application/07.FunctionCalling/Phi4/ONNX/onnx_parallel_functioncalling.ipynb)  

- √âchantillons de mixage multimodal  
  - √âchantillons Phi-4 üÜï  
    - [üìì] [Utiliser Phi-4-multimodal en tant que journaliste technologique](../../md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb)  
    - [Application console .NET utilisant Phi-4-multimodal pour analyser des images](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images)  

- Affinage des √©chantillons Phi  
  - [Sc√©narios d‚Äôaffinage](./md/03.FineTuning/FineTuning_Scenarios.md)  
  - [Affinage vs RAG](./md/03.FineTuning/FineTuning_vs_RAG.md)  
  - [Affiner Phi-3 pour en faire un expert industriel](./md/03.FineTuning/LetPhi3gotoIndustriy.md)  
  - [Affiner Phi-3 avec AI Toolkit pour VS Code](./md/03.FineTuning/Finetuning_VSCodeaitoolkit.md)  
  - [Affiner Phi-3 avec Azure Machine Learning Service](./md/03.FineTuning/Introduce_AzureML.md)  
  - [Affiner Phi-3 avec Lora](./md/03.FineTuning/FineTuning_Lora.md)  
  - [Affiner Phi-3 avec QLora](./md/03.FineTuning/FineTuning_Qlora.md)  
  - [Affiner Phi-3 avec Azure AI Foundry](./md/03.FineTuning/FineTuning_AIFoundry.md)  
  - [Affiner Phi-3 avec Azure ML CLI/SDK](./md/03.FineTuning/FineTuning_MLSDK.md)  
  - [Affiner avec Microsoft Olive](./md/03.FineTuning/FineTuning_MicrosoftOlive.md)  
  - [Atelier pratique d‚Äôaffinage avec Microsoft Olive](./md/03.FineTuning/olive-lab/readme.md)  
  - [Affiner Phi-3-vision avec Weights and Bias](./md/03.FineTuning/FineTuning_Phi-3-visionWandB.md)  
  - [Affiner Phi-3 avec le framework Apple MLX](./md/03.FineTuning/FineTuning_MLX.md)  
  - [Affiner Phi-3-vision (support officiel)](./md/03.FineTuning/FineTuning_Vision.md)  
  - [Affiner Phi-3 avec Kaito AKS, Azure Containers (support officiel)](./md/03.FineTuning/FineTuning_Kaito.md)  
  - [Affiner Phi-3 et 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)  

- Atelier pratique  
  - [Explorer les mod√®les de pointe : LLMs, SLMs, d√©veloppement local et plus](https://github.com/microsoft/aitour-exploring-cutting-edge-models)  
  - [Lib√©rer le potentiel du NLP : Affinage avec Microsoft Olive](https://github.com/azure/Ignite_FineTuning_workshop)  

- Articles de recherche acad√©mique et publications  
  - [Textbooks Are All You Need II : rapport technique phi-1.5](https://arxiv.org/abs/2309.05463)  
  - [Rapport technique Phi-3 : un mod√®le de langage tr√®s performant localement sur votre t√©l√©phone](https://arxiv.org/abs/2404.14219)  
  - [Rapport technique Phi-4](https://arxiv.org/abs/2412.08905)  
  - [Rapport technique Phi-4-Mini : mod√®les de langage multimodaux compacts mais puissants via Mixture-of-LoRAs](https://arxiv.org/abs/2503.01743)  
  - [Optimisation des petits mod√®les de langage pour l‚Äôappel de fonction embarqu√©](https://arxiv.org/abs/2501.02342)  
  - [(WhyPHI) Affinage de PHI-3 pour les questions √† choix multiples : m√©thodologie, r√©sultats et d√©fis](https://arxiv.org/abs/2501.01588)
- [Rapport technique Phi-4-reasoning](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf)  
- [Rapport technique Phi-4-mini-reasoning](https://huggingface.co/microsoft/Phi-4-mini-reasoning/blob/main/Phi-4-Mini-Reasoning.pdf)

## Utilisation des mod√®les Phi

### Phi sur Azure AI Foundry

Vous pouvez apprendre √† utiliser Microsoft Phi et √† cr√©er des solutions de bout en bout sur vos diff√©rents appareils mat√©riels. Pour d√©couvrir Phi par vous-m√™me, commencez par tester les mod√®les et personnaliser Phi pour vos sc√©narios en utilisant le‚ÄØ[Catalogue de mod√®les Azure AI Foundry](https://aka.ms/phi3-azure-ai). Vous pouvez en savoir plus dans la section Premiers pas avec [Azure AI Foundry](/md/02.QuickStart/AzureAIFoundry_QuickStart.md).

**Playground**  
Chaque mod√®le dispose d‚Äôun playground d√©di√© pour tester le mod√®le [Azure AI Playground](https://aka.ms/try-phi3).

### Phi sur GitHub Models

Vous pouvez apprendre √† utiliser Microsoft Phi et √† cr√©er des solutions de bout en bout sur vos diff√©rents appareils mat√©riels. Pour d√©couvrir Phi par vous-m√™me, commencez par tester le mod√®le et personnaliser Phi pour vos sc√©narios en utilisant le‚ÄØ[Catalogue de mod√®les GitHub](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo). Vous pouvez en savoir plus dans la section Premiers pas avec [GitHub Model Catalog](/md/02.QuickStart/GitHubModel_QuickStart.md).

**Playground**  
Chaque mod√®le dispose d‚Äôun [playground d√©di√© pour tester le mod√®le](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi sur Hugging Face

Vous pouvez √©galement retrouver le mod√®le sur [Hugging Face](https://huggingface.co/microsoft).

**Playground**  
[Hugging Chat playground](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

## IA responsable

Microsoft s‚Äôengage √† aider ses clients √† utiliser nos produits d‚ÄôIA de mani√®re responsable, √† partager nos enseignements et √† construire des partenariats bas√©s sur la confiance gr√¢ce √† des outils comme Transparency Notes et Impact Assessments. Beaucoup de ces ressources sont disponibles sur [https://aka.ms/RAI](https://aka.ms/RAI).  
L‚Äôapproche de Microsoft en mati√®re d‚ÄôIA responsable repose sur nos principes d‚ÄôIA : √©quit√©, fiabilit√© et s√©curit√©, confidentialit√© et s√©curit√©, inclusion, transparence et responsabilit√©.

Les mod√®les √† grande √©chelle de traitement du langage naturel, d‚Äôimage et de parole ‚Äì comme ceux utilis√©s dans cet exemple ‚Äì peuvent potentiellement adopter des comportements injustes, peu fiables ou offensants, causant ainsi des pr√©judices. Veuillez consulter la [note de transparence du service Azure OpenAI](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) pour vous informer des risques et des limites.

La m√©thode recommand√©e pour att√©nuer ces risques est d‚Äôint√©grer un syst√®me de s√©curit√© dans votre architecture capable de d√©tecter et pr√©venir les comportements nuisibles. [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) offre une couche de protection ind√©pendante, capable de d√©tecter les contenus nuisibles g√©n√©r√©s par les utilisateurs ou par l‚ÄôIA dans les applications et services. Azure AI Content Safety comprend des API texte et image qui permettent de d√©tecter les contenus probl√©matiques. Dans Azure AI Foundry, le service Content Safety vous permet de visualiser, explorer et tester des exemples de code pour d√©tecter les contenus nuisibles dans diff√©rentes modalit√©s. La documentation [quickstart suivante](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) vous guide pour effectuer des requ√™tes vers ce service.

Un autre aspect √† prendre en compte est la performance globale de l‚Äôapplication. Avec des applications multi-modales et multi-mod√®les, la performance signifie que le syst√®me fonctionne comme vous et vos utilisateurs l‚Äôattendez, notamment en ne g√©n√©rant pas de r√©sultats nuisibles. Il est important d‚Äô√©valuer la performance de votre application globale en utilisant les [√©valuateurs de Performance, Qualit√©, Risque et S√©curit√©](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in). Vous avez √©galement la possibilit√© de cr√©er et d‚Äô√©valuer avec des [√©valuateurs personnalis√©s](https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators).

Vous pouvez √©valuer votre application d‚ÄôIA dans votre environnement de d√©veloppement en utilisant le [Azure AI Evaluation SDK](https://microsoft.github.io/promptflow/index.html). Que vous disposiez d‚Äôun jeu de donn√©es de test ou d‚Äôun objectif, les g√©n√©rations de votre application d‚ÄôIA g√©n√©rative sont mesur√©es quantitativement avec des √©valuateurs int√©gr√©s ou personnalis√©s de votre choix. Pour commencer avec le Azure AI Evaluation SDK et √©valuer votre syst√®me, vous pouvez suivre le [guide de d√©marrage rapide](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk). Une fois une √©valuation lanc√©e, vous pouvez [visualiser les r√©sultats dans Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results).

## Marques d√©pos√©es

Ce projet peut contenir des marques ou logos de projets, produits ou services. L‚Äôutilisation autoris√©e des marques ou logos Microsoft est soumise aux [Directives sur les marques et la marque de Microsoft](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).  
L‚Äôutilisation des marques ou logos Microsoft dans des versions modifi√©es de ce projet ne doit pas pr√™ter √† confusion ni laisser entendre un parrainage par Microsoft. Toute utilisation de marques ou logos tiers est soumise aux politiques de ces tiers.

**Avertissement** :  
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle r√©alis√©e par un humain est recommand√©e. Nous d√©clinons toute responsabilit√© en cas de malentendus ou de mauvaises interpr√©tations r√©sultant de l‚Äôutilisation de cette traduction.