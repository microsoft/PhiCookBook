<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-05-09T07:11:33+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "fi"
}
-->
# Aloita Phi-3:n käyttö paikallisesti

Tämä opas auttaa sinua määrittämään paikallisen ympäristösi Phi-3-mallin ajamista varten Ollaman avulla. Mallia voi käyttää usealla eri tavalla, kuten GitHub Codespacesin, VS Code Dev Containersin tai paikallisen ympäristön kautta.

## Ympäristön asennus

### GitHub Codespaces

Voit käyttää tätä mallipohjaa virtuaalisesti GitHub Codespacesin avulla. Painike avaa selainpohjaisen VS Code -instanssin:

1. Avaa mallipohja (tämä voi kestää muutaman minuutin):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Avaa komentorivi-ikkuna

### VS Code Dev Containers

⚠️ Tämä vaihtoehto toimii vain, jos Docker Desktopille on varattu vähintään 16 GB RAM-muistia. Jos RAM-muistia on vähemmän kuin 16 GB, voit kokeilla [GitHub Codespaces -vaihtoehtoa](../../../../../md/01.Introduction/01) tai [asetella ympäristön paikallisesti](../../../../../md/01.Introduction/01).

Vaihtoehtona on myös VS Code Dev Containers, joka avaa projektin paikallisessa VS Codessa käyttäen [Dev Containers -laajennusta](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Käynnistä Docker Desktop (asenna se, jos sitä ei ole vielä asennettu)
2. Avaa projekti:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Kun VS Code -ikkuna avautuu ja projektin tiedostot näkyvät (tämä voi kestää muutaman minuutin), avaa komentorivi-ikkuna.
4. Jatka [käyttöönoton vaiheisiin](../../../../../md/01.Introduction/01)

### Paikallinen ympäristö

1. Varmista, että seuraavat työkalut ovat asennettuina:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testaa malli

1. Pyydä Ollamaa lataamaan ja ajamaan phi3:mini-malli:

    ```shell
    ollama run phi3:mini
    ```

    Mallin lataaminen vie muutaman minuutin.

2. Kun näet tulosteessa "success", voit lähettää mallille viestin kehotteesta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Muutaman sekunnin kuluttua näet mallin vastausvirran.

4. Oppiaksesi eri tekniikoista, joita käytetään kielimallien kanssa, avaa Python-muistikirja [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) ja suorita jokainen solu. Jos käytit muuta mallia kuin 'phi3:mini', vaihda tiedoston yläosassa `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` tarpeen mukaan. Voit myös muokata järjestelmäviestiä tai lisätä muutaman esimerkin halutessasi.

**Vastuuvapauslauseke**:  
Tämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, ole hyvä ja huomioi, että automaattikäännöksissä saattaa esiintyä virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäiskielellä tulee pitää auktoritatiivisena lähteenä. Tärkeissä asioissa suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa tämän käännöksen käytöstä johtuvista väärinymmärryksistä tai virhetulkinnoista.