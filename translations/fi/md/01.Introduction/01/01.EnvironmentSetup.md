<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3edae6aebc3d0143037109e8af58f1ac",
  "translation_date": "2025-07-16T18:10:39+00:00",
  "source_file": "md/01.Introduction/01/01.EnvironmentSetup.md",
  "language_code": "fi"
}
-->
# Aloita Phi-3:n käyttö paikallisesti

Tämä opas auttaa sinua määrittämään paikallisen ympäristösi Phi-3-mallin ajamista varten Ollaman avulla. Mallia voi käyttää usealla eri tavalla, kuten GitHub Codespacesin, VS Code Dev Containersin tai paikallisen ympäristön kautta.

## Ympäristön asennus

### GitHub Codespaces

Voit käyttää tätä mallipohjaa virtuaalisesti GitHub Codespacesin avulla. Painike avaa selaimeesi web-pohjaisen VS Code -instanssin:

1. Avaa mallipohja (tämä voi kestää muutaman minuutin):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Avaa terminaali-ikkuna

### VS Code Dev Containers

⚠️ Tämä vaihtoehto toimii vain, jos Docker Desktopillasi on varattu vähintään 16 Gt RAM-muistia. Jos RAM-muistia on alle 16 Gt, voit kokeilla [GitHub Codespaces -vaihtoehtoa](../../../../../md/01.Introduction/01) tai [asetella ympäristön paikallisesti](../../../../../md/01.Introduction/01).

Läheisesti liittyvä vaihtoehto on VS Code Dev Containers, joka avaa projektin paikallisessa VS Codessasi käyttäen [Dev Containers -laajennusta](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Käynnistä Docker Desktop (asenna se, jos sitä ei ole vielä asennettu)
2. Avaa projekti:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Kun VS Code -ikkuna avautuu ja projektin tiedostot näkyvät (tämä voi kestää muutaman minuutin), avaa terminaali-ikkuna.
4. Jatka [käyttöönotto-ohjeisiin](../../../../../md/01.Introduction/01)

### Paikallinen ympäristö

1. Varmista, että seuraavat työkalut ovat asennettuina:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testaa malli

1. Pyydä Ollamaa lataamaan ja ajamaan phi3:mini-malli:

    ```shell
    ollama run phi3:mini
    ```

    Mallin lataaminen kestää muutaman minuutin.

2. Kun näet tulosteessa "success", voit lähettää mallille viestin kehotteesta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Muutaman sekunnin kuluttua mallilta pitäisi alkaa tulla vastausvirta.

4. Oppiaksesi eri tekniikoista, joita käytetään kielimallien kanssa, avaa Python-muistikirja [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) ja suorita jokainen solu. Jos käytit muuta mallia kuin 'phi3:mini', vaihda ensimmäisen solun `MODEL_NAME` vastaamaan käyttämääsi mallia.

5. Keskustellaksesi phi3:mini-mallin kanssa Pythonista, avaa Python-tiedosto [chat.py](../../../../../code/01.Introduce/chat.py) ja suorita se. Voit tarvittaessa muuttaa tiedoston yläosassa olevaa `MODEL_NAME`-arvoa, ja halutessasi voit myös muokata järjestelmäviestiä tai lisätä few-shot-esimerkkejä.

**Vastuuvapauslauseke**:  
Tämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, että automaattikäännöksissä saattaa esiintyä virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäiskielellä tulee pitää virallisena lähteenä. Tärkeissä tiedoissa suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa tämän käännöksen käytöstä aiheutuvista väärinymmärryksistä tai tulkinnoista.