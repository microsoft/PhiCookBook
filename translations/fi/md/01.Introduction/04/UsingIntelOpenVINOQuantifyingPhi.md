<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3139a6a82f357a9f90f1fe51c4caf65a",
  "translation_date": "2025-07-16T22:02:28+00:00",
  "source_file": "md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md",
  "language_code": "fi"
}
-->
# **Phi-3.5:n kvantisointi Intel OpenVINO:lla**

Intel on perinteisin suorittimien valmistaja, jolla on paljon k√§ytt√§ji√§. Koneoppimisen ja syv√§oppimisen nousun my√∂t√§ Intel on my√∂s liittynyt teko√§lyn kiihdytyskilpailuun. Mallin p√§√§ttelyss√§ Intel k√§ytt√§√§ paitsi GPU:ita ja CPU:ita, my√∂s NPU:ita.

Toivomme voivamme ottaa Phi-3.x -perheen k√§ytt√∂√∂n loppuk√§ytt√§j√§n laitteissa, pyrkien siit√§ teko√§ly-PC:n ja Copilot-PC:n t√§rkein osa. Mallin lataaminen loppuk√§ytt√§j√§n laitteella riippuu eri laitevalmistajien yhteisty√∂st√§. T√§ss√§ luvussa keskityt√§√§n p√§√§asiassa Intel OpenVINO:n k√§ytt√∂tilanteeseen kvantitatiivisena mallina.


## **Mik√§ on OpenVINO**

OpenVINO on avoimen l√§hdekoodin ty√∂kalu syv√§oppimismallien optimointiin ja k√§ytt√∂√∂nottoon pilvest√§ reunalaitteisiin. Se nopeuttaa syv√§oppimisen p√§√§ttely√§ monissa k√§ytt√∂tapauksissa, kuten generatiivisessa teko√§lyss√§, videoissa, √§√§niss√§ ja kieliss√§, hy√∂dynt√§en suosittuja kehyksi√§ kuten PyTorch, TensorFlow, ONNX ja muita. Muunna ja optimoi malleja, ja ota ne k√§ytt√∂√∂n erilaisissa Intel¬Æ-laitteissa ja ymp√§rist√∂iss√§, paikallisesti tai laitteella, selaimessa tai pilvess√§.

Nyt OpenVINO:n avulla voit nopeasti kvantisoida GenAI-mallin Intel-laitteistolla ja nopeuttaa mallin referenssi√§.

OpenVINO tukee nyt Phi-3.5-Vision ja Phi-3.5 Instruct -mallien kvantisointimuunnosta.

### **Ymp√§rist√∂n asennus**

Varmista, ett√§ seuraavat ymp√§rist√∂riippuvuudet on asennettu, t√§m√§ on requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Phi-3.5-Instructin kvantisointi OpenVINO:lla**

Aja t√§m√§ skripti terminaalissa

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Phi-3.5-Vision kvantisointi OpenVINO:lla**

Aja t√§m√§ skripti Pythonissa tai Jupyter labissa

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ü§ñ Phi-3.5:n esimerkit Intel OpenVINO:lla**

| Labit    | Esittely | Siirry |
| -------- | ------- |  ------- |
| üöÄ Lab-esittely Phi-3.5 Instruct  | Opi k√§ytt√§m√§√§n Phi-3.5 Instructia teko√§ly-PC:ss√§si    |  [Siirry](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| üöÄ Lab-esittely Phi-3.5 Vision (kuva) | Opi k√§ytt√§m√§√§n Phi-3.5 Visionia kuvien analysointiin teko√§ly-PC:ss√§si      |  [Siirry](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| üöÄ Lab-esittely Phi-3.5 Vision (video)   | Opi k√§ytt√§m√§√§n Phi-3.5 Visionia videoiden analysointiin teko√§ly-PC:ss√§si    |  [Siirry](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |



## **Resurssit**

1. Lis√§tietoja Intel OpenVINO:sta [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub Repo [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattik√§√§nn√∂ksiss√§ saattaa esiinty√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§iskielell√§ tulee pit√§√§ virallisena l√§hteen√§. T√§rkeiss√§ tiedoissa suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ aiheutuvista v√§√§rinymm√§rryksist√§ tai tulkinnoista.