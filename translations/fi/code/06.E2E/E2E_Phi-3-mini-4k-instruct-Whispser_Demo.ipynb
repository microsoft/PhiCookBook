{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktiivinen Phi 3 Mini 4K Instruct Chatbot Whisperillä\n",
    "\n",
    "### Johdanto:\n",
    "Interaktiivinen Phi 3 Mini 4K Instruct Chatbot on työkalu, jonka avulla käyttäjät voivat olla vuorovaikutuksessa Microsoft Phi 3 Mini 4K instruct -demon kanssa tekstin tai äänen avulla. Chatbotia voidaan käyttää monenlaisiin tehtäviin, kuten käännöksiin, säätietoihin ja yleiseen tiedonhankintaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "Luo uusi token  \n",
    "Anna uusi nimi  \n",
    "Valitse kirjoitusoikeudet  \n",
    "Kopioi token ja tallenna se turvalliseen paikkaan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seuraava Python-koodi suorittaa kaksi päätehtävää: `os`-moduulin tuomisen ja ympäristömuuttujan asettamisen.\n",
    "\n",
    "1. `os`-moduulin tuominen:\n",
    "   - Pythonin `os`-moduuli tarjoaa tavan olla vuorovaikutuksessa käyttöjärjestelmän kanssa. Sen avulla voi suorittaa erilaisia käyttöjärjestelmään liittyviä tehtäviä, kuten käyttää ympäristömuuttujia, käsitellä tiedostoja ja hakemistoja jne.\n",
    "   - Tässä koodissa `os`-moduuli tuodaan käyttöön `import`-lauseella. Tämä lause tekee `os`-moduulin toiminnallisuudet käytettäväksi nykyisessä Python-skriptissä.\n",
    "\n",
    "2. Ympäristömuuttujan asettaminen:\n",
    "   - Ympäristömuuttuja on arvo, johon käyttöjärjestelmän ohjelmat voivat päästä käsiksi. Se on tapa tallentaa asetuksia tai muuta tietoa, jota useat ohjelmat voivat käyttää.\n",
    "   - Tässä koodissa uusi ympäristömuuttuja asetetaan käyttämällä `os.environ`-sanakirjaa. Sanakirjan avain on `'HF_TOKEN'`, ja arvo määritetään `HUGGINGFACE_TOKEN`-muuttujasta.\n",
    "   - `HUGGINGFACE_TOKEN`-muuttuja määritellään juuri tämän koodinpätkän yläpuolella, ja sille annetaan merkkijonoarvo `\"hf_**************\"` käyttäen `#@param`-syntaksia. Tätä syntaksia käytetään usein Jupyter-notebookeissa, jotta käyttäjä voi syöttää arvoja ja määrittää parametreja suoraan notebookin käyttöliittymässä.\n",
    "   - Asettamalla `'HF_TOKEN'`-ympäristömuuttujan, sitä voivat käyttää ohjelman muut osat tai muut ohjelmat, jotka toimivat samalla käyttöjärjestelmällä.\n",
    "\n",
    "Kaiken kaikkiaan tämä koodi tuo `os`-moduulin käyttöön ja asettaa ympäristömuuttujan nimeltä `'HF_TOKEN'` arvolla, joka on määritetty `HUGGINGFACE_TOKEN`-muuttujassa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tämä koodinpätkä määrittää clear_output-nimisen funktion, jota käytetään nykyisen solun tulosteen tyhjentämiseen Jupyter Notebookissa tai IPythonissa. Tarkastellaan koodia ja sen toiminnallisuutta tarkemmin:\n",
    "\n",
    "Funktio clear_output ottaa yhden parametrin nimeltä wait, joka on totuusarvo (boolean). Oletuksena wait on asetettu arvoon False. Tämä parametri määrittää, odottaako funktio uuden tulosteen ilmestymistä ennen olemassa olevan tulosteen tyhjentämistä.\n",
    "\n",
    "Itse funktiota käytetään nykyisen solun tulosteen tyhjentämiseen. Jupyter Notebookissa tai IPythonissa, kun solu tuottaa tulostetta, kuten tulostettua tekstiä tai graafisia kuvioita, tämä tuloste näytetään solun alapuolella. Funktio clear_output mahdollistaa kyseisen tulosteen tyhjentämisen.\n",
    "\n",
    "Funktion toteutusta ei ole annettu koodinpätkässä, kuten ellipsistä (...) voi päätellä. Ellipsi toimii paikkamerkkinä varsinaiselle koodille, joka suorittaa tulosteen tyhjentämisen. Funktion toteutus saattaa sisältää vuorovaikutusta Jupyter Notebookin tai IPythonin API:n kanssa, jotta olemassa oleva tuloste voidaan poistaa solusta.\n",
    "\n",
    "Kaiken kaikkiaan tämä funktio tarjoaa kätevän tavan tyhjentää nykyisen solun tuloste Jupyter Notebookissa tai IPythonissa, mikä helpottaa tulosteen hallintaa ja päivittämistä interaktiivisten koodausistuntojen aikana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suorita tekstistä puheeksi (TTS) Edge TTS -palvelun avulla. Käydään läpi olennaiset funktioiden toteutukset yksi kerrallaan:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: Tämä funktio ottaa syötteenä arvon ja laskee TTS-äänen nopeusmerkkijonon. Syöte edustaa puheen haluttua nopeutta, jossa arvo 1 tarkoittaa normaalia nopeutta. Funktio laskee nopeusmerkkijonon vähentämällä 1 syötteestä, kertomalla sen 100:lla ja määrittämällä etumerkin sen perusteella, onko syöte suurempi tai yhtä suuri kuin 1. Funktio palauttaa nopeusmerkkijonon muodossa \"{sign}{rate}\".\n",
    "\n",
    "2. `make_chunks(input_text, language)`: Tämä funktio ottaa syötteenä tekstin ja kielen. Se jakaa syötteen tekstin osiin kieleen liittyvien sääntöjen perusteella. Tässä toteutuksessa, jos kieli on \"English\", funktio jakaa tekstin pisteen (\".\") kohdalta ja poistaa mahdolliset alussa tai lopussa olevat välilyönnit. Se lisää pisteen jokaisen osan loppuun ja palauttaa suodatetun listan osista.\n",
    "\n",
    "3. `tts_file_name(text)`: Tämä funktio luo tiedostonimen TTS-äänitiedostolle syötteenä annetun tekstin perusteella. Se tekee useita muunnoksia tekstille: poistaa lopussa olevan pisteen (jos sellainen on), muuntaa tekstin pieniksi kirjaimiksi, poistaa alussa ja lopussa olevat välilyönnit ja korvaa välilyönnit alaviivoilla. Se lyhentää tekstin enintään 25 merkkiin (jos pidempi) tai käyttää koko tekstiä, jos se on tyhjä. Lopuksi se luo satunnaisen merkkijonon [`uuid`] -moduulin avulla ja yhdistää sen lyhennettyyn tekstiin luodakseen tiedostonimen muodossa \"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\".\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: Tämä funktio yhdistää useita äänitiedostoja yhdeksi tiedostoksi. Se ottaa syötteenä listan äänitiedostojen polkuja ja ulostulopolun. Funktio alustaa tyhjän `AudioSegment`-objektin nimeltä [`merged_audio`]. Se käy läpi jokaisen äänitiedoston polun, lataa äänitiedoston `AudioSegment.from_file()` -metodilla `pydub`-kirjastosta ja lisää nykyisen äänitiedoston [`merged_audio`]-objektiin. Lopuksi se vie yhdistetyn äänen määritettyyn ulostulopolkuun MP3-muodossa.\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: Tämä funktio suorittaa TTS-toiminnon Edge TTS -palvelun avulla. Se ottaa syötteenä tekstiosien listan, puheen nopeuden, äänen nimen ja tallennuspolun. Jos osien määrä on suurempi kuin 1, funktio luo hakemiston yksittäisten osien äänitiedostojen tallentamista varten. Se käy läpi jokaisen osan, rakentaa Edge TTS -komennon `calculate_rate_string()` -funktion, äänen nimen ja osatekstin avulla ja suorittaa komennon `os.system()` -funktiolla. Jos komennon suoritus onnistuu, se lisää luodun äänitiedoston polun listaan. Kun kaikki osat on käsitelty, se yhdistää yksittäiset äänitiedostot `merge_audio_files()` -funktion avulla ja tallentaa yhdistetyn äänen määritettyyn tallennuspolkuun. Jos osia on vain yksi, se luo suoraan Edge TTS -komennon ja tallentaa äänen tallennuspolkuun. Lopuksi se palauttaa luodun äänitiedoston tallennuspolun.\n",
    "\n",
    "6. `random_audio_name_generate()`: Tämä funktio luo satunnaisen äänitiedoston nimen [`uuid`] -moduulin avulla. Se luo satunnaisen UUID:n, muuntaa sen merkkijonoksi, ottaa ensimmäiset 8 merkkiä, lisää \".mp3\"-päätteen ja palauttaa satunnaisen äänitiedoston nimen.\n",
    "\n",
    "7. `talk(input_text)`: Tämä funktio on pääasiallinen sisääntulopiste TTS-toiminnon suorittamiseksi. Se ottaa syötteenä tekstin. Se tarkistaa ensin tekstin pituuden määrittääkseen, onko kyseessä pitkä lause (vähintään 600 merkkiä). Pituuden ja `translate_text_flag`-muuttujan arvon perusteella se määrittää kielen ja luo tekstiosien listan `make_chunks()` -funktion avulla. Se luo sitten tallennuspolun äänitiedostolle `random_audio_name_generate()` -funktion avulla. Lopuksi se kutsuu `edge_free_tts()` -funktion suorittamaan TTS-toiminnon ja palauttaa luodun äänitiedoston tallennuspolun.\n",
    "\n",
    "Yhteenvetona nämä funktiot toimivat yhdessä jakaakseen syötteen tekstin osiin, luodakseen tiedostonimen äänitiedostolle, suorittaakseen TTS-toiminnon Edge TTS -palvelun avulla ja yhdistääkseen yksittäiset äänitiedostot yhdeksi tiedostoksi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kahden funktion, convert_to_text ja run_text_prompt, toteutus sekä kahden luokan, str ja Audio, määrittely.\n",
    "\n",
    "convert_to_text-funktio ottaa syötteenä audio_path-parametrin ja muuntaa äänen tekstiksi käyttämällä mallia nimeltä whisper_model. Funktio tarkistaa ensin, onko gpu-lippu asetettu arvoon True. Jos se on, whisper_modelia käytetään tietyillä parametreilla, kuten word_timestamps=True, fp16=True, language='English' ja task='translate'. Jos gpu-lippu on False, whisper_modelia käytetään parametrilla fp16=False. Tuloksena saatu transkriptio tallennetaan tiedostoon nimeltä 'scan.txt' ja palautetaan tekstinä.\n",
    "\n",
    "run_text_prompt-funktio ottaa syötteenä viestin ja chat_history-parametrin. Se käyttää phi_demo-funktiota luodakseen chatbotin vastauksen syötteenä annetun viestin perusteella. Generoitu vastaus välitetään talk-funktiolle, joka muuntaa vastauksen äänenä tiedostoksi ja palauttaa tiedostopolun. Audio-luokkaa käytetään äänen näyttämiseen ja toistamiseen. Ääni näytetään IPython.display-moduulin display-funktion avulla, ja Audio-objekti luodaan autoplay=True-parametrilla, jolloin ääni alkaa toistua automaattisesti. chat_history päivitetään syötteenä annetulla viestillä ja generoidulla vastauksella, ja palautetaan tyhjä merkkijono sekä päivitetty chat_history.\n",
    "\n",
    "str-luokka on Pythonin sisäänrakennettu luokka, joka edustaa merkkijonojen sekvenssiä. Se tarjoaa erilaisia metodeja merkkijonojen käsittelyyn ja manipulointiin, kuten capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill ja muita. Näiden metodien avulla voi suorittaa operaatioita, kuten etsimistä, korvaamista, muotoilua ja merkkijonojen manipulointia.\n",
    "\n",
    "Audio-luokka on mukautettu luokka, joka edustaa ääniobjektia. Sitä käytetään luomaan äänisoitin Jupyter Notebook -ympäristössä. Luokka hyväksyy useita parametreja, kuten data, filename, url, embed, rate, autoplay ja normalize. data-parametri voi olla numpy-taulukko, näytteiden lista, merkkijono, joka edustaa tiedostonimeä tai URL-osoitetta, tai raakaa PCM-dataa. filename-parametria käytetään määrittämään paikallinen tiedosto, josta ääni data ladataan, ja url-parametria käytetään määrittämään URL-osoite, josta ääni data ladataan. embed-parametri määrittää, tulisiko ääni data upottaa data-URI:n avulla vai viitata alkuperäiseen lähteeseen. rate-parametri määrittää ääni datan näytteenottotaajuuden. autoplay-parametri määrittää, alkaako ääni toistua automaattisesti. normalize-parametri määrittää, tulisiko ääni data normalisoida (skaalata) maksimaaliseen mahdolliseen alueeseen. Audio-luokka tarjoaa myös metodeja, kuten reload, ääni datan lataamiseen uudelleen tiedostosta tai URL-osoitteesta, sekä attribuutteja, kuten src_attr, autoplay_attr ja element_id_attr, HTML-äänielementin vastaavien attribuuttien hakemiseen.\n",
    "\n",
    "Yhteenvetona nämä funktiot ja luokat käytetään äänen transkriptioon tekstiksi, chatbotin ääni vastausten luomiseen sekä äänen näyttämiseen ja toistamiseen Jupyter Notebook -ympäristössä.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Vastuuvapauslauseke**:  \nTämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, että automaattiset käännökset voivat sisältää virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäisellä kielellä tulisi pitää ensisijaisena lähteenä. Kriittisen tiedon osalta suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa väärinkäsityksistä tai virhetulkinnoista, jotka johtuvat tämän käännöksen käytöstä.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-12T23:16:41+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "fi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}