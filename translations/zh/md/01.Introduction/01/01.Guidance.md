<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd049872f37c3079c87d4fe17109cea0",
  "translation_date": "2025-05-07T14:57:55+00:00",
  "source_file": "md/01.Introduction/01/01.Guidance.md",
  "language_code": "zh"
}
-->
### Guidance-AI 和 Phi 模型即服务（MaaS）
我们将 [Guidance](https://github.com/guidance-ai/guidance) 引入 Azure AI Foundry 的 Phi-3.5-mini 无服务器端点，借助为应用量身定制的结构，使输出更具可预测性。通过 Guidance，您可以避免昂贵的重试，例如，可以限制模型从预定义列表中选择（如医疗编码）、将输出限定为提供上下文中的直接引用，或遵循任意正则表达式。Guidance 在推理堆栈中逐个标记地引导模型，降低了 30-50% 的成本和延迟，这使其成为 [Phi-3-mini 无服务器端点](https://aka.ms/try-phi3.5mini) 独特且有价值的附加组件。

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) 是一个旨在帮助开发者高效创建和部署 AI 模型的框架。它专注于提供构建稳健 AI 应用的工具和最佳实践。

结合 **Phi 模型即服务（MaaS）**，它为部署既经济又高效的小型语言模型（SLM）提供了强大解决方案。

**Guidance-AI** 是一个编程框架，旨在帮助开发者更有效地控制和引导大型语言模型（LLM）。它允许精确地结构化输出，较传统提示或微调方法减少延迟和成本。

### Guidance-AI 的主要特点：
- **高效控制**：使开发者能够控制语言模型生成文本的方式，确保输出质量高且相关。
- **降低成本和延迟**：优化生成过程，使其更经济且更快速。
- **灵活集成**：支持多种后端，包括 Transformers、llama.cpp、AzureAI、VertexAI 和 OpenAI。
- **丰富的输出结构**：支持条件语句、循环和工具使用等复杂输出结构，更容易生成清晰且可解析的结果。
- **兼容性强**：同一 Guidance 程序可在多个后端运行，提升灵活性和易用性。

### 示例用例：
- **受限生成**：使用正则表达式和上下文无关文法引导模型输出。
- **工具集成**：自动交替控制和生成，例如在文本生成任务中使用计算器。

更多详细信息和示例，请访问 [Guidance-AI GitHub 仓库](https://github.com/guidance-ai/guidance)。

[查看 Phi-3.5 示例](../../../../../code/01.Introduce/guidance.ipynb)

### Phi 模型的主要特点：
1. **成本效益高**：设计经济实惠，同时保持高性能。
2. **低延迟**：适合需要快速响应的实时应用。
3. **灵活性强**：可部署于云端、边缘和离线等多种环境。
4. **可定制**：模型可通过领域特定数据进行微调以提升性能。
5. **安全与合规**：基于微软的 AI 原则构建，确保责任、透明、公平、可靠、安全、隐私和包容性。

### Phi 模型即服务（MaaS）：
Phi 模型通过按需付费的推理 API 提供，方便将其集成到应用中，无需大量前期投入。

### Phi-3 入门：
开始使用 Phi 模型，您可以浏览 [Azure AI 模型目录](https://ai.azure.com/explore/models) 或 [GitHub Marketplace 模型](https://github.com/marketplace/models)，这里提供预构建和可定制的模型。此外，您还可以使用 [Azure AI Foundry](https://ai.azure.com) 来开发和部署 AI 应用。

### 资源
[Guidance 入门示例笔记本](../../../../../code/01.Introduce/guidance.ipynb)

**免责声明**：  
本文件由 AI 翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 翻译而成。尽管我们力求准确，但请注意自动翻译可能包含错误或不准确之处。原始语言版本的文件应被视为权威来源。对于重要信息，建议采用专业人工翻译。因使用本翻译而产生的任何误解或误释，我们概不负责。