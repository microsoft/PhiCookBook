<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "624fe133fba62773979d45f54519f7bb",
  "translation_date": "2025-07-16T18:50:29+00:00",
  "source_file": "md/01.Introduction/02/01.HF.md",
  "language_code": "zh"
}
-->
# **在 Hugging Face 中使用 Phi Family**

[Hugging Face](https://huggingface.co/) 是一个非常受欢迎的 AI 社区，拥有丰富的数据和开源模型资源。不同厂商会通过 Hugging Face 发布开源的 LLM 和 SLM，比如微软、Meta、Mistral、苹果、谷歌等。

微软的 Phi Family 已经在 Hugging Face 上发布。开发者可以根据场景和业务需求下载相应的 Phi Family 模型。除了在 Hugging Face 上部署 Phi Pytorch 模型外，我们还发布了量化模型，使用 GGUF 和 ONNX 格式，为终端用户提供更多选择。

## **在 Hugging Face 下载模型**

你可以通过以下链接下载 Phi Family 模型

[微软模型在 Hugging Face](https://huggingface.co/microsoft)

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

- **Phi-4-reasoning** https://huggingface.co/microsoft/Phi-4-reasoning

- **Phi-4-reasoning Plus** https://huggingface.co/microsoft/Phi-4-reasoning-plus 

- **Phi-4-mini-reasoning** https://huggingface.co/microsoft/Phi-4-mini-reasoning

你可以通过多种方式下载模型，比如安装 ***Hugging Face CLI SDK*** 或使用 ***git clone***。

### **使用 Hugging Face CLI 下载 Phi Family 模型**

- 安装 Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- 使用 huggingface-cli 登录

使用你的 [用户访问令牌](https://huggingface.co/docs/hub/security-tokens)（在你的 [设置页面](https://huggingface.co/settings/tokens) 获取）登录 Hugging Face

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- 下载模型

你可以下载模型并保存到缓存中

```bash

huggingface-cli download microsoft/phi-4

```

你也可以设置模型保存到指定位置

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **使用 git clone 下载 Phi Family 模型**

你也可以使用 ***git clone*** 来下载模型

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **示例 - 推理 Microsoft Phi-4**

- **安装 transformers 库**

```bash

pip install transformers -U

```

- **在 VSCode 中运行此代码**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**免责声明**：  
本文件使用 AI 翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。虽然我们力求准确，但请注意自动翻译可能包含错误或不准确之处。原始文件的母语版本应被视为权威来源。对于重要信息，建议使用专业人工翻译。对于因使用本翻译而产生的任何误解或误释，我们不承担任何责任。