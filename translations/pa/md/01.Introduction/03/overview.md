Phi-3-mini ਦੇ ਸੰਦਰਭ ਵਿੱਚ, ਇਨਫਰੈਂਸ ਦਾ ਮਤਲਬ ਮਾਡਲ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇਨਪੁੱਟ ਡੇਟਾ ਦੇ ਆਧਾਰ 'ਤੇ ਅਨੁਮਾਨ ਲਗਾਉਣ ਜਾਂ ਨਤੀਜੇ ਤਿਆਰ ਕਰਨ ਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ। ਆਓ ਮੈਂ ਤੁਹਾਨੂੰ Phi-3-mini ਅਤੇ ਇਸ ਦੀ ਇਨਫਰੈਂਸ ਸਮਰੱਥਾ ਬਾਰੇ ਹੋਰ ਜਾਣਕਾਰੀ ਦਿੰਦਾ ਹਾਂ।

Phi-3-mini Microsoft ਵੱਲੋਂ ਜਾਰੀ ਕੀਤੇ ਗਏ Phi-3 ਸੀਰੀਜ਼ ਦੇ ਮਾਡਲਾਂ ਦਾ ਹਿੱਸਾ ਹੈ। ਇਹ ਮਾਡਲ ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ (SLMs) ਨਾਲ ਸੰਭਵ ਚੀਜ਼ਾਂ ਨੂੰ ਨਵੀਂ ਪਰਿਭਾਸ਼ਾ ਦੇਣ ਲਈ ਬਣਾਏ ਗਏ ਹਨ।

ਇੱਥੇ Phi-3-mini ਅਤੇ ਇਸ ਦੀ ਇਨਫਰੈਂਸ ਸਮਰੱਥਾ ਬਾਰੇ ਕੁਝ ਮੁੱਖ ਬਿੰਦੂ ਹਨ:

## **Phi-3-mini ਦਾ ਜਾਇਜ਼ਾ:**
- Phi-3-mini ਦਾ ਪੈਰਾਮੀਟਰ ਸਾਈਜ਼ 3.8 ਬਿਲੀਅਨ ਹੈ।
- ਇਹ ਸਿਰਫ ਪਰੰਪਰਾਗਤ ਕੰਪਿਊਟਿੰਗ ਡਿਵਾਈਸਾਂ 'ਤੇ ਹੀ ਨਹੀਂ, ਸਗੋਂ ਮੋਬਾਈਲ ਅਤੇ IoT ਜਿਹੇ ਐਜ ਡਿਵਾਈਸਾਂ 'ਤੇ ਵੀ ਚੱਲ ਸਕਦਾ ਹੈ।
- Phi-3-mini ਦੀ ਰਿਲੀਜ਼ ਵਿਅਕਤੀਆਂ ਅਤੇ ਉਦਯੋਗਾਂ ਨੂੰ ਵੱਖ-ਵੱਖ ਹਾਰਡਵੇਅਰ ਡਿਵਾਈਸਾਂ 'ਤੇ SLMs ਨੂੰ ਤਾਇਨਾਤ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦੀ ਹੈ, ਖਾਸ ਕਰਕੇ ਜਿੱਥੇ ਸਰੋਤ ਸੀਮਿਤ ਹਨ।
- ਇਹ ਵੱਖ-ਵੱਖ ਮਾਡਲ ਫਾਰਮੈਟਾਂ ਨੂੰ ਕਵਰ ਕਰਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਪਰੰਪਰਾਗਤ PyTorch ਫਾਰਮੈਟ, gguf ਫਾਰਮੈਟ ਦਾ ਕੁਆੰਟਾਈਜ਼ਡ ਵਰਜਨ, ਅਤੇ ONNX-ਅਧਾਰਿਤ ਕੁਆੰਟਾਈਜ਼ਡ ਵਰਜਨ।

## **Phi-3-mini ਤੱਕ ਪਹੁੰਚ:**
Phi-3-mini ਤੱਕ ਪਹੁੰਚ ਲਈ, ਤੁਸੀਂ Copilot ਐਪਲੀਕੇਸ਼ਨ ਵਿੱਚ [Semantic Kernel](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹੋ। Semantic Kernel ਆਮ ਤੌਰ 'ਤੇ Azure OpenAI Service, Hugging Face ਉੱਤੇ ਖੁੱਲ੍ਹੇ ਸਰੋਤ ਵਾਲੇ ਮਾਡਲਾਂ ਅਤੇ ਲੋਕਲ ਮਾਡਲਾਂ ਨਾਲ ਸੰਗਤ ਹੈ।  
ਤੁਸੀਂ ਕੁਆੰਟਾਈਜ਼ਡ ਮਾਡਲਾਂ ਨੂੰ ਕਾਲ ਕਰਨ ਲਈ [Ollama](https://ollama.com) ਜਾਂ [LlamaEdge](https://llamaedge.com) ਦੀ ਵੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹੋ। Ollama ਵਿਅਕਤਿਗਤ ਉਪਭੋਗਤਾਵਾਂ ਨੂੰ ਵੱਖ-ਵੱਖ ਕੁਆੰਟਾਈਜ਼ਡ ਮਾਡਲ ਕਾਲ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ, ਜਦਕਿ LlamaEdge GGUF ਮਾਡਲਾਂ ਲਈ ਕ੍ਰਾਸ-ਪਲੇਟਫਾਰਮ ਉਪਲਬਧਤਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।

## **ਕੁਆੰਟਾਈਜ਼ਡ ਮਾਡਲ:**
ਕਈ ਉਪਭੋਗਤਾ ਲੋਕਲ ਇਨਫਰੈਂਸ ਲਈ ਕੁਆੰਟਾਈਜ਼ਡ ਮਾਡਲਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨਾ ਪਸੰਦ ਕਰਦੇ ਹਨ। ਉਦਾਹਰਨ ਵਜੋਂ, ਤੁਸੀਂ ਸਿੱਧਾ Ollama ਰਨ Phi-3 ਕਰ ਸਕਦੇ ਹੋ ਜਾਂ ਇਸਨੂੰ Modelfile ਦੀ ਵਰਤੋਂ ਨਾਲ ਆਫਲਾਈਨ ਕਨਫਿਗਰ ਕਰ ਸਕਦੇ ਹੋ। Modelfile GGUF ਫਾਈਲ ਪਾਥ ਅਤੇ ਪ੍ਰਾਂਪਟ ਫਾਰਮੈਟ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ।

## **ਜਨਰੇਟਿਵ AI ਦੀਆਂ ਸੰਭਾਵਨਾਵਾਂ:**
Phi-3-mini ਵਰਗੇ SLMs ਨੂੰ ਮਿਲਾ ਕੇ ਜਨਰੇਟਿਵ AI ਲਈ ਨਵੀਆਂ ਸੰਭਾਵਨਾਵਾਂ ਖੁਲਦੀਆਂ ਹਨ। ਇਨਫਰੈਂਸ ਸਿਰਫ ਪਹਿਲਾ ਕਦਮ ਹੈ; ਇਹ ਮਾਡਲ ਸਰੋਤ ਸੀਮਿਤ, ਲੇਟੈਂਸੀ-ਬਾਊਂਡ ਅਤੇ ਲਾਗਤ ਸੀਮਿਤ ਸਥਿਤੀਆਂ ਵਿੱਚ ਵੱਖ-ਵੱਖ ਕੰਮਾਂ ਲਈ ਵਰਤੇ ਜਾ ਸਕਦੇ ਹਨ।

## **Phi-3-mini ਨਾਲ ਜਨਰੇਟਿਵ AI ਨੂੰ ਖੋਲ੍ਹਣਾ: ਇਨਫਰੈਂਸ ਅਤੇ ਤਾਇਨਾਤੀ ਲਈ ਇੱਕ ਮਾਰਗਦਰਸ਼ਨ**  
ਸਿੱਖੋ ਕਿ Semantic Kernel, Ollama/LlamaEdge, ਅਤੇ ONNX Runtime ਦੀ ਵਰਤੋਂ ਕਰਕੇ Phi-3-mini ਮਾਡਲਾਂ ਤੱਕ ਕਿਵੇਂ ਪਹੁੰਚ ਕਰਨੀ ਹੈ ਅਤੇ ਇਨਫਰੈਂਸ ਕਰਨਾ ਹੈ, ਅਤੇ ਵੱਖ-ਵੱਖ ਐਪਲੀਕੇਸ਼ਨ ਸਥਿਤੀਆਂ ਵਿੱਚ ਜਨਰੇਟਿਵ AI ਦੀਆਂ ਸੰਭਾਵਨਾਵਾਂ ਦਾ ਪਤਾ ਲਗਾਓ।

**ਖਾਸੀਅਤਾਂ**  
phi3-mini ਮਾਡਲ ਵਿੱਚ ਇਨਫਰੈਂਸ:

- [Semantic Kernel](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo)  
- [Ollama](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)  
- [LlamaEdge WASM](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo)  
- [ONNX Runtime](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/onnx?WT.mc_id=aiml-138114-kinfeylo)  
- [iOS](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ios?WT.mc_id=aiml-138114-kinfeylo)  

ਸੰਖੇਪ ਵਿੱਚ, Phi-3-mini ਵਿਕਾਸਕਾਰਾਂ ਨੂੰ ਵੱਖ-ਵੱਖ ਮਾਡਲ ਫਾਰਮੈਟਾਂ ਦੀ ਖੋਜ ਕਰਨ ਅਤੇ ਵੱਖ-ਵੱਖ ਐਪਲੀਕੇਸ਼ਨ ਸਥਿਤੀਆਂ ਵਿੱਚ ਜਨਰੇਟਿਵ AI ਦੀ ਵਰਤੋਂ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ।

**ਅਸਵੀਕਾਰੋਪਣ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦਿਤ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਰੱਖੋ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸਮਰਥਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਆਪਣੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਪ੍ਰਮਾਣਿਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਉਤਪੰਨ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।