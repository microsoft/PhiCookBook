# Phi-3 ਨਾਲ ਸਥਾਨਕ ਤੌਰ 'ਤੇ ਸ਼ੁਰੂਆਤ ਕਰੋ

ਇਹ ਗਾਈਡ ਤੁਹਾਡੇ ਸਥਾਨਕ ਵਾਤਾਵਰਣ ਨੂੰ ਸੈੱਟਅਪ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰੇਗੀ ਤਾਂ ਜੋ ਤੁਸੀਂ Ollama ਦੀ ਵਰਤੋਂ ਕਰਕੇ Phi-3 ਮਾਡਲ ਚਲਾ ਸਕੋ। ਤੁਸੀਂ ਮਾਡਲ ਨੂੰ ਕਈ ਤਰੀਕਿਆਂ ਨਾਲ ਚਲਾ ਸਕਦੇ ਹੋ, ਜਿਵੇਂ ਕਿ GitHub Codespaces, VS Code Dev Containers, ਜਾਂ ਆਪਣੇ ਸਥਾਨਕ ਵਾਤਾਵਰਣ ਵਿੱਚ।

## ਵਾਤਾਵਰਣ ਸੈੱਟਅਪ

### GitHub Codespaces

ਤੁਸੀਂ GitHub Codespaces ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇਸ ਟੈਮਪਲੇਟ ਨੂੰ ਵਰਚੁਅਲ ਤੌਰ 'ਤੇ ਚਲਾ ਸਕਦੇ ਹੋ। ਬਟਨ ਤੁਹਾਡੇ ਬ੍ਰਾਊਜ਼ਰ ਵਿੱਚ ਵੈੱਬ-ਆਧਾਰਿਤ VS Code ਇੰਸਟੈਂਸ ਖੋਲ੍ਹੇਗਾ:

1. ਟੈਮਪਲੇਟ ਖੋਲ੍ਹੋ (ਇਸ ਵਿੱਚ ਕੁਝ ਮਿੰਟ ਲੱਗ ਸਕਦੇ ਹਨ):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. ਇੱਕ ਟਰਮੀਨਲ ਵਿੰਡੋ ਖੋਲ੍ਹੋ

### VS Code Dev Containers

⚠️ ਇਹ ਵਿਕਲਪ ਸਿਰਫ਼ ਉਸ ਵੇਲੇ ਕੰਮ ਕਰੇਗਾ ਜਦੋਂ ਤੁਹਾਡੇ Docker Desktop ਨੂੰ ਘੱਟੋ-ਘੱਟ 16 GB RAM ਦਿੱਤੀ ਗਈ ਹੋਵੇ। ਜੇ ਤੁਹਾਡੇ ਕੋਲ 16 GB ਤੋਂ ਘੱਟ RAM ਹੈ, ਤਾਂ ਤੁਸੀਂ [GitHub Codespaces ਵਿਕਲਪ](../../../../../md/01.Introduction/01) ਜਾਂ [ਸਥਾਨਕ ਤੌਰ 'ਤੇ ਸੈੱਟਅਪ](../../../../../md/01.Introduction/01) ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰ ਸਕਦੇ ਹੋ।

ਇੱਕ ਸੰਬੰਧਿਤ ਵਿਕਲਪ VS Code Dev Containers ਹੈ, ਜੋ ਤੁਹਾਡੇ ਸਥਾਨਕ VS Code ਵਿੱਚ ਪ੍ਰੋਜੈਕਟ ਨੂੰ [Dev Containers ਐਕਸਟੈਂਸ਼ਨ](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) ਦੀ ਵਰਤੋਂ ਨਾਲ ਖੋਲ੍ਹੇਗਾ:

1. Docker Desktop ਸ਼ੁਰੂ ਕਰੋ (ਜੇ ਇੰਸਟਾਲ ਨਹੀਂ ਕੀਤਾ ਤਾਂ ਇੰਸਟਾਲ ਕਰੋ)
2. ਪ੍ਰੋਜੈਕਟ ਖੋਲ੍ਹੋ:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. ਜਦੋਂ VS Code ਵਿੰਡੋ ਖੁਲੇ ਅਤੇ ਪ੍ਰੋਜੈਕਟ ਫਾਈਲਾਂ ਦਿਖਾਈ ਦੇਣ ਲੱਗਣ (ਇਸ ਵਿੱਚ ਕੁਝ ਮਿੰਟ ਲੱਗ ਸਕਦੇ ਹਨ), ਇੱਕ ਟਰਮੀਨਲ ਵਿੰਡੋ ਖੋਲ੍ਹੋ।
4. [ਡਿਪਲੋਇਮੈਂਟ ਕਦਮ](../../../../../md/01.Introduction/01) ਨਾਲ ਜਾਰੀ ਰੱਖੋ

### ਸਥਾਨਕ ਵਾਤਾਵਰਣ

1. ਇਹ ਯਕੀਨੀ ਬਣਾਓ ਕਿ ਹੇਠਾਂ ਦਿੱਤੇ ਟੂਲ ਇੰਸਟਾਲ ਹਨ:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## ਮਾਡਲ ਦੀ ਜਾਂਚ ਕਰੋ

1. Ollama ਨੂੰ ਕਹੋ ਕਿ phi3:mini ਮਾਡਲ ਡਾਊਨਲੋਡ ਅਤੇ ਚਲਾਓ:

    ```shell
    ollama run phi3:mini
    ```

    ਮਾਡਲ ਡਾਊਨਲੋਡ ਕਰਨ ਵਿੱਚ ਕੁਝ ਮਿੰਟ ਲੱਗਣਗੇ।

2. ਜਦੋਂ ਤੁਸੀਂ ਆਉਟਪੁੱਟ ਵਿੱਚ "success" ਵੇਖੋ, ਤਾਂ ਤੁਸੀਂ ਪ੍ਰਾਂਪਟ ਤੋਂ ਉਸ ਮਾਡਲ ਨੂੰ ਸੁਨੇਹਾ ਭੇਜ ਸਕਦੇ ਹੋ।

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. ਕੁਝ ਸਕਿੰਟਾਂ ਬਾਅਦ, ਤੁਹਾਨੂੰ ਮਾਡਲ ਵੱਲੋਂ ਜਵਾਬ ਦਾ ਸਟ੍ਰੀਮ ਮਿਲਣਾ ਸ਼ੁਰੂ ਹੋ ਜਾਵੇਗਾ।

4. ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨਾਲ ਵਰਤੇ ਜਾਂਦੇ ਵੱਖ-ਵੱਖ ਤਰੀਕਿਆਂ ਬਾਰੇ ਜਾਣਨ ਲਈ, Python ਨੋਟਬੁੱਕ [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) ਖੋਲ੍ਹੋ ਅਤੇ ਹਰ ਸੈੱਲ ਚਲਾਓ। ਜੇ ਤੁਸੀਂ 'phi3:mini' ਤੋਂ ਵੱਖਰਾ ਮਾਡਲ ਵਰਤਿਆ ਹੈ, ਤਾਂ ਪਹਿਲੇ ਸੈੱਲ ਵਿੱਚ `MODEL_NAME` ਬਦਲੋ।

5. Python ਤੋਂ phi3:mini ਮਾਡਲ ਨਾਲ ਗੱਲਬਾਤ ਕਰਨ ਲਈ, Python ਫਾਈਲ [chat.py](../../../../../code/01.Introduce/chat.py) ਖੋਲ੍ਹੋ ਅਤੇ ਚਲਾਓ। ਤੁਸੀਂ ਜਰੂਰਤ ਮੁਤਾਬਕ ਫਾਈਲ ਦੇ ਸਿਰਲੇਖ ਵਿੱਚ `MODEL_NAME` ਬਦਲ ਸਕਦੇ ਹੋ, ਅਤੇ ਸਿਸਟਮ ਸੁਨੇਹਾ ਜਾਂ few-shot ਉਦਾਹਰਣਾਂ ਵੀ ਜੋੜ ਸਕਦੇ ਹੋ।

**ਅਸਵੀਕਾਰੋਪਣ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦਿਤ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਰੱਖੋ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸਮਰਥਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਆਪਣੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਪ੍ਰਮਾਣਿਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਅਸੀਂ ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਉਤਪੰਨ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।