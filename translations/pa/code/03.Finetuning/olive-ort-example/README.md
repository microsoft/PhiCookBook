<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4164123a700fecd535d850f09506d72a",
  "translation_date": "2025-05-09T04:31:27+00:00",
  "source_file": "code/03.Finetuning/olive-ort-example/README.md",
  "language_code": "pa"
}
-->
# Olive ‡®®‡®æ‡®≤ Phi3 ‡®®‡©Ç‡©∞ Fine-tune ‡®ï‡®∞‡©ã

‡®á‡®∏ ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®µ‡®ø‡©±‡®ö ‡®§‡©Å‡®∏‡©Ä‡®Ç Olive ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á:

1. ‡®á‡©±‡®ï LoRA adapter ‡®®‡©Ç‡©∞ fine-tune ‡®ï‡®∞‡©ã ‡®ú‡©ã phrases ‡®®‡©Ç‡©∞ Sad, Joy, Fear, Surprise ‡®µ‡®ø‡©±‡®ö classify ‡®ï‡®∞‡©á‡•§
1. adapter ‡®¶‡©á weights ‡®®‡©Ç‡©∞ base model ‡®µ‡®ø‡©±‡®ö merge ‡®ï‡®∞‡©ã‡•§
1. ‡®Æ‡®æ‡®°‡®≤ ‡®®‡©Ç‡©∞ optimize ‡®Ö‡®§‡©á quantize ‡®ï‡®∞‡©ã `int4` ‡®µ‡®ø‡©±‡®ö‡•§

‡®Ö‡®∏‡©Ä‡®Ç ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ONNX Runtime (ORT) Generate API ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á fine-tuned ‡®Æ‡®æ‡®°‡®≤ ‡®®‡©Ç‡©∞ inference ‡®ï‡®∞‡®® ‡®¶‡®æ ‡®§‡®∞‡©Ä‡®ï‡®æ ‡®µ‡©Ä ‡®¶‡®ø‡®ñ‡®æ‡®µ‡®æ‡®Ç‡®ó‡©á‡•§

> **‚ö†Ô∏è Fine-tuning ‡®≤‡®à, ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ ‡®á‡©±‡®ï suitable GPU ‡®π‡©ã‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à - ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®µ‡®ú‡©ã‡®Ç, A10, V100, A100‡•§**

## üíæ Install

‡®®‡®µ‡®æ‡®Ç Python virtual environment ‡®¨‡®£‡®æ‡®ì (‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®µ‡®ú‡©ã‡®Ç, `conda` ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

‡®´‡®ø‡®∞, Olive ‡®Ö‡®§‡©á fine-tuning workflow ‡®≤‡®à dependencies install ‡®ï‡®∞‡©ã:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Olive ‡®®‡®æ‡®≤ Phi3 ‡®®‡©Ç‡©∞ Fine-tune ‡®ï‡®∞‡©ã
[Olive configuration file](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) ‡®µ‡®ø‡©±‡®ö ‡®á‡©±‡®ï *workflow* ‡®π‡©à ‡®ú‡®ø‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®á‡®π *passes* ‡®π‡®®:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

‡®â‡©±‡®ö ‡®∏‡®§‡®∞ '‡®§‡©á, ‡®á‡®π workflow ‡®á‡®π ‡®ï‡®∞‡©á‡®ó‡®æ:

1. Phi3 ‡®®‡©Ç‡©∞ fine-tune ‡®ï‡®∞‡©á‡®ó‡®æ (150 steps ‡®≤‡®à, ‡®ú‡®ø‡®∏‡®®‡©Ç‡©∞ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¨‡®¶‡®≤ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã) [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) ‡®°‡©á‡®ü‡®æ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á‡•§
1. LoRA adapter ‡®¶‡©á weights ‡®®‡©Ç‡©∞ base model ‡®µ‡®ø‡©±‡®ö merge ‡®ï‡®∞‡©á‡®ó‡®æ‡•§ ‡®á‡®∏ ‡®®‡®æ‡®≤ ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ ONNX ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®á‡©±‡®ï single ‡®Æ‡®æ‡®°‡®≤ artifact ‡®π‡©ã‡®µ‡©á‡®ó‡®æ‡•§
1. Model Builder ‡®Æ‡®æ‡®°‡®≤ ‡®®‡©Ç‡©∞ ONNX runtime ‡®≤‡®à optimize ‡®Ö‡®§‡©á `int4` ‡®µ‡®ø‡©±‡®ö quantize ‡®ï‡®∞‡©á‡®ó‡®æ‡•§

Workflow ‡®ö‡®≤‡®æ‡®â‡®£ ‡®≤‡®à, ‡®á‡®π ‡®ö‡®≤‡®æ‡®ì:

```bash
olive run --config phrase-classification.json
```

‡®ú‡®¶‡©ã‡®Ç Olive ‡®Æ‡©Å‡®ï‡©∞‡®Æ‡®≤ ‡®π‡©ã ‡®ú‡®æ‡®µ‡©á, ‡®§‡®æ‡®Ç ‡®§‡©Å‡®π‡®æ‡®°‡®æ optimized `int4` fine-tuned Phi3 ‡®Æ‡®æ‡®°‡®≤ ‡®á‡®∏ ‡®•‡®æ‡®Ç ‡®â‡®™‡®≤‡®¨‡®ß ‡®π‡©ã‡®µ‡©á‡®ó‡®æ: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Fine-tuned Phi3 ‡®®‡©Ç‡©∞ ‡®Ü‡®™‡®£‡©á ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã

‡®ê‡®™ ‡®ö‡®≤‡®æ‡®â‡®£ ‡®≤‡®à:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

‡®á‡®∏ ‡®¶‡®æ ‡®ú‡®µ‡®æ‡®¨ phrase ‡®¶‡©Ä single word classification ‡®π‡©ã‡®µ‡©á‡®ó‡©Ä (Sad/Joy/Fear/Surprise)‡•§

**‡®°‡®ø‡®∏‡®ï‡®≤‡©á‡®Æ‡®∞**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®ø‡®§ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®ú‡®¶‡©ã‡®Ç ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä‡®Ö‡®§ ‡®≤‡®à ‡®ï‡©ã‡®∏‡®º‡®ø‡®∏‡®º ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®µ‡®ø‡©±‡®ö ‡®∞‡©±‡®ñ‡©ã ‡®ï‡®ø ‡®Ü‡®ü‡©ã‡®Æ‡©à‡®ü‡®ø‡®ï ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®£‡®∏‡®π‡©Ä‡®§‡©Ä‡®Ü‡®Ç ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®Æ‡©Ç‡®≤ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®Ü‡®™‡®£‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®™‡©ç‡®∞‡®Æ‡®æ‡®£‡®ø‡®ï ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®ø‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©á ‡®á‡®∏‡®§‡©á‡®Æ‡®æ‡®≤ ‡®§‡©ã‡®Ç ‡®â‡©±‡®™‡®ú‡®£ ‡®µ‡®æ‡®≤‡©Ä‡®Ü‡®Ç ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§‡®´‡®π‡®ø‡®Æ‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®≠‡©ç‡®∞‡®Æ‡®æ‡®Ç ‡®≤‡®à ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§