{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਇੰਟਰਐਕਟਿਵ ਫਾਈ 3 ਮਿਨੀ 4K ਇੰਸਟਰਕਟ ਚੈਟਬੋਟ ਵਿਥ ਵਿਸਪਰ\n",
    "\n",
    "### ਜਾਣ ਪਛਾਣ:\n",
    "ਇੰਟਰਐਕਟਿਵ ਫਾਈ 3 ਮਿਨੀ 4K ਇੰਸਟਰਕਟ ਚੈਟਬੋਟ ਇੱਕ ਸੰਦ ਹੈ ਜੋ ਵਰਤੋਂਕਾਰਾਂ ਨੂੰ ਮਾਈਕਰੋਸਾਫਟ ਫਾਈ 3 ਮਿਨੀ 4K ਇੰਸਟਰਕਟ ਡੈਮੋ ਨਾਲ ਟੈਕਸਟ ਜਾਂ ਆਡੀਓ ਇਨਪੁਟ ਰਾਹੀਂ ਸੰਚਾਰ ਕਰਨ ਦੀ ਸਹੂਲਤ ਦਿੰਦਾ ਹੈ। ਇਹ ਚੈਟਬੋਟ ਅਨੇਕ ਤਰ੍ਹਾਂ ਦੇ ਕੰਮਾਂ ਲਈ ਵਰਤਿਆ ਜਾ ਸਕਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਅਨੁਵਾਦ, ਮੌਸਮ ਦੀ ਜਾਣਕਾਰੀ, ਅਤੇ ਆਮ ਜਾਣਕਾਰੀ ਇਕੱਠੀ ਕਰਨਾ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Atl_WEmtR0Yd"
   },
   "outputs": [],
   "source": [
    "#Install required Python Packages\n",
    "!pip install accelerate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install flash-attn --no-build-isolation', env={'FLASH_ATTENTION_SKIP_CUDA_BUILD': \"TRUE\"}, shell=True\n",
    "!pip install transformers\n",
    "!pip install wheel\n",
    "!pip install gradio\n",
    "!pip install pydub==0.25.1\n",
    "!pip install edge-tts\n",
    "!pip install openai-whisper==20231117\n",
    "!pip install ffmpeg==1.4\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if Cuda support is available \n",
    "# Output True = Cuda\n",
    "# Output False = No Cuda (installing Cuda will be required to run the model on GPU)\n",
    "import os \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKAUp20H4ZXl"
   },
   "source": [
    "ਹੱਗਿੰਗਫੇਸ ਐਕਸੈਸ ਟੋਕਨ ਬਣਾਓ\n",
    "\n",
    "ਨਵਾਂ ਟੋਕਨ ਬਣਾਓ  \n",
    "ਨਵਾਂ ਨਾਮ ਦਿਓ  \n",
    "ਲਿਖਣ ਦੀਆਂ ਅਧਿਕਾਰਾਂ ਚੁਣੋ  \n",
    "ਟੋਕਨ ਕਾਪੀ ਕਰੋ ਅਤੇ ਇਸਨੂੰ ਸੁਰੱਖਿਅਤ ਜਗ੍ਹਾ 'ਤੇ ਸੰਭਾਲੋ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਹੇਠਾਂ ਦਿੱਤੇ ਕੋਡ ਵਿੱਚ Python ਦੋ ਮੁੱਖ ਕੰਮ ਕਰਦਾ ਹੈ: `os` ਮੋਡਿਊਲ ਨੂੰ ਇੰਪੋਰਟ ਕਰਨਾ ਅਤੇ ਇੱਕ ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ ਸੈਟ ਕਰਨਾ।\n",
    "\n",
    "1. `os` ਮੋਡਿਊਲ ਨੂੰ ਇੰਪੋਰਟ ਕਰਨਾ:\n",
    "   - Python ਵਿੱਚ `os` ਮੋਡਿਊਲ ਸਿਸਟਮ ਨਾਲ ਇੰਟਰਐਕਟ ਕਰਨ ਦਾ ਇੱਕ ਤਰੀਕਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ। ਇਹ ਤੁਹਾਨੂੰ ਵੱਖ-ਵੱਖ ਸਿਸਟਮ-ਸੰਬੰਧੀ ਕੰਮ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲਾਂ ਤੱਕ ਪਹੁੰਚਣਾ, ਫਾਈਲਾਂ ਅਤੇ ਡਾਇਰੈਕਟਰੀਆਂ ਨਾਲ ਕੰਮ ਕਰਨਾ ਆਦਿ।\n",
    "   - ਇਸ ਕੋਡ ਵਿੱਚ, `os` ਮੋਡਿਊਲ ਨੂੰ `import` ਸਟੇਟਮੈਂਟ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੰਪੋਰਟ ਕੀਤਾ ਗਿਆ ਹੈ। ਇਹ ਸਟੇਟਮੈਂਟ `os` ਮੋਡਿਊਲ ਦੀ ਫੰਕਸ਼ਨਾਲਿਟੀ ਨੂੰ ਮੌਜੂਦਾ Python ਸਕ੍ਰਿਪਟ ਵਿੱਚ ਵਰਤਣ ਲਈ ਉਪਲਬਧ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "2. ਇੱਕ ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ ਸੈਟ ਕਰਨਾ:\n",
    "   - ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ ਇੱਕ ਮੁੱਲ ਹੁੰਦਾ ਹੈ ਜਿਸਨੂੰ ਸਿਸਟਮ 'ਤੇ ਚੱਲ ਰਹੇ ਪ੍ਰੋਗਰਾਮਾਂ ਦੁਆਰਾ ਪਹੁੰਚਿਆ ਜਾ ਸਕਦਾ ਹੈ। ਇਹ ਕਨਫਿਗਰੇਸ਼ਨ ਸੈਟਿੰਗਾਂ ਜਾਂ ਹੋਰ ਜਾਣਕਾਰੀ ਸਟੋਰ ਕਰਨ ਦਾ ਇੱਕ ਤਰੀਕਾ ਹੈ ਜੋ ਕਈ ਪ੍ਰੋਗਰਾਮਾਂ ਦੁਆਰਾ ਵਰਤੀ ਜਾ ਸਕਦੀ ਹੈ।\n",
    "   - ਇਸ ਕੋਡ ਵਿੱਚ, ਇੱਕ ਨਵਾਂ ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ `os.environ` ਡਿਕਸ਼ਨਰੀ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਸੈਟ ਕੀਤਾ ਜਾ ਰਿਹਾ ਹੈ। ਡਿਕਸ਼ਨਰੀ ਦੀ ਕੁੰਜੀ `'HF_TOKEN'` ਹੈ, ਅਤੇ ਮੁੱਲ `HUGGINGFACE_TOKEN` ਵੈਰੀਏਬਲ ਤੋਂ ਲਿਆ ਗਿਆ ਹੈ।\n",
    "   - `HUGGINGFACE_TOKEN` ਵੈਰੀਏਬਲ ਇਸ ਕੋਡ ਸਨਿੱਪਟ ਦੇ ਥੋੜ੍ਹਾ ਉੱਪਰ ਪਰिभਾਸ਼ਿਤ ਕੀਤਾ ਗਿਆ ਹੈ, ਅਤੇ ਇਸਨੂੰ `#@param` ਸਿੰਟੈਕਸ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਸਟ੍ਰਿੰਗ ਮੁੱਲ `\"hf_**************\"` ਦਿੱਤਾ ਗਿਆ ਹੈ। ਇਹ ਸਿੰਟੈਕਸ ਅਕਸਰ Jupyter ਨੋਟਬੁੱਕ ਵਿੱਚ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ ਤਾਂ ਜੋ ਯੂਜ਼ਰ ਇਨਪੁਟ ਅਤੇ ਪੈਰਾਮੀਟਰ ਕਨਫਿਗਰੇਸ਼ਨ ਨੂੰ ਸਿੱਧੇ ਨੋਟਬੁੱਕ ਇੰਟਰਫੇਸ ਵਿੱਚ ਸਹੂਲਤ ਮਿਲੇ।\n",
    "   - `'HF_TOKEN'` ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ ਸੈਟ ਕਰਨ ਦੁਆਰਾ, ਇਸਨੂੰ ਪ੍ਰੋਗਰਾਮ ਦੇ ਹੋਰ ਹਿੱਸਿਆਂ ਜਾਂ ਉਸੇ ਸਿਸਟਮ 'ਤੇ ਚੱਲ ਰਹੇ ਹੋਰ ਪ੍ਰੋਗਰਾਮਾਂ ਦੁਆਰਾ ਪਹੁੰਚਿਆ ਜਾ ਸਕਦਾ ਹੈ।\n",
    "\n",
    "ਕੁੱਲ ਮਿਲਾ ਕੇ, ਇਹ ਕੋਡ `os` ਮੋਡਿਊਲ ਨੂੰ ਇੰਪੋਰਟ ਕਰਦਾ ਹੈ ਅਤੇ `'HF_TOKEN'` ਨਾਮਕ ਇੱਕ ਐਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ ਸੈਟ ਕਰਦਾ ਹੈ ਜਿਸਦਾ ਮੁੱਲ `HUGGINGFACE_TOKEN` ਵੈਰੀਏਬਲ ਵਿੱਚ ਦਿੱਤਾ ਗਿਆ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N5r2ikbwR68c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set the Hugging Face Token from \n",
    "# add the Hugging Face Token to the environment variables\n",
    "HUGGINGFACE_TOKEN = \"Enter Hugging Face Key\" #@param {type:\"string\"}\n",
    "os.environ['HF_TOKEN']HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਇਹ ਕੋਡ ਸਨਿੱਪਟ ਇੱਕ ਫੰਕਸ਼ਨ clear_output ਨੂੰ ਪਰਿਭਾਸ਼ਿਤ ਕਰਦਾ ਹੈ ਜੋ Jupyter Notebook ਜਾਂ IPython ਵਿੱਚ ਮੌਜੂਦਾ ਸੈੱਲ ਦੇ ਆਉਟਪੁੱਟ ਨੂੰ ਸਾਫ਼ ਕਰਨ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ। ਆਓ ਕੋਡ ਨੂੰ ਵੱਖਰਾ ਕਰਕੇ ਸਮਝਦੇ ਹਾਂ ਅਤੇ ਇਸਦੀ ਕਾਰਗੁਜ਼ਾਰੀ ਨੂੰ ਸਮਝਦੇ ਹਾਂ:\n",
    "\n",
    "ਫੰਕਸ਼ਨ clear_output ਇੱਕ ਪੈਰਾਮੀਟਰ ਲੈਂਦਾ ਹੈ ਜਿਸਨੂੰ wait ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਜੋ ਕਿ ਇੱਕ boolean ਮੁੱਲ ਹੈ। ਡਿਫਾਲਟ ਰੂਪ ਵਿੱਚ, wait ਨੂੰ False 'ਤੇ ਸੈਟ ਕੀਤਾ ਜਾਂਦਾ ਹੈ। ਇਹ ਪੈਰਾਮੀਟਰ ਇਹ ਨਿਰਧਾਰਤ ਕਰਦਾ ਹੈ ਕਿ ਕੀ ਫੰਕਸ਼ਨ ਨੂੰ ਮੌਜੂਦਾ ਆਉਟਪੁੱਟ ਨੂੰ ਸਾਫ਼ ਕਰਨ ਤੋਂ ਪਹਿਲਾਂ ਨਵਾਂ ਆਉਟਪੁੱਟ ਉਪਲਬਧ ਹੋਣ ਦੀ ਉਡੀਕ ਕਰਨੀ ਚਾਹੀਦੀ ਹੈ।\n",
    "\n",
    "ਫੰਕਸ਼ਨ ਖੁਦ ਮੌਜੂਦਾ ਸੈੱਲ ਦੇ ਆਉਟਪੁੱਟ ਨੂੰ ਸਾਫ਼ ਕਰਨ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ। Jupyter Notebook ਜਾਂ IPython ਵਿੱਚ, ਜਦੋਂ ਇੱਕ ਸੈੱਲ ਆਉਟਪੁੱਟ ਪੈਦਾ ਕਰਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਪ੍ਰਿੰਟ ਕੀਤਾ ਟੈਕਸਟ ਜਾਂ ਗ੍ਰਾਫਿਕਲ ਪਲਾਟ, ਉਹ ਆਉਟਪੁੱਟ ਸੈੱਲ ਦੇ ਹੇਠਾਂ ਦਿਖਾਈ ਦਿੰਦਾ ਹੈ। ਫੰਕਸ਼ਨ clear_output ਤੁਹਾਨੂੰ ਉਸ ਆਉਟਪੁੱਟ ਨੂੰ ਸਾਫ਼ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ।\n",
    "\n",
    "ਫੰਕਸ਼ਨ ਦੀ ਕਾਰਗੁਜ਼ਾਰੀ ਕੋਡ ਸਨਿੱਪਟ ਵਿੱਚ ਪ੍ਰਦਾਨ ਨਹੀਂ ਕੀਤੀ ਗਈ ਹੈ, ਜਿਵੇਂ ਕਿ ਤਿੰਨ ਬਿੰਦੂ (...). ਤਿੰਨ ਬਿੰਦੂ ਅਸਲ ਕੋਡ ਲਈ ਇੱਕ ਪਲੇਸਹੋਲਡਰ ਨੂੰ ਦਰਸਾਉਂਦੇ ਹਨ ਜੋ ਆਉਟਪੁੱਟ ਨੂੰ ਸਾਫ਼ ਕਰਨ ਦੀ ਕਾਰਵਾਈ ਕਰਦਾ ਹੈ। ਫੰਕਸ਼ਨ ਦੀ ਕਾਰਗੁਜ਼ਾਰੀ ਵਿੱਚ Jupyter Notebook ਜਾਂ IPython API ਨਾਲ ਸੰਚਾਰ ਕਰਨਾ ਸ਼ਾਮਲ ਹੋ ਸਕਦਾ ਹੈ ਤਾਂ ਜੋ ਸੈੱਲ ਤੋਂ ਮੌਜੂਦਾ ਆਉਟਪੁੱਟ ਨੂੰ ਹਟਾਇਆ ਜਾ ਸਕੇ।\n",
    "\n",
    "ਕੁੱਲ ਮਿਲਾ ਕੇ, ਇਹ ਫੰਕਸ਼ਨ Jupyter Notebook ਜਾਂ IPython ਵਿੱਚ ਮੌਜੂਦਾ ਸੈੱਲ ਦੇ ਆਉਟਪੁੱਟ ਨੂੰ ਸਾਫ਼ ਕਰਨ ਦਾ ਇੱਕ ਸੁਵਿਧਾਜਨਕ ਤਰੀਕਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ, ਜਿਸ ਨਾਲ ਇੰਟਰਐਕਟਿਵ ਕੋਡਿੰਗ ਸੈਸ਼ਨ ਦੌਰਾਨ ਦਿਖਾਈ ਜਾ ਰਹੇ ਆਉਟਪੁੱਟ ਨੂੰ ਪ੍ਰਬੰਧਿਤ ਅਤੇ ਅਪਡੇਟ ਕਰਨਾ ਆਸਾਨ ਬਣ ਜਾਂਦਾ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nmXm0dxuRinA"
   },
   "outputs": [],
   "source": [
    "# Download Phi-3-mini-4k-instruct model & Whisper Tiny\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#whisper for speech to text()\n",
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਐਜ ਟੀਟੀਐਸ ਸੇਵਾ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਟੈਕਸਟ-ਟੂ-ਸਪੀਚ (TTS) ਕਰਨ ਲਈ ਸਬੰਧਤ ਫੰਕਸ਼ਨ ਦੀਆਂ ਕਾਰਜਵਾਹੀਆਂ ਨੂੰ ਇੱਕ-ਇੱਕ ਕਰਕੇ ਸਮਝਦੇ ਹਾਂ:\n",
    "\n",
    "1. `calculate_rate_string(input_value)`: ਇਹ ਫੰਕਸ਼ਨ ਇੱਕ ਇਨਪੁਟ ਮੁੱਲ ਲੈਂਦਾ ਹੈ ਅਤੇ TTS ਵਾਇਸ ਲਈ ਰੇਟ ਸਟ੍ਰਿੰਗ ਦੀ ਗਣਨਾ ਕਰਦਾ ਹੈ। ਇਨਪੁਟ ਮੁੱਲ ਸਪੀਚ ਦੀ ਗਤੀ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ, ਜਿੱਥੇ 1 ਸਧਾਰਨ ਗਤੀ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ। ਫੰਕਸ਼ਨ 1 ਨੂੰ ਇਨਪੁਟ ਮੁੱਲ ਤੋਂ ਘਟਾਉਂਦਾ ਹੈ, ਇਸਨੂੰ 100 ਨਾਲ ਗੁਣਾ ਕਰਦਾ ਹੈ, ਅਤੇ ਫਿਰ ਇਹ ਨਿਰਧਾਰਤ ਕਰਦਾ ਹੈ ਕਿ ਇਨਪੁਟ ਮੁੱਲ 1 ਤੋਂ ਵੱਧ ਜਾਂ ਬਰਾਬਰ ਹੈ ਕਿ ਨਹੀਂ। ਫੰਕਸ਼ਨ ਰੇਟ ਸਟ੍ਰਿੰਗ `{sign}{rate}` ਦੇ ਫਾਰਮੈਟ ਵਿੱਚ ਵਾਪਸ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "2. `make_chunks(input_text, language)`: ਇਹ ਫੰਕਸ਼ਨ ਇਨਪੁਟ ਟੈਕਸਟ ਅਤੇ ਭਾਸ਼ਾ ਨੂੰ ਪੈਰਾਮੀਟਰ ਵਜੋਂ ਲੈਂਦਾ ਹੈ। ਇਹ ਟੈਕਸਟ ਨੂੰ ਭਾਸ਼ਾ-ਵਿਸ਼ੇਸ਼ ਨਿਯਮਾਂ ਦੇ ਅਧਾਰ 'ਤੇ ਚੰਕਸ ਵਿੱਚ ਵੰਡਦਾ ਹੈ। ਇਸ ਕਾਰਜਵਾਹੀ ਵਿੱਚ, ਜੇਕਰ ਭਾਸ਼ਾ \"English\" ਹੈ, ਤਾਂ ਫੰਕਸ਼ਨ ਟੈਕਸਟ ਨੂੰ ਹਰ ਪੀਰੀਅਡ (\".\") 'ਤੇ ਵੰਡਦਾ ਹੈ ਅਤੇ ਕੋਈ ਵੀ ਅਗਲੇ ਜਾਂ ਪਿਛਲੇ ਖਾਲੀ ਸਥਾਨ ਨੂੰ ਹਟਾ ਦਿੰਦਾ ਹੈ। ਫਿਰ ਇਹ ਹਰ ਚੰਕ ਵਿੱਚ ਪੀਰੀਅਡ ਜੋੜਦਾ ਹੈ ਅਤੇ ਫਿਲਟਰ ਕੀਤੇ ਚੰਕਸ ਦੀ ਸੂਚੀ ਵਾਪਸ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "3. `tts_file_name(text)`: ਇਹ ਫੰਕਸ਼ਨ TTS ਆਡੀਓ ਫਾਈਲ ਲਈ ਇੱਕ ਫਾਈਲ ਨਾਮ ਬਣਾਉਂਦਾ ਹੈ। ਇਹ ਟੈਕਸਟ 'ਤੇ ਕਈ ਤਬਦੀਲੀਆਂ ਕਰਦਾ ਹੈ: ਪਿਛਲੇ ਪੀਰੀਅਡ ਨੂੰ ਹਟਾਉਣਾ (ਜੇਕਰ ਮੌਜੂਦ ਹੋਵੇ), ਟੈਕਸਟ ਨੂੰ ਛੋਟੇ ਅੱਖਰਾਂ ਵਿੱਚ ਬਦਲਣਾ, ਅਗਲੇ ਅਤੇ ਪਿਛਲੇ ਖਾਲੀ ਸਥਾਨ ਨੂੰ ਹਟਾਉਣਾ, ਅਤੇ ਖਾਲੀ ਸਥਾਨਾਂ ਨੂੰ ਅੰਡਰਸਕੋਰ ਨਾਲ ਬਦਲਣਾ। ਫਿਰ ਇਹ ਟੈਕਸਟ ਨੂੰ ਵੱਧ ਤੋਂ ਵੱਧ 25 ਅੱਖਰਾਂ ਤੱਕ ਕੱਟਦਾ ਹੈ (ਜੇਕਰ ਲੰਬਾ ਹੋਵੇ) ਜਾਂ ਪੂਰਾ ਟੈਕਸਟ ਵਰਤਦਾ ਹੈ ਜੇਕਰ ਇਹ ਖਾਲੀ ਹੋਵੇ। ਆਖਿਰ ਵਿੱਚ, ਇਹ [`uuid`] ਮੋਡੀਊਲ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਰੈਂਡਮ ਸਟ੍ਰਿੰਗ ਬਣਾਉਂਦਾ ਹੈ ਅਤੇ ਇਸਨੂੰ ਕੱਟੇ ਟੈਕਸਟ ਨਾਲ ਜੋੜਦਾ ਹੈ, `/content/edge_tts_voice/{truncated_text}_{random_string}.mp3` ਦੇ ਫਾਰਮੈਟ ਵਿੱਚ ਫਾਈਲ ਨਾਮ ਬਣਾਉਂਦਾ ਹੈ।\n",
    "\n",
    "4. `merge_audio_files(audio_paths, output_path)`: ਇਹ ਫੰਕਸ਼ਨ ਕਈ ਆਡੀਓ ਫਾਈਲਾਂ ਨੂੰ ਇੱਕ ਆਡੀਓ ਫਾਈਲ ਵਿੱਚ ਜੋੜਦਾ ਹੈ। ਇਹ ਆਡੀਓ ਫਾਈਲ ਪਾਥਾਂ ਦੀ ਸੂਚੀ ਅਤੇ ਇੱਕ ਆਉਟਪੁੱਟ ਪਾਥ ਨੂੰ ਪੈਰਾਮੀਟਰ ਵਜੋਂ ਲੈਂਦਾ ਹੈ। ਫੰਕਸ਼ਨ ਇੱਕ ਖਾਲੀ `AudioSegment` ਆਬਜੈਕਟ [`merged_audio`] ਸ਼ੁਰੂ ਕਰਦਾ ਹੈ। ਫਿਰ ਇਹ ਹਰ ਆਡੀਓ ਫਾਈਲ ਪਾਥ ਦੇ ਰਾਹੀਂ ਦੌੜਦਾ ਹੈ, `pydub` ਲਾਇਬ੍ਰੇਰੀ ਦੇ `AudioSegment.from_file()` ਮੈਥਡ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਆਡੀਓ ਫਾਈਲ ਨੂੰ ਲੋਡ ਕਰਦਾ ਹੈ, ਅਤੇ ਮੌਜੂਦਾ ਆਡੀਓ ਫਾਈਲ ਨੂੰ [`merged_audio`] ਆਬਜੈਕਟ ਵਿੱਚ ਜੋੜਦਾ ਹੈ। ਆਖਿਰ ਵਿੱਚ, ਇਹ ਜੋੜੀ ਗਈ ਆਡੀਓ ਨੂੰ MP3 ਫਾਰਮੈਟ ਵਿੱਚ ਨਿਰਧਾਰਤ ਆਉਟਪੁੱਟ ਪਾਥ 'ਤੇ ਐਕਸਪੋਰਟ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "5. `edge_free_tts(chunks_list, speed, voice_name, save_path)`: ਇਹ ਫੰਕਸ਼ਨ ਐਜ ਟੀਟੀਐਸ ਸੇਵਾ ਦੀ ਵਰਤੋਂ ਕਰਕੇ TTS ਕਾਰਜਵਾਹੀ ਕਰਦਾ ਹੈ। ਇਹ ਟੈਕਸਟ ਚੰਕਸ ਦੀ ਸੂਚੀ, ਸਪੀਚ ਦੀ ਗਤੀ, ਵਾਇਸ ਨਾਮ, ਅਤੇ ਸੇਵ ਪਾਥ ਨੂੰ ਪੈਰਾਮੀਟਰ ਵਜੋਂ ਲੈਂਦਾ ਹੈ। ਜੇਕਰ ਚੰਕਸ ਦੀ ਗਿਣਤੀ 1 ਤੋਂ ਵੱਧ ਹੈ, ਤਾਂ ਫੰਕਸ਼ਨ ਵਿਅਕਤੀਗਤ ਚੰਕ ਆਡੀਓ ਫਾਈਲਾਂ ਨੂੰ ਸਟੋਰ ਕਰਨ ਲਈ ਇੱਕ ਡਾਇਰੈਕਟਰੀ ਬਣਾਉਂਦਾ ਹੈ। ਫਿਰ ਇਹ ਹਰ ਚੰਕ ਦੇ ਰਾਹੀਂ ਦੌੜਦਾ ਹੈ, `calculate_rate_string()` ਫੰਕਸ਼ਨ, ਵਾਇਸ ਨਾਮ, ਅਤੇ ਚੰਕ ਟੈਕਸਟ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਐਜ ਟੀਟੀਐਸ ਕਮਾਂਡ ਬਣਾਉਂਦਾ ਹੈ, ਅਤੇ `os.system()` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਕਮਾਂਡ ਨੂੰ ਐਗਜ਼ਿਕਿਊਟ ਕਰਦਾ ਹੈ। ਜੇਕਰ ਕਮਾਂਡ ਐਗਜ਼ਿਕਿਊਸ਼ਨ ਸਫਲ ਹੁੰਦੀ ਹੈ, ਤਾਂ ਇਹ ਬਣਾਈ ਗਈ ਆਡੀਓ ਫਾਈਲ ਦੇ ਪਾਥ ਨੂੰ ਸੂਚੀ ਵਿੱਚ ਜੋੜਦਾ ਹੈ। ਸਾਰੇ ਚੰਕਸ ਨੂੰ ਪ੍ਰੋਸੈਸ ਕਰਨ ਤੋਂ ਬਾਅਦ, ਇਹ ਵਿਅਕਤੀਗਤ ਆਡੀਓ ਫਾਈਲਾਂ ਨੂੰ `merge_audio_files()` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਜੋੜਦਾ ਹੈ ਅਤੇ ਜੋੜੀ ਗਈ ਆਡੀਓ ਨੂੰ ਨਿਰਧਾਰਤ ਸੇਵ ਪਾਥ 'ਤੇ ਸੇਵ ਕਰਦਾ ਹੈ। ਜੇਕਰ ਸਿਰਫ ਇੱਕ ਚੰਕ ਹੈ, ਤਾਂ ਇਹ ਸਿੱਧੇ ਐਜ ਟੀਟੀਐਸ ਕਮਾਂਡ ਬਣਾਉਂਦਾ ਹੈ ਅਤੇ ਆਡੀਓ ਨੂੰ ਸੇਵ ਪਾਥ 'ਤੇ ਸੇਵ ਕਰਦਾ ਹੈ। ਆਖਿਰ ਵਿੱਚ, ਇਹ ਬਣਾਈ ਗਈ ਆਡੀਓ ਫਾਈਲ ਦੇ ਸੇਵ ਪਾਥ ਨੂੰ ਵਾਪਸ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "6. `random_audio_name_generate()`: ਇਹ ਫੰਕਸ਼ਨ [`uuid`] ਮੋਡੀਊਲ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਰੈਂਡਮ ਆਡੀਓ ਫਾਈਲ ਨਾਮ ਬਣਾਉਂਦਾ ਹੈ। ਇਹ ਇੱਕ ਰੈਂਡਮ UUID ਬਣਾਉਂਦਾ ਹੈ, ਇਸਨੂੰ ਸਟ੍ਰਿੰਗ ਵਿੱਚ ਬਦਲਦਾ ਹੈ, ਪਹਿਲੇ 8 ਅੱਖਰ ਲੈਂਦਾ ਹੈ, \".mp3\" ਐਕਸਟੈਂਸ਼ਨ ਜੋੜਦਾ ਹੈ, ਅਤੇ ਰੈਂਡਮ ਆਡੀਓ ਫਾਈਲ ਨਾਮ ਵਾਪਸ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "7. `talk(input_text)`: ਇਹ ਫੰਕਸ਼ਨ TTS ਕਾਰਜਵਾਹੀ ਕਰਨ ਲਈ ਮੁੱਖ ਐਂਟਰੀ ਪੌਇੰਟ ਹੈ। ਇਹ ਇੱਕ ਇਨਪੁਟ ਟੈਕਸਟ ਨੂੰ ਪੈਰਾਮੀਟਰ ਵਜੋਂ ਲੈਂਦਾ ਹੈ। ਇਹ ਪਹਿਲਾਂ ਇਨਪੁਟ ਟੈਕਸਟ ਦੀ ਲੰਬਾਈ ਦੀ ਜਾਂਚ ਕਰਦਾ ਹੈ ਤਾਂ ਜੋ ਇਹ ਨਿਰਧਾਰਤ ਕਰ ਸਕੇ ਕਿ ਕੀ ਇਹ ਲੰਬਾ ਵਾਕ ਹੈ (600 ਅੱਖਰਾਂ ਤੋਂ ਵੱਧ ਜਾਂ ਬਰਾਬਰ)। ਲੰਬਾਈ ਅਤੇ `translate_text_flag` ਵੈਰੀਏਬਲ ਦੀ ਮੁੱਲ ਦੇ ਅਧਾਰ 'ਤੇ, ਇਹ ਭਾਸ਼ਾ ਨਿਰਧਾਰਤ ਕਰਦਾ ਹੈ ਅਤੇ `make_chunks()` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਟੈਕਸਟ ਚੰਕਸ ਦੀ ਸੂਚੀ ਬਣਾਉਂਦਾ ਹੈ। ਫਿਰ ਇਹ `random_audio_name_generate()` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਆਡੀਓ ਫਾਈਲ ਲਈ ਸੇਵ ਪਾਥ ਬਣਾਉਂਦਾ ਹੈ। ਆਖਿਰ ਵਿੱਚ, ਇਹ TTS ਕਾਰਜਵਾਹੀ ਕਰਨ ਲਈ `edge_free_tts()` ਫੰਕਸ਼ਨ ਨੂੰ ਕਾਲ ਕਰਦਾ ਹੈ ਅਤੇ ਬਣਾਈ ਗਈ ਆਡੀਓ ਫਾਈਲ ਦੇ ਸੇਵ ਪਾਥ ਨੂੰ ਵਾਪਸ ਕਰਦਾ ਹੈ।\n",
    "\n",
    "ਸਮੁੱਚੇ ਤੌਰ 'ਤੇ, ਇਹ ਫੰਕਸ਼ਨ ਇਨਪੁਟ ਟੈਕਸਟ ਨੂੰ ਚੰਕਸ ਵਿੱਚ ਵੰਡਣ, ਆਡੀਓ ਫਾਈਲ ਲਈ ਫਾਈਲ ਨਾਮ ਬਣਾਉਣ, ਐਜ ਟੀਟੀਐਸ ਸੇਵਾ ਦੀ ਵਰਤੋਂ ਕਰਕੇ TTS ਕਾਰਜਵਾਹੀ ਕਰਨ, ਅਤੇ ਵਿਅਕਤੀਗਤ ਆਡੀਓ ਫਾਈਲਾਂ ਨੂੰ ਇੱਕ ਆਡੀਓ ਫਾਈਲ ਵਿੱਚ ਜੋੜਨ ਲਈ ਕੰਮ ਕਰਦੇ ਹਨ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "Mv4WVhNUz4IL",
    "outputId": "7f177f73-3eb1-4d7c-d5e9-1e7cabe32f63"
   },
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
    "    os.mkdir(\"/content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path\n",
    "\n",
    "# text = \"This is Microsoft Phi 3 mini 4k instruct Demo\" Simply update the text variable with the text you want to convert to speech\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "    # voice_name=\"en-US-AriaNeural\"\n",
    "\n",
    "\n",
    "if translate_text_flag:\n",
    "  input_text=text\n",
    "  # input_text=translate_text(text, Language)\n",
    "  # print(\"Translateting\")\n",
    "else:\n",
    "  input_text=text\n",
    "if long_sentence==True and translate_text_flag==True:\n",
    "  chunks_list=make_chunks(input_text,Language)\n",
    "elif long_sentence==True and translate_text_flag==False:\n",
    "  chunks_list=make_chunks(input_text,\"English\")\n",
    "else:\n",
    "  chunks_list=[input_text]\n",
    "# print(chunks_list)\n",
    "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "# from IPython.display import Audio\n",
    "# Audio(edge_save_path, autoplay=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "if not os.path.exists(\"/content/audio\"):\n",
    "    os.mkdir(\"/content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path\n",
    "\n",
    "\n",
    "edge_save_path=talk(text)\n",
    "Audio(edge_save_path, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਦੋ ਫੰਕਸ਼ਨਾਂ: convert_to_text ਅਤੇ run_text_prompt ਦੀ ਕਾਰਗੁਜ਼ਾਰੀ, ਅਤੇ ਦੋ ਕਲਾਸਾਂ: str ਅਤੇ Audio ਦੀ ਘੋਸ਼ਣਾ।\n",
    "\n",
    "convert_to_text ਫੰਕਸ਼ਨ audio_path ਨੂੰ ਇਨਪੁਟ ਵਜੋਂ ਲੈਂਦਾ ਹੈ ਅਤੇ ਇੱਕ ਮਾਡਲ ਜਿਸਨੂੰ whisper_model ਕਿਹਾ ਜਾਂਦਾ ਹੈ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਆਡੀਓ ਨੂੰ ਟੈਕਸਟ ਵਿੱਚ ਟ੍ਰਾਂਸਕ੍ਰਾਈਬ ਕਰਦਾ ਹੈ। ਫੰਕਸ਼ਨ ਪਹਿਲਾਂ ਜਾਂਚਦਾ ਹੈ ਕਿ gpu ਫਲੈਗ True ਹੈ ਜਾਂ ਨਹੀਂ। ਜੇ ਇਹ True ਹੈ, ਤਾਂ whisper_model ਨੂੰ ਕੁਝ ਪੈਰਾਮੀਟਰਾਂ ਨਾਲ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ ਜਿਵੇਂ ਕਿ word_timestamps=True, fp16=True, language='English', ਅਤੇ task='translate'। ਜੇ gpu ਫਲੈਗ False ਹੈ, ਤਾਂ whisper_model ਨੂੰ fp16=False ਨਾਲ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ। ਨਤੀਜੇ ਵਜੋਂ ਟ੍ਰਾਂਸਕ੍ਰਿਪਸ਼ਨ ਨੂੰ 'scan.txt' ਨਾਮਕ ਫਾਈਲ ਵਿੱਚ ਸੇਵ ਕੀਤਾ ਜਾਂਦਾ ਹੈ ਅਤੇ ਟੈਕਸਟ ਵਜੋਂ ਵਾਪਸ ਕੀਤਾ ਜਾਂਦਾ ਹੈ।\n",
    "\n",
    "run_text_prompt ਫੰਕਸ਼ਨ ਇੱਕ message ਅਤੇ chat_history ਨੂੰ ਇਨਪੁਟ ਵਜੋਂ ਲੈਂਦਾ ਹੈ। ਇਹ phi_demo ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇਨਪੁਟ message ਦੇ ਆਧਾਰ 'ਤੇ ਇੱਕ ਚੈਟਬੋਟ ਤੋਂ ਜਵਾਬ ਤਿਆਰ ਕਰਦਾ ਹੈ। ਤਿਆਰ ਕੀਤਾ ਗਿਆ ਜਵਾਬ talk ਫੰਕਸ਼ਨ ਨੂੰ ਪਾਸ ਕੀਤਾ ਜਾਂਦਾ ਹੈ, ਜੋ ਜਵਾਬ ਨੂੰ ਇੱਕ ਆਡੀਓ ਫਾਈਲ ਵਿੱਚ ਬਦਲਦਾ ਹੈ ਅਤੇ ਫਾਈਲ ਪਾਥ ਵਾਪਸ ਕਰਦਾ ਹੈ। Audio ਕਲਾਸ ਆਡੀਓ ਫਾਈਲ ਨੂੰ ਦਿਖਾਉਣ ਅਤੇ ਚਲਾਉਣ ਲਈ ਵਰਤੀ ਜਾਂਦੀ ਹੈ। ਆਡੀਓ ਨੂੰ IPython.display ਮੋਡਿਊਲ ਦੇ display ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਦਿਖਾਇਆ ਜਾਂਦਾ ਹੈ, ਅਤੇ Audio ਆਬਜੈਕਟ autoplay=True ਪੈਰਾਮੀਟਰ ਨਾਲ ਬਣਾਇਆ ਜਾਂਦਾ ਹੈ, ਤਾਂ ਜੋ ਆਡੀਓ ਆਪਣੇ ਆਪ ਚਲਣਾ ਸ਼ੁਰੂ ਕਰ ਦੇਵੇ। chat_history ਨੂੰ ਇਨਪੁਟ message ਅਤੇ ਤਿਆਰ ਕੀਤੇ ਜਵਾਬ ਨਾਲ ਅਪਡੇਟ ਕੀਤਾ ਜਾਂਦਾ ਹੈ, ਅਤੇ ਇੱਕ ਖਾਲੀ ਸਤਰ ਅਤੇ ਅਪਡੇਟ ਕੀਤਾ chat_history ਵਾਪਸ ਕੀਤਾ ਜਾਂਦਾ ਹੈ।\n",
    "\n",
    "str ਕਲਾਸ ਪਾਇਥਨ ਵਿੱਚ ਇੱਕ ਬਿਲਟ-ਇਨ ਕਲਾਸ ਹੈ ਜੋ ਅੱਖਰਾਂ ਦੀ ਲੜੀ ਨੂੰ ਦਰਸਾਉਂਦੀ ਹੈ। ਇਹ ਸਟ੍ਰਿੰਗਾਂ ਨਾਲ ਕੰਮ ਕਰਨ ਅਤੇ ਉਨ੍ਹਾਂ ਨੂੰ ਮੋੜਨ ਲਈ ਵੱਖ-ਵੱਖ ਮੈਥਡਾਂ ਪ੍ਰਦਾਨ ਕਰਦੀ ਹੈ, ਜਿਵੇਂ ਕਿ capitalize, casefold, center, count, encode, endswith, expandtabs, find, format, index, isalnum, isalpha, isascii, isdecimal, isdigit, isidentifier, islower, isnumeric, isprintable, isspace, istitle, isupper, join, ljust, lower, lstrip, partition, replace, removeprefix, removesuffix, rfind, rindex, rjust, rpartition, rsplit, rstrip, split, splitlines, startswith, strip, swapcase, title, translate, upper, zfill, ਅਤੇ ਹੋਰ। ਇਹ ਮੈਥਡਾਂ ਤੁਹਾਨੂੰ ਖੋਜ, ਬਦਲਾਅ, ਫਾਰਮੈਟਿੰਗ, ਅਤੇ ਸਟ੍ਰਿੰਗਾਂ ਨੂੰ ਮੋੜਨ ਵਰਗੇ ਕੰਮ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦੇ ਹਨ।\n",
    "\n",
    "Audio ਕਲਾਸ ਇੱਕ ਕਸਟਮ ਕਲਾਸ ਹੈ ਜੋ ਇੱਕ ਆਡੀਓ ਆਬਜੈਕਟ ਨੂੰ ਦਰਸਾਉਂਦੀ ਹੈ। ਇਹ Jupyter Notebook ਵਾਤਾਵਰਣ ਵਿੱਚ ਇੱਕ ਆਡੀਓ ਪਲੇਅਰ ਬਣਾਉਣ ਲਈ ਵਰਤੀ ਜਾਂਦੀ ਹੈ। ਕਲਾਸ ਵੱਖ-ਵੱਖ ਪੈਰਾਮੀਟਰਾਂ ਨੂੰ ਸਵੀਕਾਰ ਕਰਦੀ ਹੈ ਜਿਵੇਂ ਕਿ data, filename, url, embed, rate, autoplay, ਅਤੇ normalize। data ਪੈਰਾਮੀਟਰ numpy array, ਸੈਂਪਲਾਂ ਦੀ ਸੂਚੀ, filename ਜਾਂ URL ਨੂੰ ਦਰਸਾਉਣ ਵਾਲੀ ਸਟ੍ਰਿੰਗ, ਜਾਂ raw PCM ਡਾਟਾ ਹੋ ਸਕਦਾ ਹੈ। filename ਪੈਰਾਮੀਟਰ ਨੂੰ ਆਡੀਓ ਡਾਟਾ ਨੂੰ ਲੋਡ ਕਰਨ ਲਈ ਇੱਕ ਸਥਾਨਕ ਫਾਈਲ ਨੂੰ ਦਰਸਾਉਣ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ, ਅਤੇ url ਪੈਰਾਮੀਟਰ ਨੂੰ ਆਡੀਓ ਡਾਟਾ ਨੂੰ ਡਾਊਨਲੋਡ ਕਰਨ ਲਈ ਇੱਕ URL ਨੂੰ ਦਰਸਾਉਣ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ। embed ਪੈਰਾਮੀਟਰ ਇਹ ਨਿਰਧਾਰਤ ਕਰਦਾ ਹੈ ਕਿ ਆਡੀਓ ਡਾਟਾ ਨੂੰ data URI ਦੀ ਵਰਤੋਂ ਕਰਕੇ embed ਕੀਤਾ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ ਜਾਂ ਮੂਲ ਸਰੋਤ ਤੋਂ ਰਿਫਰੈਂਸ ਕੀਤਾ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। rate ਪੈਰਾਮੀਟਰ ਆਡੀਓ ਡਾਟਾ ਦੀ ਸੈਂਪਲਿੰਗ ਦਰ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ। autoplay ਪੈਰਾਮੀਟਰ ਇਹ ਨਿਰਧਾਰਤ ਕਰਦਾ ਹੈ ਕਿ ਆਡੀਓ ਆਪਣੇ ਆਪ ਚਲਣਾ ਸ਼ੁਰੂ ਕਰੇ। normalize ਪੈਰਾਮੀਟਰ ਇਹ ਨਿਰਧਾਰਤ ਕਰਦਾ ਹੈ ਕਿ ਆਡੀਓ ਡਾਟਾ ਨੂੰ ਵੱਧ ਤੋਂ ਵੱਧ ਸੰਭਾਵਿਤ ਰੇਂਜ ਵਿੱਚ rescale ਕੀਤਾ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। Audio ਕਲਾਸ reload ਵਰਗੇ ਮੈਥਡਾਂ ਪ੍ਰਦਾਨ ਕਰਦੀ ਹੈ ਜੋ ਫਾਈਲ ਜਾਂ URL ਤੋਂ ਆਡੀਓ ਡਾਟਾ ਨੂੰ ਮੁੜ ਲੋਡ ਕਰਨ ਲਈ ਵਰਤੇ ਜਾਂਦੇ ਹਨ, ਅਤੇ src_attr, autoplay_attr, ਅਤੇ element_id_attr ਵਰਗੇ ਗੁਣ ਜੋ HTML ਵਿੱਚ ਆਡੀਓ ਐਲਿਮੈਂਟ ਲਈ ਸੰਬੰਧਿਤ ਗੁਣਾਂ ਨੂੰ ਪ੍ਰਾਪਤ ਕਰਨ ਲਈ ਵਰਤੇ ਜਾਂਦੇ ਹਨ।\n",
    "\n",
    "ਕੁੱਲ ਮਿਲਾ ਕੇ, ਇਹ ਫੰਕਸ਼ਨ ਅਤੇ ਕਲਾਸਾਂ ਆਡੀਓ ਨੂੰ ਟੈਕਸਟ ਵਿੱਚ ਟ੍ਰਾਂਸਕ੍ਰਾਈਬ ਕਰਨ, ਚੈਟਬੋਟ ਤੋਂ ਆਡੀਓ ਜਵਾਬ ਤਿਆਰ ਕਰਨ, ਅਤੇ Jupyter Notebook ਵਾਤਾਵਰਣ ਵਿੱਚ ਆਡੀਓ ਨੂੰ ਦਿਖਾਉਣ ਅਤੇ ਚਲਾਉਣ ਲਈ ਵਰਤੇ ਜਾਂਦੇ ਹਨ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e6aTA6mk7Gi",
    "outputId": "4c4825c9-f1ef-4d9e-d294-83d67248e073"
   },
   "outputs": [],
   "source": [
    "#@title Run gradio app\n",
    "def convert_to_text(audio_path):\n",
    "  gpu=True\n",
    "  if gpu:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=True,language='English',task='translate')\n",
    "  else:\n",
    "    result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ਅਸਵੀਕਰਤੀ**:  \nਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀ ਹੋਣ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚਤਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤ ਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "751cbc4b70dda9c27b60003cc36ce794",
   "translation_date": "2025-09-12T19:56:24+00:00",
   "source_file": "code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb",
   "language_code": "pa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}